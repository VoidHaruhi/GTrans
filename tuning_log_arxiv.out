/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.18it/s]100%|██████████| 1/1 [00:00<00:00,  3.00it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6706709265708923
Epoch 1: -0.6706709265708923
Mem used: -900MB
best_loss: tensor(-0.8105, device='cuda:1')
best_loss: tensor(-0.8137, device='cuda:1')
final loss: -0.7651175856590271
Test:
Test: 0.44052436351374136
0.44052436351374136
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
=== training GCN model ===
Epoch 0, training loss: 4.0121660232543945
Epoch 10, training loss: 2.36460542678833
Epoch 20, training loss: 1.9979748725891113
Epoch 30, training loss: 1.772011160850525
Epoch 40, training loss: 1.6276665925979614
Epoch 50, training loss: 1.5150115489959717
Epoch 60, training loss: 1.4229167699813843
Epoch 70, training loss: 1.343504786491394
Epoch 80, training loss: 1.2742658853530884
Epoch 90, training loss: 1.2125799655914307
Epoch 100, training loss: 1.1631991863250732
Epoch 110, training loss: 1.1147079467773438
Epoch 120, training loss: 1.0772078037261963
Epoch 130, training loss: 1.0434703826904297
Epoch 140, training loss: 1.010069489479065
Epoch 150, training loss: 0.9817137122154236
Epoch 160, training loss: 0.9602154493331909
Epoch 170, training loss: 0.9410904049873352
Epoch 180, training loss: 0.925563395023346
Epoch 190, training loss: 0.9128358364105225
Epoch 200, training loss: 0.8931244611740112
Epoch 210, training loss: 0.8771737217903137
Epoch 220, training loss: 0.8633456826210022
Epoch 230, training loss: 0.8578150868415833
Epoch 240, training loss: 0.8401822447776794
Epoch 250, training loss: 0.8322126269340515
Epoch 260, training loss: 0.8230005502700806
Epoch 270, training loss: 0.809624433517456
Epoch 280, training loss: 0.8028728365898132
Epoch 290, training loss: 0.7958523631095886
Epoch 300, training loss: 0.7912868857383728
Epoch 310, training loss: 0.7784521579742432
Epoch 320, training loss: 0.7745019793510437
Epoch 330, training loss: 0.7694727182388306
Epoch 340, training loss: 0.7653841972351074
Epoch 350, training loss: 0.7593004107475281
Epoch 360, training loss: 0.7498542070388794
Epoch 370, training loss: 0.7495704293251038
Epoch 380, training loss: 0.7409683465957642
Epoch 390, training loss: 0.7372440099716187
Epoch 400, training loss: 0.7302833795547485
Epoch 410, training loss: 0.7255547046661377
Epoch 420, training loss: 0.7204437255859375
Epoch 430, training loss: 0.7275078296661377
Epoch 440, training loss: 0.7124091982841492
Epoch 450, training loss: 0.7130817770957947
Epoch 460, training loss: 0.7118390798568726
Epoch 470, training loss: 0.7083471417427063
Epoch 480, training loss: 0.6996414661407471
Epoch 490, training loss: 0.7065222859382629
=== early stopping at 499, acc_val = 0.4542657224751307 ===
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.99it/s]100%|██████████| 1/1 [00:00<00:00,  3.98it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6068490147590637
Epoch 0, Loop Adj 0: -0.6695926189422607
Epoch 1: -0.6695926189422607
Mem used: -694MB
best_loss: tensor(-0.8002, device='cuda:1')
best_loss: tensor(-0.8019, device='cuda:1')
final loss: -0.7601146697998047
Test:
Test: 0.4419153599730231
0.4419153599730231
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
=== training GCN model ===
Epoch 0, training loss: 4.20035982131958
Epoch 10, training loss: 2.3692636489868164
Epoch 20, training loss: 1.9954171180725098
Epoch 30, training loss: 1.7866623401641846
Epoch 40, training loss: 1.6437877416610718
Epoch 50, training loss: 1.5346260070800781
Epoch 60, training loss: 1.4445960521697998
Epoch 70, training loss: 1.3658689260482788
Epoch 80, training loss: 1.295694351196289
Epoch 90, training loss: 1.2330650091171265
Epoch 100, training loss: 1.177855134010315
Epoch 110, training loss: 1.1277954578399658
Epoch 120, training loss: 1.0859713554382324
Epoch 130, training loss: 1.0495716333389282
Epoch 140, training loss: 1.0142545700073242
Epoch 150, training loss: 0.9879936575889587
Epoch 160, training loss: 0.9618931412696838
Epoch 170, training loss: 0.9387657046318054
Epoch 180, training loss: 0.924903392791748
Epoch 190, training loss: 0.9029343724250793
Epoch 200, training loss: 0.8929274678230286
Epoch 210, training loss: 0.8735580444335938
Epoch 220, training loss: 0.8644747138023376
Epoch 230, training loss: 0.8517771363258362
Epoch 240, training loss: 0.8389356732368469
Epoch 250, training loss: 0.8350170254707336
Epoch 260, training loss: 0.8198338150978088
Epoch 270, training loss: 0.8113501667976379
Epoch 280, training loss: 0.8067922592163086
Epoch 290, training loss: 0.7971930503845215
Epoch 300, training loss: 0.7862957715988159
Epoch 310, training loss: 0.7787752151489258
Epoch 320, training loss: 0.7696512341499329
Epoch 330, training loss: 0.7639200687408447
Epoch 340, training loss: 0.7595176100730896
Epoch 350, training loss: 0.7537296414375305
Epoch 360, training loss: 0.7441434264183044
Epoch 370, training loss: 0.7420044541358948
Epoch 380, training loss: 0.7391167283058167
Epoch 390, training loss: 0.7312642931938171
Epoch 400, training loss: 0.7357025146484375
Epoch 410, training loss: 0.722807765007019
Epoch 420, training loss: 0.7243161201477051
Epoch 430, training loss: 0.7161824107170105
Epoch 440, training loss: 0.714145839214325
Epoch 450, training loss: 0.7152872681617737
Epoch 460, training loss: 0.7093674540519714
Epoch 470, training loss: 0.7007008790969849
Epoch 480, training loss: 0.6971564888954163
Epoch 490, training loss: 0.703275740146637
=== early stopping at 499, acc_val = 0.4516944865958523 ===
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.09it/s]100%|██████████| 1/1 [00:00<00:00,  2.95it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5851351022720337
Epoch 0, Loop Adj 0: -0.6439412832260132
Epoch 1: -0.6439412832260132
Mem used: -1026MB
best_loss: tensor(-0.7797, device='cuda:1')
best_loss: tensor(-0.7815, device='cuda:1')
final loss: -0.7407020330429077
Test:
Test: 0.4426740853144495
0.4426740853144495
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
=== training GCN model ===
Epoch 0, training loss: 4.067350387573242
Epoch 10, training loss: 2.405161142349243
Epoch 20, training loss: 1.9816009998321533
Epoch 30, training loss: 1.7628729343414307
Epoch 40, training loss: 1.6110024452209473
Epoch 50, training loss: 1.496898889541626
Epoch 60, training loss: 1.4072730541229248
Epoch 70, training loss: 1.3321170806884766
Epoch 80, training loss: 1.266655683517456
Epoch 90, training loss: 1.2061182260513306
Epoch 100, training loss: 1.1538408994674683
Epoch 110, training loss: 1.106522560119629
Epoch 120, training loss: 1.0686471462249756
Epoch 130, training loss: 1.035239338874817
Epoch 140, training loss: 1.010806679725647
Epoch 150, training loss: 0.9865168333053589
Epoch 160, training loss: 0.9588744044303894
Epoch 170, training loss: 0.9385764598846436
Epoch 180, training loss: 0.9251657724380493
Epoch 190, training loss: 0.9030451774597168
Epoch 200, training loss: 0.8865699172019958
Epoch 210, training loss: 0.8732122778892517
Epoch 220, training loss: 0.862352192401886
Epoch 230, training loss: 0.85194993019104
Epoch 240, training loss: 0.8386344909667969
Epoch 250, training loss: 0.8274158239364624
Epoch 260, training loss: 0.816353440284729
Epoch 270, training loss: 0.8077479004859924
Epoch 280, training loss: 0.7970097064971924
Epoch 290, training loss: 0.79417884349823
Epoch 300, training loss: 0.784787118434906
Epoch 310, training loss: 0.7734984755516052
Epoch 320, training loss: 0.7739322781562805
Epoch 330, training loss: 0.7604467868804932
Epoch 340, training loss: 0.7529051899909973
Epoch 350, training loss: 0.7538555860519409
Epoch 360, training loss: 0.7463687062263489
Epoch 370, training loss: 0.7458358407020569
Epoch 380, training loss: 0.7383808493614197
Epoch 390, training loss: 0.7297462821006775
Epoch 400, training loss: 0.728117048740387
Epoch 410, training loss: 0.7205049395561218
Epoch 420, training loss: 0.7218338251113892
Epoch 430, training loss: 0.7161071300506592
Epoch 440, training loss: 0.711889922618866
Epoch 450, training loss: 0.7080766558647156
Epoch 460, training loss: 0.7026548385620117
Epoch 470, training loss: 0.6992861032485962
Epoch 480, training loss: 0.6994612216949463
Epoch 490, training loss: 0.6896966099739075
=== early stopping at 499, acc_val = 0.45999831394368573 ===
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.28it/s]100%|██████████| 1/1 [00:00<00:00,  3.27it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5971710085868835
Epoch 0, Loop Adj 0: -0.6655998229980469
Epoch 1: -0.6655998229980469
Mem used: -686MB
best_loss: tensor(-0.8035, device='cuda:1')
best_loss: tensor(-0.8050, device='cuda:1')
final loss: -0.7643916010856628
Test:
Test: 0.43786882481874895
0.43786882481874895
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
=== training GCN model ===
Epoch 0, training loss: 3.8932838439941406
Epoch 10, training loss: 2.3119335174560547
Epoch 20, training loss: 1.943930745124817
Epoch 30, training loss: 1.7267893552780151
Epoch 40, training loss: 1.5660744905471802
Epoch 50, training loss: 1.4494962692260742
Epoch 60, training loss: 1.3529032468795776
Epoch 70, training loss: 1.2708065509796143
Epoch 80, training loss: 1.2004331350326538
Epoch 90, training loss: 1.1435166597366333
Epoch 100, training loss: 1.0931302309036255
Epoch 110, training loss: 1.051181674003601
Epoch 120, training loss: 1.0120506286621094
Epoch 130, training loss: 0.9829539060592651
Epoch 140, training loss: 0.9532983303070068
Epoch 150, training loss: 0.9294177293777466
Epoch 160, training loss: 0.9085792899131775
Epoch 170, training loss: 0.8866956233978271
Epoch 180, training loss: 0.8713139891624451
Epoch 190, training loss: 0.8581234812736511
Epoch 200, training loss: 0.840915858745575
Epoch 210, training loss: 0.8298656940460205
Epoch 220, training loss: 0.8178713321685791
Epoch 230, training loss: 0.8099482655525208
Epoch 240, training loss: 0.8000673055648804
Epoch 250, training loss: 0.789894700050354
Epoch 260, training loss: 0.7817761898040771
Epoch 270, training loss: 0.7787966728210449
Epoch 280, training loss: 0.7594305276870728
Epoch 290, training loss: 0.759046733379364
Epoch 300, training loss: 0.7460689544677734
Epoch 310, training loss: 0.740218997001648
Epoch 320, training loss: 0.7391526699066162
Epoch 330, training loss: 0.7332209348678589
Epoch 340, training loss: 0.7237803339958191
Epoch 350, training loss: 0.7189942598342896
Epoch 360, training loss: 0.7232688665390015
Epoch 370, training loss: 0.7042463421821594
Epoch 380, training loss: 0.7086082696914673
Epoch 390, training loss: 0.7067456245422363
Epoch 400, training loss: 0.6958450675010681
Epoch 410, training loss: 0.6905165314674377
Epoch 420, training loss: 0.6821383833885193
Epoch 430, training loss: 0.6864547729492188
Epoch 440, training loss: 0.6776095032691956
Epoch 450, training loss: 0.6715184450149536
Epoch 460, training loss: 0.6697028875350952
Epoch 470, training loss: 0.669741153717041
Epoch 480, training loss: 0.6698369383811951
Epoch 490, training loss: 0.662537157535553
=== early stopping at 499, acc_val = 0.45139942674085315 ===
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.88it/s]100%|██████████| 1/1 [00:00<00:00,  3.87it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.596738338470459
Epoch 0, Loop Adj 0: -0.6713169813156128
Epoch 1: -0.6713169813156128
Mem used: -692MB
best_loss: tensor(-0.8004, device='cuda:1')
final loss: -0.7607682347297668
Test:
Test: 0.4424633282751644
0.4424633282751644
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
=== training GCN model ===
Epoch 0, training loss: 3.813610792160034
Epoch 10, training loss: 2.3022329807281494
Epoch 20, training loss: 1.9890776872634888
Epoch 30, training loss: 1.7902448177337646
Epoch 40, training loss: 1.6384992599487305
Epoch 50, training loss: 1.5208086967468262
Epoch 60, training loss: 1.4235128164291382
Epoch 70, training loss: 1.3421705961227417
Epoch 80, training loss: 1.2724215984344482
Epoch 90, training loss: 1.207931637763977
Epoch 100, training loss: 1.1510872840881348
Epoch 110, training loss: 1.1034431457519531
Epoch 120, training loss: 1.0587447881698608
Epoch 130, training loss: 1.0231126546859741
Epoch 140, training loss: 0.988853931427002
Epoch 150, training loss: 0.9623026847839355
Epoch 160, training loss: 0.939642608165741
Epoch 170, training loss: 0.9173303842544556
Epoch 180, training loss: 0.9001935720443726
Epoch 190, training loss: 0.8862150311470032
Epoch 200, training loss: 0.8663352727890015
Epoch 210, training loss: 0.8526692986488342
Epoch 220, training loss: 0.8429403901100159
Epoch 230, training loss: 0.8272983431816101
Epoch 240, training loss: 0.8194275498390198
Epoch 250, training loss: 0.8067649006843567
Epoch 260, training loss: 0.8025584816932678
Epoch 270, training loss: 0.7853400707244873
Epoch 280, training loss: 0.7825051546096802
Epoch 290, training loss: 0.7722165584564209
Epoch 300, training loss: 0.7618211507797241
Epoch 310, training loss: 0.7584994435310364
Epoch 320, training loss: 0.7482843995094299
Epoch 330, training loss: 0.7425667643547058
Epoch 340, training loss: 0.7365666031837463
Epoch 350, training loss: 0.7292295098304749
Epoch 360, training loss: 0.7238912582397461
Epoch 370, training loss: 0.7221977114677429
Epoch 380, training loss: 0.7217430472373962
Epoch 390, training loss: 0.7074291706085205
Epoch 400, training loss: 0.7039809823036194
Epoch 410, training loss: 0.7050424218177795
Epoch 420, training loss: 0.7004919052124023
Epoch 430, training loss: 0.6923072934150696
Epoch 440, training loss: 0.6938913464546204
Epoch 450, training loss: 0.6820529699325562
Epoch 460, training loss: 0.6860437393188477
Epoch 470, training loss: 0.6791093945503235
Epoch 480, training loss: 0.6755757331848145
Epoch 490, training loss: 0.6726675033569336
=== early stopping at 499, acc_val = 0.4513151239251391 ===
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.50it/s]100%|██████████| 1/1 [00:00<00:00,  2.50it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5958998799324036
Epoch 0, Loop Adj 0: -0.6566439867019653
Epoch 1: -0.6566439867019653
Mem used: -760MB
best_loss: tensor(-0.8012, device='cuda:1')
best_loss: tensor(-0.8033, device='cuda:1')
final loss: -0.7601454257965088
Test:
Test: 0.4272045186309223
0.4272045186309223
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
=== training GCN model ===
Epoch 0, training loss: 4.0485429763793945
Epoch 10, training loss: 2.3810300827026367
Epoch 20, training loss: 1.9600452184677124
Epoch 30, training loss: 1.7569366693496704
Epoch 40, training loss: 1.609067440032959
Epoch 50, training loss: 1.4932585954666138
Epoch 60, training loss: 1.3959100246429443
Epoch 70, training loss: 1.3112819194793701
Epoch 80, training loss: 1.2392627000808716
Epoch 90, training loss: 1.1786444187164307
Epoch 100, training loss: 1.1278839111328125
Epoch 110, training loss: 1.0829381942749023
Epoch 120, training loss: 1.0450550317764282
Epoch 130, training loss: 1.009606957435608
Epoch 140, training loss: 0.9835315942764282
Epoch 150, training loss: 0.9587885141372681
Epoch 160, training loss: 0.9350950717926025
Epoch 170, training loss: 0.913540780544281
Epoch 180, training loss: 0.8983938097953796
Epoch 190, training loss: 0.8797659873962402
Epoch 200, training loss: 0.8632915616035461
Epoch 210, training loss: 0.853457510471344
Epoch 220, training loss: 0.8343089818954468
Epoch 230, training loss: 0.8227466940879822
Epoch 240, training loss: 0.8157934546470642
Epoch 250, training loss: 0.802386462688446
Epoch 260, training loss: 0.7933825850486755
Epoch 270, training loss: 0.7842114567756653
Epoch 280, training loss: 0.7747713327407837
Epoch 290, training loss: 0.7735373377799988
Epoch 300, training loss: 0.7593181133270264
Epoch 310, training loss: 0.7506983876228333
Epoch 320, training loss: 0.742562472820282
Epoch 330, training loss: 0.7393395900726318
Epoch 340, training loss: 0.7323464155197144
Epoch 350, training loss: 0.7258731126785278
Epoch 360, training loss: 0.7323397994041443
Epoch 370, training loss: 0.7162054181098938
Epoch 380, training loss: 0.7189310193061829
Epoch 390, training loss: 0.7053982615470886
Epoch 400, training loss: 0.7025972604751587
Epoch 410, training loss: 0.7014972567558289
Epoch 420, training loss: 0.701235830783844
Epoch 430, training loss: 0.6909623146057129
Epoch 440, training loss: 0.6897489428520203
Epoch 450, training loss: 0.6906547546386719
Epoch 460, training loss: 0.6835126280784607
Epoch 470, training loss: 0.6824433207511902
Epoch 480, training loss: 0.6777447462081909
Epoch 490, training loss: 0.6693155169487
=== early stopping at 499, acc_val = 0.4458354409037262 ===
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.10it/s]100%|██████████| 1/1 [00:00<00:00,  2.09it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.56541907787323
Epoch 0, Loop Adj 0: -0.6460601091384888
Epoch 1: -0.6460601091384888
Mem used: -2879MB
best_loss: tensor(-0.7829, device='cuda:1')
best_loss: tensor(-0.7857, device='cuda:1')
final loss: -0.7459223866462708
Test:
Test: 0.4277946383409206
0.4277946383409206
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
=== training GCN model ===
Epoch 0, training loss: 4.007125377655029
Epoch 10, training loss: 2.3489811420440674
Epoch 20, training loss: 1.993022084236145
Epoch 30, training loss: 1.7692673206329346
Epoch 40, training loss: 1.6127982139587402
Epoch 50, training loss: 1.5025185346603394
Epoch 60, training loss: 1.4117755889892578
Epoch 70, training loss: 1.3332722187042236
Epoch 80, training loss: 1.2646987438201904
Epoch 90, training loss: 1.2023017406463623
Epoch 100, training loss: 1.1484934091567993
Epoch 110, training loss: 1.1016558408737183
Epoch 120, training loss: 1.0635138750076294
Epoch 130, training loss: 1.0254566669464111
Epoch 140, training loss: 1.001036286354065
Epoch 150, training loss: 0.9667617678642273
Epoch 160, training loss: 0.9425026178359985
Epoch 170, training loss: 0.9245980978012085
Epoch 180, training loss: 0.9038410782814026
Epoch 190, training loss: 0.8867349624633789
Epoch 200, training loss: 0.8713842034339905
Epoch 210, training loss: 0.8549442291259766
Epoch 220, training loss: 0.8454426527023315
Epoch 230, training loss: 0.8336898684501648
Epoch 240, training loss: 0.8233432769775391
Epoch 250, training loss: 0.8088399171829224
Epoch 260, training loss: 0.8066121935844421
Epoch 270, training loss: 0.7940182089805603
Epoch 280, training loss: 0.7855437397956848
Epoch 290, training loss: 0.7836190462112427
Epoch 300, training loss: 0.7706844806671143
Epoch 310, training loss: 0.7719448208808899
Epoch 320, training loss: 0.7621175646781921
Epoch 330, training loss: 0.7535035610198975
Epoch 340, training loss: 0.7432048916816711
Epoch 350, training loss: 0.7381584644317627
Epoch 360, training loss: 0.7307597398757935
Epoch 370, training loss: 0.724014401435852
Epoch 380, training loss: 0.720339834690094
Epoch 390, training loss: 0.7143049240112305
Epoch 400, training loss: 0.707592248916626
Epoch 410, training loss: 0.7109999060630798
Epoch 420, training loss: 0.6988378167152405
Epoch 430, training loss: 0.6971213817596436
Epoch 440, training loss: 0.6991121172904968
Epoch 450, training loss: 0.6895838975906372
Epoch 460, training loss: 0.68736732006073
Epoch 470, training loss: 0.6853387355804443
Epoch 480, training loss: 0.6797037124633789
Epoch 490, training loss: 0.6765919327735901
=== early stopping at 499, acc_val = 0.4558253245658405 ===
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.17it/s]100%|██████████| 1/1 [00:00<00:00,  2.16it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6177235245704651
Epoch 0, Loop Adj 0: -0.6627610921859741
Epoch 1: -0.6627610921859741
Mem used: -1026MB
best_loss: tensor(-0.8046, device='cuda:1')
final loss: -0.7611690759658813
Test:
Test: 0.44048221210588434
0.44048221210588434
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
=== training GCN model ===
Epoch 0, training loss: 3.932485580444336
Epoch 10, training loss: 2.3223955631256104
Epoch 20, training loss: 2.0017805099487305
Epoch 30, training loss: 1.7787660360336304
Epoch 40, training loss: 1.621665120124817
Epoch 50, training loss: 1.5030384063720703
Epoch 60, training loss: 1.4031139612197876
Epoch 70, training loss: 1.3194102048873901
Epoch 80, training loss: 1.2479606866836548
Epoch 90, training loss: 1.1833596229553223
Epoch 100, training loss: 1.1285748481750488
Epoch 110, training loss: 1.087332844734192
Epoch 120, training loss: 1.0444276332855225
Epoch 130, training loss: 1.0159223079681396
Epoch 140, training loss: 0.9806665182113647
Epoch 150, training loss: 0.9550537467002869
Epoch 160, training loss: 0.9355549812316895
Epoch 170, training loss: 0.913246750831604
Epoch 180, training loss: 0.8955078721046448
Epoch 190, training loss: 0.8779196739196777
Epoch 200, training loss: 0.8616253137588501
Epoch 210, training loss: 0.8516610264778137
Epoch 220, training loss: 0.836440920829773
Epoch 230, training loss: 0.8283337354660034
Epoch 240, training loss: 0.8169249296188354
Epoch 250, training loss: 0.8063310980796814
Epoch 260, training loss: 0.7984243035316467
Epoch 270, training loss: 0.7855966687202454
Epoch 280, training loss: 0.7748889923095703
Epoch 290, training loss: 0.7704697251319885
Epoch 300, training loss: 0.7582815885543823
Epoch 310, training loss: 0.7508319616317749
Epoch 320, training loss: 0.7411525249481201
Epoch 330, training loss: 0.7412819266319275
Epoch 340, training loss: 0.7324426174163818
Epoch 350, training loss: 0.7305954098701477
Epoch 360, training loss: 0.7215629816055298
Epoch 370, training loss: 0.7175931930541992
Epoch 380, training loss: 0.7134921550750732
Epoch 390, training loss: 0.7074005603790283
Epoch 400, training loss: 0.7041416764259338
Epoch 410, training loss: 0.7048713564872742
Epoch 420, training loss: 0.6966752409934998
Epoch 430, training loss: 0.6894218921661377
Epoch 440, training loss: 0.6841656565666199
Epoch 450, training loss: 0.6854929327964783
Epoch 460, training loss: 0.6779762506484985
Epoch 470, training loss: 0.6791747808456421
Epoch 480, training loss: 0.6708528399467468
Epoch 490, training loss: 0.6667168140411377
=== early stopping at 499, acc_val = 0.44541392682515596 ===
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.49it/s]100%|██████████| 1/1 [00:00<00:00,  2.48it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5782843828201294
Epoch 0, Loop Adj 0: -0.6599246859550476
Epoch 1: -0.6599246859550476
Mem used: -870MB
best_loss: tensor(-0.7863, device='cuda:1')
best_loss: tensor(-0.7879, device='cuda:1')
final loss: -0.7464691400527954
Test:
Test: 0.4331478671387624
0.4331478671387624
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
=== training GCN model ===
Epoch 0, training loss: 3.7755026817321777
Epoch 10, training loss: 2.2821853160858154
Epoch 20, training loss: 1.9549989700317383
Epoch 30, training loss: 1.7501572370529175
Epoch 40, training loss: 1.5973364114761353
Epoch 50, training loss: 1.4750367403030396
Epoch 60, training loss: 1.3749078512191772
Epoch 70, training loss: 1.2926346063613892
Epoch 80, training loss: 1.2243425846099854
Epoch 90, training loss: 1.1655856370925903
Epoch 100, training loss: 1.1157622337341309
Epoch 110, training loss: 1.0739277601242065
Epoch 120, training loss: 1.0369547605514526
Epoch 130, training loss: 1.0007702112197876
Epoch 140, training loss: 0.9747007489204407
Epoch 150, training loss: 0.946417510509491
Epoch 160, training loss: 0.9267877340316772
Epoch 170, training loss: 0.9037802815437317
Epoch 180, training loss: 0.896480143070221
Epoch 190, training loss: 0.8690121173858643
Epoch 200, training loss: 0.8541344404220581
Epoch 210, training loss: 0.8470807671546936
Epoch 220, training loss: 0.8304771184921265
Epoch 230, training loss: 0.8238775134086609
Epoch 240, training loss: 0.8169562220573425
Epoch 250, training loss: 0.8011864423751831
Epoch 260, training loss: 0.7930272221565247
Epoch 270, training loss: 0.7845203280448914
Epoch 280, training loss: 0.7827327251434326
Epoch 290, training loss: 0.7871724963188171
Epoch 300, training loss: 0.7644445300102234
Epoch 310, training loss: 0.7567151784896851
Epoch 320, training loss: 0.754033625125885
Epoch 330, training loss: 0.7466232180595398
Epoch 340, training loss: 0.744102418422699
Epoch 350, training loss: 0.7389826774597168
Epoch 360, training loss: 0.7308809757232666
Epoch 370, training loss: 0.7283622026443481
Epoch 380, training loss: 0.7301744222640991
Epoch 390, training loss: 0.7200691103935242
Epoch 400, training loss: 0.7164597511291504
Epoch 410, training loss: 0.7140904068946838
Epoch 420, training loss: 0.7134511470794678
Epoch 430, training loss: 0.7046318650245667
Epoch 440, training loss: 0.6981891989707947
Epoch 450, training loss: 0.7077605128288269
Epoch 460, training loss: 0.6938254237174988
Epoch 470, training loss: 0.6943739056587219
Epoch 480, training loss: 0.6889930367469788
Epoch 490, training loss: 0.6871655583381653
=== early stopping at 499, acc_val = 0.45435002529084473 ===
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.88it/s]100%|██████████| 1/1 [00:00<00:00,  2.88it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5742571353912354
Epoch 0, Loop Adj 0: -0.6327428221702576
Epoch 1: -0.6327428221702576
Mem used: -784MB
best_loss: tensor(-0.7788, device='cuda:1')
best_loss: tensor(-0.7809, device='cuda:1')
final loss: -0.7380826473236084
Test:
Test: 0.43567695161018377
0.43567695161018377
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.37it/s]100%|██████████| 1/1 [00:00<00:00,  2.37it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6706709861755371
Epoch 1: -0.6706709861755371
Mem used: -514MB
best_loss: tensor(-0.7991, device='cuda:1')
best_loss: tensor(-0.8057, device='cuda:1')
final loss: -0.7608773708343506
Test:
Test: 0.4395548811330298
0.4395548811330298
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.08it/s]100%|██████████| 1/1 [00:00<00:00,  3.08it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6704381108283997
Epoch 1: -0.6704381108283997
Mem used: -900MB
best_loss: tensor(-0.7879, device='cuda:1')
best_loss: tensor(-0.7958, device='cuda:1')
final loss: -0.7542629241943359
Test:
Test: 0.4444444444444444
0.4444444444444444
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.31it/s]100%|██████████| 1/1 [00:00<00:00,  3.19it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.6442331075668335
Epoch 1: -0.6442331075668335
Mem used: -748MB
best_loss: tensor(-0.7674, device='cuda:1')
best_loss: tensor(-0.7763, device='cuda:1')
final loss: -0.7365593314170837
Test:
Test: 0.4447816557073006
0.4447816557073006
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  1.73it/s]100%|██████████| 1/1 [00:00<00:00,  1.72it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.665550947189331
Epoch 1: -0.665550947189331
Mem used: -598MB
best_loss: tensor(-0.7916, device='cuda:1')
best_loss: tensor(-0.7979, device='cuda:1')
final loss: -0.7595512866973877
Test:
Test: 0.4406508177373124
0.4406508177373124
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.73it/s]100%|██████████| 1/1 [00:00<00:00,  2.72it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6711763143539429
Epoch 1: -0.6711763143539429
Mem used: -900MB
best_loss: tensor(-0.7887, device='cuda:1')
best_loss: tensor(-0.7973, device='cuda:1')
final loss: -0.7583272457122803
Test:
Test: 0.4444022930365874
0.4444022930365874
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.19it/s]100%|██████████| 1/1 [00:00<00:00,  2.18it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.6571148633956909
Epoch 1: -0.6571148633956909
Mem used: -726MB
best_loss: tensor(-0.7882, device='cuda:1')
best_loss: tensor(-0.7958, device='cuda:1')
final loss: -0.7551073431968689
Test:
Test: 0.4306187826673411
0.4306187826673411
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.51it/s]100%|██████████| 1/1 [00:00<00:00,  3.50it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.6467176079750061
Epoch 1: -0.6467176079750061
Mem used: -900MB
best_loss: tensor(-0.7701, device='cuda:1')
best_loss: tensor(-0.7787, device='cuda:1')
final loss: -0.7388982176780701
Test:
Test: 0.4320519305344799
0.4320519305344799
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.27it/s]100%|██████████| 1/1 [00:00<00:00,  2.27it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6630133986473083
Epoch 1: -0.6630133986473083
Mem used: -758MB
best_loss: tensor(-0.7939, device='cuda:1')
final loss: -0.7505113482475281
Test:
Test: 0.44347496206373294
0.44347496206373294
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.51it/s]100%|██████████| 1/1 [00:00<00:00,  3.51it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.6589507460594177
Epoch 1: -0.6589507460594177
Mem used: -900MB
best_loss: tensor(-0.7755, device='cuda:1')
best_loss: tensor(-0.7827, device='cuda:1')
final loss: -0.7414661049842834
Test:
Test: 0.43487607486090035
0.43487607486090035
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.21it/s]100%|██████████| 1/1 [00:00<00:00,  3.20it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.6326050758361816
Epoch 1: -0.6326050758361816
Mem used: -728MB
best_loss: tensor(-0.7666, device='cuda:1')
best_loss: tensor(-0.7739, device='cuda:1')
final loss: -0.7328092455863953
Test:
Test: 0.43786882481874895
0.43786882481874895
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.63it/s]100%|██████████| 1/1 [00:00<00:00,  2.63it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6706709861755371
Epoch 1: -0.6706709861755371
Mem used: -680MB
best_loss: tensor(-0.8152, device='cuda:1')
best_loss: tensor(-0.8153, device='cuda:1')
final loss: -0.766745388507843
Test:
Test: 0.4395127297251728
0.4395127297251728
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.45it/s]100%|██████████| 1/1 [00:00<00:00,  3.44it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.670438289642334
Epoch 1: -0.670438289642334
Mem used: -588MB
best_loss: tensor(-0.8035, device='cuda:1')
best_loss: tensor(-0.8038, device='cuda:1')
final loss: -0.7619290351867676
Test:
Test: 0.4414516944865958
0.4414516944865958
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.32it/s]100%|██████████| 1/1 [00:00<00:00,  2.29it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.6442331075668335
Epoch 1: -0.6442331075668335
Mem used: -536MB
best_loss: tensor(-0.7836, device='cuda:1')
best_loss: tensor(-0.7839, device='cuda:1')
final loss: -0.7421251535415649
Test:
Test: 0.439892092395886
0.439892092395886
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.44it/s]100%|██████████| 1/1 [00:00<00:00,  3.44it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011685371399
Epoch 0, Loop Adj 0: -0.665550947189331
Epoch 1: -0.665550947189331
Mem used: -900MB
best_loss: tensor(-0.8078, device='cuda:1')
final loss: -0.7656160593032837
Test:
Test: 0.4376580677794638
0.4376580677794638
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.76it/s]100%|██████████| 1/1 [00:00<00:00,  2.75it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6711763143539429
Epoch 1: -0.6711763143539429
Mem used: -900MB
best_loss: tensor(-0.8055, device='cuda:1')
best_loss: tensor(-0.8058, device='cuda:1')
final loss: -0.765336275100708
Test:
Test: 0.439892092395886
0.439892092395886
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.25it/s]100%|██████████| 1/1 [00:00<00:00,  2.24it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.6571149826049805
Epoch 1: -0.6571149826049805
Mem used: -762MB
best_loss: tensor(-0.8054, device='cuda:1')
final loss: -0.7614463567733765
Test:
Test: 0.4269094587759231
0.4269094587759231
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.76it/s]100%|██████████| 1/1 [00:00<00:00,  2.76it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.6467175483703613
Epoch 1: -0.6467175483703613
Mem used: -900MB
best_loss: tensor(-0.7874, device='cuda:1')
best_loss: tensor(-0.7876, device='cuda:1')
final loss: -0.7471469640731812
Test:
Test: 0.4269094587759231
0.4269094587759231
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.82it/s]100%|██████████| 1/1 [00:00<00:00,  3.75it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6630133986473083
Epoch 1: -0.6630133986473083
Mem used: -900MB
best_loss: tensor(-0.8077, device='cuda:1')
final loss: -0.7642503380775452
Test:
Test: 0.4383746417130332
0.4383746417130332
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.86it/s]100%|██████████| 1/1 [00:00<00:00,  3.85it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.6589507460594177
Epoch 1: -0.6589507460594177
Mem used: -402MB
best_loss: tensor(-0.7897, device='cuda:1')
best_loss: tensor(-0.7898, device='cuda:1')
final loss: -0.7480679750442505
Test:
Test: 0.4325577474287641
0.4325577474287641
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.31it/s]100%|██████████| 1/1 [00:00<00:00,  2.31it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.6326050758361816
Epoch 1: -0.6326050758361816
Mem used: -724MB
best_loss: tensor(-0.7837, device='cuda:1')
final loss: -0.7402695417404175
Test:
Test: 0.4340330467037599
0.4340330467037599
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  1.95it/s]100%|██████████| 2/2 [00:00<00:00,  2.05it/s]100%|██████████| 2/2 [00:00<00:00,  2.00it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6706709861755371
Epoch 1, Loop Feat 0: -0.6697251796722412
Epoch 1, Loop Adj 0: -0.6980568170547485
Epoch 2: -0.6980568170547485
Mem used: -311MB
best_loss: tensor(-0.8366, device='cuda:1')
best_loss: tensor(-0.8390, device='cuda:1')
final loss: -0.8057346940040588
Test:
Test: 0.4230736806609341
0.4230736806609341
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  1.86it/s]100%|██████████| 2/2 [00:00<00:00,  2.19it/s]100%|██████████| 2/2 [00:00<00:00,  2.14it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6704381108283997
Epoch 1, Loop Feat 0: -0.6611239314079285
Epoch 1, Loop Adj 0: -0.6869081854820251
Epoch 2: -0.6869081854820251
Mem used: -317MB
best_loss: tensor(-0.8242, device='cuda:1')
best_loss: tensor(-0.8269, device='cuda:1')
final loss: -0.8013585805892944
Test:
Test: 0.4256870679480695
0.4256870679480695
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.00it/s]100%|██████████| 2/2 [00:00<00:00,  1.90it/s]100%|██████████| 2/2 [00:00<00:00,  2.01it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.6442331075668335
Epoch 1, Loop Feat 0: -0.6409562230110168
Epoch 1, Loop Adj 0: -0.6696188449859619
Epoch 2: -0.6696188449859619
Mem used: -668MB
best_loss: tensor(-0.8028, device='cuda:1')
best_loss: tensor(-0.8055, device='cuda:1')
final loss: -0.7799652814865112
Test:
Test: 0.4234530433316473
0.4234530433316473
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.81it/s]100%|██████████| 2/2 [00:00<00:00,  2.59it/s]100%|██████████| 2/2 [00:00<00:00,  2.62it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.665550947189331
Epoch 1, Loop Feat 0: -0.6583226919174194
Epoch 1, Loop Adj 0: -0.6930356025695801
Epoch 2: -0.6930356025695801
Mem used: -886MB
best_loss: tensor(-0.8267, device='cuda:1')
best_loss: tensor(-0.8289, device='cuda:1')
final loss: -0.80517578125
Test:
Test: 0.40747765975383576
0.40747765975383576
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.92it/s]100%|██████████| 2/2 [00:00<00:00,  2.63it/s]100%|██████████| 2/2 [00:00<00:00,  2.77it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6711763143539429
Epoch 1, Loop Feat 0: -0.6626694798469543
Epoch 1, Loop Adj 0: -0.7002673149108887
Epoch 2: -0.7002673149108887
Mem used: -900MB
best_loss: tensor(-0.8313, device='cuda:1')
best_loss: tensor(-0.8341, device='cuda:1')
final loss: -0.8102754354476929
Test:
Test: 0.4169617265216658
0.4169617265216658
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.74it/s]100%|██████████| 2/2 [00:00<00:00,  3.61it/s]100%|██████████| 2/2 [00:00<00:00,  3.59it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388945579529
Epoch 0, Loop Adj 0: -0.6571149230003357
Epoch 1, Loop Feat 0: -0.6549244523048401
Epoch 1, Loop Adj 0: -0.6825063824653625
Epoch 2: -0.6825063824653625
Mem used: -536MB
best_loss: tensor(-0.8248, device='cuda:1')
best_loss: tensor(-0.8270, device='cuda:1')
final loss: -0.8002902269363403
Test:
Test: 0.4024616422188501
0.4024616422188501
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.11it/s]100%|██████████| 2/2 [00:00<00:00,  2.30it/s]100%|██████████| 2/2 [00:00<00:00,  2.40it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.6467185616493225
Epoch 1, Loop Feat 0: -0.6459116339683533
Epoch 1, Loop Adj 0: -0.6750932335853577
Epoch 2: -0.6750932335853577
Mem used: -900MB
best_loss: tensor(-0.8083, device='cuda:1')
best_loss: tensor(-0.8102, device='cuda:1')
final loss: -0.785886287689209
Test:
Test: 0.4075198111616928
0.4075198111616928
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.25it/s]100%|██████████| 2/2 [00:00<00:00,  2.13it/s]100%|██████████| 2/2 [00:00<00:00,  2.22it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6630133986473083
Epoch 1, Loop Feat 0: -0.6643063426017761
Epoch 1, Loop Adj 0: -0.6857125163078308
Epoch 2: -0.6857125163078308
Mem used: -646MB
best_loss: tensor(-0.8262, device='cuda:1')
best_loss: tensor(-0.8287, device='cuda:1')
final loss: -0.8016113042831421
Test:
Test: 0.4290591805766313
0.4290591805766313
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.50it/s]100%|██████████| 2/2 [00:00<00:00,  2.68it/s]100%|██████████| 2/2 [00:00<00:00,  2.65it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.6589508652687073
Epoch 1, Loop Feat 0: -0.6532421708106995
Epoch 1, Loop Adj 0: -0.6867710947990417
Epoch 2: -0.6867710947990417
Mem used: -900MB
best_loss: tensor(-0.8168, device='cuda:1')
best_loss: tensor(-0.8182, device='cuda:1')
final loss: -0.793494701385498
Test:
Test: 0.4159500927330973
0.4159500927330973
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.15it/s]100%|██████████| 2/2 [00:00<00:00,  2.31it/s]100%|██████████| 2/2 [00:00<00:00,  2.29it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.6326050758361816
Epoch 1, Loop Feat 0: -0.6328169703483582
Epoch 1, Loop Adj 0: -0.6603339910507202
Epoch 2: -0.6603339910507202
Mem used: -730MB
best_loss: tensor(-0.8027, device='cuda:1')
best_loss: tensor(-0.8047, device='cuda:1')
final loss: -0.7794130444526672
Test:
Test: 0.4131680998145338
0.4131680998145338
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.88it/s]100%|██████████| 2/2 [00:00<00:00,  2.85it/s]100%|██████████| 2/2 [00:00<00:00,  2.83it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6706709861755371
Epoch 1, Loop Feat 0: -0.6644095182418823
Epoch 1, Loop Adj 0: -0.6933606266975403
Epoch 2: -0.6933606266975403
Mem used: -900MB
best_loss: tensor(-0.8301, device='cuda:1')
best_loss: tensor(-0.8319, device='cuda:1')
final loss: -0.8006068468093872
Test:
Test: 0.42282077221379194
0.42282077221379194
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.43it/s]100%|██████████| 2/2 [00:00<00:00,  2.02it/s]100%|██████████| 2/2 [00:00<00:00,  2.14it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6704383492469788
Epoch 1, Loop Feat 0: -0.6564136147499084
Epoch 1, Loop Adj 0: -0.6828230619430542
Epoch 2: -0.6828230619430542
Mem used: -672MB
best_loss: tensor(-0.8171, device='cuda:1')
best_loss: tensor(-0.8208, device='cuda:1')
final loss: -0.7947542667388916
Test:
Test: 0.4244646771202158
0.4244646771202158
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.19it/s]100%|██████████| 2/2 [00:00<00:00,  2.43it/s]100%|██████████| 2/2 [00:00<00:00,  2.39it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.6442331075668335
Epoch 1, Loop Feat 0: -0.6368935108184814
Epoch 1, Loop Adj 0: -0.6653205752372742
Epoch 2: -0.6653205752372742
Mem used: -900MB
best_loss: tensor(-0.7978, device='cuda:1')
best_loss: tensor(-0.8002, device='cuda:1')
final loss: -0.7769854664802551
Test:
Test: 0.42703591299949417
0.42703591299949417
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.64it/s]100%|██████████| 2/2 [00:00<00:00,  2.27it/s]100%|██████████| 2/2 [00:00<00:00,  2.30it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.665550947189331
Epoch 1, Loop Feat 0: -0.6539178490638733
Epoch 1, Loop Adj 0: -0.6890704035758972
Epoch 2: -0.6890704035758972
Mem used: -544MB
best_loss: tensor(-0.8205, device='cuda:1')
final loss: -0.79738450050354
Test:
Test: 0.4140954307873883
0.4140954307873883
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.78it/s]100%|██████████| 2/2 [00:00<00:00,  2.04it/s]100%|██████████| 2/2 [00:00<00:00,  2.12it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6711763143539429
Epoch 1, Loop Feat 0: -0.6568177342414856
Epoch 1, Loop Adj 0: -0.6962913870811462
Epoch 2: -0.6962913870811462
Mem used: -708MB
best_loss: tensor(-0.8277, device='cuda:1')
best_loss: tensor(-0.8296, device='cuda:1')
final loss: -0.8071925640106201
Test:
Test: 0.4212190187152251
0.4212190187152251
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.25it/s]100%|██████████| 2/2 [00:00<00:00,  3.12it/s]100%|██████████| 2/2 [00:00<00:00,  3.14it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388945579529
Epoch 0, Loop Adj 0: -0.6571149826049805
Epoch 1, Loop Feat 0: -0.6503215432167053
Epoch 1, Loop Adj 0: -0.6785681843757629
Epoch 2: -0.6785681843757629
Mem used: -900MB
best_loss: tensor(-0.8168, device='cuda:1')
best_loss: tensor(-0.8199, device='cuda:1')
final loss: -0.7938099503517151
Test:
Test: 0.40684538863598046
0.40684538863598046
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.03it/s]100%|██████████| 2/2 [00:01<00:00,  1.86it/s]100%|██████████| 2/2 [00:01<00:00,  1.87it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.6467185616493225
Epoch 1, Loop Feat 0: -0.6403850317001343
Epoch 1, Loop Adj 0: -0.6715127825737
Epoch 2: -0.6715127825737
Mem used: -2615MB
best_loss: tensor(-0.8029, device='cuda:1')
best_loss: tensor(-0.8040, device='cuda:1')
final loss: -0.7804765105247498
Test:
Test: 0.4118614061709661
0.4118614061709661
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.68it/s]100%|██████████| 2/2 [00:00<00:00,  2.55it/s]100%|██████████| 2/2 [00:00<00:00,  2.67it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6630133986473083
Epoch 1, Loop Feat 0: -0.6607182621955872
Epoch 1, Loop Adj 0: -0.6815310716629028
Epoch 2: -0.6815310716629028
Mem used: -900MB
best_loss: tensor(-0.8188, device='cuda:1')
best_loss: tensor(-0.8232, device='cuda:1')
final loss: -0.7974361777305603
Test:
Test: 0.43112459956162535
0.43112459956162535
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.91it/s]100%|██████████| 2/2 [00:00<00:00,  2.34it/s]100%|██████████| 2/2 [00:00<00:00,  2.34it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.6589508652687073
Epoch 1, Loop Feat 0: -0.6473398804664612
Epoch 1, Loop Adj 0: -0.6828214526176453
Epoch 2: -0.6828214526176453
Mem used: -734MB
best_loss: tensor(-0.8131, device='cuda:1')
best_loss: tensor(-0.8135, device='cuda:1')
final loss: -0.7892954349517822
Test:
Test: 0.41548642724667006
0.41548642724667006
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.66it/s]100%|██████████| 2/2 [00:00<00:00,  2.87it/s]100%|██████████| 2/2 [00:00<00:00,  2.83it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.6326050758361816
Epoch 1, Loop Feat 0: -0.6284829378128052
Epoch 1, Loop Adj 0: -0.6568279266357422
Epoch 2: -0.6568279266357422
Mem used: -900MB
best_loss: tensor(-0.7957, device='cuda:1')
best_loss: tensor(-0.7983, device='cuda:1')
final loss: -0.7734935283660889
Test:
Test: 0.4150649131680998
0.4150649131680998
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.33it/s]100%|██████████| 2/2 [00:00<00:00,  2.32it/s]100%|██████████| 2/2 [00:00<00:00,  2.31it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6706709265708923
Epoch 1, Loop Feat 0: -0.6712949275970459
Epoch 1, Loop Adj 0: -0.6991555094718933
Epoch 2: -0.6991555094718933
Mem used: -900MB
best_loss: tensor(-0.8403, device='cuda:1')
best_loss: tensor(-0.8405, device='cuda:1')
final loss: -0.8070286512374878
Test:
Test: 0.4214719271623672
0.4214719271623672
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.00it/s]100%|██████████| 2/2 [00:01<00:00,  1.70it/s]100%|██████████| 2/2 [00:01<00:00,  1.74it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6704381704330444
Epoch 1, Loop Feat 0: -0.6624138951301575
Epoch 1, Loop Adj 0: -0.6884156465530396
Epoch 2: -0.6884156465530396
Mem used: -82MB
best_loss: tensor(-0.8284, device='cuda:1')
final loss: -0.8029875159263611
Test:
Test: 0.4246332827516439
0.4246332827516439
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.86it/s]100%|██████████| 2/2 [00:00<00:00,  3.05it/s]100%|██████████| 2/2 [00:00<00:00,  3.15it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.6442331075668335
Epoch 1, Loop Feat 0: -0.6419910788536072
Epoch 1, Loop Adj 0: -0.6706289649009705
Epoch 2: -0.6706289649009705
Mem used: -226MB
best_loss: tensor(-0.8071, device='cuda:1')
best_loss: tensor(-0.8074, device='cuda:1')
final loss: -0.7814958095550537
Test:
Test: 0.4208818074523689
0.4208818074523689
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.38it/s]100%|██████████| 2/2 [00:00<00:00,  2.39it/s]100%|██████████| 2/2 [00:00<00:00,  2.49it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.665550947189331
Epoch 1, Loop Feat 0: -0.6596089601516724
Epoch 1, Loop Adj 0: -0.6942144632339478
Epoch 2: -0.6942144632339478
Mem used: -498MB
best_loss: tensor(-0.8315, device='cuda:1')
final loss: -0.8065029382705688
Test:
Test: 0.4062131175181251
0.4062131175181251
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.93it/s]100%|██████████| 2/2 [00:00<00:00,  2.84it/s]100%|██████████| 2/2 [00:00<00:00,  2.96it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6711763143539429
Epoch 1, Loop Feat 0: -0.6649919152259827
Epoch 1, Loop Adj 0: -0.7018256783485413
Epoch 2: -0.7018256783485413
Mem used: -888MB
best_loss: tensor(-0.8355, device='cuda:1')
best_loss: tensor(-0.8357, device='cuda:1')
final loss: -0.8116521835327148
Test:
Test: 0.4162873039959535
0.4162873039959535
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.11it/s]100%|██████████| 2/2 [00:00<00:00,  2.09it/s]100%|██████████| 2/2 [00:00<00:00,  2.10it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.6571148633956909
Epoch 1, Loop Feat 0: -0.6565510034561157
Epoch 1, Loop Adj 0: -0.6840487122535706
Epoch 2: -0.6840487122535706
Mem used: -423MB
best_loss: tensor(-0.8291, device='cuda:1')
best_loss: tensor(-0.8293, device='cuda:1')
final loss: -0.8025670647621155
Test:
Test: 0.4037683358624178
0.4037683358624178
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.25it/s]100%|██████████| 2/2 [00:00<00:00,  4.02it/s]100%|██████████| 2/2 [00:00<00:00,  4.01it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.6467175483703613
Epoch 1, Loop Feat 0: -0.647710382938385
Epoch 1, Loop Adj 0: -0.6763680577278137
Epoch 2: -0.6763680577278137
Mem used: -900MB
best_loss: tensor(-0.8128, device='cuda:1')
best_loss: tensor(-0.8129, device='cuda:1')
final loss: -0.7884009480476379
Test:
Test: 0.4061288147024111
0.4061288147024111
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.24it/s]100%|██████████| 2/2 [00:00<00:00,  2.67it/s]100%|██████████| 2/2 [00:00<00:00,  2.74it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6630133986473083
Epoch 1, Loop Feat 0: -0.6655045747756958
Epoch 1, Loop Adj 0: -0.6870824694633484
Epoch 2: -0.6870824694633484
Mem used: -900MB
best_loss: tensor(-0.8301, device='cuda:1')
final loss: -0.80291748046875
Test:
Test: 0.4283426066430619
0.4283426066430619
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.59it/s]100%|██████████| 2/2 [00:00<00:00,  1.97it/s]100%|██████████| 2/2 [00:00<00:00,  2.03it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.6589507460594177
Epoch 1, Loop Feat 0: -0.6553701162338257
Epoch 1, Loop Adj 0: -0.6880768537521362
Epoch 2: -0.6880768537521362
Mem used: -714MB
best_loss: tensor(-0.8200, device='cuda:1')
final loss: -0.7942577004432678
Test:
Test: 0.4146855504973866
0.4146855504973866
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.93it/s]100%|██████████| 2/2 [00:00<00:00,  2.54it/s]100%|██████████| 2/2 [00:00<00:00,  2.68it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.6326050758361816
Epoch 1, Loop Feat 0: -0.6342841386795044
Epoch 1, Loop Adj 0: -0.6610926985740662
Epoch 2: -0.6610926985740662
Mem used: -634MB
best_loss: tensor(-0.8061, device='cuda:1')
final loss: -0.7812637686729431
Test:
Test: 0.41342100826167594
0.41342100826167594
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.36it/s]100%|██████████| 1/1 [00:00<00:00,  2.33it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6706709265708923
Epoch 1: -0.6706709265708923
Mem used: -690MB
best_loss: tensor(-0.8105, device='cuda:1')
best_loss: tensor(-0.8138, device='cuda:1')
final loss: -0.7652007937431335
Test:
Test: 0.4406508177373124
0.4406508177373124
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.99it/s]100%|██████████| 1/1 [00:00<00:00,  2.98it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6704381108283997
Epoch 1: -0.6704381108283997
Mem used: -754MB
best_loss: tensor(-0.8001, device='cuda:1')
best_loss: tensor(-0.8026, device='cuda:1')
final loss: -0.7605141997337341
Test:
Test: 0.44242117686730736
0.44242117686730736
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.13it/s]100%|██████████| 1/1 [00:00<00:00,  3.13it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.6442331075668335
Epoch 1: -0.6442331075668335
Mem used: -758MB
best_loss: tensor(-0.7799, device='cuda:1')
best_loss: tensor(-0.7819, device='cuda:1')
final loss: -0.7414615154266357
Test:
Test: 0.44048221210588434
0.44048221210588434
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.72it/s]100%|██████████| 1/1 [00:00<00:00,  2.72it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011685371399
Epoch 0, Loop Adj 0: -0.665550947189331
Epoch 1: -0.665550947189331
Mem used: -900MB
best_loss: tensor(-0.8026, device='cuda:1')
best_loss: tensor(-0.8055, device='cuda:1')
final loss: -0.7646472454071045
Test:
Test: 0.4381638846737481
0.4381638846737481
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.70it/s]100%|██████████| 1/1 [00:00<00:00,  3.69it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6711763739585876
Epoch 1: -0.6711763739585876
Mem used: -796MB
best_loss: tensor(-0.8005, device='cuda:1')
final loss: -0.7611307501792908
Test:
Test: 0.44242117686730736
0.44242117686730736
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.55it/s]100%|██████████| 1/1 [00:00<00:00,  2.55it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.6571149826049805
Epoch 1: -0.6571149826049805
Mem used: -900MB
best_loss: tensor(-0.8014, device='cuda:1')
best_loss: tensor(-0.8032, device='cuda:1')
final loss: -0.7604823708534241
Test:
Test: 0.4276260327094925
0.4276260327094925
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.94it/s]100%|██████████| 1/1 [00:00<00:00,  3.93it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.6467176079750061
Epoch 1: -0.6467176079750061
Mem used: -511MB
best_loss: tensor(-0.7835, device='cuda:1')
best_loss: tensor(-0.7856, device='cuda:1')
final loss: -0.7451025247573853
Test:
Test: 0.4278789411566346
0.4278789411566346
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  1.82it/s]100%|██████████| 1/1 [00:00<00:00,  1.80it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6630133986473083
Epoch 1: -0.6630133986473083
Mem used: -554MB
best_loss: tensor(-0.8049, device='cuda:1')
final loss: -0.7605937123298645
Test:
Test: 0.44048221210588434
0.44048221210588434
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.73it/s]100%|██████████| 1/1 [00:00<00:00,  2.72it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.6589508652687073
Epoch 1: -0.6589508652687073
Mem used: -796MB
best_loss: tensor(-0.7860, device='cuda:1')
best_loss: tensor(-0.7883, device='cuda:1')
final loss: -0.7463573813438416
Test:
Test: 0.4339065924801888
0.4339065924801888
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.31it/s]100%|██████████| 1/1 [00:00<00:00,  4.31it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.6326050758361816
Epoch 1: -0.6326050758361816
Mem used: -824MB
best_loss: tensor(-0.7786, device='cuda:1')
best_loss: tensor(-0.7815, device='cuda:1')
final loss: -0.738562822341919
Test:
Test: 0.4368150396223234
0.4368150396223234
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.17it/s]100%|██████████| 1/1 [00:00<00:00,  2.17it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6706709861755371
Epoch 1: -0.6706709861755371
Mem used: -900MB
best_loss: tensor(-0.7991, device='cuda:1')
best_loss: tensor(-0.8109, device='cuda:1')
final loss: -0.7631964683532715
Test:
Test: 0.44128308885516776
0.44128308885516776
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.42it/s]100%|██████████| 1/1 [00:00<00:00,  2.42it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6704383492469788
Epoch 1: -0.6704383492469788
Mem used: -2168MB
best_loss: tensor(-0.7879, device='cuda:1')
best_loss: tensor(-0.7996, device='cuda:1')
final loss: -0.758612334728241
Test:
Test: 0.4429691451694487
0.4429691451694487
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.87it/s]100%|██████████| 1/1 [00:00<00:00,  2.86it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.6442331075668335
Epoch 1: -0.6442331075668335
Mem used: -720MB
best_loss: tensor(-0.7674, device='cuda:1')
best_loss: tensor(-0.7797, device='cuda:1')
final loss: -0.7393544912338257
Test:
Test: 0.441788905749452
0.441788905749452
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.92it/s]100%|██████████| 1/1 [00:00<00:00,  2.92it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.665550947189331
Epoch 1: -0.665550947189331
Mem used: -900MB
best_loss: tensor(-0.7916, device='cuda:1')
best_loss: tensor(-0.8019, device='cuda:1')
final loss: -0.7628943920135498
Test:
Test: 0.4388383071994605
0.4388383071994605
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  6.19it/s]100%|██████████| 1/1 [00:00<00:00,  6.17it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6711763143539429
Epoch 1: -0.6711763143539429
Mem used: -900MB
best_loss: tensor(-0.7887, device='cuda:1')
best_loss: tensor(-0.8011, device='cuda:1')
final loss: -0.7629237174987793
Test:
Test: 0.44233687405159333
0.44233687405159333
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.73it/s]100%|██████████| 1/1 [00:00<00:00,  2.73it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.6571148633956909
Epoch 1: -0.6571148633956909
Mem used: -2743MB
best_loss: tensor(-0.7882, device='cuda:1')
best_loss: tensor(-0.7999, device='cuda:1')
final loss: -0.7577304244041443
Test:
Test: 0.42994436014162873
0.42994436014162873
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.13it/s]100%|██████████| 1/1 [00:00<00:00,  2.12it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.6467176079750061
Epoch 1: -0.6467176079750061
Mem used: -900MB
best_loss: tensor(-0.7701, device='cuda:1')
best_loss: tensor(-0.7832, device='cuda:1')
final loss: -0.7425206899642944
Test:
Test: 0.4291013319844883
0.4291013319844883
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.55it/s]100%|██████████| 1/1 [00:00<00:00,  3.54it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6630133986473083
Epoch 1: -0.6630133986473083
Mem used: -128MB
best_loss: tensor(-0.7939, device='cuda:1')
best_loss: tensor(-0.8031, device='cuda:1')
final loss: -0.7609402537345886
Test:
Test: 0.43900691283088855
0.43900691283088855
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  1.61it/s]100%|██████████| 1/1 [00:00<00:00,  1.61it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.6589508056640625
Epoch 1: -0.6589508056640625
Mem used: -438MB
best_loss: tensor(-0.7755, device='cuda:1')
best_loss: tensor(-0.7862, device='cuda:1')
final loss: -0.7439345121383667
Test:
Test: 0.4344124093744731
0.4344124093744731
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.26it/s]100%|██████████| 1/1 [00:00<00:00,  3.25it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.6326050758361816
Epoch 1: -0.6326050758361816
Mem used: -900MB
best_loss: tensor(-0.7666, device='cuda:1')
best_loss: tensor(-0.7787, device='cuda:1')
final loss: -0.7366946935653687
Test:
Test: 0.4362249199123251
0.4362249199123251
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.27it/s]100%|██████████| 1/1 [00:00<00:00,  3.22it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6706709265708923
Epoch 1: -0.6706709265708923
Mem used: -752MB
best_loss: tensor(-0.8152, device='cuda:1')
best_loss: tensor(-0.8153, device='cuda:1')
final loss: -0.7667329907417297
Test:
Test: 0.43934412409374474
0.43934412409374474
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.16it/s]100%|██████████| 1/1 [00:00<00:00,  3.13it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.670438289642334
Epoch 1: -0.670438289642334
Mem used: -900MB
best_loss: tensor(-0.8035, device='cuda:1')
best_loss: tensor(-0.8038, device='cuda:1')
final loss: -0.7615458369255066
Test:
Test: 0.4414516944865958
0.4414516944865958
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.19it/s]100%|██████████| 1/1 [00:00<00:00,  2.19it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.6442331075668335
Epoch 1: -0.6442331075668335
Mem used: -576MB
best_loss: tensor(-0.7836, device='cuda:1')
best_loss: tensor(-0.7839, device='cuda:1')
final loss: -0.7424477338790894
Test:
Test: 0.439849940988029
0.439849940988029
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.90it/s]100%|██████████| 1/1 [00:00<00:00,  2.90it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.665550947189331
Epoch 1: -0.665550947189331
Mem used: -900MB
best_loss: tensor(-0.8078, device='cuda:1')
final loss: -0.7659742832183838
Test:
Test: 0.4376580677794638
0.4376580677794638
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.28it/s]100%|██████████| 1/1 [00:00<00:00,  2.28it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6711763143539429
Epoch 1: -0.6711763143539429
Mem used: -2168MB
best_loss: tensor(-0.8055, device='cuda:1')
best_loss: tensor(-0.8058, device='cuda:1')
final loss: -0.7660184502601624
Test:
Test: 0.4400185466194571
0.4400185466194571
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.87it/s]100%|██████████| 1/1 [00:00<00:00,  2.87it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388945579529
Epoch 0, Loop Adj 0: -0.6571148633956909
Epoch 1: -0.6571148633956909
Mem used: -768MB
best_loss: tensor(-0.8054, device='cuda:1')
best_loss: tensor(-0.8056, device='cuda:1')
final loss: -0.7612487077713013
Test:
Test: 0.4272045186309223
0.4272045186309223
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.79it/s]100%|██████████| 1/1 [00:00<00:00,  2.79it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.6467176079750061
Epoch 1: -0.6467176079750061
Mem used: -900MB
best_loss: tensor(-0.7876, device='cuda:1')
best_loss: tensor(-0.7876, device='cuda:1')
final loss: -0.7470458149909973
Test:
Test: 0.4271623672230653
0.4271623672230653
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.16it/s]100%|██████████| 1/1 [00:00<00:00,  2.16it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6630133986473083
Epoch 1: -0.6630133986473083
Mem used: -738MB
best_loss: tensor(-0.8077, device='cuda:1')
final loss: -0.7644094824790955
Test:
Test: 0.4383746417130332
0.4383746417130332
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.90it/s]100%|██████████| 1/1 [00:00<00:00,  2.86it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.6589507460594177
Epoch 1: -0.6589507460594177
Mem used: -802MB
best_loss: tensor(-0.7896, device='cuda:1')
best_loss: tensor(-0.7898, device='cuda:1')
final loss: -0.7481092810630798
Test:
Test: 0.4325155960209071
0.4325155960209071
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.67it/s]100%|██████████| 1/1 [00:00<00:00,  2.67it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.6326050162315369
Epoch 1: -0.6326050162315369
Mem used: -900MB
best_loss: tensor(-0.7837, device='cuda:1')
final loss: -0.7402695417404175
Test:
Test: 0.4340330467037599
0.4340330467037599
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.16it/s]100%|██████████| 2/2 [00:00<00:00,  2.28it/s]100%|██████████| 2/2 [00:00<00:00,  2.35it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6706709861755371
Epoch 1, Loop Feat 0: -0.6698949933052063
Epoch 1, Loop Adj 0: -0.6981658935546875
Epoch 2: -0.6981658935546875
Mem used: -599MB
best_loss: tensor(-0.8367, device='cuda:1')
best_loss: tensor(-0.8392, device='cuda:1')
final loss: -0.8059473633766174
Test:
Test: 0.4230736806609341
0.4230736806609341
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.52it/s]100%|██████████| 2/2 [00:00<00:00,  2.81it/s]100%|██████████| 2/2 [00:00<00:00,  2.89it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6704381108283997
Epoch 1, Loop Feat 0: -0.6612682938575745
Epoch 1, Loop Adj 0: -0.6870707273483276
Epoch 2: -0.6870707273483276
Mem used: -620MB
best_loss: tensor(-0.8243, device='cuda:1')
best_loss: tensor(-0.8269, device='cuda:1')
final loss: -0.8014805316925049
Test:
Test: 0.4255606137244984
0.4255606137244984
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.65it/s]100%|██████████| 2/2 [00:01<00:00,  1.55it/s]100%|██████████| 2/2 [00:01<00:00,  1.65it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.6442331075668335
Epoch 1, Loop Feat 0: -0.641072154045105
Epoch 1, Loop Adj 0: -0.6697320342063904
Epoch 2: -0.6697320342063904
Mem used: -144MB
best_loss: tensor(-0.8028, device='cuda:1')
best_loss: tensor(-0.8057, device='cuda:1')
final loss: -0.7802922129631042
Test:
Test: 0.422947226437363
0.422947226437363
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.01it/s]100%|██████████| 2/2 [00:01<00:00,  1.77it/s]100%|██████████| 2/2 [00:01<00:00,  1.89it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011685371399
Epoch 0, Loop Adj 0: -0.665550947189331
Epoch 1, Loop Feat 0: -0.6584663391113281
Epoch 1, Loop Adj 0: -0.6931518316268921
Epoch 2: -0.6931518316268921
Mem used: -544MB
best_loss: tensor(-0.8266, device='cuda:1')
final loss: -0.8027297854423523
Test:
Test: 0.41097622660596866
0.41097622660596866
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.89it/s]100%|██████████| 2/2 [00:00<00:00,  2.60it/s]100%|██████████| 2/2 [00:00<00:00,  2.64it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6711763143539429
Epoch 1, Loop Feat 0: -0.6628793478012085
Epoch 1, Loop Adj 0: -0.700400710105896
Epoch 2: -0.700400710105896
Mem used: -746MB
best_loss: tensor(-0.8315, device='cuda:1')
best_loss: tensor(-0.8343, device='cuda:1')
final loss: -0.8109893202781677
Test:
Test: 0.417298937784522
0.417298937784522
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.31it/s]100%|██████████| 2/2 [00:00<00:00,  2.51it/s]100%|██████████| 2/2 [00:00<00:00,  2.60it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.6571149230003357
Epoch 1, Loop Feat 0: -0.6550891995429993
Epoch 1, Loop Adj 0: -0.6826391816139221
Epoch 2: -0.6826391816139221
Mem used: -900MB
best_loss: tensor(-0.8247, device='cuda:1')
best_loss: tensor(-0.8274, device='cuda:1')
final loss: -0.8011125326156616
Test:
Test: 0.40233518799527906
0.40233518799527906
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.31it/s]100%|██████████| 2/2 [00:00<00:00,  2.47it/s]100%|██████████| 2/2 [00:00<00:00,  2.45it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.6467176079750061
Epoch 1, Loop Feat 0: -0.6461078524589539
Epoch 1, Loop Adj 0: -0.6752310991287231
Epoch 2: -0.6752310991287231
Mem used: -590MB
best_loss: tensor(-0.8085, device='cuda:1')
best_loss: tensor(-0.8108, device='cuda:1')
final loss: -0.7868351340293884
Test:
Test: 0.40684538863598046
0.40684538863598046
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.75it/s]100%|██████████| 2/2 [00:00<00:00,  3.01it/s]100%|██████████| 2/2 [00:00<00:00,  3.10it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6630133986473083
Epoch 1, Loop Feat 0: -0.6644279956817627
Epoch 1, Loop Adj 0: -0.6858356595039368
Epoch 2: -0.6858356595039368
Mem used: -406MB
best_loss: tensor(-0.8261, device='cuda:1')
final loss: -0.7984043955802917
Test:
Test: 0.4297336031023436
0.4297336031023436
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.35it/s]100%|██████████| 2/2 [00:00<00:00,  2.80it/s]100%|██████████| 2/2 [00:00<00:00,  2.85it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.6589507460594177
Epoch 1, Loop Feat 0: -0.6534461975097656
Epoch 1, Loop Adj 0: -0.6868855953216553
Epoch 2: -0.6868855953216553
Mem used: -226MB
best_loss: tensor(-0.8166, device='cuda:1')
best_loss: tensor(-0.8185, device='cuda:1')
final loss: -0.7939101457595825
Test:
Test: 0.41531782161524194
0.41531782161524194
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.83it/s]100%|██████████| 2/2 [00:00<00:00,  2.12it/s]100%|██████████| 2/2 [00:00<00:00,  2.20it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.6326050758361816
Epoch 1, Loop Feat 0: -0.6329826712608337
Epoch 1, Loop Adj 0: -0.6604255437850952
Epoch 2: -0.6604255437850952
Mem used: -544MB
best_loss: tensor(-0.8024, device='cuda:1')
final loss: -0.7768964767456055
Test:
Test: 0.4148120047209577
0.4148120047209577
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.19it/s]100%|██████████| 2/2 [00:01<00:00,  1.58it/s]100%|██████████| 2/2 [00:01<00:00,  1.65it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6706709861755371
Epoch 1, Loop Feat 0: -0.6674405932426453
Epoch 1, Loop Adj 0: -0.6962534189224243
Epoch 2: -0.6962534189224243
Mem used: -888MB
best_loss: tensor(-0.8307, device='cuda:1')
best_loss: tensor(-0.8350, device='cuda:1')
final loss: -0.8024824261665344
Test:
Test: 0.424886191198786
0.424886191198786
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.35it/s]100%|██████████| 2/2 [00:00<00:00,  3.26it/s]100%|██████████| 2/2 [00:00<00:00,  3.46it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6704381704330444
Epoch 1, Loop Feat 0: -0.6592068076133728
Epoch 1, Loop Adj 0: -0.6851099729537964
Epoch 2: -0.6851099729537964
Mem used: -770MB
best_loss: tensor(-0.8175, device='cuda:1')
best_loss: tensor(-0.8227, device='cuda:1')
final loss: -0.7969154715538025
Test:
Test: 0.4274152756702074
0.4274152756702074
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.86it/s]100%|██████████| 2/2 [00:00<00:00,  2.48it/s]100%|██████████| 2/2 [00:00<00:00,  2.53it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.6442331075668335
Epoch 1, Loop Feat 0: -0.6394398212432861
Epoch 1, Loop Adj 0: -0.6679189801216125
Epoch 2: -0.6679189801216125
Mem used: -2699MB
best_loss: tensor(-0.7966, device='cuda:1')
best_loss: tensor(-0.8010, device='cuda:1')
final loss: -0.7767108082771301
Test:
Test: 0.4253920080930703
0.4253920080930703
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.31it/s]100%|██████████| 2/2 [00:00<00:00,  2.57it/s]100%|██████████| 2/2 [00:00<00:00,  2.66it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011685371399
Epoch 0, Loop Adj 0: -0.665550947189331
Epoch 1, Loop Feat 0: -0.6563128232955933
Epoch 1, Loop Adj 0: -0.6913285255432129
Epoch 2: -0.6913285255432129
Mem used: -458MB
best_loss: tensor(-0.8208, device='cuda:1')
best_loss: tensor(-0.8252, device='cuda:1')
final loss: -0.8002797961235046
Test:
Test: 0.4105547125273984
0.4105547125273984
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.79it/s]100%|██████████| 2/2 [00:00<00:00,  3.06it/s]100%|██████████| 2/2 [00:00<00:00,  3.15it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6711763143539429
Epoch 1, Loop Feat 0: -0.6603161096572876
Epoch 1, Loop Adj 0: -0.6988182663917542
Epoch 2: -0.6988182663917542
Mem used: -900MB
best_loss: tensor(-0.8282, device='cuda:1')
best_loss: tensor(-0.8314, device='cuda:1')
final loss: -0.8067172169685364
Test:
Test: 0.41738324060023607
0.41738324060023607
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.12it/s]100%|██████████| 2/2 [00:01<00:00,  1.93it/s]100%|██████████| 2/2 [00:01<00:00,  1.95it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.6571149826049805
Epoch 1, Loop Feat 0: -0.6528757214546204
Epoch 1, Loop Adj 0: -0.6808722019195557
Epoch 2: -0.6808722019195557
Mem used: -22MB
best_loss: tensor(-0.8181, device='cuda:1')
best_loss: tensor(-0.8217, device='cuda:1')
final loss: -0.7953731417655945
Test:
Test: 0.40591805766312594
0.40591805766312594
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.31it/s]100%|██████████| 2/2 [00:00<00:00,  2.38it/s]100%|██████████| 2/2 [00:00<00:00,  2.36it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.6467175483703613
Epoch 1, Loop Feat 0: -0.6438139081001282
Epoch 1, Loop Adj 0: -0.6736834049224854
Epoch 2: -0.6736834049224854
Mem used: -226MB
best_loss: tensor(-0.8032, device='cuda:1')
best_loss: tensor(-0.8077, device='cuda:1')
final loss: -0.7826902866363525
Test:
Test: 0.4106811667509695
0.4106811667509695
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.09it/s]100%|██████████| 2/2 [00:00<00:00,  2.92it/s]100%|██████████| 2/2 [00:00<00:00,  2.88it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6630133986473083
Epoch 1, Loop Feat 0: -0.6628559231758118
Epoch 1, Loop Adj 0: -0.683988630771637
Epoch 2: -0.683988630771637
Mem used: -722MB
best_loss: tensor(-0.8199, device='cuda:1')
best_loss: tensor(-0.8242, device='cuda:1')
final loss: -0.7974830865859985
Test:
Test: 0.4301129657730568
0.4301129657730568
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.29it/s]100%|██████████| 2/2 [00:00<00:00,  3.07it/s]100%|██████████| 2/2 [00:00<00:00,  2.92it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.6589507460594177
Epoch 1, Loop Feat 0: -0.6510500907897949
Epoch 1, Loop Adj 0: -0.6852765083312988
Epoch 2: -0.6852765083312988
Mem used: -2669MB
best_loss: tensor(-0.8131, device='cuda:1')
best_loss: tensor(-0.8150, device='cuda:1')
final loss: -0.7897447347640991
Test:
Test: 0.4145169448659585
0.4145169448659585
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.10it/s]100%|██████████| 2/2 [00:00<00:00,  3.18it/s]100%|██████████| 2/2 [00:00<00:00,  3.29it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.6326050758361816
Epoch 1, Loop Feat 0: -0.6308816075325012
Epoch 1, Loop Adj 0: -0.6590058207511902
Epoch 2: -0.6590058207511902
Mem used: -2169MB
best_loss: tensor(-0.7963, device='cuda:1')
best_loss: tensor(-0.7998, device='cuda:1')
final loss: -0.7742847204208374
Test:
Test: 0.4127887371438206
0.4127887371438206
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.99it/s]100%|██████████| 2/2 [00:00<00:00,  3.09it/s]100%|██████████| 2/2 [00:00<00:00,  3.07it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6706709265708923
Epoch 1, Loop Feat 0: -0.6713246703147888
Epoch 1, Loop Adj 0: -0.6991767287254333
Epoch 2: -0.6991767287254333
Mem used: -583MB
best_loss: tensor(-0.8403, device='cuda:1')
best_loss: tensor(-0.8405, device='cuda:1')
final loss: -0.807533323764801
Test:
Test: 0.42151407857022427
0.42151407857022427
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.35it/s]100%|██████████| 2/2 [00:01<00:00,  1.86it/s]100%|██████████| 2/2 [00:01<00:00,  1.92it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6704381108283997
Epoch 1, Loop Feat 0: -0.6624274849891663
Epoch 1, Loop Adj 0: -0.6884413361549377
Epoch 2: -0.6884413361549377
Mem used: 28MB
best_loss: tensor(-0.8283, device='cuda:1')
best_loss: tensor(-0.8283, device='cuda:1')
final loss: -0.8030681014060974
Test:
Test: 0.4251812510537852
0.4251812510537852
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.88it/s]100%|██████████| 2/2 [00:00<00:00,  2.84it/s]100%|██████████| 2/2 [00:00<00:00,  2.80it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.6442331075668335
Epoch 1, Loop Feat 0: -0.6420115232467651
Epoch 1, Loop Adj 0: -0.6706558465957642
Epoch 2: -0.6706558465957642
Mem used: -2464MB
best_loss: tensor(-0.8071, device='cuda:1')
best_loss: tensor(-0.8074, device='cuda:1')
final loss: -0.782137930393219
Test:
Test: 0.4208818074523689
0.4208818074523689
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.99it/s]100%|██████████| 2/2 [00:00<00:00,  2.70it/s]100%|██████████| 2/2 [00:00<00:00,  2.74it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.665550947189331
Epoch 1, Loop Feat 0: -0.659626841545105
Epoch 1, Loop Adj 0: -0.694240152835846
Epoch 2: -0.694240152835846
Mem used: -882MB
best_loss: tensor(-0.8315, device='cuda:1')
final loss: -0.8066189289093018
Test:
Test: 0.40629742033383914
0.40629742033383914
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.56it/s]100%|██████████| 2/2 [00:00<00:00,  2.35it/s]100%|██████████| 2/2 [00:00<00:00,  2.38it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6711763143539429
Epoch 1, Loop Feat 0: -0.665052056312561
Epoch 1, Loop Adj 0: -0.7018651962280273
Epoch 2: -0.7018651962280273
Mem used: -900MB
best_loss: tensor(-0.8355, device='cuda:1')
best_loss: tensor(-0.8357, device='cuda:1')
final loss: -0.8115013837814331
Test:
Test: 0.4167509694823807
0.4167509694823807
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.95it/s]100%|██████████| 2/2 [00:00<00:00,  3.07it/s]100%|██████████| 2/2 [00:00<00:00,  3.05it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.6571149826049805
Epoch 1, Loop Feat 0: -0.6565876007080078
Epoch 1, Loop Adj 0: -0.6840888261795044
Epoch 2: -0.6840888261795044
Mem used: -664MB
best_loss: tensor(-0.8290, device='cuda:1')
best_loss: tensor(-0.8293, device='cuda:1')
final loss: -0.8027305603027344
Test:
Test: 0.40368403304670375
0.40368403304670375
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.30it/s]100%|██████████| 2/2 [00:00<00:00,  1.98it/s]100%|██████████| 2/2 [00:00<00:00,  2.11it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.6467185616493225
Epoch 1, Loop Feat 0: -0.6477526426315308
Epoch 1, Loop Adj 0: -0.6764037013053894
Epoch 2: -0.6764037013053894
Mem used: -462MB
best_loss: tensor(-0.8128, device='cuda:1')
best_loss: tensor(-0.8129, device='cuda:1')
final loss: -0.7888497114181519
Test:
Test: 0.40608666329455406
0.40608666329455406
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  1.61it/s]100%|██████████| 2/2 [00:01<00:00,  1.57it/s]100%|██████████| 2/2 [00:01<00:00,  1.58it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6630134582519531
Epoch 1, Loop Feat 0: -0.6655309796333313
Epoch 1, Loop Adj 0: -0.6871178150177002
Epoch 2: -0.6871178150177002
Mem used: -1927MB
best_loss: tensor(-0.8301, device='cuda:1')
best_loss: tensor(-0.8304, device='cuda:1')
final loss: -0.8035783171653748
Test:
Test: 0.4279632439723487
0.4279632439723487
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.24it/s]100%|██████████| 2/2 [00:00<00:00,  2.17it/s]100%|██████████| 2/2 [00:00<00:00,  2.29it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.6589507460594177
Epoch 1, Loop Feat 0: -0.6554306745529175
Epoch 1, Loop Adj 0: -0.6881139278411865
Epoch 2: -0.6881139278411865
Mem used: -900MB
best_loss: tensor(-0.8200, device='cuda:1')
best_loss: tensor(-0.8201, device='cuda:1')
final loss: -0.7954606413841248
Test:
Test: 0.41472770190524366
0.41472770190524366
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.73it/s]100%|██████████| 2/2 [00:00<00:00,  3.69it/s]100%|██████████| 2/2 [00:00<00:00,  3.89it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.6326050758361816
Epoch 1, Loop Feat 0: -0.6343185305595398
Epoch 1, Loop Adj 0: -0.6611002087593079
Epoch 2: -0.6611002087593079
Mem used: -84MB
best_loss: tensor(-0.8061, device='cuda:1')
final loss: -0.7813122868537903
Test:
Test: 0.4133788568538189
0.4133788568538189
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.49it/s]100%|██████████| 1/1 [00:00<00:00,  3.48it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6706709265708923
Epoch 1: -0.6706709265708923
Mem used: -784MB
best_loss: tensor(-0.8105, device='cuda:1')
best_loss: tensor(-0.8151, device='cuda:1')
final loss: -0.7670595645904541
Test:
Test: 0.439892092395886
0.439892092395886
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.80it/s]100%|██████████| 1/1 [00:00<00:00,  2.75it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6704381704330444
Epoch 1: -0.6704381704330444
Mem used: -692MB
best_loss: tensor(-0.8001, device='cuda:1')
best_loss: tensor(-0.8035, device='cuda:1')
final loss: -0.7616348266601562
Test:
Test: 0.44162030011802395
0.44162030011802395
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.82it/s]100%|██████████| 1/1 [00:00<00:00,  2.81it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.6442331075668335
Epoch 1: -0.6442331075668335
Mem used: -786MB
best_loss: tensor(-0.7799, device='cuda:1')
best_loss: tensor(-0.7836, device='cuda:1')
final loss: -0.741908073425293
Test:
Test: 0.43972348676445794
0.43972348676445794
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.79it/s]100%|██████████| 1/1 [00:00<00:00,  4.78it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.665550947189331
Epoch 1: -0.665550947189331
Mem used: -710MB
best_loss: tensor(-0.8026, device='cuda:1')
best_loss: tensor(-0.8073, device='cuda:1')
final loss: -0.7658737897872925
Test:
Test: 0.4377002191873209
0.4377002191873209
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  1.87it/s]100%|██████████| 1/1 [00:00<00:00,  1.86it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6711763143539429
Epoch 1: -0.6711763143539429
Mem used: -900MB
best_loss: tensor(-0.8005, device='cuda:1')
best_loss: tensor(-0.8052, device='cuda:1')
final loss: -0.7653669118881226
Test:
Test: 0.44010284943517114
0.44010284943517114
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.48it/s]100%|██████████| 1/1 [00:00<00:00,  3.47it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.6571149230003357
Epoch 1: -0.6571149230003357
Mem used: -818MB
best_loss: tensor(-0.8014, device='cuda:1')
best_loss: tensor(-0.8050, device='cuda:1')
final loss: -0.7614450454711914
Test:
Test: 0.4280053953802057
0.4280053953802057
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.73it/s]100%|██████████| 1/1 [00:00<00:00,  2.73it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.6467175483703613
Epoch 1: -0.6467175483703613
Mem used: -758MB
best_loss: tensor(-0.7835, device='cuda:1')
best_loss: tensor(-0.7873, device='cuda:1')
final loss: -0.746446430683136
Test:
Test: 0.42703591299949417
0.42703591299949417
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.56it/s]100%|██████████| 1/1 [00:00<00:00,  2.56it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6630133986473083
Epoch 1: -0.6630133986473083
Mem used: -524MB
best_loss: tensor(-0.8049, device='cuda:1')
best_loss: tensor(-0.8071, device='cuda:1')
final loss: -0.7639740109443665
Test:
Test: 0.4383746417130332
0.4383746417130332
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.81it/s]100%|██████████| 1/1 [00:00<00:00,  2.80it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.6589508652687073
Epoch 1: -0.6589508652687073
Mem used: -900MB
best_loss: tensor(-0.7860, device='cuda:1')
best_loss: tensor(-0.7897, device='cuda:1')
final loss: -0.7479820847511292
Test:
Test: 0.432389141797336
0.432389141797336
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.79it/s]100%|██████████| 1/1 [00:00<00:00,  3.78it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.6326051950454712
Epoch 1: -0.6326051950454712
Mem used: -604MB
best_loss: tensor(-0.7786, device='cuda:1')
best_loss: tensor(-0.7828, device='cuda:1')
final loss: -0.7401728630065918
Test:
Test: 0.43487607486090035
0.43487607486090035
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.00it/s]100%|██████████| 1/1 [00:00<00:00,  3.95it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6706709861755371
Epoch 1: -0.6706709861755371
Mem used: -742MB
best_loss: tensor(-0.7991, device='cuda:1')
best_loss: tensor(-0.8151, device='cuda:1')
final loss: -0.7670597434043884
Test:
Test: 0.439892092395886
0.439892092395886
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.85it/s]100%|██████████| 1/1 [00:00<00:00,  2.84it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6704381108283997
Epoch 1: -0.6704381108283997
Mem used: -684MB
best_loss: tensor(-0.7879, device='cuda:1')
best_loss: tensor(-0.8035, device='cuda:1')
final loss: -0.7616347670555115
Test:
Test: 0.44162030011802395
0.44162030011802395
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.17it/s]100%|██████████| 1/1 [00:00<00:00,  3.16it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.6442331075668335
Epoch 1: -0.6442331075668335
Mem used: -780MB
best_loss: tensor(-0.7674, device='cuda:1')
best_loss: tensor(-0.7836, device='cuda:1')
final loss: -0.7419081330299377
Test:
Test: 0.43972348676445794
0.43972348676445794
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.30it/s]100%|██████████| 1/1 [00:00<00:00,  2.30it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.665550947189331
Epoch 1: -0.665550947189331
Mem used: -846MB
best_loss: tensor(-0.7916, device='cuda:1')
best_loss: tensor(-0.8073, device='cuda:1')
final loss: -0.7658737897872925
Test:
Test: 0.4377002191873209
0.4377002191873209
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.89it/s]100%|██████████| 1/1 [00:00<00:00,  2.75it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6711763143539429
Epoch 1: -0.6711763143539429
Mem used: -900MB
best_loss: tensor(-0.7887, device='cuda:1')
best_loss: tensor(-0.8052, device='cuda:1')
final loss: -0.7653669118881226
Test:
Test: 0.44010284943517114
0.44010284943517114
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.43it/s]100%|██████████| 1/1 [00:00<00:00,  2.41it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.6571148633956909
Epoch 1: -0.6571148633956909
Mem used: -900MB
best_loss: tensor(-0.7882, device='cuda:1')
best_loss: tensor(-0.8050, device='cuda:1')
final loss: -0.7614451050758362
Test:
Test: 0.4280053953802057
0.4280053953802057
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.98it/s]100%|██████████| 1/1 [00:00<00:00,  2.98it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.6467175483703613
Epoch 1: -0.6467175483703613
Mem used: -830MB
best_loss: tensor(-0.7701, device='cuda:1')
best_loss: tensor(-0.7873, device='cuda:1')
final loss: -0.746446430683136
Test:
Test: 0.42703591299949417
0.42703591299949417
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.83it/s]100%|██████████| 1/1 [00:00<00:00,  2.83it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6630133986473083
Epoch 1: -0.6630133986473083
Mem used: -642MB
best_loss: tensor(-0.7939, device='cuda:1')
best_loss: tensor(-0.8071, device='cuda:1')
final loss: -0.7639740109443665
Test:
Test: 0.4383746417130332
0.4383746417130332
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.93it/s]100%|██████████| 1/1 [00:00<00:00,  2.93it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.6589508652687073
Epoch 1: -0.6589508652687073
Mem used: -720MB
best_loss: tensor(-0.7755, device='cuda:1')
best_loss: tensor(-0.7897, device='cuda:1')
final loss: -0.7479821443557739
Test:
Test: 0.432389141797336
0.432389141797336
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.08it/s]100%|██████████| 1/1 [00:00<00:00,  3.08it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.6326050758361816
Epoch 1: -0.6326050758361816
Mem used: -784MB
best_loss: tensor(-0.7666, device='cuda:1')
best_loss: tensor(-0.7828, device='cuda:1')
final loss: -0.7401728630065918
Test:
Test: 0.43487607486090035
0.43487607486090035
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.87it/s]100%|██████████| 1/1 [00:00<00:00,  2.87it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6706709265708923
Epoch 1: -0.6706709265708923
Mem used: -900MB
best_loss: tensor(-0.8152, device='cuda:1')
best_loss: tensor(-0.8153, device='cuda:1')
final loss: -0.7667195796966553
Test:
Test: 0.43934412409374474
0.43934412409374474
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  1.88it/s]100%|██████████| 1/1 [00:00<00:00,  1.87it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6704381704330444
Epoch 1: -0.6704381704330444
Mem used: -808MB
best_loss: tensor(-0.8035, device='cuda:1')
best_loss: tensor(-0.8038, device='cuda:1')
final loss: -0.7617285251617432
Test:
Test: 0.4413673916708818
0.4413673916708818
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.66it/s]100%|██████████| 1/1 [00:00<00:00,  2.66it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.6442331075668335
Epoch 1: -0.6442331075668335
Mem used: -888MB
best_loss: tensor(-0.7836, device='cuda:1')
best_loss: tensor(-0.7839, device='cuda:1')
final loss: -0.7428662180900574
Test:
Test: 0.43972348676445794
0.43972348676445794
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.45it/s]100%|██████████| 1/1 [00:00<00:00,  3.45it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.665550947189331
Epoch 1: -0.665550947189331
Mem used: -760MB
best_loss: tensor(-0.8078, device='cuda:1')
final loss: -0.7659742832183838
Test:
Test: 0.4376580677794638
0.4376580677794638
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.69it/s]100%|██████████| 1/1 [00:00<00:00,  2.65it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6711763143539429
Epoch 1: -0.6711763143539429
Mem used: -2824MB
best_loss: tensor(-0.8055, device='cuda:1')
best_loss: tensor(-0.8058, device='cuda:1')
final loss: -0.7658547163009644
Test:
Test: 0.4400185466194571
0.4400185466194571
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.13it/s]100%|██████████| 1/1 [00:00<00:00,  3.13it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388945579529
Epoch 0, Loop Adj 0: -0.6571149826049805
Epoch 1: -0.6571149826049805
Mem used: -768MB
best_loss: tensor(-0.8054, device='cuda:1')
best_loss: tensor(-0.8056, device='cuda:1')
final loss: -0.7618589997291565
Test:
Test: 0.4272045186309223
0.4272045186309223
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.16it/s]100%|██████████| 1/1 [00:00<00:00,  2.07it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.6467185616493225
Epoch 1: -0.6467185616493225
Mem used: -604MB
best_loss: tensor(-0.7876, device='cuda:1')
best_loss: tensor(-0.7878, device='cuda:1')
final loss: -0.7468603849411011
Test:
Test: 0.42695161018378014
0.42695161018378014
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.17it/s]100%|██████████| 1/1 [00:00<00:00,  4.17it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6630133986473083
Epoch 1: -0.6630133986473083
Mem used: -820MB
best_loss: tensor(-0.8077, device='cuda:1')
final loss: -0.7644094824790955
Test:
Test: 0.4383746417130332
0.4383746417130332
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.17it/s]100%|██████████| 1/1 [00:00<00:00,  3.16it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.6589507460594177
Epoch 1: -0.6589507460594177
Mem used: -900MB
best_loss: tensor(-0.7897, device='cuda:1')
best_loss: tensor(-0.7898, device='cuda:1')
final loss: -0.7480621933937073
Test:
Test: 0.4324734446130501
0.4324734446130501
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.75it/s]100%|██████████| 1/1 [00:00<00:00,  3.74it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.6326050758361816
Epoch 1: -0.6326050758361816
Mem used: -810MB
best_loss: tensor(-0.7837, device='cuda:1')
final loss: -0.7402695417404175
Test:
Test: 0.4340330467037599
0.4340330467037599
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.43it/s]100%|██████████| 2/2 [00:01<00:00,  1.82it/s]100%|██████████| 2/2 [00:01<00:00,  1.89it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6706709861755371
Epoch 1, Loop Feat 0: -0.6710430383682251
Epoch 1, Loop Adj 0: -0.6989921927452087
Epoch 2: -0.6989921927452087
Mem used: -226MB
best_loss: tensor(-0.8366, device='cuda:1')
best_loss: tensor(-0.8401, device='cuda:1')
final loss: -0.8066210746765137
Test:
Test: 0.4218512898330804
0.4218512898330804
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.04it/s]100%|██████████| 2/2 [00:00<00:00,  2.02it/s]100%|██████████| 2/2 [00:00<00:00,  2.03it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.670438289642334
Epoch 1, Loop Feat 0: -0.6622414588928223
Epoch 1, Loop Adj 0: -0.6881877779960632
Epoch 2: -0.6881877779960632
Mem used: -458MB
best_loss: tensor(-0.8241, device='cuda:1')
best_loss: tensor(-0.8276, device='cuda:1')
final loss: -0.8020754456520081
Test:
Test: 0.4259821278030686
0.4259821278030686
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  1.98it/s]100%|██████████| 2/2 [00:00<00:00,  2.06it/s]100%|██████████| 2/2 [00:00<00:00,  2.05it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.644233226776123
Epoch 1, Loop Feat 0: -0.6418282985687256
Epoch 1, Loop Adj 0: -0.6704713702201843
Epoch 2: -0.6704713702201843
Mem used: -900MB
best_loss: tensor(-0.8036, device='cuda:1')
best_loss: tensor(-0.8070, device='cuda:1')
final loss: -0.7819366455078125
Test:
Test: 0.4215562299780813
0.4215562299780813
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.13it/s]100%|██████████| 2/2 [00:01<00:00,  1.74it/s]100%|██████████| 2/2 [00:01<00:00,  1.79it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.665550947189331
Epoch 1, Loop Feat 0: -0.6594280004501343
Epoch 1, Loop Adj 0: -0.69402676820755
Epoch 2: -0.69402676820755
Mem used: -470MB
best_loss: tensor(-0.8268, device='cuda:1')
best_loss: tensor(-0.8307, device='cuda:1')
final loss: -0.8059178590774536
Test:
Test: 0.4073512055302647
0.4073512055302647
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.91it/s]100%|██████████| 2/2 [00:00<00:00,  2.22it/s]100%|██████████| 2/2 [00:00<00:00,  2.27it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6711763143539429
Epoch 1, Loop Feat 0: -0.6646072268486023
Epoch 1, Loop Adj 0: -0.7015783190727234
Epoch 2: -0.7015783190727234
Mem used: -226MB
best_loss: tensor(-0.8311, device='cuda:1')
best_loss: tensor(-0.8352, device='cuda:1')
final loss: -0.8108311891555786
Test:
Test: 0.4171303321530939
0.4171303321530939
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.14it/s]100%|██████████| 2/2 [00:00<00:00,  2.99it/s]100%|██████████| 2/2 [00:00<00:00,  2.82it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961389541625977
Epoch 0, Loop Adj 0: -0.6571149230003357
Epoch 1, Loop Feat 0: -0.6563184857368469
Epoch 1, Loop Adj 0: -0.6837918162345886
Epoch 2: -0.6837918162345886
Mem used: -389MB
best_loss: tensor(-0.8252, device='cuda:1')
best_loss: tensor(-0.8288, device='cuda:1')
final loss: -0.8018282055854797
Test:
Test: 0.4031782161524195
0.4031782161524195
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.20it/s]100%|██████████| 2/2 [00:00<00:00,  4.09it/s]100%|██████████| 2/2 [00:00<00:00,  4.17it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.6467175483703613
Epoch 1, Loop Feat 0: -0.6474489569664001
Epoch 1, Loop Adj 0: -0.676156759262085
Epoch 2: -0.676156759262085
Mem used: -900MB
best_loss: tensor(-0.8090, device='cuda:1')
best_loss: tensor(-0.8124, device='cuda:1')
final loss: -0.7876481413841248
Test:
Test: 0.40671893441240936
0.40671893441240936
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.21it/s]100%|██████████| 2/2 [00:00<00:00,  2.28it/s]100%|██████████| 2/2 [00:00<00:00,  2.45it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6630133986473083
Epoch 1, Loop Feat 0: -0.6653102040290833
Epoch 1, Loop Adj 0: -0.686884880065918
Epoch 2: -0.686884880065918
Mem used: -716MB
best_loss: tensor(-0.8268, device='cuda:1')
best_loss: tensor(-0.8299, device='cuda:1')
final loss: -0.8024964332580566
Test:
Test: 0.4276260327094925
0.4276260327094925
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.93it/s]100%|██████████| 2/2 [00:00<00:00,  2.87it/s]100%|██████████| 2/2 [00:00<00:00,  2.88it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.6589508652687073
Epoch 1, Loop Feat 0: -0.6550218462944031
Epoch 1, Loop Adj 0: -0.6878458857536316
Epoch 2: -0.6878458857536316
Mem used: -888MB
best_loss: tensor(-0.8166, device='cuda:1')
best_loss: tensor(-0.8192, device='cuda:1')
final loss: -0.7942197322845459
Test:
Test: 0.4147698533131007
0.4147698533131007
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  1.66it/s]100%|██████████| 2/2 [00:01<00:00,  1.90it/s]100%|██████████| 2/2 [00:01<00:00,  1.86it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.6326050758361816
Epoch 1, Loop Feat 0: -0.6340520977973938
Epoch 1, Loop Adj 0: -0.6609973907470703
Epoch 2: -0.6609973907470703
Mem used: -682MB
best_loss: tensor(-0.8028, device='cuda:1')
best_loss: tensor(-0.8059, device='cuda:1')
final loss: -0.7803856730461121
Test:
Test: 0.4128308885516776
0.4128308885516776
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.97it/s]100%|██████████| 2/2 [00:00<00:00,  3.33it/s]100%|██████████| 2/2 [00:00<00:00,  3.26it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6706709861755371
Epoch 1, Loop Feat 0: -0.6710430383682251
Epoch 1, Loop Adj 0: -0.6989920139312744
Epoch 2: -0.6989920139312744
Mem used: -900MB
best_loss: tensor(-0.8294, device='cuda:1')
best_loss: tensor(-0.8401, device='cuda:1')
final loss: -0.8066210746765137
Test:
Test: 0.4218512898330804
0.4218512898330804
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.13it/s]100%|██████████| 2/2 [00:00<00:00,  3.34it/s]100%|██████████| 2/2 [00:00<00:00,  3.44it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6704381108283997
Epoch 1, Loop Feat 0: -0.6622413396835327
Epoch 1, Loop Adj 0: -0.6881876587867737
Epoch 2: -0.6881876587867737
Mem used: -2168MB
best_loss: tensor(-0.8187, device='cuda:1')
best_loss: tensor(-0.8276, device='cuda:1')
final loss: -0.8020755052566528
Test:
Test: 0.4259821278030686
0.4259821278030686
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.20it/s]100%|██████████| 2/2 [00:01<00:00,  1.74it/s]100%|██████████| 2/2 [00:01<00:00,  1.79it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.6442332863807678
Epoch 1, Loop Feat 0: -0.6418282985687256
Epoch 1, Loop Adj 0: -0.6704713702201843
Epoch 2: -0.6704713702201843
Mem used: -530MB
best_loss: tensor(-0.7968, device='cuda:1')
best_loss: tensor(-0.8070, device='cuda:1')
final loss: -0.7819366455078125
Test:
Test: 0.4215562299780813
0.4215562299780813
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.50it/s]100%|██████████| 2/2 [00:00<00:00,  2.01it/s]100%|██████████| 2/2 [00:00<00:00,  2.04it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.665550947189331
Epoch 1, Loop Feat 0: -0.6594280004501343
Epoch 1, Loop Adj 0: -0.6940266489982605
Epoch 2: -0.6940266489982605
Mem used: -658MB
best_loss: tensor(-0.8204, device='cuda:1')
best_loss: tensor(-0.8307, device='cuda:1')
final loss: -0.8059176206588745
Test:
Test: 0.4073512055302647
0.4073512055302647
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.29it/s]100%|██████████| 2/2 [00:00<00:00,  3.17it/s]100%|██████████| 2/2 [00:00<00:00,  3.18it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6711763143539429
Epoch 1, Loop Feat 0: -0.6646072268486023
Epoch 1, Loop Adj 0: -0.7015783190727234
Epoch 2: -0.7015783190727234
Mem used: -788MB
best_loss: tensor(-0.8273, device='cuda:1')
best_loss: tensor(-0.8352, device='cuda:1')
final loss: -0.8108312487602234
Test:
Test: 0.4171303321530939
0.4171303321530939
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.08it/s]100%|██████████| 2/2 [00:00<00:00,  2.26it/s]100%|██████████| 2/2 [00:00<00:00,  2.23it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.6571148633956909
Epoch 1, Loop Feat 0: -0.6563184261322021
Epoch 1, Loop Adj 0: -0.6837916374206543
Epoch 2: -0.6837916374206543
Mem used: -606MB
best_loss: tensor(-0.8179, device='cuda:1')
best_loss: tensor(-0.8288, device='cuda:1')
final loss: -0.8018284440040588
Test:
Test: 0.4031782161524195
0.4031782161524195
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.40it/s]100%|██████████| 2/2 [00:00<00:00,  2.28it/s]100%|██████████| 2/2 [00:00<00:00,  2.30it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.6467175483703613
Epoch 1, Loop Feat 0: -0.6474489569664001
Epoch 1, Loop Adj 0: -0.676156759262085
Epoch 2: -0.676156759262085
Mem used: -514MB
best_loss: tensor(-0.8036, device='cuda:1')
best_loss: tensor(-0.8124, device='cuda:1')
final loss: -0.7876482605934143
Test:
Test: 0.40671893441240936
0.40671893441240936
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.16it/s]100%|██████████| 2/2 [00:00<00:00,  2.21it/s]100%|██████████| 2/2 [00:00<00:00,  2.31it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6630133986473083
Epoch 1, Loop Feat 0: -0.6653102040290833
Epoch 1, Loop Adj 0: -0.6868849396705627
Epoch 2: -0.6868849396705627
Mem used: -704MB
best_loss: tensor(-0.8199, device='cuda:1')
best_loss: tensor(-0.8299, device='cuda:1')
final loss: -0.8024965524673462
Test:
Test: 0.4276260327094925
0.4276260327094925
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.69it/s]100%|██████████| 2/2 [00:01<00:00,  1.63it/s]100%|██████████| 2/2 [00:01<00:00,  1.74it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.6589507460594177
Epoch 1, Loop Feat 0: -0.6550219655036926
Epoch 1, Loop Adj 0: -0.6878458261489868
Epoch 2: -0.6878458261489868
Mem used: -283MB
best_loss: tensor(-0.8124, device='cuda:1')
best_loss: tensor(-0.8192, device='cuda:1')
final loss: -0.7942196726799011
Test:
Test: 0.4147698533131007
0.4147698533131007
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.36it/s]100%|██████████| 2/2 [00:00<00:00,  2.75it/s]100%|██████████| 2/2 [00:00<00:00,  2.83it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.6326051950454712
Epoch 1, Loop Feat 0: -0.6340521574020386
Epoch 1, Loop Adj 0: -0.6609975695610046
Epoch 2: -0.6609975695610046
Mem used: -655MB
best_loss: tensor(-0.7968, device='cuda:1')
best_loss: tensor(-0.8059, device='cuda:1')
final loss: -0.7803857326507568
Test:
Test: 0.4128308885516776
0.4128308885516776
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.21it/s]100%|██████████| 2/2 [00:00<00:00,  2.13it/s]100%|██████████| 2/2 [00:00<00:00,  2.25it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6706709861755371
Epoch 1, Loop Feat 0: -0.6713428497314453
Epoch 1, Loop Adj 0: -0.6991886496543884
Epoch 2: -0.6991886496543884
Mem used: -900MB
best_loss: tensor(-0.8403, device='cuda:1')
best_loss: tensor(-0.8405, device='cuda:1')
final loss: -0.8074867725372314
Test:
Test: 0.42151407857022427
0.42151407857022427
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.96it/s]100%|██████████| 2/2 [00:00<00:00,  2.74it/s]100%|██████████| 2/2 [00:00<00:00,  2.73it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6704381108283997
Epoch 1, Loop Feat 0: -0.6624382734298706
Epoch 1, Loop Adj 0: -0.6884693503379822
Epoch 2: -0.6884693503379822
Mem used: -686MB
best_loss: tensor(-0.8283, device='cuda:1')
final loss: -0.8030495047569275
Test:
Test: 0.42475973697521496
0.42475973697521496
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.19it/s]100%|██████████| 2/2 [00:00<00:00,  2.19it/s]100%|██████████| 2/2 [00:00<00:00,  2.29it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.6442331075668335
Epoch 1, Loop Feat 0: -0.6420249938964844
Epoch 1, Loop Adj 0: -0.6706602573394775
Epoch 2: -0.6706602573394775
Mem used: -758MB
best_loss: tensor(-0.8071, device='cuda:1')
best_loss: tensor(-0.8075, device='cuda:1')
final loss: -0.782189130783081
Test:
Test: 0.4208396560445119
0.4208396560445119
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.21it/s]100%|██████████| 2/2 [00:00<00:00,  3.13it/s]100%|██████████| 2/2 [00:00<00:00,  3.14it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.665550947189331
Epoch 1, Loop Feat 0: -0.6596377491950989
Epoch 1, Loop Adj 0: -0.6942651271820068
Epoch 2: -0.6942651271820068
Mem used: -900MB
best_loss: tensor(-0.8315, device='cuda:1')
final loss: -0.806614875793457
Test:
Test: 0.4065503287809813
0.4065503287809813
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.43it/s]100%|██████████| 2/2 [00:00<00:00,  4.08it/s]100%|██████████| 2/2 [00:00<00:00,  3.96it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6711763143539429
Epoch 1, Loop Feat 0: -0.665088415145874
Epoch 1, Loop Adj 0: -0.7018871307373047
Epoch 2: -0.7018871307373047
Mem used: -2168MB
best_loss: tensor(-0.8356, device='cuda:1')
best_loss: tensor(-0.8358, device='cuda:1')
final loss: -0.8112103939056396
Test:
Test: 0.4159922441409543
0.4159922441409543
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.91it/s]100%|██████████| 2/2 [00:00<00:00,  2.79it/s]100%|██████████| 2/2 [00:00<00:00,  2.80it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.6571148633956909
Epoch 1, Loop Feat 0: -0.6566063165664673
Epoch 1, Loop Adj 0: -0.6841182708740234
Epoch 2: -0.6841182708740234
Mem used: -712MB
best_loss: tensor(-0.8291, device='cuda:1')
best_loss: tensor(-0.8293, device='cuda:1')
final loss: -0.8022045493125916
Test:
Test: 0.4035154274152757
0.4035154274152757
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  1.51it/s]100%|██████████| 2/2 [00:01<00:00,  1.55it/s]100%|██████████| 2/2 [00:01<00:00,  1.54it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.6467185616493225
Epoch 1, Loop Feat 0: -0.647777795791626
Epoch 1, Loop Adj 0: -0.6764348745346069
Epoch 2: -0.6764348745346069
Mem used: -1495MB
best_loss: tensor(-0.8128, device='cuda:1')
best_loss: tensor(-0.8130, device='cuda:1')
final loss: -0.7889686226844788
Test:
Test: 0.40608666329455406
0.40608666329455406
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.42it/s]100%|██████████| 2/2 [00:00<00:00,  3.03it/s]100%|██████████| 2/2 [00:00<00:00,  2.92it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6630133986473083
Epoch 1, Loop Feat 0: -0.665546715259552
Epoch 1, Loop Adj 0: -0.6871354579925537
Epoch 2: -0.6871354579925537
Mem used: -749MB
best_loss: tensor(-0.8301, device='cuda:1')
best_loss: tensor(-0.8304, device='cuda:1')
final loss: -0.8034784197807312
Test:
Test: 0.4280053953802057
0.4280053953802057
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.08it/s]100%|██████████| 2/2 [00:00<00:00,  3.54it/s]100%|██████████| 2/2 [00:00<00:00,  3.46it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.6589507460594177
Epoch 1, Loop Feat 0: -0.6554659008979797
Epoch 1, Loop Adj 0: -0.6881308555603027
Epoch 2: -0.6881308555603027
Mem used: -772MB
best_loss: tensor(-0.8201, device='cuda:1')
best_loss: tensor(-0.8201, device='cuda:1')
final loss: -0.7951939105987549
Test:
Test: 0.4145169448659585
0.4145169448659585
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.36it/s]100%|██████████| 2/2 [00:00<00:00,  2.12it/s]100%|██████████| 2/2 [00:00<00:00,  2.15it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.6326051354408264
Epoch 1, Loop Feat 0: -0.6343383193016052
Epoch 1, Loop Adj 0: -0.6610987782478333
Epoch 2: -0.6610987782478333
Mem used: -437MB
best_loss: tensor(-0.8061, device='cuda:1')
best_loss: tensor(-0.8062, device='cuda:1')
final loss: -0.7820085287094116
Test:
Test: 0.4136317653009611
0.4136317653009611
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.04it/s]100%|██████████| 1/1 [00:00<00:00,  2.04it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6330797076225281
Epoch 1: -0.6330797076225281
Mem used: -585MB
best_loss: tensor(-0.6790, device='cuda:1')
best_loss: tensor(-0.6807, device='cuda:1')
final loss: -0.6584515571594238
Test:
Test: 0.454940145000843
0.454940145000843
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.44it/s]100%|██████████| 1/1 [00:00<00:00,  2.43it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6295340657234192
Epoch 1: -0.6295340657234192
Mem used: -900MB
best_loss: tensor(-0.6648, device='cuda:1')
best_loss: tensor(-0.6660, device='cuda:1')
final loss: -0.6488616466522217
Test:
Test: 0.4583544090372618
0.4583544090372618
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.84it/s]100%|██████████| 1/1 [00:00<00:00,  2.84it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.6023542881011963
Epoch 1: -0.6023542881011963
Mem used: -782MB
best_loss: tensor(-0.6461, device='cuda:1')
best_loss: tensor(-0.6469, device='cuda:1')
final loss: -0.6293072700500488
Test:
Test: 0.4564575956836958
0.4564575956836958
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.66it/s]100%|██████████| 1/1 [00:00<00:00,  2.66it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011685371399
Epoch 0, Loop Adj 0: -0.6233816742897034
Epoch 1: -0.6233816742897034
Mem used: -1495MB
best_loss: tensor(-0.6631, device='cuda:1')
final loss: -0.6457242965698242
Test:
Test: 0.4633282751643905
0.4633282751643905
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.88it/s]100%|██████████| 1/1 [00:00<00:00,  2.88it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.621468722820282
Epoch 1: -0.621468722820282
Mem used: -838MB
best_loss: tensor(-0.6572, device='cuda:1')
final loss: -0.6421880125999451
Test:
Test: 0.4565418984994099
0.4565418984994099
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.95it/s]100%|██████████| 1/1 [00:00<00:00,  2.68it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961389541625977
Epoch 0, Loop Adj 0: -0.6129634976387024
Epoch 1: -0.6129634976387024
Mem used: -900MB
best_loss: tensor(-0.6586, device='cuda:1')
best_loss: tensor(-0.6617, device='cuda:1')
final loss: -0.6431730389595032
Test:
Test: 0.4540971168437026
0.4540971168437026
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.99it/s]100%|██████████| 1/1 [00:00<00:00,  2.99it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.591787576675415
Epoch 1: -0.591787576675415
Mem used: -748MB
best_loss: tensor(-0.6342, device='cuda:1')
best_loss: tensor(-0.6367, device='cuda:1')
final loss: -0.6186112761497498
Test:
Test: 0.44798516270443434
0.44798516270443434
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.57it/s]100%|██████████| 1/1 [00:00<00:00,  4.56it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6288900375366211
Epoch 1: -0.6288900375366211
Mem used: -2824MB
best_loss: tensor(-0.6738, device='cuda:1')
final loss: -0.6578753590583801
Test:
Test: 0.4616422188501096
0.4616422188501096
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.64it/s]100%|██████████| 1/1 [00:00<00:00,  2.64it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.6072772741317749
Epoch 1: -0.6072772741317749
Mem used: -650MB
best_loss: tensor(-0.6419, device='cuda:1')
final loss: -0.6237425804138184
Test:
Test: 0.4495869162030012
0.4495869162030012
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.79it/s]100%|██████████| 1/1 [00:00<00:00,  2.79it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5905102491378784
Epoch 1: -0.5905102491378784
Mem used: -732MB
best_loss: tensor(-0.6370, device='cuda:1')
best_loss: tensor(-0.6386, device='cuda:1')
final loss: -0.621177613735199
Test:
Test: 0.4591131343786882
0.4591131343786882
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.09it/s]100%|██████████| 1/1 [00:00<00:00,  3.09it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6330797076225281
Epoch 1: -0.6330797076225281
Mem used: -900MB
best_loss: tensor(-0.6745, device='cuda:1')
best_loss: tensor(-0.6786, device='cuda:1')
final loss: -0.657514750957489
Test:
Test: 0.45666835272298095
0.45666835272298095
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.06it/s]100%|██████████| 1/1 [00:00<00:00,  3.05it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194772720337
Epoch 0, Loop Adj 0: -0.629534125328064
Epoch 1: -0.629534125328064
Mem used: -776MB
best_loss: tensor(-0.6593, device='cuda:1')
best_loss: tensor(-0.6630, device='cuda:1')
final loss: -0.646964967250824
Test:
Test: 0.4589866801551172
0.4589866801551172
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.11it/s]100%|██████████| 1/1 [00:00<00:00,  3.11it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.6023542881011963
Epoch 1: -0.6023542881011963
Mem used: -900MB
best_loss: tensor(-0.6406, device='cuda:1')
best_loss: tensor(-0.6457, device='cuda:1')
final loss: -0.6299344897270203
Test:
Test: 0.4595767998651155
0.4595767998651155
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.21it/s]100%|██████████| 1/1 [00:00<00:00,  2.20it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.6233816146850586
Epoch 1: -0.6233816146850586
Mem used: -76MB
best_loss: tensor(-0.6564, device='cuda:1')
best_loss: tensor(-0.6595, device='cuda:1')
final loss: -0.6465826630592346
Test:
Test: 0.46530939133367055
0.46530939133367055
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.95it/s]100%|██████████| 1/1 [00:00<00:00,  2.95it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.621468722820282
Epoch 1: -0.621468722820282
Mem used: -794MB
best_loss: tensor(-0.6525, device='cuda:1')
best_loss: tensor(-0.6573, device='cuda:1')
final loss: -0.642507791519165
Test:
Test: 0.4584387118529759
0.4584387118529759
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.66it/s]100%|██████████| 1/1 [00:00<00:00,  3.65it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.6129634976387024
Epoch 1: -0.6129634976387024
Mem used: -900MB
best_loss: tensor(-0.6557, device='cuda:1')
best_loss: tensor(-0.6590, device='cuda:1')
final loss: -0.6406407356262207
Test:
Test: 0.45574102175012643
0.45574102175012643
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.08it/s]100%|██████████| 1/1 [00:00<00:00,  3.07it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.591787576675415
Epoch 1: -0.591787576675415
Mem used: -2MB
best_loss: tensor(-0.6316, device='cuda:1')
best_loss: tensor(-0.6351, device='cuda:1')
final loss: -0.616448700428009
Test:
Test: 0.4489967964930029
0.4489967964930029
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.50it/s]100%|██████████| 1/1 [00:00<00:00,  3.49it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6288900375366211
Epoch 1: -0.6288900375366211
Mem used: -698MB
best_loss: tensor(-0.6681, device='cuda:1')
final loss: -0.6533992886543274
Test:
Test: 0.46290676108582024
0.46290676108582024
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.82it/s]100%|██████████| 1/1 [00:00<00:00,  2.81it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.6072772741317749
Epoch 1: -0.6072772741317749
Mem used: -796MB
best_loss: tensor(-0.6373, device='cuda:1')
best_loss: tensor(-0.6414, device='cuda:1')
final loss: -0.6252354383468628
Test:
Test: 0.4507250042151408
0.4507250042151408
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.16it/s]100%|██████████| 1/1 [00:00<00:00,  3.16it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5905102491378784
Epoch 1: -0.5905102491378784
Mem used: -726MB
best_loss: tensor(-0.6321, device='cuda:1')
best_loss: tensor(-0.6358, device='cuda:1')
final loss: -0.6199980974197388
Test:
Test: 0.45999831394368573
0.45999831394368573
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.86it/s]100%|██████████| 1/1 [00:00<00:00,  4.86it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6330797076225281
Epoch 1: -0.6330797076225281
Mem used: -810MB
best_loss: tensor(-0.6816, device='cuda:1')
final loss: -0.6593083739280701
Test:
Test: 0.4527061203844208
0.4527061203844208
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.90it/s]100%|██████████| 1/1 [00:00<00:00,  2.90it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.629534125328064
Epoch 1: -0.629534125328064
Mem used: -882MB
best_loss: tensor(-0.6663, device='cuda:1')
best_loss: tensor(-0.6668, device='cuda:1')
final loss: -0.649665355682373
Test:
Test: 0.4583965604451189
0.4583965604451189
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.28it/s]100%|██████████| 1/1 [00:00<00:00,  2.27it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.6023542881011963
Epoch 1: -0.6023542881011963
Mem used: -2447MB
best_loss: tensor(-0.6475, device='cuda:1')
best_loss: tensor(-0.6478, device='cuda:1')
final loss: -0.6299706101417542
Test:
Test: 0.454897993592986
0.454897993592986
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.49it/s]100%|██████████| 1/1 [00:00<00:00,  3.48it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.6233816146850586
Epoch 1: -0.6233816146850586
Mem used: -660MB
best_loss: tensor(-0.6637, device='cuda:1')
final loss: -0.646945059299469
Test:
Test: 0.46193727870510876
0.46193727870510876
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.82it/s]100%|██████████| 1/1 [00:00<00:00,  2.82it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.621468722820282
Epoch 1: -0.621468722820282
Mem used: -588MB
best_loss: tensor(-0.6599, device='cuda:1')
best_loss: tensor(-0.6603, device='cuda:1')
final loss: -0.6446150541305542
Test:
Test: 0.4563732928679818
0.4563732928679818
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.59it/s]100%|██████████| 1/1 [00:00<00:00,  3.59it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.6129634976387024
Epoch 1: -0.6129634976387024
Mem used: -592MB
best_loss: tensor(-0.6625, device='cuda:1')
final loss: -0.6429339051246643
Test:
Test: 0.45220030349013657
0.45220030349013657
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.02it/s]100%|██████████| 1/1 [00:00<00:00,  4.02it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.591787576675415
Epoch 1: -0.591787576675415
Mem used: -820MB
best_loss: tensor(-0.6371, device='cuda:1')
best_loss: tensor(-0.6373, device='cuda:1')
final loss: -0.6188713312149048
Test:
Test: 0.44655201483729556
0.44655201483729556
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.60it/s]100%|██████████| 1/1 [00:00<00:00,  4.59it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6288900375366211
Epoch 1: -0.6288900375366211
Mem used: -900MB
best_loss: tensor(-0.6748, device='cuda:1')
final loss: -0.660372257232666
Test:
Test: 0.4594924970494014
0.4594924970494014
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.46it/s]100%|██████████| 1/1 [00:00<00:00,  4.46it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.6072772145271301
Epoch 1: -0.6072772145271301
Mem used: -798MB
best_loss: tensor(-0.6424, device='cuda:1')
best_loss: tensor(-0.6426, device='cuda:1')
final loss: -0.6260564923286438
Test:
Test: 0.44844882819086157
0.44844882819086157
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.63it/s]100%|██████████| 1/1 [00:00<00:00,  3.63it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5905102491378784
Epoch 1: -0.5905102491378784
Mem used: -494MB
best_loss: tensor(-0.6387, device='cuda:1')
best_loss: tensor(-0.6388, device='cuda:1')
final loss: -0.6222453713417053
Test:
Test: 0.45852301466868994
0.45852301466868994
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.22it/s]100%|██████████| 2/2 [00:00<00:00,  2.71it/s]100%|██████████| 2/2 [00:00<00:00,  2.63it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6330797076225281
Epoch 1, Loop Feat 0: -0.6324247717857361
Epoch 1, Loop Adj 0: -0.6496412754058838
Epoch 2: -0.6496412754058838
Mem used: -2577MB
best_loss: tensor(-0.7020, device='cuda:1')
best_loss: tensor(-0.7030, device='cuda:1')
final loss: -0.6824032664299011
Test:
Test: 0.45363345135727534
0.45363345135727534
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.66it/s]100%|██████████| 2/2 [00:00<00:00,  2.46it/s]100%|██████████| 2/2 [00:00<00:00,  2.49it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6295340657234192
Epoch 1, Loop Feat 0: -0.6232921481132507
Epoch 1, Loop Adj 0: -0.6348770260810852
Epoch 2: -0.6348770260810852
Mem used: -588MB
best_loss: tensor(-0.6876, device='cuda:1')
best_loss: tensor(-0.6883, device='cuda:1')
final loss: -0.6741853952407837
Test:
Test: 0.45966110268082955
0.45966110268082955
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.90it/s]100%|██████████| 2/2 [00:00<00:00,  2.86it/s]100%|██████████| 2/2 [00:00<00:00,  3.05it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.6023542881011963
Epoch 1, Loop Feat 0: -0.5994032621383667
Epoch 1, Loop Adj 0: -0.6158592700958252
Epoch 2: -0.6158592700958252
Mem used: -83MB
best_loss: tensor(-0.6679, device='cuda:1')
best_loss: tensor(-0.6700, device='cuda:1')
final loss: -0.6555073261260986
Test:
Test: 0.45742707806440736
0.45742707806440736
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.59it/s]100%|██████████| 2/2 [00:00<00:00,  2.45it/s]100%|██████████| 2/2 [00:00<00:00,  2.47it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.6233816742897034
Epoch 1, Loop Feat 0: -0.61460280418396
Epoch 1, Loop Adj 0: -0.6379545331001282
Epoch 2: -0.6379545331001282
Mem used: -314MB
best_loss: tensor(-0.6868, device='cuda:1')
best_loss: tensor(-0.6874, device='cuda:1')
final loss: -0.6738955974578857
Test:
Test: 0.46189512729725174
0.46189512729725174
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  1.70it/s]100%|██████████| 2/2 [00:01<00:00,  1.96it/s]100%|██████████| 2/2 [00:01<00:00,  1.92it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.621468722820282
Epoch 1, Loop Feat 0: -0.6122483015060425
Epoch 1, Loop Adj 0: -0.6333338618278503
Epoch 2: -0.6333338618278503
Mem used: -77MB
best_loss: tensor(-0.6832, device='cuda:1')
best_loss: tensor(-0.6854, device='cuda:1')
final loss: -0.6732531785964966
Test:
Test: 0.45814365199797674
0.45814365199797674
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.73it/s]100%|██████████| 2/2 [00:00<00:00,  1.97it/s]100%|██████████| 2/2 [00:00<00:00,  2.05it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.6129634976387024
Epoch 1, Loop Feat 0: -0.6104461550712585
Epoch 1, Loop Adj 0: -0.6263492703437805
Epoch 2: -0.6263492703437805
Mem used: -351MB
best_loss: tensor(-0.6847, device='cuda:1')
best_loss: tensor(-0.6861, device='cuda:1')
final loss: -0.6705197691917419
Test:
Test: 0.45274827179227783
0.45274827179227783
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.56it/s]100%|██████████| 2/2 [00:00<00:00,  2.26it/s]100%|██████████| 2/2 [00:00<00:00,  2.30it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5917875170707703
Epoch 1, Loop Feat 0: -0.5897591710090637
Epoch 1, Loop Adj 0: -0.6068335175514221
Epoch 2: -0.6068335175514221
Mem used: -8MB
best_loss: tensor(-0.6641, device='cuda:1')
best_loss: tensor(-0.6649, device='cuda:1')
final loss: -0.6502220630645752
Test:
Test: 0.4482802225594335
0.4482802225594335
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.46it/s]100%|██████████| 2/2 [00:00<00:00,  2.93it/s]100%|██████████| 2/2 [00:00<00:00,  2.99it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6288900375366211
Epoch 1, Loop Feat 0: -0.6315767765045166
Epoch 1, Loop Adj 0: -0.6430379152297974
Epoch 2: -0.6430379152297974
Mem used: -270MB
best_loss: tensor(-0.6922, device='cuda:1')
best_loss: tensor(-0.6934, device='cuda:1')
final loss: -0.6817140579223633
Test:
Test: 0.458691620300118
0.458691620300118
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.77it/s]100%|██████████| 2/2 [00:00<00:00,  2.87it/s]100%|██████████| 2/2 [00:00<00:00,  2.85it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.6072772145271301
Epoch 1, Loop Feat 0: -0.6003803014755249
Epoch 1, Loop Adj 0: -0.613635778427124
Epoch 2: -0.613635778427124
Mem used: -668MB
best_loss: tensor(-0.6670, device='cuda:1')
best_loss: tensor(-0.6682, device='cuda:1')
final loss: -0.6539545059204102
Test:
Test: 0.4524532119372787
0.4524532119372787
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.28it/s]100%|██████████| 2/2 [00:00<00:00,  2.53it/s]100%|██████████| 2/2 [00:00<00:00,  2.49it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5905102491378784
Epoch 1, Loop Feat 0: -0.5906060338020325
Epoch 1, Loop Adj 0: -0.6065888404846191
Epoch 2: -0.6065888404846191
Mem used: -1943MB
best_loss: tensor(-0.6620, device='cuda:1')
final loss: -0.6470486521720886
Test:
Test: 0.45966110268082955
0.45966110268082955
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.00it/s]100%|██████████| 2/2 [00:00<00:00,  2.91it/s]100%|██████████| 2/2 [00:00<00:00,  3.03it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6330797076225281
Epoch 1, Loop Feat 0: -0.6282941102981567
Epoch 1, Loop Adj 0: -0.6450409293174744
Epoch 2: -0.6450409293174744
Mem used: -900MB
best_loss: tensor(-0.7016, device='cuda:1')
final loss: -0.6835686564445496
Test:
Test: 0.45295902883156297
0.45295902883156297
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.89it/s]100%|██████████| 2/2 [00:00<00:00,  2.97it/s]100%|██████████| 2/2 [00:00<00:00,  3.07it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6295340657234192
Epoch 1, Loop Feat 0: -0.6185327768325806
Epoch 1, Loop Adj 0: -0.6299118995666504
Epoch 2: -0.6299118995666504
Mem used: -722MB
best_loss: tensor(-0.6884, device='cuda:1')
final loss: -0.6753970980644226
Test:
Test: 0.4599561625358287
0.4599561625358287
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.04it/s]100%|██████████| 2/2 [00:00<00:00,  2.36it/s]100%|██████████| 2/2 [00:00<00:00,  2.51it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.6023542881011963
Epoch 1, Loop Feat 0: -0.5956120491027832
Epoch 1, Loop Adj 0: -0.6108516454696655
Epoch 2: -0.6108516454696655
Mem used: -900MB
best_loss: tensor(-0.6699, device='cuda:1')
final loss: -0.657107949256897
Test:
Test: 0.4601669195751138
0.4601669195751138
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.85it/s]100%|██████████| 2/2 [00:00<00:00,  2.99it/s]100%|██████████| 2/2 [00:00<00:00,  3.09it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011685371399
Epoch 0, Loop Adj 0: -0.6233816742897034
Epoch 1, Loop Feat 0: -0.6104814410209656
Epoch 1, Loop Adj 0: -0.6326131820678711
Epoch 2: -0.6326131820678711
Mem used: -2407MB
best_loss: tensor(-0.6856, device='cuda:1')
final loss: -0.6732351779937744
Test:
Test: 0.4651829371100995
0.4651829371100995
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.59it/s]100%|██████████| 2/2 [00:00<00:00,  2.30it/s]100%|██████████| 2/2 [00:00<00:00,  2.33it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.621468722820282
Epoch 1, Loop Feat 0: -0.6063398718833923
Epoch 1, Loop Adj 0: -0.6276982426643372
Epoch 2: -0.6276982426643372
Mem used: -454MB
best_loss: tensor(-0.6849, device='cuda:1')
final loss: -0.6738690137863159
Test:
Test: 0.46122070477153937
0.46122070477153937
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.11it/s]100%|██████████| 2/2 [00:00<00:00,  2.65it/s]100%|██████████| 2/2 [00:00<00:00,  2.71it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.6129634976387024
Epoch 1, Loop Feat 0: -0.6060823202133179
Epoch 1, Loop Adj 0: -0.6220846176147461
Epoch 2: -0.6220846176147461
Mem used: -2168MB
best_loss: tensor(-0.6848, device='cuda:1')
best_loss: tensor(-0.6848, device='cuda:1')
final loss: -0.6682393550872803
Test:
Test: 0.453043331647277
0.453043331647277
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.25it/s]100%|██████████| 2/2 [00:00<00:00,  2.62it/s]100%|██████████| 2/2 [00:00<00:00,  2.52it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.591787576675415
Epoch 1, Loop Feat 0: -0.5844047665596008
Epoch 1, Loop Adj 0: -0.6018050909042358
Epoch 2: -0.6018050909042358
Mem used: -2824MB
best_loss: tensor(-0.6664, device='cuda:1')
final loss: -0.6506121754646301
Test:
Test: 0.4515258809644242
0.4515258809644242
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.09it/s]100%|██████████| 2/2 [00:00<00:00,  2.79it/s]100%|██████████| 2/2 [00:00<00:00,  2.99it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6288900375366211
Epoch 1, Loop Feat 0: -0.6279423832893372
Epoch 1, Loop Adj 0: -0.6386592984199524
Epoch 2: -0.6386592984199524
Mem used: -458MB
best_loss: tensor(-0.6913, device='cuda:1')
final loss: -0.6807821393013
Test:
Test: 0.46248524700725
0.46248524700725
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.19it/s]100%|██████████| 2/2 [00:00<00:00,  2.69it/s]100%|██████████| 2/2 [00:00<00:00,  2.75it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.6072772741317749
Epoch 1, Loop Feat 0: -0.5950545072555542
Epoch 1, Loop Adj 0: -0.6090890169143677
Epoch 2: -0.6090890169143677
Mem used: -752MB
best_loss: tensor(-0.6691, device='cuda:1')
final loss: -0.6557576060295105
Test:
Test: 0.45249536334513574
0.45249536334513574
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.44it/s]100%|██████████| 2/2 [00:00<00:00,  3.42it/s]100%|██████████| 2/2 [00:00<00:00,  3.54it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5905102491378784
Epoch 1, Loop Feat 0: -0.5873122811317444
Epoch 1, Loop Adj 0: -0.6023558378219604
Epoch 2: -0.6023558378219604
Mem used: -596MB
best_loss: tensor(-0.6613, device='cuda:1')
final loss: -0.6473501324653625
Test:
Test: 0.4584808632608329
0.4584808632608329
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.45it/s]100%|██████████| 2/2 [00:00<00:00,  2.52it/s]100%|██████████| 2/2 [00:00<00:00,  2.63it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6330797076225281
Epoch 1, Loop Feat 0: -0.633931577205658
Epoch 1, Loop Adj 0: -0.6507347822189331
Epoch 2: -0.6507347822189331
Mem used: -694MB
best_loss: tensor(-0.7029, device='cuda:1')
best_loss: tensor(-0.7031, device='cuda:1')
final loss: -0.6836423277854919
Test:
Test: 0.4532119372787051
0.4532119372787051
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.59it/s]100%|██████████| 2/2 [00:00<00:00,  2.05it/s]100%|██████████| 2/2 [00:00<00:00,  2.11it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.629534125328064
Epoch 1, Loop Feat 0: -0.6249610185623169
Epoch 1, Loop Adj 0: -0.6368882060050964
Epoch 2: -0.6368882060050964
Mem used: -257MB
best_loss: tensor(-0.6893, device='cuda:1')
best_loss: tensor(-0.6894, device='cuda:1')
final loss: -0.6751412749290466
Test:
Test: 0.4590709829708312
0.4590709829708312
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.32it/s]100%|██████████| 2/2 [00:00<00:00,  4.40it/s]100%|██████████| 2/2 [00:00<00:00,  4.19it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.6023542881011963
Epoch 1, Loop Feat 0: -0.6009124517440796
Epoch 1, Loop Adj 0: -0.6174381971359253
Epoch 2: -0.6174381971359253
Mem used: -900MB
best_loss: tensor(-0.6709, device='cuda:1')
best_loss: tensor(-0.6710, device='cuda:1')
final loss: -0.6553472876548767
Test:
Test: 0.4571320182094082
0.4571320182094082
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.62it/s]100%|██████████| 2/2 [00:00<00:00,  2.87it/s]100%|██████████| 2/2 [00:00<00:00,  2.83it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.6233816742897034
Epoch 1, Loop Feat 0: -0.6160821318626404
Epoch 1, Loop Adj 0: -0.6398493051528931
Epoch 2: -0.6398493051528931
Mem used: -2824MB
best_loss: tensor(-0.6885, device='cuda:1')
final loss: -0.6739190816879272
Test:
Test: 0.46189512729725174
0.46189512729725174
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.92it/s]100%|██████████| 2/2 [00:00<00:00,  3.41it/s]100%|██████████| 2/2 [00:00<00:00,  3.32it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.621468722820282
Epoch 1, Loop Feat 0: -0.6149516701698303
Epoch 1, Loop Adj 0: -0.6355782151222229
Epoch 2: -0.6355782151222229
Mem used: -794MB
best_loss: tensor(-0.6854, device='cuda:1')
best_loss: tensor(-0.6858, device='cuda:1')
final loss: -0.6733933687210083
Test:
Test: 0.4590709829708312
0.4590709829708312
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.46it/s]100%|██████████| 2/2 [00:00<00:00,  2.67it/s]100%|██████████| 2/2 [00:00<00:00,  2.63it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.6129634976387024
Epoch 1, Loop Feat 0: -0.6125779151916504
Epoch 1, Loop Adj 0: -0.6278412938117981
Epoch 2: -0.6278412938117981
Mem used: -722MB
best_loss: tensor(-0.6870, device='cuda:1')
best_loss: tensor(-0.6874, device='cuda:1')
final loss: -0.6704186201095581
Test:
Test: 0.45236890912156463
0.45236890912156463
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.48it/s]100%|██████████| 2/2 [00:00<00:00,  2.97it/s]100%|██████████| 2/2 [00:00<00:00,  3.12it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.591787576675415
Epoch 1, Loop Feat 0: -0.5921516418457031
Epoch 1, Loop Adj 0: -0.608971893787384
Epoch 2: -0.608971893787384
Mem used: -900MB
best_loss: tensor(-0.6656, device='cuda:1')
best_loss: tensor(-0.6660, device='cuda:1')
final loss: -0.6505618095397949
Test:
Test: 0.4460040465351543
0.4460040465351543
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.39it/s]100%|██████████| 2/2 [00:00<00:00,  2.87it/s]100%|██████████| 2/2 [00:00<00:00,  2.79it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6288900375366211
Epoch 1, Loop Feat 0: -0.6329054236412048
Epoch 1, Loop Adj 0: -0.6446738243103027
Epoch 2: -0.6446738243103027
Mem used: -900MB
best_loss: tensor(-0.6946, device='cuda:1')
final loss: -0.6826900243759155
Test:
Test: 0.4583965604451189
0.4583965604451189
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.27it/s]100%|██████████| 2/2 [00:00<00:00,  2.96it/s]100%|██████████| 2/2 [00:00<00:00,  3.10it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.6072772145271301
Epoch 1, Loop Feat 0: -0.6025709509849548
Epoch 1, Loop Adj 0: -0.6157233119010925
Epoch 2: -0.6157233119010925
Mem used: -2667MB
best_loss: tensor(-0.6687, device='cuda:1')
best_loss: tensor(-0.6687, device='cuda:1')
final loss: -0.6541712880134583
Test:
Test: 0.45097791266228293
0.45097791266228293
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.74it/s]100%|██████████| 2/2 [00:00<00:00,  2.25it/s]100%|██████████| 2/2 [00:00<00:00,  2.31it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5905102491378784
Epoch 1, Loop Feat 0: -0.5918660759925842
Epoch 1, Loop Adj 0: -0.6077417731285095
Epoch 2: -0.6077417731285095
Mem used: -226MB
best_loss: tensor(-0.6626, device='cuda:1')
best_loss: tensor(-0.6629, device='cuda:1')
final loss: -0.6492113471031189
Test:
Test: 0.4594503456415444
0.4594503456415444
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.15it/s]100%|██████████| 1/1 [00:00<00:00,  4.14it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6330797076225281
Epoch 1: -0.6330797076225281
Mem used: -768MB
best_loss: tensor(-0.6790, device='cuda:1')
best_loss: tensor(-0.6810, device='cuda:1')
final loss: -0.6587494015693665
Test:
Test: 0.454897993592986
0.454897993592986
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.86it/s]100%|██████████| 1/1 [00:00<00:00,  5.85it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.629534125328064
Epoch 1: -0.629534125328064
Mem used: -680MB
best_loss: tensor(-0.6648, device='cuda:1')
best_loss: tensor(-0.6661, device='cuda:1')
final loss: -0.6490271091461182
Test:
Test: 0.458649468892261
0.458649468892261
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.94it/s]100%|██████████| 1/1 [00:00<00:00,  3.93it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.6023542881011963
Epoch 1: -0.6023542881011963
Mem used: -808MB
best_loss: tensor(-0.6461, device='cuda:1')
best_loss: tensor(-0.6468, device='cuda:1')
final loss: -0.6293507814407349
Test:
Test: 0.45574102175012643
0.45574102175012643
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.43it/s]100%|██████████| 1/1 [00:00<00:00,  2.43it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.6233816742897034
Epoch 1: -0.6233816742897034
Mem used: -900MB
best_loss: tensor(-0.6631, device='cuda:1')
final loss: -0.6457242965698242
Test:
Test: 0.4633282751643905
0.4633282751643905
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.30it/s]100%|██████████| 1/1 [00:00<00:00,  3.29it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.621468722820282
Epoch 1: -0.621468722820282
Mem used: -900MB
best_loss: tensor(-0.6572, device='cuda:1')
final loss: -0.6421879529953003
Test:
Test: 0.4565418984994099
0.4565418984994099
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.35it/s]100%|██████████| 1/1 [00:00<00:00,  4.34it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388945579529
Epoch 0, Loop Adj 0: -0.6129634976387024
Epoch 1: -0.6129634976387024
Mem used: -900MB
best_loss: tensor(-0.6586, device='cuda:1')
best_loss: tensor(-0.6617, device='cuda:1')
final loss: -0.642936110496521
Test:
Test: 0.4538442083965604
0.4538442083965604
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.83it/s]100%|██████████| 1/1 [00:00<00:00,  3.82it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.591787576675415
Epoch 1: -0.591787576675415
Mem used: -900MB
best_loss: tensor(-0.6342, device='cuda:1')
best_loss: tensor(-0.6364, device='cuda:1')
final loss: -0.6186836957931519
Test:
Test: 0.4471421345472939
0.4471421345472939
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.87it/s]100%|██████████| 1/1 [00:00<00:00,  2.87it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6288900375366211
Epoch 1: -0.6288900375366211
Mem used: -900MB
best_loss: tensor(-0.6738, device='cuda:1')
final loss: -0.6578753590583801
Test:
Test: 0.4616422188501096
0.4616422188501096
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.49it/s]100%|██████████| 1/1 [00:00<00:00,  3.48it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.6072772741317749
Epoch 1: -0.6072772741317749
Mem used: -734MB
best_loss: tensor(-0.6419, device='cuda:1')
final loss: -0.6237425804138184
Test:
Test: 0.4495869162030012
0.4495869162030012
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.83it/s]100%|██████████| 1/1 [00:00<00:00,  4.82it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5905102491378784
Epoch 1: -0.5905102491378784
Mem used: -900MB
best_loss: tensor(-0.6370, device='cuda:1')
best_loss: tensor(-0.6385, device='cuda:1')
final loss: -0.6220759153366089
Test:
Test: 0.45894452874726016
0.45894452874726016
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.97it/s]100%|██████████| 1/1 [00:00<00:00,  4.96it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6330797076225281
Epoch 1: -0.6330797076225281
Mem used: -900MB
best_loss: tensor(-0.6745, device='cuda:1')
best_loss: tensor(-0.6800, device='cuda:1')
final loss: -0.6582361459732056
Test:
Test: 0.45666835272298095
0.45666835272298095
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.33it/s]100%|██████████| 1/1 [00:00<00:00,  5.32it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.629534125328064
Epoch 1: -0.629534125328064
Mem used: -2824MB
best_loss: tensor(-0.6593, device='cuda:1')
best_loss: tensor(-0.6651, device='cuda:1')
final loss: -0.6488463878631592
Test:
Test: 0.458691620300118
0.458691620300118
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.94it/s]100%|██████████| 1/1 [00:00<00:00,  2.94it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.6023542881011963
Epoch 1: -0.6023542881011963
Mem used: -900MB
best_loss: tensor(-0.6406, device='cuda:1')
best_loss: tensor(-0.6463, device='cuda:1')
final loss: -0.628800094127655
Test:
Test: 0.45666835272298095
0.45666835272298095
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.72it/s]100%|██████████| 1/1 [00:00<00:00,  4.59it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.6233816742897034
Epoch 1: -0.6233816742897034
Mem used: -826MB
best_loss: tensor(-0.6564, device='cuda:1')
best_loss: tensor(-0.6605, device='cuda:1')
final loss: -0.6467199325561523
Test:
Test: 0.4629910639015343
0.4629910639015343
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.27it/s]100%|██████████| 1/1 [00:00<00:00,  3.26it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.621468722820282
Epoch 1: -0.621468722820282
Mem used: -900MB
best_loss: tensor(-0.6525, device='cuda:1')
best_loss: tensor(-0.6589, device='cuda:1')
final loss: -0.643601655960083
Test:
Test: 0.45776428932726354
0.45776428932726354
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.95it/s]100%|██████████| 1/1 [00:00<00:00,  3.95it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.6129634976387024
Epoch 1: -0.6129634976387024
Mem used: -900MB
best_loss: tensor(-0.6557, device='cuda:1')
best_loss: tensor(-0.6602, device='cuda:1')
final loss: -0.6420187950134277
Test:
Test: 0.4541814196594166
0.4541814196594166
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.13it/s]100%|██████████| 1/1 [00:00<00:00,  4.13it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5917875170707703
Epoch 1: -0.5917875170707703
Mem used: -736MB
best_loss: tensor(-0.6316, device='cuda:1')
best_loss: tensor(-0.6362, device='cuda:1')
final loss: -0.6171149611473083
Test:
Test: 0.44806946552014837
0.44806946552014837
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.66it/s]100%|██████████| 1/1 [00:00<00:00,  3.66it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6288900375366211
Epoch 1: -0.6288900375366211
Mem used: -782MB
best_loss: tensor(-0.6681, device='cuda:1')
best_loss: tensor(-0.6723, device='cuda:1')
final loss: -0.659602701663971
Test:
Test: 0.46025122239082783
0.46025122239082783
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.91it/s]100%|██████████| 1/1 [00:00<00:00,  4.90it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.6072772145271301
Epoch 1: -0.6072772145271301
Mem used: -806MB
best_loss: tensor(-0.6373, device='cuda:1')
best_loss: tensor(-0.6418, device='cuda:1')
final loss: -0.6251327991485596
Test:
Test: 0.4497555218344293
0.4497555218344293
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.69it/s]100%|██████████| 1/1 [00:00<00:00,  3.62it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5905102491378784
Epoch 1: -0.5905102491378784
Mem used: -900MB
best_loss: tensor(-0.6321, device='cuda:1')
best_loss: tensor(-0.6370, device='cuda:1')
final loss: -0.6214102506637573
Test:
Test: 0.45886022593154613
0.45886022593154613
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.62it/s]100%|██████████| 1/1 [00:00<00:00,  3.61it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6330797076225281
Epoch 1: -0.6330797076225281
Mem used: -900MB
best_loss: tensor(-0.6816, device='cuda:1')
best_loss: tensor(-0.6817, device='cuda:1')
final loss: -0.6591452956199646
Test:
Test: 0.4531276344629911
0.4531276344629911
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.21it/s]100%|██████████| 1/1 [00:00<00:00,  3.21it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6295340657234192
Epoch 1: -0.6295340657234192
Mem used: -900MB
best_loss: tensor(-0.6663, device='cuda:1')
best_loss: tensor(-0.6669, device='cuda:1')
final loss: -0.6497316360473633
Test:
Test: 0.4583965604451189
0.4583965604451189
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.66it/s]100%|██████████| 1/1 [00:00<00:00,  3.66it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.6023542881011963
Epoch 1: -0.6023542881011963
Mem used: -900MB
best_loss: tensor(-0.6476, device='cuda:1')
best_loss: tensor(-0.6479, device='cuda:1')
final loss: -0.6302897334098816
Test:
Test: 0.454855842185129
0.454855842185129
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.13it/s]100%|██████████| 1/1 [00:00<00:00,  5.13it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.6233816742897034
Epoch 1: -0.6233816742897034
Mem used: -900MB
best_loss: tensor(-0.6637, device='cuda:1')
final loss: -0.6466473340988159
Test:
Test: 0.46193727870510876
0.46193727870510876
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.09it/s]100%|██████████| 1/1 [00:00<00:00,  4.09it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.621468722820282
Epoch 1: -0.621468722820282
Mem used: -900MB
best_loss: tensor(-0.6599, device='cuda:1')
best_loss: tensor(-0.6603, device='cuda:1')
final loss: -0.6446574926376343
Test:
Test: 0.4563732928679818
0.4563732928679818
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.57it/s]100%|██████████| 1/1 [00:00<00:00,  5.56it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.6129634976387024
Epoch 1: -0.6129634976387024
Mem used: -2824MB
best_loss: tensor(-0.6625, device='cuda:1')
best_loss: tensor(-0.6625, device='cuda:1')
final loss: -0.6430020332336426
Test:
Test: 0.4527904232001349
0.4527904232001349
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.02it/s]100%|██████████| 1/1 [00:00<00:00,  4.02it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5917874574661255
Epoch 1: -0.5917874574661255
Mem used: -776MB
best_loss: tensor(-0.6371, device='cuda:1')
best_loss: tensor(-0.6374, device='cuda:1')
final loss: -0.6191589832305908
Test:
Test: 0.44646771202158153
0.44646771202158153
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.70it/s]100%|██████████| 1/1 [00:00<00:00,  3.69it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6288900375366211
Epoch 1: -0.6288900375366211
Mem used: -730MB
best_loss: tensor(-0.6748, device='cuda:1')
final loss: -0.660372257232666
Test:
Test: 0.4594924970494014
0.4594924970494014
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.10it/s]100%|██████████| 1/1 [00:00<00:00,  4.10it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.6072772741317749
Epoch 1: -0.6072772741317749
Mem used: -900MB
best_loss: tensor(-0.6424, device='cuda:1')
best_loss: tensor(-0.6425, device='cuda:1')
final loss: -0.6261687874794006
Test:
Test: 0.4486595852301467
0.4486595852301467
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.46it/s]100%|██████████| 1/1 [00:00<00:00,  3.46it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5905102491378784
Epoch 1: -0.5905102491378784
Mem used: -900MB
best_loss: tensor(-0.6387, device='cuda:1')
best_loss: tensor(-0.6388, device='cuda:1')
final loss: -0.622366189956665
Test:
Test: 0.4583122576294048
0.4583122576294048
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.51it/s]100%|██████████| 2/2 [00:00<00:00,  4.10it/s]100%|██████████| 2/2 [00:00<00:00,  4.15it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6330797076225281
Epoch 1, Loop Feat 0: -0.632588267326355
Epoch 1, Loop Adj 0: -0.6497666835784912
Epoch 2: -0.6497666835784912
Mem used: -900MB
best_loss: tensor(-0.7019, device='cuda:1')
best_loss: tensor(-0.7031, device='cuda:1')
final loss: -0.6835762858390808
Test:
Test: 0.4537599055808464
0.4537599055808464
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.22it/s]100%|██████████| 2/2 [00:00<00:00,  3.11it/s]100%|██████████| 2/2 [00:00<00:00,  3.24it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6295340657234192
Epoch 1, Loop Feat 0: -0.6234789490699768
Epoch 1, Loop Adj 0: -0.6350740790367126
Epoch 2: -0.6350740790367126
Mem used: -638MB
best_loss: tensor(-0.6876, device='cuda:1')
best_loss: tensor(-0.6883, device='cuda:1')
final loss: -0.6738576292991638
Test:
Test: 0.45928174001011635
0.45928174001011635
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.77it/s]100%|██████████| 2/2 [00:00<00:00,  3.13it/s]100%|██████████| 2/2 [00:00<00:00,  3.07it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.6023542881011963
Epoch 1, Loop Feat 0: -0.5995578169822693
Epoch 1, Loop Adj 0: -0.6160470843315125
Epoch 2: -0.6160470843315125
Mem used: -666MB
best_loss: tensor(-0.6684, device='cuda:1')
best_loss: tensor(-0.6702, device='cuda:1')
final loss: -0.656022846698761
Test:
Test: 0.4577221379194065
0.4577221379194065
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.92it/s]100%|██████████| 2/2 [00:00<00:00,  4.24it/s]100%|██████████| 2/2 [00:00<00:00,  4.18it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.6233816742897034
Epoch 1, Loop Feat 0: -0.6147472262382507
Epoch 1, Loop Adj 0: -0.6381478905677795
Epoch 2: -0.6381478905677795
Mem used: -900MB
best_loss: tensor(-0.6870, device='cuda:1')
final loss: -0.6725802421569824
Test:
Test: 0.4667425392008093
0.4667425392008093
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.65it/s]100%|██████████| 2/2 [00:00<00:00,  5.24it/s]100%|██████████| 2/2 [00:00<00:00,  5.13it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.621468722820282
Epoch 1, Loop Feat 0: -0.612497091293335
Epoch 1, Loop Adj 0: -0.6335612535476685
Epoch 2: -0.6335612535476685
Mem used: -900MB
best_loss: tensor(-0.6831, device='cuda:1')
best_loss: tensor(-0.6853, device='cuda:1')
final loss: -0.6721842885017395
Test:
Test: 0.4581015005901197
0.4581015005901197
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.09it/s]100%|██████████| 2/2 [00:00<00:00,  3.44it/s]100%|██████████| 2/2 [00:00<00:00,  3.38it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388945579529
Epoch 0, Loop Adj 0: -0.6129634976387024
Epoch 1, Loop Feat 0: -0.6106545329093933
Epoch 1, Loop Adj 0: -0.6264928579330444
Epoch 2: -0.6264928579330444
Mem used: -584MB
best_loss: tensor(-0.6848, device='cuda:1')
best_loss: tensor(-0.6864, device='cuda:1')
final loss: -0.6714327931404114
Test:
Test: 0.45274827179227783
0.45274827179227783
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.62it/s]100%|██████████| 2/2 [00:00<00:00,  3.42it/s]100%|██████████| 2/2 [00:00<00:00,  3.45it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.591787576675415
Epoch 1, Loop Feat 0: -0.5899839401245117
Epoch 1, Loop Adj 0: -0.6070303320884705
Epoch 2: -0.6070303320884705
Mem used: -900MB
best_loss: tensor(-0.6643, device='cuda:1')
best_loss: tensor(-0.6648, device='cuda:1')
final loss: -0.650755763053894
Test:
Test: 0.4486595852301467
0.4486595852301467
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.98it/s]100%|██████████| 2/2 [00:00<00:00,  4.60it/s]100%|██████████| 2/2 [00:00<00:00,  4.65it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6288900375366211
Epoch 1, Loop Feat 0: -0.6317080855369568
Epoch 1, Loop Adj 0: -0.6432021856307983
Epoch 2: -0.6432021856307983
Mem used: -900MB
best_loss: tensor(-0.6921, device='cuda:1')
best_loss: tensor(-0.6937, device='cuda:1')
final loss: -0.6825423836708069
Test:
Test: 0.4573427752486933
0.4573427752486933
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.82it/s]100%|██████████| 2/2 [00:00<00:00,  3.23it/s]100%|██████████| 2/2 [00:00<00:00,  3.30it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.6072772741317749
Epoch 1, Loop Feat 0: -0.6005737781524658
Epoch 1, Loop Adj 0: -0.613835871219635
Epoch 2: -0.613835871219635
Mem used: -900MB
best_loss: tensor(-0.6672, device='cuda:1')
best_loss: tensor(-0.6680, device='cuda:1')
final loss: -0.6542093753814697
Test:
Test: 0.4516944865958523
0.4516944865958523
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.24it/s]100%|██████████| 2/2 [00:00<00:00,  5.60it/s]100%|██████████| 2/2 [00:00<00:00,  5.54it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5905102491378784
Epoch 1, Loop Feat 0: -0.5907154679298401
Epoch 1, Loop Adj 0: -0.6067171692848206
Epoch 2: -0.6067171692848206
Mem used: -900MB
best_loss: tensor(-0.6619, device='cuda:1')
final loss: -0.647111713886261
Test:
Test: 0.4599561625358287
0.4599561625358287
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.32it/s]100%|██████████| 2/2 [00:00<00:00,  2.68it/s]100%|██████████| 2/2 [00:00<00:00,  2.75it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6330797076225281
Epoch 1, Loop Feat 0: -0.63039630651474
Epoch 1, Loop Adj 0: -0.647763729095459
Epoch 2: -0.647763729095459
Mem used: -742MB
best_loss: tensor(-0.7019, device='cuda:1')
final loss: -0.6834995746612549
Test:
Test: 0.4533383915022762
0.4533383915022762
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.01it/s]100%|██████████| 2/2 [00:00<00:00,  3.61it/s]100%|██████████| 2/2 [00:00<00:00,  3.66it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.629534125328064
Epoch 1, Loop Feat 0: -0.6212894320487976
Epoch 1, Loop Adj 0: -0.6327019929885864
Epoch 2: -0.6327019929885864
Mem used: -768MB
best_loss: tensor(-0.6873, device='cuda:1')
final loss: -0.674946129322052
Test:
Test: 0.4583122576294048
0.4583122576294048
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.33it/s]100%|██████████| 2/2 [00:00<00:00,  3.00it/s]100%|██████████| 2/2 [00:00<00:00,  3.14it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.6023542881011963
Epoch 1, Loop Feat 0: -0.5977910757064819
Epoch 1, Loop Adj 0: -0.6137164235115051
Epoch 2: -0.6137164235115051
Mem used: -38MB
best_loss: tensor(-0.6694, device='cuda:1')
final loss: -0.656189501285553
Test:
Test: 0.46008261675939977
0.46008261675939977
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.35it/s]100%|██████████| 2/2 [00:00<00:00,  3.03it/s]100%|██████████| 2/2 [00:00<00:00,  3.18it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.6233816742897034
Epoch 1, Loop Feat 0: -0.6126855611801147
Epoch 1, Loop Adj 0: -0.6356146931648254
Epoch 2: -0.6356146931648254
Mem used: -610MB
best_loss: tensor(-0.6860, device='cuda:1')
final loss: -0.6737358570098877
Test:
Test: 0.46682684201652336
0.46682684201652336
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.70it/s]100%|██████████| 2/2 [00:00<00:00,  3.84it/s]100%|██████████| 2/2 [00:00<00:00,  3.95it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.621468722820282
Epoch 1, Loop Feat 0: -0.609711229801178
Epoch 1, Loop Adj 0: -0.631030797958374
Epoch 2: -0.631030797958374
Mem used: -714MB
best_loss: tensor(-0.6857, device='cuda:1')
final loss: -0.6745637655258179
Test:
Test: 0.4610942505479683
0.4610942505479683
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.31it/s]100%|██████████| 2/2 [00:00<00:00,  4.18it/s]100%|██████████| 2/2 [00:00<00:00,  4.20it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.6129634976387024
Epoch 1, Loop Feat 0: -0.6083807945251465
Epoch 1, Loop Adj 0: -0.6245977878570557
Epoch 2: -0.6245977878570557
Mem used: -900MB
best_loss: tensor(-0.6856, device='cuda:1')
final loss: -0.6701335906982422
Test:
Test: 0.4541814196594166
0.4541814196594166
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.34it/s]100%|██████████| 2/2 [00:00<00:00,  2.14it/s]100%|██████████| 2/2 [00:00<00:00,  2.26it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.591787576675415
Epoch 1, Loop Feat 0: -0.5874767303466797
Epoch 1, Loop Adj 0: -0.6047900915145874
Epoch 2: -0.6047900915145874
Mem used: -648MB
best_loss: tensor(-0.6659, device='cuda:1')
final loss: -0.650095522403717
Test:
Test: 0.44950261338728714
0.44950261338728714
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.46it/s]100%|██████████| 2/2 [00:00<00:00,  3.44it/s]100%|██████████| 2/2 [00:00<00:00,  3.44it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6288900375366211
Epoch 1, Loop Feat 0: -0.6300451755523682
Epoch 1, Loop Adj 0: -0.6410649418830872
Epoch 2: -0.6410649418830872
Mem used: -900MB
best_loss: tensor(-0.6922, device='cuda:1')
final loss: -0.6805223226547241
Test:
Test: 0.46084134210082617
0.46084134210082617
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.27it/s]100%|██████████| 2/2 [00:00<00:00,  3.08it/s]100%|██████████| 2/2 [00:00<00:00,  3.21it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.6072772741317749
Epoch 1, Loop Feat 0: -0.598361611366272
Epoch 1, Loop Adj 0: -0.6117163300514221
Epoch 2: -0.6117163300514221
Mem used: -900MB
best_loss: tensor(-0.6690, device='cuda:1')
final loss: -0.6563889980316162
Test:
Test: 0.45220030349013657
0.45220030349013657
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.13it/s]100%|██████████| 2/2 [00:00<00:00,  3.29it/s]100%|██████████| 2/2 [00:00<00:00,  3.26it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5905102491378784
Epoch 1, Loop Feat 0: -0.5891096591949463
Epoch 1, Loop Adj 0: -0.6048621535301208
Epoch 2: -0.6048621535301208
Mem used: -900MB
best_loss: tensor(-0.6622, device='cuda:1')
final loss: -0.6489346623420715
Test:
Test: 0.45814365199797674
0.45814365199797674
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.10it/s]100%|██████████| 2/2 [00:00<00:00,  4.29it/s]100%|██████████| 2/2 [00:00<00:00,  4.39it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6330797076225281
Epoch 1, Loop Feat 0: -0.6339684128761292
Epoch 1, Loop Adj 0: -0.6507545113563538
Epoch 2: -0.6507545113563538
Mem used: -900MB
best_loss: tensor(-0.7028, device='cuda:1')
best_loss: tensor(-0.7031, device='cuda:1')
final loss: -0.683095395565033
Test:
Test: 0.45329624009441916
0.45329624009441916
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.93it/s]100%|██████████| 2/2 [00:00<00:00,  2.77it/s]100%|██████████| 2/2 [00:00<00:00,  2.96it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.629534125328064
Epoch 1, Loop Feat 0: -0.6249935626983643
Epoch 1, Loop Adj 0: -0.6369369626045227
Epoch 2: -0.6369369626045227
Mem used: -900MB
best_loss: tensor(-0.6893, device='cuda:1')
best_loss: tensor(-0.6895, device='cuda:1')
final loss: -0.6754968166351318
Test:
Test: 0.4591131343786882
0.4591131343786882
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.19it/s]100%|██████████| 2/2 [00:00<00:00,  3.27it/s]100%|██████████| 2/2 [00:00<00:00,  3.04it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.6023542881011963
Epoch 1, Loop Feat 0: -0.6009491086006165
Epoch 1, Loop Adj 0: -0.6174673438072205
Epoch 2: -0.6174673438072205
Mem used: -900MB
best_loss: tensor(-0.6709, device='cuda:1')
best_loss: tensor(-0.6710, device='cuda:1')
final loss: -0.655413806438446
Test:
Test: 0.45700556398583714
0.45700556398583714
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.66it/s]100%|██████████| 2/2 [00:00<00:00,  2.09it/s]100%|██████████| 2/2 [00:00<00:00,  2.16it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011685371399
Epoch 0, Loop Adj 0: -0.6233816742897034
Epoch 1, Loop Feat 0: -0.6161071062088013
Epoch 1, Loop Adj 0: -0.6398899555206299
Epoch 2: -0.6398899555206299
Mem used: -502MB
best_loss: tensor(-0.6885, device='cuda:1')
final loss: -0.6738173365592957
Test:
Test: 0.46214803574439384
0.46214803574439384
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.69it/s]100%|██████████| 2/2 [00:00<00:00,  3.06it/s]100%|██████████| 2/2 [00:00<00:00,  3.00it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.621468722820282
Epoch 1, Loop Feat 0: -0.6150231957435608
Epoch 1, Loop Adj 0: -0.6356369853019714
Epoch 2: -0.6356369853019714
Mem used: -696MB
best_loss: tensor(-0.6854, device='cuda:1')
best_loss: tensor(-0.6856, device='cuda:1')
final loss: -0.6731756329536438
Test:
Test: 0.458607317484404
0.458607317484404
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.63it/s]100%|██████████| 2/2 [00:00<00:00,  3.94it/s]100%|██████████| 2/2 [00:00<00:00,  3.89it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.6129634976387024
Epoch 1, Loop Feat 0: -0.6126300096511841
Epoch 1, Loop Adj 0: -0.6278719305992126
Epoch 2: -0.6278719305992126
Mem used: -758MB
best_loss: tensor(-0.6869, device='cuda:1')
best_loss: tensor(-0.6872, device='cuda:1')
final loss: -0.6707547307014465
Test:
Test: 0.4519052436351374
0.4519052436351374
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.14it/s]100%|██████████| 2/2 [00:00<00:00,  4.18it/s]100%|██████████| 2/2 [00:00<00:00,  3.98it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5917875170707703
Epoch 1, Loop Feat 0: -0.5922161340713501
Epoch 1, Loop Adj 0: -0.6090263724327087
Epoch 2: -0.6090263724327087
Mem used: -592MB
best_loss: tensor(-0.6654, device='cuda:1')
best_loss: tensor(-0.6659, device='cuda:1')
final loss: -0.6506982445716858
Test:
Test: 0.4459197437194402
0.4459197437194402
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.47it/s]100%|██████████| 2/2 [00:00<00:00,  4.21it/s]100%|██████████| 2/2 [00:00<00:00,  4.07it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6288900375366211
Epoch 1, Loop Feat 0: -0.6329373717308044
Epoch 1, Loop Adj 0: -0.6447057723999023
Epoch 2: -0.6447057723999023
Mem used: -900MB
best_loss: tensor(-0.6946, device='cuda:1')
final loss: -0.682690441608429
Test:
Test: 0.4584808632608329
0.4584808632608329
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.14it/s]100%|██████████| 2/2 [00:00<00:00,  3.57it/s]100%|██████████| 2/2 [00:00<00:00,  3.50it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.6072772741317749
Epoch 1, Loop Feat 0: -0.6026303768157959
Epoch 1, Loop Adj 0: -0.6157838106155396
Epoch 2: -0.6157838106155396
Mem used: -900MB
best_loss: tensor(-0.6687, device='cuda:1')
final loss: -0.6540206670761108
Test:
Test: 0.45144157814871017
0.45144157814871017
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.47it/s]100%|██████████| 2/2 [00:00<00:00,  2.79it/s]100%|██████████| 2/2 [00:00<00:00,  2.74it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5905102491378784
Epoch 1, Loop Feat 0: -0.5918969511985779
Epoch 1, Loop Adj 0: -0.6077656745910645
Epoch 2: -0.6077656745910645
Mem used: -900MB
best_loss: tensor(-0.6627, device='cuda:1')
best_loss: tensor(-0.6630, device='cuda:1')
final loss: -0.6492025256156921
Test:
Test: 0.4594503456415444
0.4594503456415444
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.40it/s]100%|██████████| 1/1 [00:00<00:00,  3.40it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6330797076225281
Epoch 1: -0.6330797076225281
Mem used: -900MB
best_loss: tensor(-0.6790, device='cuda:1')
best_loss: tensor(-0.6815, device='cuda:1')
final loss: -0.6592422723770142
Test:
Test: 0.4539706626201315
0.4539706626201315
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.29it/s]100%|██████████| 1/1 [00:00<00:00,  3.28it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.629534125328064
Epoch 1: -0.629534125328064
Mem used: -900MB
best_loss: tensor(-0.6648, device='cuda:1')
best_loss: tensor(-0.6667, device='cuda:1')
final loss: -0.6491179466247559
Test:
Test: 0.4584387118529759
0.4584387118529759
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.46it/s]100%|██████████| 1/1 [00:00<00:00,  3.46it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.6023542881011963
Epoch 1: -0.6023542881011963
Mem used: -900MB
best_loss: tensor(-0.6461, device='cuda:1')
best_loss: tensor(-0.6478, device='cuda:1')
final loss: -0.6293275952339172
Test:
Test: 0.45519305344798516
0.45519305344798516
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.81it/s]100%|██████████| 1/1 [00:00<00:00,  3.67it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011685371399
Epoch 0, Loop Adj 0: -0.6233815550804138
Epoch 1: -0.6233815550804138
Mem used: -900MB
best_loss: tensor(-0.6631, device='cuda:1')
final loss: -0.6457242369651794
Test:
Test: 0.4633282751643905
0.4633282751643905
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.73it/s]100%|██████████| 1/1 [00:00<00:00,  2.73it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.621468722820282
Epoch 1: -0.621468722820282
Mem used: -900MB
best_loss: tensor(-0.6572, device='cuda:1')
best_loss: tensor(-0.6601, device='cuda:1')
final loss: -0.6444013714790344
Test:
Test: 0.45633114146012477
0.45633114146012477
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.19it/s]100%|██████████| 1/1 [00:00<00:00,  5.18it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388945579529
Epoch 0, Loop Adj 0: -0.6129634976387024
Epoch 1: -0.6129634976387024
Mem used: -900MB
best_loss: tensor(-0.6586, device='cuda:1')
best_loss: tensor(-0.6623, device='cuda:1')
final loss: -0.6425337195396423
Test:
Test: 0.4534648457258472
0.4534648457258472
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.10it/s]100%|██████████| 1/1 [00:00<00:00,  5.09it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.591787576675415
Epoch 1: -0.591787576675415
Mem used: -900MB
best_loss: tensor(-0.6342, device='cuda:1')
best_loss: tensor(-0.6371, device='cuda:1')
final loss: -0.6184781193733215
Test:
Test: 0.4465941662451526
0.4465941662451526
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.58it/s]100%|██████████| 1/1 [00:00<00:00,  4.57it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6288900375366211
Epoch 1: -0.6288900375366211
Mem used: -900MB
best_loss: tensor(-0.6737, device='cuda:1')
final loss: -0.6574515104293823
Test:
Test: 0.46151576462653854
0.46151576462653854
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.47it/s]100%|██████████| 1/1 [00:00<00:00,  2.47it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.6072772145271301
Epoch 1: -0.6072772145271301
Mem used: -900MB
best_loss: tensor(-0.6419, device='cuda:1')
best_loss: tensor(-0.6423, device='cuda:1')
final loss: -0.6260249614715576
Test:
Test: 0.4481537683358624
0.4481537683358624
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.01it/s]100%|██████████| 1/1 [00:00<00:00,  4.00it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5905102491378784
Epoch 1: -0.5905102491378784
Mem used: -900MB
best_loss: tensor(-0.6370, device='cuda:1')
best_loss: tensor(-0.6389, device='cuda:1')
final loss: -0.6222890615463257
Test:
Test: 0.458691620300118
0.458691620300118
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.37it/s]100%|██████████| 1/1 [00:00<00:00,  4.37it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6330797076225281
Epoch 1: -0.6330797076225281
Mem used: -900MB
best_loss: tensor(-0.6745, device='cuda:1')
best_loss: tensor(-0.6815, device='cuda:1')
final loss: -0.6592423319816589
Test:
Test: 0.4539706626201315
0.4539706626201315
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.56it/s]100%|██████████| 1/1 [00:00<00:00,  3.55it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.629534125328064
Epoch 1: -0.629534125328064
Mem used: -900MB
best_loss: tensor(-0.6593, device='cuda:1')
best_loss: tensor(-0.6667, device='cuda:1')
final loss: -0.6491179466247559
Test:
Test: 0.4584387118529759
0.4584387118529759
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.83it/s]100%|██████████| 1/1 [00:00<00:00,  5.82it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.6023542881011963
Epoch 1: -0.6023542881011963
Mem used: -900MB
best_loss: tensor(-0.6406, device='cuda:1')
best_loss: tensor(-0.6478, device='cuda:1')
final loss: -0.6293275952339172
Test:
Test: 0.45519305344798516
0.45519305344798516
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  6.66it/s]100%|██████████| 1/1 [00:00<00:00,  6.65it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.6233816742897034
Epoch 1: -0.6233816742897034
Mem used: -900MB
best_loss: tensor(-0.6564, device='cuda:1')
best_loss: tensor(-0.6628, device='cuda:1')
final loss: -0.647110641002655
Test:
Test: 0.4612628561793964
0.4612628561793964
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.64it/s]100%|██████████| 1/1 [00:00<00:00,  2.64it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.621468722820282
Epoch 1: -0.621468722820282
Mem used: -900MB
best_loss: tensor(-0.6525, device='cuda:1')
best_loss: tensor(-0.6601, device='cuda:1')
final loss: -0.6444013118743896
Test:
Test: 0.45633114146012477
0.45633114146012477
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.99it/s]100%|██████████| 1/1 [00:00<00:00,  3.98it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388945579529
Epoch 0, Loop Adj 0: -0.6129634976387024
Epoch 1: -0.6129634976387024
Mem used: -900MB
best_loss: tensor(-0.6557, device='cuda:1')
best_loss: tensor(-0.6623, device='cuda:1')
final loss: -0.6425336599349976
Test:
Test: 0.4534648457258472
0.4534648457258472
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.75it/s]100%|██████████| 1/1 [00:00<00:00,  4.75it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5917875170707703
Epoch 1: -0.5917875170707703
Mem used: -900MB
best_loss: tensor(-0.6316, device='cuda:1')
best_loss: tensor(-0.6371, device='cuda:1')
final loss: -0.6184781193733215
Test:
Test: 0.4465941662451526
0.4465941662451526
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.53it/s]100%|██████████| 1/1 [00:00<00:00,  5.52it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6288900375366211
Epoch 1: -0.6288900375366211
Mem used: -900MB
best_loss: tensor(-0.6681, device='cuda:1')
best_loss: tensor(-0.6736, device='cuda:1')
final loss: -0.6595817804336548
Test:
Test: 0.45890237733940314
0.45890237733940314
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.63it/s]100%|██████████| 1/1 [00:00<00:00,  4.63it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.6072772145271301
Epoch 1: -0.6072772145271301
Mem used: -900MB
best_loss: tensor(-0.6373, device='cuda:1')
best_loss: tensor(-0.6423, device='cuda:1')
final loss: -0.6260249614715576
Test:
Test: 0.4481537683358624
0.4481537683358624
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.50it/s]100%|██████████| 1/1 [00:00<00:00,  3.49it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5905102491378784
Epoch 1: -0.5905102491378784
Mem used: -900MB
best_loss: tensor(-0.6321, device='cuda:1')
best_loss: tensor(-0.6389, device='cuda:1')
final loss: -0.6222890019416809
Test:
Test: 0.458691620300118
0.458691620300118
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.14it/s]100%|██████████| 1/1 [00:00<00:00,  4.14it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6330797076225281
Epoch 1: -0.6330797076225281
Mem used: -900MB
best_loss: tensor(-0.6816, device='cuda:1')
best_loss: tensor(-0.6817, device='cuda:1')
final loss: -0.659045398235321
Test:
Test: 0.4531276344629911
0.4531276344629911
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.97it/s]100%|██████████| 1/1 [00:00<00:00,  3.90it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6295340657234192
Epoch 1: -0.6295340657234192
Mem used: -900MB
best_loss: tensor(-0.6663, device='cuda:1')
best_loss: tensor(-0.6669, device='cuda:1')
final loss: -0.6494997143745422
Test:
Test: 0.4583544090372618
0.4583544090372618
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.41it/s]100%|██████████| 1/1 [00:00<00:00,  3.38it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.6023542881011963
Epoch 1: -0.6023542881011963
Mem used: -900MB
best_loss: tensor(-0.6475, device='cuda:1')
best_loss: tensor(-0.6478, device='cuda:1')
final loss: -0.6297071576118469
Test:
Test: 0.454897993592986
0.454897993592986
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.41it/s]100%|██████████| 1/1 [00:00<00:00,  4.41it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.6233816742897034
Epoch 1: -0.6233816742897034
Mem used: -900MB
best_loss: tensor(-0.6637, device='cuda:1')
final loss: -0.646945059299469
Test:
Test: 0.46193727870510876
0.46193727870510876
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.25it/s]100%|██████████| 1/1 [00:00<00:00,  3.25it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.621468722820282
Epoch 1: -0.621468722820282
Mem used: -900MB
best_loss: tensor(-0.6599, device='cuda:1')
best_loss: tensor(-0.6603, device='cuda:1')
final loss: -0.6447142958641052
Test:
Test: 0.4563732928679818
0.4563732928679818
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.14it/s]100%|██████████| 1/1 [00:00<00:00,  3.14it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.6129634976387024
Epoch 1: -0.6129634976387024
Mem used: -900MB
best_loss: tensor(-0.6625, device='cuda:1')
best_loss: tensor(-0.6625, device='cuda:1')
final loss: -0.6429116725921631
Test:
Test: 0.4527904232001349
0.4527904232001349
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.84it/s]100%|██████████| 1/1 [00:00<00:00,  2.84it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.591787576675415
Epoch 1: -0.591787576675415
Mem used: -900MB
best_loss: tensor(-0.6371, device='cuda:1')
best_loss: tensor(-0.6374, device='cuda:1')
final loss: -0.6191867589950562
Test:
Test: 0.44655201483729556
0.44655201483729556
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.25it/s]100%|██████████| 1/1 [00:00<00:00,  4.25it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6288900375366211
Epoch 1: -0.6288900375366211
Mem used: -900MB
best_loss: tensor(-0.6748, device='cuda:1')
final loss: -0.660372257232666
Test:
Test: 0.4594924970494014
0.4594924970494014
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.80it/s]100%|██████████| 1/1 [00:00<00:00,  3.79it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.6072772741317749
Epoch 1: -0.6072772741317749
Mem used: -900MB
best_loss: tensor(-0.6424, device='cuda:1')
best_loss: tensor(-0.6426, device='cuda:1')
final loss: -0.6260169148445129
Test:
Test: 0.44844882819086157
0.44844882819086157
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.53it/s]100%|██████████| 1/1 [00:00<00:00,  3.46it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5905102491378784
Epoch 1: -0.5905102491378784
Mem used: -900MB
best_loss: tensor(-0.6387, device='cuda:1')
best_loss: tensor(-0.6387, device='cuda:1')
final loss: -0.6223294138908386
Test:
Test: 0.4583544090372618
0.4583544090372618
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.07it/s]100%|██████████| 2/2 [00:00<00:00,  3.24it/s]100%|██████████| 2/2 [00:00<00:00,  3.21it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6330797076225281
Epoch 1, Loop Feat 0: -0.6336767077445984
Epoch 1, Loop Adj 0: -0.6505547761917114
Epoch 2: -0.6505547761917114
Mem used: -900MB
best_loss: tensor(-0.7022, device='cuda:1')
best_loss: tensor(-0.7032, device='cuda:1')
final loss: -0.6828474402427673
Test:
Test: 0.4534226943179902
0.4534226943179902
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.71it/s]100%|██████████| 2/2 [00:00<00:00,  2.83it/s]100%|██████████| 2/2 [00:00<00:00,  2.81it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6295340657234192
Epoch 1, Loop Feat 0: -0.6247259378433228
Epoch 1, Loop Adj 0: -0.6365694999694824
Epoch 2: -0.6365694999694824
Mem used: -900MB
best_loss: tensor(-0.6878, device='cuda:1')
best_loss: tensor(-0.6891, device='cuda:1')
final loss: -0.6748191714286804
Test:
Test: 0.4593660428258304
0.4593660428258304
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.75it/s]100%|██████████| 2/2 [00:00<00:00,  4.13it/s]100%|██████████| 2/2 [00:00<00:00,  4.06it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.6023542881011963
Epoch 1, Loop Feat 0: -0.6006742715835571
Epoch 1, Loop Adj 0: -0.6172281503677368
Epoch 2: -0.6172281503677368
Mem used: -900MB
best_loss: tensor(-0.6686, device='cuda:1')
best_loss: tensor(-0.6710, device='cuda:1')
final loss: -0.6559006571769714
Test:
Test: 0.456794806946552
0.456794806946552
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.27it/s]100%|██████████| 2/2 [00:00<00:00,  3.22it/s]100%|██████████| 2/2 [00:00<00:00,  3.23it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011685371399
Epoch 0, Loop Adj 0: -0.6233815550804138
Epoch 1, Loop Feat 0: -0.6158637404441833
Epoch 1, Loop Adj 0: -0.6395553946495056
Epoch 2: -0.6395553946495056
Mem used: -900MB
best_loss: tensor(-0.6862, device='cuda:1')
best_loss: tensor(-0.6879, device='cuda:1')
final loss: -0.6741539239883423
Test:
Test: 0.46155791603439555
0.46155791603439555
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.56it/s]100%|██████████| 2/2 [00:00<00:00,  3.47it/s]100%|██████████| 2/2 [00:00<00:00,  3.29it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.621468722820282
Epoch 1, Loop Feat 0: -0.614501953125
Epoch 1, Loop Adj 0: -0.6352204084396362
Epoch 2: -0.6352204084396362
Mem used: -900MB
best_loss: tensor(-0.6831, device='cuda:1')
best_loss: tensor(-0.6853, device='cuda:1')
final loss: -0.6729835867881775
Test:
Test: 0.458649468892261
0.458649468892261
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.70it/s]100%|██████████| 2/2 [00:00<00:00,  2.28it/s]100%|██████████| 2/2 [00:00<00:00,  2.42it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388945579529
Epoch 0, Loop Adj 0: -0.6129634976387024
Epoch 1, Loop Feat 0: -0.6122392416000366
Epoch 1, Loop Adj 0: -0.6276168823242188
Epoch 2: -0.6276168823242188
Mem used: -900MB
best_loss: tensor(-0.6847, device='cuda:1')
best_loss: tensor(-0.6872, device='cuda:1')
final loss: -0.6709228157997131
Test:
Test: 0.45253751475299275
0.45253751475299275
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.44it/s]100%|██████████| 2/2 [00:00<00:00,  4.03it/s]100%|██████████| 2/2 [00:00<00:00,  4.09it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.591787576675415
Epoch 1, Loop Feat 0: -0.5917791724205017
Epoch 1, Loop Adj 0: -0.6086379289627075
Epoch 2: -0.6086379289627075
Mem used: -900MB
best_loss: tensor(-0.6649, device='cuda:1')
best_loss: tensor(-0.6660, device='cuda:1')
final loss: -0.6507322788238525
Test:
Test: 0.44646771202158153
0.44646771202158153
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.79it/s]100%|██████████| 2/2 [00:00<00:00,  4.15it/s]100%|██████████| 2/2 [00:00<00:00,  4.23it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6288900375366211
Epoch 1, Loop Feat 0: -0.6326903104782104
Epoch 1, Loop Adj 0: -0.6444060206413269
Epoch 2: -0.6444060206413269
Mem used: -900MB
best_loss: tensor(-0.6926, device='cuda:1')
best_loss: tensor(-0.6940, device='cuda:1')
final loss: -0.682518482208252
Test:
Test: 0.45704771539369415
0.45704771539369415
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.01it/s]100%|██████████| 2/2 [00:00<00:00,  3.18it/s]100%|██████████| 2/2 [00:00<00:00,  3.28it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.6072772741317749
Epoch 1, Loop Feat 0: -0.6022279858589172
Epoch 1, Loop Adj 0: -0.615382730960846
Epoch 2: -0.615382730960846
Mem used: -900MB
best_loss: tensor(-0.6661, device='cuda:1')
best_loss: tensor(-0.6681, device='cuda:1')
final loss: -0.654256284236908
Test:
Test: 0.4509357612544259
0.4509357612544259
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.24it/s]100%|██████████| 2/2 [00:00<00:00,  3.62it/s]100%|██████████| 2/2 [00:00<00:00,  3.70it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5905102491378784
Epoch 1, Loop Feat 0: -0.5916306376457214
Epoch 1, Loop Adj 0: -0.6075690388679504
Epoch 2: -0.6075690388679504
Mem used: -900MB
best_loss: tensor(-0.6620, device='cuda:1')
best_loss: tensor(-0.6630, device='cuda:1')
final loss: -0.6492536664009094
Test:
Test: 0.4594503456415444
0.4594503456415444
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.18it/s]100%|██████████| 2/2 [00:00<00:00,  4.05it/s]100%|██████████| 2/2 [00:00<00:00,  4.06it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6330797076225281
Epoch 1, Loop Feat 0: -0.6336767077445984
Epoch 1, Loop Adj 0: -0.6505547761917114
Epoch 2: -0.6505547761917114
Mem used: -900MB
best_loss: tensor(-0.7002, device='cuda:1')
best_loss: tensor(-0.7032, device='cuda:1')
final loss: -0.6828474998474121
Test:
Test: 0.4534226943179902
0.4534226943179902
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.67it/s]100%|██████████| 2/2 [00:00<00:00,  5.19it/s]100%|██████████| 2/2 [00:00<00:00,  5.25it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.629534125328064
Epoch 1, Loop Feat 0: -0.6247259378433228
Epoch 1, Loop Adj 0: -0.6365694999694824
Epoch 2: -0.6365694999694824
Mem used: -900MB
best_loss: tensor(-0.6884, device='cuda:1')
best_loss: tensor(-0.6891, device='cuda:1')
final loss: -0.6748192310333252
Test:
Test: 0.4593660428258304
0.4593660428258304
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.78it/s]100%|██████████| 2/2 [00:00<00:00,  4.46it/s]100%|██████████| 2/2 [00:00<00:00,  4.34it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.6023542881011963
Epoch 1, Loop Feat 0: -0.6006742715835571
Epoch 1, Loop Adj 0: -0.6172282099723816
Epoch 2: -0.6172282099723816
Mem used: -900MB
best_loss: tensor(-0.6681, device='cuda:1')
best_loss: tensor(-0.6710, device='cuda:1')
final loss: -0.6559006571769714
Test:
Test: 0.456794806946552
0.456794806946552
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.48it/s]100%|██████████| 2/2 [00:00<00:00,  3.42it/s]100%|██████████| 2/2 [00:00<00:00,  3.54it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.6233816742897034
Epoch 1, Loop Feat 0: -0.6158636212348938
Epoch 1, Loop Adj 0: -0.6395553350448608
Epoch 2: -0.6395553350448608
Mem used: -900MB
best_loss: tensor(-0.6850, device='cuda:1')
best_loss: tensor(-0.6879, device='cuda:1')
final loss: -0.6741538643836975
Test:
Test: 0.46155791603439555
0.46155791603439555
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.74it/s]100%|██████████| 2/2 [00:00<00:00,  3.75it/s]100%|██████████| 2/2 [00:00<00:00,  3.75it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.621468722820282
Epoch 1, Loop Feat 0: -0.614501953125
Epoch 1, Loop Adj 0: -0.6352204084396362
Epoch 2: -0.6352204084396362
Mem used: -900MB
best_loss: tensor(-0.6844, device='cuda:1')
best_loss: tensor(-0.6853, device='cuda:1')
final loss: -0.6729835867881775
Test:
Test: 0.458649468892261
0.458649468892261
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.88it/s]100%|██████████| 2/2 [00:00<00:00,  2.88it/s]100%|██████████| 2/2 [00:00<00:00,  2.88it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.6129634976387024
Epoch 1, Loop Feat 0: -0.6122391819953918
Epoch 1, Loop Adj 0: -0.6276168823242188
Epoch 2: -0.6276168823242188
Mem used: -900MB
best_loss: tensor(-0.6850, device='cuda:1')
best_loss: tensor(-0.6872, device='cuda:1')
final loss: -0.6709228157997131
Test:
Test: 0.45253751475299275
0.45253751475299275
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.36it/s]100%|██████████| 2/2 [00:00<00:00,  2.44it/s]100%|██████████| 2/2 [00:00<00:00,  2.54it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5917874574661255
Epoch 1, Loop Feat 0: -0.5917791724205017
Epoch 1, Loop Adj 0: -0.6086379289627075
Epoch 2: -0.6086379289627075
Mem used: -900MB
best_loss: tensor(-0.6660, device='cuda:1')
final loss: -0.6514809131622314
Test:
Test: 0.44840667678300455
0.44840667678300455
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.95it/s]100%|██████████| 2/2 [00:00<00:00,  4.45it/s]100%|██████████| 2/2 [00:00<00:00,  4.36it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6288900375366211
Epoch 1, Loop Feat 0: -0.6326903104782104
Epoch 1, Loop Adj 0: -0.6444059610366821
Epoch 2: -0.6444059610366821
Mem used: -900MB
best_loss: tensor(-0.6916, device='cuda:1')
best_loss: tensor(-0.6940, device='cuda:1')
final loss: -0.682518482208252
Test:
Test: 0.45704771539369415
0.45704771539369415
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.71it/s]100%|██████████| 2/2 [00:00<00:00,  5.14it/s]100%|██████████| 2/2 [00:00<00:00,  5.21it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.6072772741317749
Epoch 1, Loop Feat 0: -0.6022279858589172
Epoch 1, Loop Adj 0: -0.615382730960846
Epoch 2: -0.615382730960846
Mem used: -900MB
best_loss: tensor(-0.6687, device='cuda:1')
final loss: -0.6558184623718262
Test:
Test: 0.451104366885854
0.451104366885854
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.77it/s]100%|██████████| 2/2 [00:00<00:00,  4.62it/s]100%|██████████| 2/2 [00:00<00:00,  4.76it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5905102491378784
Epoch 1, Loop Feat 0: -0.5916306376457214
Epoch 1, Loop Adj 0: -0.6075690388679504
Epoch 2: -0.6075690388679504
Mem used: -900MB
best_loss: tensor(-0.6610, device='cuda:1')
best_loss: tensor(-0.6630, device='cuda:1')
final loss: -0.6492536664009094
Test:
Test: 0.4594503456415444
0.4594503456415444
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.70it/s]100%|██████████| 2/2 [00:00<00:00,  3.84it/s]100%|██████████| 2/2 [00:00<00:00,  3.81it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6330797076225281
Epoch 1, Loop Feat 0: -0.6339899301528931
Epoch 1, Loop Adj 0: -0.6507682800292969
Epoch 2: -0.6507682800292969
Mem used: -900MB
best_loss: tensor(-0.7028, device='cuda:1')
best_loss: tensor(-0.7032, device='cuda:1')
final loss: -0.6829733848571777
Test:
Test: 0.4533383915022762
0.4533383915022762
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.40it/s]100%|██████████| 2/2 [00:00<00:00,  3.37it/s]100%|██████████| 2/2 [00:00<00:00,  3.49it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.629534125328064
Epoch 1, Loop Feat 0: -0.6250136494636536
Epoch 1, Loop Adj 0: -0.6369687914848328
Epoch 2: -0.6369687914848328
Mem used: -900MB
best_loss: tensor(-0.6893, device='cuda:1')
best_loss: tensor(-0.6895, device='cuda:1')
final loss: -0.6751691102981567
Test:
Test: 0.4591552857865453
0.4591552857865453
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.01it/s]100%|██████████| 2/2 [00:00<00:00,  2.93it/s]100%|██████████| 2/2 [00:00<00:00,  2.94it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.6023542881011963
Epoch 1, Loop Feat 0: -0.6009705066680908
Epoch 1, Loop Adj 0: -0.6174868941307068
Epoch 2: -0.6174868941307068
Mem used: -900MB
best_loss: tensor(-0.6709, device='cuda:1')
best_loss: tensor(-0.6711, device='cuda:1')
final loss: -0.6550961136817932
Test:
Test: 0.45687910976226603
0.45687910976226603
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.64it/s]100%|██████████| 2/2 [00:00<00:00,  3.67it/s]100%|██████████| 2/2 [00:00<00:00,  3.87it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.6233816742897034
Epoch 1, Loop Feat 0: -0.6161209940910339
Epoch 1, Loop Adj 0: -0.6399148106575012
Epoch 2: -0.6399148106575012
Mem used: -900MB
best_loss: tensor(-0.6885, device='cuda:1')
final loss: -0.6740291118621826
Test:
Test: 0.46214803574439384
0.46214803574439384
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.95it/s]100%|██████████| 2/2 [00:00<00:00,  3.46it/s]100%|██████████| 2/2 [00:00<00:00,  3.37it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.621468722820282
Epoch 1, Loop Feat 0: -0.61506587266922
Epoch 1, Loop Adj 0: -0.6356692314147949
Epoch 2: -0.6356692314147949
Mem used: -900MB
best_loss: tensor(-0.6855, device='cuda:1')
best_loss: tensor(-0.6857, device='cuda:1')
final loss: -0.6729768514633179
Test:
Test: 0.458607317484404
0.458607317484404
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.56it/s]100%|██████████| 2/2 [00:00<00:00,  3.81it/s]100%|██████████| 2/2 [00:00<00:00,  3.99it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.6129634976387024
Epoch 1, Loop Feat 0: -0.612660825252533
Epoch 1, Loop Adj 0: -0.6278912425041199
Epoch 2: -0.6278912425041199
Mem used: -900MB
best_loss: tensor(-0.6869, device='cuda:1')
best_loss: tensor(-0.6872, device='cuda:1')
final loss: -0.6705904006958008
Test:
Test: 0.4515680323722812
0.4515680323722812
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.34it/s]100%|██████████| 2/2 [00:00<00:00,  4.15it/s]100%|██████████| 2/2 [00:00<00:00,  4.18it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.591787576675415
Epoch 1, Loop Feat 0: -0.592254102230072
Epoch 1, Loop Adj 0: -0.6090587377548218
Epoch 2: -0.6090587377548218
Mem used: -900MB
best_loss: tensor(-0.6654, device='cuda:1')
best_loss: tensor(-0.6659, device='cuda:1')
final loss: -0.650650680065155
Test:
Test: 0.4459197437194402
0.4459197437194402
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.80it/s]100%|██████████| 2/2 [00:00<00:00,  2.19it/s]100%|██████████| 2/2 [00:00<00:00,  2.26it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6288900375366211
Epoch 1, Loop Feat 0: -0.6329574584960938
Epoch 1, Loop Adj 0: -0.6447274684906006
Epoch 2: -0.6447274684906006
Mem used: -900MB
best_loss: tensor(-0.6946, device='cuda:1')
final loss: -0.6831047534942627
Test:
Test: 0.4583965604451189
0.4583965604451189
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.88it/s]100%|██████████| 2/2 [00:00<00:00,  4.63it/s]100%|██████████| 2/2 [00:00<00:00,  4.67it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.6072772145271301
Epoch 1, Loop Feat 0: -0.6026658415794373
Epoch 1, Loop Adj 0: -0.6158161759376526
Epoch 2: -0.6158161759376526
Mem used: -900MB
best_loss: tensor(-0.6687, device='cuda:1')
final loss: -0.6539662480354309
Test:
Test: 0.45144157814871017
0.45144157814871017
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  6.47it/s]100%|██████████| 2/2 [00:00<00:00,  5.45it/s]100%|██████████| 2/2 [00:00<00:00,  5.58it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5905102491378784
Epoch 1, Loop Feat 0: -0.5919148921966553
Epoch 1, Loop Adj 0: -0.6077786684036255
Epoch 2: -0.6077786684036255
Mem used: -900MB
best_loss: tensor(-0.6632, device='cuda:1')
final loss: -0.6496028900146484
Test:
Test: 0.4599140111279717
0.4599140111279717
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.22it/s]100%|██████████| 1/1 [00:00<00:00,  5.22it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6201845407485962
Epoch 1: -0.6201845407485962
Mem used: -900MB
best_loss: tensor(-0.6287, device='cuda:1')
best_loss: tensor(-0.6293, device='cuda:1')
final loss: -0.6216147541999817
Test:
Test: 0.449334007755859
0.449334007755859
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.88it/s]100%|██████████| 1/1 [00:00<00:00,  4.87it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.614953339099884
Epoch 1: -0.614953339099884
Mem used: -900MB
best_loss: tensor(-0.6114, device='cuda:1')
best_loss: tensor(-0.6129, device='cuda:1')
final loss: -0.6105123162269592
Test:
Test: 0.4560782330129826
0.4560782330129826
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.63it/s]100%|██████████| 1/1 [00:00<00:00,  3.63it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5871880054473877
Epoch 1: -0.5871880054473877
Mem used: -900MB
best_loss: tensor(-0.5918, device='cuda:1')
best_loss: tensor(-0.5926, device='cuda:1')
final loss: -0.5900325775146484
Test:
Test: 0.4533805429101332
0.4533805429101332
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  6.05it/s]100%|██████████| 1/1 [00:00<00:00,  6.04it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011685371399
Epoch 0, Loop Adj 0: -0.6072602868080139
Epoch 1: -0.6072602868080139
Mem used: -900MB
best_loss: tensor(-0.6056, device='cuda:1')
final loss: -0.6038134098052979
Test:
Test: 0.4614314618108245
0.4614314618108245
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.05it/s]100%|██████████| 1/1 [00:00<00:00,  5.05it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.604135274887085
Epoch 1: -0.604135274887085
Mem used: -900MB
best_loss: tensor(-0.6019, device='cuda:1')
final loss: -0.6003860235214233
Test:
Test: 0.4509357612544259
0.4509357612544259
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.37it/s]100%|██████████| 1/1 [00:00<00:00,  4.36it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.596156895160675
Epoch 1: -0.596156895160675
Mem used: -900MB
best_loss: tensor(-0.6018, device='cuda:1')
best_loss: tensor(-0.6032, device='cuda:1')
final loss: -0.600371778011322
Test:
Test: 0.453043331647277
0.453043331647277
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.72it/s]100%|██████████| 1/1 [00:00<00:00,  4.71it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5703567862510681
Epoch 1: -0.5703567862510681
Mem used: -900MB
best_loss: tensor(-0.5720, device='cuda:1')
best_loss: tensor(-0.5731, device='cuda:1')
final loss: -0.5704109072685242
Test:
Test: 0.4470156803237228
0.4470156803237228
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.50it/s]100%|██████████| 1/1 [00:00<00:00,  5.49it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.617407500743866
Epoch 1: -0.617407500743866
Mem used: -900MB
best_loss: tensor(-0.6246, device='cuda:1')
final loss: -0.6237850189208984
Test:
Test: 0.458649468892261
0.458649468892261
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.97it/s]100%|██████████| 1/1 [00:00<00:00,  4.96it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.5894481539726257
Epoch 1: -0.5894481539726257
Mem used: -900MB
best_loss: tensor(-0.5854, device='cuda:1')
final loss: -0.5830718278884888
Test:
Test: 0.44537177541729894
0.44537177541729894
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.28it/s]100%|██████████| 1/1 [00:00<00:00,  4.28it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.575211763381958
Epoch 1: -0.575211763381958
Mem used: -900MB
best_loss: tensor(-0.5819, device='cuda:1')
final loss: -0.5792099237442017
Test:
Test: 0.4556145675265554
0.4556145675265554
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.50it/s]100%|██████████| 1/1 [00:00<00:00,  4.50it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6201845407485962
Epoch 1: -0.6201845407485962
Mem used: -900MB
best_loss: tensor(-0.6275, device='cuda:1')
best_loss: tensor(-0.6295, device='cuda:1')
final loss: -0.6230258941650391
Test:
Test: 0.4507250042151408
0.4507250042151408
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.25it/s]100%|██████████| 1/1 [00:00<00:00,  4.25it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6149532794952393
Epoch 1: -0.6149532794952393
Mem used: -900MB
best_loss: tensor(-0.6103, device='cuda:1')
best_loss: tensor(-0.6122, device='cuda:1')
final loss: -0.6091142296791077
Test:
Test: 0.456794806946552
0.456794806946552
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.87it/s]100%|██████████| 1/1 [00:00<00:00,  2.87it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5871880054473877
Epoch 1: -0.5871880054473877
Mem used: -900MB
best_loss: tensor(-0.5915, device='cuda:1')
best_loss: tensor(-0.5932, device='cuda:1')
final loss: -0.5913707613945007
Test:
Test: 0.45557241611869836
0.45557241611869836
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.80it/s]100%|██████████| 1/1 [00:00<00:00,  2.79it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011685371399
Epoch 0, Loop Adj 0: -0.6072602868080139
Epoch 1: -0.6072602868080139
Mem used: -900MB
best_loss: tensor(-0.6036, device='cuda:1')
best_loss: tensor(-0.6047, device='cuda:1')
final loss: -0.6062972545623779
Test:
Test: 0.46450851458438713
0.46450851458438713
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.40it/s]100%|██████████| 1/1 [00:00<00:00,  2.40it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6041353344917297
Epoch 1: -0.6041353344917297
Mem used: -900MB
best_loss: tensor(-0.6017, device='cuda:1')
best_loss: tensor(-0.6031, device='cuda:1')
final loss: -0.6019325256347656
Test:
Test: 0.45287472601584894
0.45287472601584894
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.72it/s]100%|██████████| 1/1 [00:00<00:00,  4.72it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388945579529
Epoch 0, Loop Adj 0: -0.596156895160675
Epoch 1: -0.596156895160675
Mem used: -900MB
best_loss: tensor(-0.6021, device='cuda:1')
best_loss: tensor(-0.6033, device='cuda:1')
final loss: -0.5990960597991943
Test:
Test: 0.4537599055808464
0.4537599055808464
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.31it/s]100%|██████████| 1/1 [00:00<00:00,  4.30it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5703567862510681
Epoch 1: -0.5703567862510681
Mem used: -900MB
best_loss: tensor(-0.5748, device='cuda:1')
final loss: -0.5694079995155334
Test:
Test: 0.45064070139942675
0.45064070139942675
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.27it/s]100%|██████████| 1/1 [00:00<00:00,  5.26it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.617407500743866
Epoch 1: -0.617407500743866
Mem used: -900MB
best_loss: tensor(-0.6221, device='cuda:1')
final loss: -0.6206212043762207
Test:
Test: 0.4620637329286798
0.4620637329286798
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.97it/s]100%|██████████| 1/1 [00:00<00:00,  3.97it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.5894481539726257
Epoch 1: -0.5894481539726257
Mem used: -900MB
best_loss: tensor(-0.5856, device='cuda:1')
best_loss: tensor(-0.5870, device='cuda:1')
final loss: -0.5844040513038635
Test:
Test: 0.4490389479008599
0.4490389479008599
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.95it/s]100%|██████████| 1/1 [00:00<00:00,  3.95it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5752118229866028
Epoch 1: -0.5752118229866028
Mem used: -900MB
best_loss: tensor(-0.5800, device='cuda:1')
best_loss: tensor(-0.5810, device='cuda:1')
final loss: -0.5807456970214844
Test:
Test: 0.4565840499072669
0.4565840499072669
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.52it/s]100%|██████████| 1/1 [00:00<00:00,  3.51it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6201845407485962
Epoch 1: -0.6201845407485962
Mem used: -900MB
best_loss: tensor(-0.6296, device='cuda:1')
final loss: -0.6222742795944214
Test:
Test: 0.4478587084808633
0.4478587084808633
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.27it/s]100%|██████████| 1/1 [00:00<00:00,  4.27it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6149532794952393
Epoch 1: -0.6149532794952393
Mem used: -900MB
best_loss: tensor(-0.6127, device='cuda:1')
best_loss: tensor(-0.6131, device='cuda:1')
final loss: -0.6103108525276184
Test:
Test: 0.4550244478165571
0.4550244478165571
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.68it/s]100%|██████████| 1/1 [00:00<00:00,  3.68it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5871880054473877
Epoch 1: -0.5871880054473877
Mem used: -900MB
best_loss: tensor(-0.5927, device='cuda:1')
best_loss: tensor(-0.5928, device='cuda:1')
final loss: -0.5899022817611694
Test:
Test: 0.45182094081942337
0.45182094081942337
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.36it/s]100%|██████████| 1/1 [00:00<00:00,  4.36it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011685371399
Epoch 0, Loop Adj 0: -0.6072602868080139
Epoch 1: -0.6072602868080139
Mem used: -900MB
best_loss: tensor(-0.6046, device='cuda:1')
final loss: -0.6039245128631592
Test:
Test: 0.46075703928511214
0.46075703928511214
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.19it/s]100%|██████████| 1/1 [00:00<00:00,  3.19it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6041353344917297
Epoch 1: -0.6041353344917297
Mem used: -900MB
best_loss: tensor(-0.6031, device='cuda:1')
best_loss: tensor(-0.6034, device='cuda:1')
final loss: -0.6023064255714417
Test:
Test: 0.45161018378013823
0.45161018378013823
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.70it/s]100%|██████████| 1/1 [00:00<00:00,  3.70it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388945579529
Epoch 0, Loop Adj 0: -0.596156895160675
Epoch 1: -0.596156895160675
Mem used: -900MB
best_loss: tensor(-0.6037, device='cuda:1')
final loss: -0.6001454591751099
Test:
Test: 0.4522424548979936
0.4522424548979936
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.10it/s]100%|██████████| 1/1 [00:00<00:00,  3.91it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5703567862510681
Epoch 1: -0.5703567862510681
Mem used: -900MB
best_loss: tensor(-0.5729, device='cuda:1')
best_loss: tensor(-0.5732, device='cuda:1')
final loss: -0.5712859630584717
Test:
Test: 0.44693137750800876
0.44693137750800876
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.37it/s]100%|██████████| 1/1 [00:00<00:00,  4.36it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.617407500743866
Epoch 1: -0.617407500743866
Mem used: -900MB
best_loss: tensor(-0.6242, device='cuda:1')
final loss: -0.6245819330215454
Test:
Test: 0.4571320182094082
0.4571320182094082
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.40it/s]100%|██████████| 1/1 [00:00<00:00,  5.39it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.5894481539726257
Epoch 1: -0.5894481539726257
Mem used: -900MB
best_loss: tensor(-0.5853, device='cuda:1')
best_loss: tensor(-0.5853, device='cuda:1')
final loss: -0.5836898684501648
Test:
Test: 0.44579328949586916
0.44579328949586916
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.30it/s]100%|██████████| 1/1 [00:00<00:00,  5.29it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.575211763381958
Epoch 1: -0.575211763381958
Mem used: -900MB
best_loss: tensor(-0.5811, device='cuda:1')
best_loss: tensor(-0.5814, device='cuda:1')
final loss: -0.5805479288101196
Test:
Test: 0.4552352048558422
0.4552352048558422
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.32it/s]100%|██████████| 2/2 [00:00<00:00,  3.16it/s]100%|██████████| 2/2 [00:00<00:00,  3.18it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6201845407485962
Epoch 1, Loop Feat 0: -0.6198201775550842
Epoch 1, Loop Adj 0: -0.6265186667442322
Epoch 2: -0.6265186667442322
Mem used: -900MB
best_loss: tensor(-0.6330, device='cuda:1')
best_loss: tensor(-0.6332, device='cuda:1')
final loss: -0.6252411007881165
Test:
Test: 0.4500084302815714
0.4500084302815714
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.38it/s]100%|██████████| 2/2 [00:00<00:00,  2.86it/s]100%|██████████| 2/2 [00:00<00:00,  2.92it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6149532794952393
Epoch 1, Loop Feat 0: -0.6098437905311584
Epoch 1, Loop Adj 0: -0.6092079877853394
Epoch 2: -0.6092079877853394
Mem used: -900MB
best_loss: tensor(-0.6162, device='cuda:1')
final loss: -0.613681435585022
Test:
Test: 0.456752655538695
0.456752655538695
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.75it/s]100%|██████████| 2/2 [00:00<00:00,  4.23it/s]100%|██████████| 2/2 [00:00<00:00,  4.29it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5871880054473877
Epoch 1, Loop Feat 0: -0.5845052003860474
Epoch 1, Loop Adj 0: -0.5885375738143921
Epoch 2: -0.5885375738143921
Mem used: -900MB
best_loss: tensor(-0.5954, device='cuda:1')
final loss: -0.5935599207878113
Test:
Test: 0.45666835272298095
0.45666835272298095
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.48it/s]100%|██████████| 2/2 [00:00<00:00,  4.02it/s]100%|██████████| 2/2 [00:00<00:00,  3.92it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.6072602868080139
Epoch 1, Loop Feat 0: -0.5986106395721436
Epoch 1, Loop Adj 0: -0.6089938282966614
Epoch 2: -0.6089938282966614
Mem used: -900MB
best_loss: tensor(-0.6083, device='cuda:1')
final loss: -0.6073368787765503
Test:
Test: 0.46307536671724836
0.46307536671724836
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.72it/s]100%|██████████| 2/2 [00:00<00:00,  3.31it/s]100%|██████████| 2/2 [00:00<00:00,  3.37it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6041353344917297
Epoch 1, Loop Feat 0: -0.595224142074585
Epoch 1, Loop Adj 0: -0.6019603610038757
Epoch 2: -0.6019603610038757
Mem used: -900MB
best_loss: tensor(-0.6063, device='cuda:1')
best_loss: tensor(-0.6068, device='cuda:1')
final loss: -0.60540372133255
Test:
Test: 0.453085483055134
0.453085483055134
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.16it/s]100%|██████████| 2/2 [00:00<00:00,  4.36it/s]100%|██████████| 2/2 [00:00<00:00,  4.33it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.596156895160675
Epoch 1, Loop Feat 0: -0.5941613912582397
Epoch 1, Loop Adj 0: -0.5961611270904541
Epoch 2: -0.5961611270904541
Mem used: -900MB
best_loss: tensor(-0.6065, device='cuda:1')
best_loss: tensor(-0.6068, device='cuda:1')
final loss: -0.6040645241737366
Test:
Test: 0.4526639689765638
0.4526639689765638
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.61it/s]100%|██████████| 2/2 [00:00<00:00,  2.99it/s]100%|██████████| 2/2 [00:00<00:00,  3.07it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5703567862510681
Epoch 1, Loop Feat 0: -0.5682713985443115
Epoch 1, Loop Adj 0: -0.5686731934547424
Epoch 2: -0.5686731934547424
Mem used: -900MB
best_loss: tensor(-0.5779, device='cuda:1')
final loss: -0.5744856595993042
Test:
Test: 0.4493761591637161
0.4493761591637161
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.06it/s]100%|██████████| 2/2 [00:00<00:00,  3.29it/s]100%|██████████| 2/2 [00:00<00:00,  3.38it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.617407500743866
Epoch 1, Loop Feat 0: -0.6203911304473877
Epoch 1, Loop Adj 0: -0.6229084134101868
Epoch 2: -0.6229084134101868
Mem used: -900MB
best_loss: tensor(-0.6258, device='cuda:1')
best_loss: tensor(-0.6260, device='cuda:1')
final loss: -0.6266475319862366
Test:
Test: 0.4575113808801214
0.4575113808801214
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.29it/s]100%|██████████| 2/2 [00:00<00:00,  4.14it/s]100%|██████████| 2/2 [00:00<00:00,  4.16it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.5894481539726257
Epoch 1, Loop Feat 0: -0.5824425220489502
Epoch 1, Loop Adj 0: -0.5806339383125305
Epoch 2: -0.5806339383125305
Mem used: -900MB
best_loss: tensor(-0.5904, device='cuda:1')
final loss: -0.587963342666626
Test:
Test: 0.4497555218344293
0.4497555218344293
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.36it/s]100%|██████████| 2/2 [00:00<00:00,  3.93it/s]100%|██████████| 2/2 [00:00<00:00,  3.99it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.575211763381958
Epoch 1, Loop Feat 0: -0.574852466583252
Epoch 1, Loop Adj 0: -0.5785022974014282
Epoch 2: -0.5785022974014282
Mem used: -900MB
best_loss: tensor(-0.5856, device='cuda:1')
final loss: -0.5836007595062256
Test:
Test: 0.4594503456415444
0.4594503456415444
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.21it/s]100%|██████████| 2/2 [00:00<00:00,  3.91it/s]100%|██████████| 2/2 [00:00<00:00,  4.06it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6201845407485962
Epoch 1, Loop Feat 0: -0.6159092783927917
Epoch 1, Loop Adj 0: -0.6225085854530334
Epoch 2: -0.6225085854530334
Mem used: -900MB
best_loss: tensor(-0.6364, device='cuda:1')
final loss: -0.6295874118804932
Test:
Test: 0.4508514584387118
0.4508514584387118
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.09it/s]100%|██████████| 2/2 [00:00<00:00,  3.93it/s]100%|██████████| 2/2 [00:00<00:00,  4.07it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6149532794952393
Epoch 1, Loop Feat 0: -0.6053262948989868
Epoch 1, Loop Adj 0: -0.6044272184371948
Epoch 2: -0.6044272184371948
Mem used: -900MB
best_loss: tensor(-0.6193, device='cuda:1')
final loss: -0.617439329624176
Test:
Test: 0.4576799865115495
0.4576799865115495
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.78it/s]100%|██████████| 2/2 [00:00<00:00,  3.27it/s]100%|██████████| 2/2 [00:00<00:00,  3.34it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5871880054473877
Epoch 1, Loop Feat 0: -0.5811050534248352
Epoch 1, Loop Adj 0: -0.5841163992881775
Epoch 2: -0.5841163992881775
Mem used: -900MB
best_loss: tensor(-0.6003, device='cuda:1')
final loss: -0.5990304946899414
Test:
Test: 0.45746922947226437
0.45746922947226437
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.92it/s]100%|██████████| 2/2 [00:00<00:00,  3.74it/s]100%|██████████| 2/2 [00:00<00:00,  3.87it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.6072602868080139
Epoch 1, Loop Feat 0: -0.5948413014411926
Epoch 1, Loop Adj 0: -0.6043067574501038
Epoch 2: -0.6043067574501038
Mem used: -900MB
best_loss: tensor(-0.6113, device='cuda:1')
final loss: -0.6113222241401672
Test:
Test: 0.4648457258472433
0.4648457258472433
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.24it/s]100%|██████████| 2/2 [00:00<00:00,  2.61it/s]100%|██████████| 2/2 [00:00<00:00,  2.69it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6041353344917297
Epoch 1, Loop Feat 0: -0.5894607901573181
Epoch 1, Loop Adj 0: -0.5971561074256897
Epoch 2: -0.5971561074256897
Mem used: -900MB
best_loss: tensor(-0.6112, device='cuda:1')
final loss: -0.6111326217651367
Test:
Test: 0.456794806946552
0.456794806946552
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.69it/s]100%|██████████| 2/2 [00:00<00:00,  3.05it/s]100%|██████████| 2/2 [00:00<00:00,  3.13it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.596156895160675
Epoch 1, Loop Feat 0: -0.5902328491210938
Epoch 1, Loop Adj 0: -0.5922693014144897
Epoch 2: -0.5922693014144897
Mem used: -900MB
best_loss: tensor(-0.6103, device='cuda:1')
final loss: -0.608919084072113
Test:
Test: 0.4545607823301298
0.4545607823301298
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.64it/s]100%|██████████| 2/2 [00:00<00:00,  3.88it/s]100%|██████████| 2/2 [00:00<00:00,  3.84it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5703567862510681
Epoch 1, Loop Feat 0: -0.5636200308799744
Epoch 1, Loop Adj 0: -0.5638735294342041
Epoch 2: -0.5638735294342041
Mem used: -900MB
best_loss: tensor(-0.5849, device='cuda:1')
final loss: -0.5797692537307739
Test:
Test: 0.4504299443601416
0.4504299443601416
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.28it/s]100%|██████████| 2/2 [00:00<00:00,  4.47it/s]100%|██████████| 2/2 [00:00<00:00,  4.57it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.617407500743866
Epoch 1, Loop Feat 0: -0.6169229745864868
Epoch 1, Loop Adj 0: -0.6191743016242981
Epoch 2: -0.6191743016242981
Mem used: -900MB
best_loss: tensor(-0.6278, device='cuda:1')
final loss: -0.6286020874977112
Test:
Test: 0.4613050075872534
0.4613050075872534
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.29it/s]100%|██████████| 2/2 [00:00<00:00,  2.60it/s]100%|██████████| 2/2 [00:00<00:00,  2.55it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.5894481539726257
Epoch 1, Loop Feat 0: -0.5776172280311584
Epoch 1, Loop Adj 0: -0.576613187789917
Epoch 2: -0.576613187789917
Mem used: -900MB
best_loss: tensor(-0.5947, device='cuda:1')
final loss: -0.5931366086006165
Test:
Test: 0.44878603945371776
0.44878603945371776
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.12it/s]100%|██████████| 2/2 [00:00<00:00,  5.24it/s]100%|██████████| 2/2 [00:00<00:00,  5.22it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.575211763381958
Epoch 1, Loop Feat 0: -0.5719056725502014
Epoch 1, Loop Adj 0: -0.5745977759361267
Epoch 2: -0.5745977759361267
Mem used: -900MB
best_loss: tensor(-0.5890, device='cuda:1')
final loss: -0.587494432926178
Test:
Test: 0.45738492665655034
0.45738492665655034
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.61it/s]100%|██████████| 2/2 [00:00<00:00,  3.13it/s]100%|██████████| 2/2 [00:00<00:00,  3.20it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6201845407485962
Epoch 1, Loop Feat 0: -0.6212395429611206
Epoch 1, Loop Adj 0: -0.6275411248207092
Epoch 2: -0.6275411248207092
Mem used: -900MB
best_loss: tensor(-0.6322, device='cuda:1')
best_loss: tensor(-0.6324, device='cuda:1')
final loss: -0.6249818801879883
Test:
Test: 0.4479430112965773
0.4479430112965773
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.84it/s]100%|██████████| 2/2 [00:00<00:00,  3.25it/s]100%|██████████| 2/2 [00:00<00:00,  3.18it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6149532794952393
Epoch 1, Loop Feat 0: -0.611443042755127
Epoch 1, Loop Adj 0: -0.6112957000732422
Epoch 2: -0.6112957000732422
Mem used: -900MB
best_loss: tensor(-0.6161, device='cuda:1')
best_loss: tensor(-0.6162, device='cuda:1')
final loss: -0.6141562461853027
Test:
Test: 0.45536165907941323
0.45536165907941323
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.22it/s]100%|██████████| 2/2 [00:00<00:00,  3.65it/s]100%|██████████| 2/2 [00:00<00:00,  3.82it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5871880054473877
Epoch 1, Loop Feat 0: -0.5859298706054688
Epoch 1, Loop Adj 0: -0.5899778604507446
Epoch 2: -0.5899778604507446
Mem used: -900MB
best_loss: tensor(-0.5954, device='cuda:1')
best_loss: tensor(-0.5958, device='cuda:1')
final loss: -0.5927025675773621
Test:
Test: 0.45253751475299275
0.45253751475299275
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.45it/s]100%|██████████| 2/2 [00:00<00:00,  3.54it/s]100%|██████████| 2/2 [00:00<00:00,  3.65it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011685371399
Epoch 0, Loop Adj 0: -0.6072602868080139
Epoch 1, Loop Feat 0: -0.5999954342842102
Epoch 1, Loop Adj 0: -0.6108570098876953
Epoch 2: -0.6108570098876953
Mem used: -900MB
best_loss: tensor(-0.6076, device='cuda:1')
final loss: -0.6074885129928589
Test:
Test: 0.46008261675939977
0.46008261675939977
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.06it/s]100%|██████████| 2/2 [00:00<00:00,  5.02it/s]100%|██████████| 2/2 [00:00<00:00,  5.03it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6041353344917297
Epoch 1, Loop Feat 0: -0.5977070927619934
Epoch 1, Loop Adj 0: -0.6041132807731628
Epoch 2: -0.6041132807731628
Mem used: -900MB
best_loss: tensor(-0.6066, device='cuda:1')
best_loss: tensor(-0.6066, device='cuda:1')
final loss: -0.6059858202934265
Test:
Test: 0.45215815208227955
0.45215815208227955
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.91it/s]100%|██████████| 2/2 [00:00<00:00,  3.32it/s]100%|██████████| 2/2 [00:00<00:00,  3.40it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.596156895160675
Epoch 1, Loop Feat 0: -0.5962652564048767
Epoch 1, Loop Adj 0: -0.5978688597679138
Epoch 2: -0.5978688597679138
Mem used: -900MB
best_loss: tensor(-0.6066, device='cuda:1')
best_loss: tensor(-0.6069, device='cuda:1')
final loss: -0.6031656861305237
Test:
Test: 0.45291687742370595
0.45291687742370595
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.07it/s]100%|██████████| 2/2 [00:00<00:00,  2.79it/s]100%|██████████| 2/2 [00:00<00:00,  2.83it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5703567862510681
Epoch 1, Loop Feat 0: -0.5707364082336426
Epoch 1, Loop Adj 0: -0.5709754228591919
Epoch 2: -0.5709754228591919
Mem used: -900MB
best_loss: tensor(-0.5767, device='cuda:1')
best_loss: tensor(-0.5772, device='cuda:1')
final loss: -0.5756963491439819
Test:
Test: 0.4465941662451526
0.4465941662451526
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.45it/s]100%|██████████| 2/2 [00:00<00:00,  4.84it/s]100%|██████████| 2/2 [00:00<00:00,  4.77it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.617407500743866
Epoch 1, Loop Feat 0: -0.6216585636138916
Epoch 1, Loop Adj 0: -0.6243049502372742
Epoch 2: -0.6243049502372742
Mem used: -900MB
best_loss: tensor(-0.6263, device='cuda:1')
final loss: -0.6283066272735596
Test:
Test: 0.456752655538695
0.456752655538695
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.29it/s]100%|██████████| 2/2 [00:00<00:00,  5.41it/s]100%|██████████| 2/2 [00:00<00:00,  5.39it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.5894481539726257
Epoch 1, Loop Feat 0: -0.5844780802726746
Epoch 1, Loop Adj 0: -0.5824620127677917
Epoch 2: -0.5824620127677917
Mem used: -900MB
best_loss: tensor(-0.5887, device='cuda:1')
best_loss: tensor(-0.5889, device='cuda:1')
final loss: -0.5874672532081604
Test:
Test: 0.4463834092058675
0.4463834092058675
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.22it/s]100%|██████████| 2/2 [00:00<00:00,  3.87it/s]100%|██████████| 2/2 [00:00<00:00,  3.91it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.575211763381958
Epoch 1, Loop Feat 0: -0.576178789138794
Epoch 1, Loop Adj 0: -0.5797104239463806
Epoch 2: -0.5797104239463806
Mem used: -900MB
best_loss: tensor(-0.5845, device='cuda:1')
final loss: -0.5843218564987183
Test:
Test: 0.4559939301972686
0.4559939301972686
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.51it/s]100%|██████████| 1/1 [00:00<00:00,  5.51it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6201845407485962
Epoch 1: -0.6201845407485962
Mem used: -900MB
best_loss: tensor(-0.6287, device='cuda:1')
best_loss: tensor(-0.6294, device='cuda:1')
final loss: -0.6216006278991699
Test:
Test: 0.44882819086157477
0.44882819086157477
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.30it/s]100%|██████████| 1/1 [00:00<00:00,  5.29it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.614953339099884
Epoch 1: -0.614953339099884
Mem used: -900MB
best_loss: tensor(-0.6114, device='cuda:1')
best_loss: tensor(-0.6127, device='cuda:1')
final loss: -0.6103399395942688
Test:
Test: 0.4562046872365537
0.4562046872365537
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.05it/s]100%|██████████| 1/1 [00:00<00:00,  4.05it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5871880054473877
Epoch 1: -0.5871880054473877
Mem used: -900MB
best_loss: tensor(-0.5918, device='cuda:1')
best_loss: tensor(-0.5925, device='cuda:1')
final loss: -0.5900163650512695
Test:
Test: 0.4527061203844208
0.4527061203844208
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.48it/s]100%|██████████| 1/1 [00:00<00:00,  4.47it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011685371399
Epoch 0, Loop Adj 0: -0.6072602868080139
Epoch 1: -0.6072602868080139
Mem used: -900MB
best_loss: tensor(-0.6056, device='cuda:1')
final loss: -0.6038134098052979
Test:
Test: 0.4614314618108245
0.4614314618108245
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.64it/s]100%|██████████| 1/1 [00:00<00:00,  5.55it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.604135274887085
Epoch 1: -0.604135274887085
Mem used: -900MB
best_loss: tensor(-0.6017, device='cuda:1')
final loss: -0.6007843613624573
Test:
Test: 0.4507250042151408
0.4507250042151408
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.43it/s]100%|██████████| 1/1 [00:00<00:00,  4.42it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.596156895160675
Epoch 1: -0.596156895160675
Mem used: -900MB
best_loss: tensor(-0.6018, device='cuda:1')
best_loss: tensor(-0.6033, device='cuda:1')
final loss: -0.5998547673225403
Test:
Test: 0.4527061203844208
0.4527061203844208
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.82it/s]100%|██████████| 1/1 [00:00<00:00,  2.82it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5703567862510681
Epoch 1: -0.5703567862510681
Mem used: -900MB
best_loss: tensor(-0.5720, device='cuda:1')
best_loss: tensor(-0.5730, device='cuda:1')
final loss: -0.5705633163452148
Test:
Test: 0.4469735289158658
0.4469735289158658
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.77it/s]100%|██████████| 1/1 [00:00<00:00,  3.77it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.617407500743866
Epoch 1: -0.617407500743866
Mem used: -900MB
best_loss: tensor(-0.6246, device='cuda:1')
final loss: -0.6237850189208984
Test:
Test: 0.458649468892261
0.458649468892261
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.42it/s]100%|██████████| 1/1 [00:00<00:00,  5.41it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.5894481539726257
Epoch 1: -0.5894481539726257
Mem used: -900MB
best_loss: tensor(-0.5854, device='cuda:1')
final loss: -0.5830718278884888
Test:
Test: 0.44537177541729894
0.44537177541729894
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.98it/s]100%|██████████| 1/1 [00:00<00:00,  3.97it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5752118229866028
Epoch 1: -0.5752118229866028
Mem used: -900MB
best_loss: tensor(-0.5819, device='cuda:1')
final loss: -0.5792099237442017
Test:
Test: 0.4556145675265554
0.4556145675265554
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.28it/s]100%|██████████| 1/1 [00:00<00:00,  4.28it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6201845407485962
Epoch 1: -0.6201845407485962
Mem used: -900MB
best_loss: tensor(-0.6275, device='cuda:1')
best_loss: tensor(-0.6298, device='cuda:1')
final loss: -0.6221334338188171
Test:
Test: 0.45102006407013995
0.45102006407013995
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.62it/s]100%|██████████| 1/1 [00:00<00:00,  3.61it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6149532794952393
Epoch 1: -0.6149532794952393
Mem used: -900MB
best_loss: tensor(-0.6103, device='cuda:1')
best_loss: tensor(-0.6123, device='cuda:1')
final loss: -0.6105144619941711
Test:
Test: 0.45590962738155455
0.45590962738155455
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.26it/s]100%|██████████| 1/1 [00:00<00:00,  3.26it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5871880054473877
Epoch 1: -0.5871880054473877
Mem used: -900MB
best_loss: tensor(-0.5915, device='cuda:1')
best_loss: tensor(-0.5926, device='cuda:1')
final loss: -0.5902021527290344
Test:
Test: 0.4537177541729894
0.4537177541729894
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.73it/s]100%|██████████| 1/1 [00:00<00:00,  3.73it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.6072602868080139
Epoch 1: -0.6072602868080139
Mem used: -900MB
best_loss: tensor(-0.6036, device='cuda:1')
best_loss: tensor(-0.6040, device='cuda:1')
final loss: -0.6051884293556213
Test:
Test: 0.462443095599393
0.462443095599393
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.14it/s]100%|██████████| 1/1 [00:00<00:00,  3.14it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.604135274887085
Epoch 1: -0.604135274887085
Mem used: -900MB
best_loss: tensor(-0.6017, device='cuda:1')
best_loss: tensor(-0.6034, device='cuda:1')
final loss: -0.6022639870643616
Test:
Test: 0.4524532119372787
0.4524532119372787
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.74it/s]100%|██████████| 1/1 [00:00<00:00,  3.73it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.596156895160675
Epoch 1: -0.596156895160675
Mem used: -900MB
best_loss: tensor(-0.6021, device='cuda:1')
best_loss: tensor(-0.6029, device='cuda:1')
final loss: -0.5993484258651733
Test:
Test: 0.45291687742370595
0.45291687742370595
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.92it/s]100%|██████████| 1/1 [00:00<00:00,  3.85it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5703567862510681
Epoch 1: -0.5703567862510681
Mem used: -900MB
best_loss: tensor(-0.5748, device='cuda:1')
final loss: -0.5694079995155334
Test:
Test: 0.45064070139942675
0.45064070139942675
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.65it/s]100%|██████████| 1/1 [00:00<00:00,  4.64it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.617407500743866
Epoch 1: -0.617407500743866
Mem used: -900MB
best_loss: tensor(-0.6221, device='cuda:1')
best_loss: tensor(-0.6232, device='cuda:1')
final loss: -0.6240082383155823
Test:
Test: 0.45742707806440736
0.45742707806440736
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.70it/s]100%|██████████| 1/1 [00:00<00:00,  3.69it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.5894481539726257
Epoch 1: -0.5894481539726257
Mem used: -900MB
best_loss: tensor(-0.5856, device='cuda:1')
best_loss: tensor(-0.5860, device='cuda:1')
final loss: -0.5834227204322815
Test:
Test: 0.44798516270443434
0.44798516270443434
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.12it/s]100%|██████████| 1/1 [00:00<00:00,  5.12it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5752118229866028
Epoch 1: -0.5752118229866028
Mem used: -900MB
best_loss: tensor(-0.5800, device='cuda:1')
best_loss: tensor(-0.5811, device='cuda:1')
final loss: -0.5803070068359375
Test:
Test: 0.45553026471084135
0.45553026471084135
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.13it/s]100%|██████████| 1/1 [00:00<00:00,  4.12it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6201845407485962
Epoch 1: -0.6201845407485962
Mem used: -900MB
best_loss: tensor(-0.6296, device='cuda:1')
final loss: -0.6222742795944214
Test:
Test: 0.4478587084808633
0.4478587084808633
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.55it/s]100%|██████████| 1/1 [00:00<00:00,  3.51it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6149532794952393
Epoch 1: -0.6149532794952393
Mem used: -900MB
best_loss: tensor(-0.6127, device='cuda:1')
best_loss: tensor(-0.6133, device='cuda:1')
final loss: -0.6112737059593201
Test:
Test: 0.45510875063227113
0.45510875063227113
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.77it/s]100%|██████████| 1/1 [00:00<00:00,  5.76it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5871880054473877
Epoch 1: -0.5871880054473877
Mem used: -900MB
best_loss: tensor(-0.5927, device='cuda:1')
best_loss: tensor(-0.5927, device='cuda:1')
final loss: -0.5895220637321472
Test:
Test: 0.45182094081942337
0.45182094081942337
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.92it/s]100%|██████████| 1/1 [00:00<00:00,  4.91it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.6072602868080139
Epoch 1: -0.6072602868080139
Mem used: -900MB
best_loss: tensor(-0.6046, device='cuda:1')
final loss: -0.6039245128631592
Test:
Test: 0.46075703928511214
0.46075703928511214
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.90it/s]100%|██████████| 1/1 [00:00<00:00,  2.90it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6041353344917297
Epoch 1: -0.6041353344917297
Mem used: -900MB
best_loss: tensor(-0.6031, device='cuda:1')
best_loss: tensor(-0.6034, device='cuda:1')
final loss: -0.6019322276115417
Test:
Test: 0.45161018378013823
0.45161018378013823
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.38it/s]100%|██████████| 1/1 [00:00<00:00,  5.37it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388945579529
Epoch 0, Loop Adj 0: -0.596156895160675
Epoch 1: -0.596156895160675
Mem used: -900MB
best_loss: tensor(-0.6037, device='cuda:1')
final loss: -0.6001454591751099
Test:
Test: 0.4522424548979936
0.4522424548979936
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.23it/s]100%|██████████| 1/1 [00:00<00:00,  3.23it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5703567862510681
Epoch 1: -0.5703567862510681
Mem used: -900MB
best_loss: tensor(-0.5729, device='cuda:1')
best_loss: tensor(-0.5733, device='cuda:1')
final loss: -0.5706957578659058
Test:
Test: 0.44684707469229473
0.44684707469229473
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.63it/s]100%|██████████| 1/1 [00:00<00:00,  2.63it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.617407500743866
Epoch 1: -0.617407500743866
Mem used: -900MB
best_loss: tensor(-0.6242, device='cuda:1')
final loss: -0.6245819330215454
Test:
Test: 0.4571320182094082
0.4571320182094082
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.95it/s]100%|██████████| 1/1 [00:00<00:00,  4.94it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.5894481539726257
Epoch 1: -0.5894481539726257
Mem used: -900MB
best_loss: tensor(-0.5853, device='cuda:1')
best_loss: tensor(-0.5853, device='cuda:1')
final loss: -0.5841103196144104
Test:
Test: 0.44575113808801214
0.44575113808801214
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.44it/s]100%|██████████| 1/1 [00:00<00:00,  4.44it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.575211763381958
Epoch 1: -0.575211763381958
Mem used: -900MB
best_loss: tensor(-0.5811, device='cuda:1')
best_loss: tensor(-0.5814, device='cuda:1')
final loss: -0.5808722972869873
Test:
Test: 0.4550244478165571
0.4550244478165571
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.88it/s]100%|██████████| 2/2 [00:00<00:00,  3.43it/s]100%|██████████| 2/2 [00:00<00:00,  3.49it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6201845407485962
Epoch 1, Loop Feat 0: -0.6199697852134705
Epoch 1, Loop Adj 0: -0.6266331076622009
Epoch 2: -0.6266331076622009
Mem used: -900MB
best_loss: tensor(-0.6330, device='cuda:1')
best_loss: tensor(-0.6331, device='cuda:1')
final loss: -0.6252840161323547
Test:
Test: 0.44992412746585736
0.44992412746585736
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.28it/s]100%|██████████| 2/2 [00:00<00:00,  3.87it/s]100%|██████████| 2/2 [00:00<00:00,  3.92it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.614953339099884
Epoch 1, Loop Feat 0: -0.6100184321403503
Epoch 1, Loop Adj 0: -0.6094089150428772
Epoch 2: -0.6094089150428772
Mem used: -900MB
best_loss: tensor(-0.6155, device='cuda:1')
best_loss: tensor(-0.6159, device='cuda:1')
final loss: -0.6136195659637451
Test:
Test: 0.45595177878941157
0.45595177878941157
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.24it/s]100%|██████████| 2/2 [00:00<00:00,  3.52it/s]100%|██████████| 2/2 [00:00<00:00,  3.48it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5871880054473877
Epoch 1, Loop Feat 0: -0.5846582651138306
Epoch 1, Loop Adj 0: -0.5887033343315125
Epoch 2: -0.5887033343315125
Mem used: -900MB
best_loss: tensor(-0.5954, device='cuda:1')
final loss: -0.5939521193504333
Test:
Test: 0.45612038442083963
0.45612038442083963
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.33it/s]100%|██████████| 2/2 [00:00<00:00,  4.01it/s]100%|██████████| 2/2 [00:00<00:00,  4.12it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011685371399
Epoch 0, Loop Adj 0: -0.6072602868080139
Epoch 1, Loop Feat 0: -0.5987526178359985
Epoch 1, Loop Adj 0: -0.6091902256011963
Epoch 2: -0.6091902256011963
Mem used: -900MB
best_loss: tensor(-0.6080, device='cuda:1')
final loss: -0.607544481754303
Test:
Test: 0.4632439723486764
0.4632439723486764
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.94it/s]100%|██████████| 2/2 [00:00<00:00,  3.37it/s]100%|██████████| 2/2 [00:00<00:00,  3.44it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6041353344917297
Epoch 1, Loop Feat 0: -0.5954523086547852
Epoch 1, Loop Adj 0: -0.602168619632721
Epoch 2: -0.602168619632721
Mem used: -900MB
best_loss: tensor(-0.6060, device='cuda:1')
best_loss: tensor(-0.6071, device='cuda:1')
final loss: -0.6062589883804321
Test:
Test: 0.4531276344629911
0.4531276344629911
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.88it/s]100%|██████████| 2/2 [00:00<00:00,  2.88it/s]100%|██████████| 2/2 [00:00<00:00,  2.99it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.596156895160675
Epoch 1, Loop Feat 0: -0.594346821308136
Epoch 1, Loop Adj 0: -0.5963103771209717
Epoch 2: -0.5963103771209717
Mem used: -900MB
best_loss: tensor(-0.6067, device='cuda:1')
best_loss: tensor(-0.6068, device='cuda:1')
final loss: -0.603661835193634
Test:
Test: 0.45274827179227783
0.45274827179227783
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.82it/s]100%|██████████| 2/2 [00:00<00:00,  2.76it/s]100%|██████████| 2/2 [00:00<00:00,  2.77it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5703567862510681
Epoch 1, Loop Feat 0: -0.5684963464736938
Epoch 1, Loop Adj 0: -0.5688841342926025
Epoch 2: -0.5688841342926025
Mem used: -900MB
best_loss: tensor(-0.5778, device='cuda:1')
final loss: -0.5744749307632446
Test:
Test: 0.449249704940145
0.449249704940145
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.32it/s]100%|██████████| 2/2 [00:00<00:00,  5.56it/s]100%|██████████| 2/2 [00:00<00:00,  5.52it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.617407500743866
Epoch 1, Loop Feat 0: -0.6205226182937622
Epoch 1, Loop Adj 0: -0.6230402588844299
Epoch 2: -0.6230402588844299
Mem used: -900MB
best_loss: tensor(-0.6258, device='cuda:1')
final loss: -0.6257065534591675
Test:
Test: 0.4583544090372618
0.4583544090372618
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.14it/s]100%|██████████| 2/2 [00:00<00:00,  5.19it/s]100%|██████████| 2/2 [00:00<00:00,  5.18it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.5894481539726257
Epoch 1, Loop Feat 0: -0.5826440453529358
Epoch 1, Loop Adj 0: -0.5808116793632507
Epoch 2: -0.5808116793632507
Mem used: -900MB
best_loss: tensor(-0.5904, device='cuda:1')
final loss: -0.5880624651908875
Test:
Test: 0.4500927330972854
0.4500927330972854
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.94it/s]100%|██████████| 2/2 [00:00<00:00,  4.49it/s]100%|██████████| 2/2 [00:00<00:00,  4.66it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.575211763381958
Epoch 1, Loop Feat 0: -0.5749673843383789
Epoch 1, Loop Adj 0: -0.5786150097846985
Epoch 2: -0.5786150097846985
Mem used: -900MB
best_loss: tensor(-0.5855, device='cuda:1')
final loss: -0.5838854312896729
Test:
Test: 0.45923958860225933
0.45923958860225933
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.94it/s]100%|██████████| 2/2 [00:00<00:00,  5.41it/s]100%|██████████| 2/2 [00:00<00:00,  5.33it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6201845407485962
Epoch 1, Loop Feat 0: -0.6178689002990723
Epoch 1, Loop Adj 0: -0.6248807907104492
Epoch 2: -0.6248807907104492
Mem used: -900MB
best_loss: tensor(-0.6359, device='cuda:1')
final loss: -0.6301863789558411
Test:
Test: 0.45135727533299613
0.45135727533299613
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.45it/s]100%|██████████| 2/2 [00:00<00:00,  3.87it/s]100%|██████████| 2/2 [00:00<00:00,  3.94it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6149532794952393
Epoch 1, Loop Feat 0: -0.6079473495483398
Epoch 1, Loop Adj 0: -0.6070784330368042
Epoch 2: -0.6070784330368042
Mem used: -900MB
best_loss: tensor(-0.6204, device='cuda:1')
final loss: -0.618478536605835
Test:
Test: 0.456752655538695
0.456752655538695
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.17it/s]100%|██████████| 2/2 [00:00<00:00,  3.54it/s]100%|██████████| 2/2 [00:00<00:00,  3.48it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5871880054473877
Epoch 1, Loop Feat 0: -0.5830009579658508
Epoch 1, Loop Adj 0: -0.5866718292236328
Epoch 2: -0.5866718292236328
Mem used: -900MB
best_loss: tensor(-0.5995, device='cuda:1')
final loss: -0.5989460945129395
Test:
Test: 0.4571741696172652
0.4571741696172652
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.54it/s]100%|██████████| 2/2 [00:00<00:00,  4.63it/s]100%|██████████| 2/2 [00:00<00:00,  4.42it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.6072602868080139
Epoch 1, Loop Feat 0: -0.5968722701072693
Epoch 1, Loop Adj 0: -0.6068593859672546
Epoch 2: -0.6068593859672546
Mem used: -900MB
best_loss: tensor(-0.6121, device='cuda:1')
final loss: -0.6120728850364685
Test:
Test: 0.4631596695329624
0.4631596695329624
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.84it/s]100%|██████████| 2/2 [00:00<00:00,  3.30it/s]100%|██████████| 2/2 [00:00<00:00,  3.22it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.604135274887085
Epoch 1, Loop Feat 0: -0.592711329460144
Epoch 1, Loop Adj 0: -0.5999054312705994
Epoch 2: -0.5999054312705994
Mem used: -900MB
best_loss: tensor(-0.6111, device='cuda:1')
final loss: -0.6121309399604797
Test:
Test: 0.45801719777440564
0.45801719777440564
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  6.46it/s]100%|██████████| 2/2 [00:00<00:00,  4.87it/s]100%|██████████| 2/2 [00:00<00:00,  5.05it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.596156895160675
Epoch 1, Loop Feat 0: -0.5922212600708008
Epoch 1, Loop Adj 0: -0.5944821238517761
Epoch 2: -0.5944821238517761
Mem used: -900MB
best_loss: tensor(-0.6099, device='cuda:1')
final loss: -0.6084311604499817
Test:
Test: 0.45649974709155283
0.45649974709155283
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.07it/s]100%|██████████| 2/2 [00:00<00:00,  5.42it/s]100%|██████████| 2/2 [00:00<00:00,  5.36it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5703567862510681
Epoch 1, Loop Feat 0: -0.5661922097206116
Epoch 1, Loop Adj 0: -0.566574215888977
Epoch 2: -0.566574215888977
Mem used: -900MB
best_loss: tensor(-0.5832, device='cuda:1')
final loss: -0.5794589519500732
Test:
Test: 0.4513151239251391
0.4513151239251391
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.23it/s]100%|██████████| 2/2 [00:00<00:00,  3.82it/s]100%|██████████| 2/2 [00:00<00:00,  3.72it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.617407500743866
Epoch 1, Loop Feat 0: -0.6189273595809937
Epoch 1, Loop Adj 0: -0.6212771534919739
Epoch 2: -0.6212771534919739
Mem used: -900MB
best_loss: tensor(-0.6283, device='cuda:1')
final loss: -0.6289237141609192
Test:
Test: 0.4613471589951104
0.4613471589951104
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.12it/s]100%|██████████| 2/2 [00:00<00:00,  4.54it/s]100%|██████████| 2/2 [00:00<00:00,  4.47it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.5894481539726257
Epoch 1, Loop Feat 0: -0.5805741548538208
Epoch 1, Loop Adj 0: -0.5789803266525269
Epoch 2: -0.5789803266525269
Mem used: -900MB
best_loss: tensor(-0.5951, device='cuda:1')
final loss: -0.5924209952354431
Test:
Test: 0.4495869162030012
0.4495869162030012
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.20it/s]100%|██████████| 2/2 [00:00<00:00,  3.69it/s]100%|██████████| 2/2 [00:00<00:00,  3.76it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.575211763381958
Epoch 1, Loop Feat 0: -0.5734703540802002
Epoch 1, Loop Adj 0: -0.5768995881080627
Epoch 2: -0.5768995881080627
Mem used: -900MB
best_loss: tensor(-0.5899, device='cuda:1')
final loss: -0.5873947739601135
Test:
Test: 0.456836958354409
0.456836958354409
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.41it/s]100%|██████████| 2/2 [00:00<00:00,  3.94it/s]100%|██████████| 2/2 [00:00<00:00,  4.10it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6201845407485962
Epoch 1, Loop Feat 0: -0.621275007724762
Epoch 1, Loop Adj 0: -0.6275625228881836
Epoch 2: -0.6275625228881836
Mem used: -900MB
best_loss: tensor(-0.6321, device='cuda:1')
best_loss: tensor(-0.6323, device='cuda:1')
final loss: -0.6246863603591919
Test:
Test: 0.44798516270443434
0.44798516270443434
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.00it/s]100%|██████████| 2/2 [00:00<00:00,  3.99it/s]100%|██████████| 2/2 [00:00<00:00,  3.80it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.614953339099884
Epoch 1, Loop Feat 0: -0.6114749908447266
Epoch 1, Loop Adj 0: -0.6113468408584595
Epoch 2: -0.6113468408584595
Mem used: -900MB
best_loss: tensor(-0.6160, device='cuda:1')
best_loss: tensor(-0.6161, device='cuda:1')
final loss: -0.6140937209129333
Test:
Test: 0.45536165907941323
0.45536165907941323
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.72it/s]100%|██████████| 2/2 [00:00<00:00,  3.94it/s]100%|██████████| 2/2 [00:00<00:00,  4.03it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5871880054473877
Epoch 1, Loop Feat 0: -0.5859690308570862
Epoch 1, Loop Adj 0: -0.5900091528892517
Epoch 2: -0.5900091528892517
Mem used: -900MB
best_loss: tensor(-0.5955, device='cuda:1')
best_loss: tensor(-0.5958, device='cuda:1')
final loss: -0.592649519443512
Test:
Test: 0.45253751475299275
0.45253751475299275
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.15it/s]100%|██████████| 2/2 [00:00<00:00,  4.40it/s]100%|██████████| 2/2 [00:00<00:00,  4.50it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011685371399
Epoch 0, Loop Adj 0: -0.6072602868080139
Epoch 1, Loop Feat 0: -0.6000204086303711
Epoch 1, Loop Adj 0: -0.6109041571617126
Epoch 2: -0.6109041571617126
Mem used: -900MB
best_loss: tensor(-0.6078, device='cuda:1')
final loss: -0.6067472100257874
Test:
Test: 0.46075703928511214
0.46075703928511214
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  6.00it/s]100%|██████████| 2/2 [00:00<00:00,  3.25it/s]100%|██████████| 2/2 [00:00<00:00,  3.48it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6041353344917297
Epoch 1, Loop Feat 0: -0.5977725386619568
Epoch 1, Loop Adj 0: -0.6041733026504517
Epoch 2: -0.6041733026504517
Mem used: -900MB
best_loss: tensor(-0.6066, device='cuda:1')
final loss: -0.6050915122032166
Test:
Test: 0.4531697858708481
0.4531697858708481
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.17it/s]100%|██████████| 2/2 [00:00<00:00,  3.22it/s]100%|██████████| 2/2 [00:00<00:00,  3.33it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388945579529
Epoch 0, Loop Adj 0: -0.596156895160675
Epoch 1, Loop Feat 0: -0.5963214039802551
Epoch 1, Loop Adj 0: -0.5979082584381104
Epoch 2: -0.5979082584381104
Mem used: -900MB
best_loss: tensor(-0.6065, device='cuda:1')
best_loss: tensor(-0.6069, device='cuda:1')
final loss: -0.6035284399986267
Test:
Test: 0.4528325746079919
0.4528325746079919
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.33it/s]100%|██████████| 2/2 [00:00<00:00,  2.41it/s]100%|██████████| 2/2 [00:00<00:00,  2.40it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5703567862510681
Epoch 1, Loop Feat 0: -0.5708069205284119
Epoch 1, Loop Adj 0: -0.5710410475730896
Epoch 2: -0.5710410475730896
Mem used: -900MB
best_loss: tensor(-0.5766, device='cuda:1')
best_loss: tensor(-0.5771, device='cuda:1')
final loss: -0.5752539038658142
Test:
Test: 0.4466784690608666
0.4466784690608666
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.28it/s]100%|██████████| 2/2 [00:00<00:00,  4.36it/s]100%|██████████| 2/2 [00:00<00:00,  4.48it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.617407500743866
Epoch 1, Loop Feat 0: -0.6216917634010315
Epoch 1, Loop Adj 0: -0.6243356466293335
Epoch 2: -0.6243356466293335
Mem used: -900MB
best_loss: tensor(-0.6263, device='cuda:1')
final loss: -0.6282545328140259
Test:
Test: 0.45666835272298095
0.45666835272298095
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  6.64it/s]100%|██████████| 2/2 [00:00<00:00,  4.05it/s]100%|██████████| 2/2 [00:00<00:00,  4.29it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.5894481539726257
Epoch 1, Loop Feat 0: -0.5845295786857605
Epoch 1, Loop Adj 0: -0.5825176239013672
Epoch 2: -0.5825176239013672
Mem used: -900MB
best_loss: tensor(-0.5887, device='cuda:1')
best_loss: tensor(-0.5888, device='cuda:1')
final loss: -0.5877910852432251
Test:
Test: 0.4462569549822964
0.4462569549822964
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.13it/s]100%|██████████| 2/2 [00:00<00:00,  3.01it/s]100%|██████████| 2/2 [00:00<00:00,  3.14it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.575211763381958
Epoch 1, Loop Feat 0: -0.5762196183204651
Epoch 1, Loop Adj 0: -0.579731822013855
Epoch 2: -0.579731822013855
Mem used: -900MB
best_loss: tensor(-0.5845, device='cuda:1')
final loss: -0.584561288356781
Test:
Test: 0.4559939301972686
0.4559939301972686
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.76it/s]100%|██████████| 1/1 [00:00<00:00,  3.76it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6201845407485962
Epoch 1: -0.6201845407485962
Mem used: -900MB
best_loss: tensor(-0.6287, device='cuda:1')
best_loss: tensor(-0.6296, device='cuda:1')
final loss: -0.6223474740982056
Test:
Test: 0.4481537683358624
0.4481537683358624
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.73it/s]100%|██████████| 1/1 [00:00<00:00,  4.73it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6149532794952393
Epoch 1: -0.6149532794952393
Mem used: -900MB
best_loss: tensor(-0.6114, device='cuda:1')
best_loss: tensor(-0.6130, device='cuda:1')
final loss: -0.6102110147476196
Test:
Test: 0.4552773562636992
0.4552773562636992
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.67it/s]100%|██████████| 1/1 [00:00<00:00,  4.67it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5871880054473877
Epoch 1: -0.5871880054473877
Mem used: -900MB
best_loss: tensor(-0.5918, device='cuda:1')
best_loss: tensor(-0.5929, device='cuda:1')
final loss: -0.5895351767539978
Test:
Test: 0.45215815208227955
0.45215815208227955
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.95it/s]100%|██████████| 1/1 [00:00<00:00,  3.95it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.6072602868080139
Epoch 1: -0.6072602868080139
Mem used: -900MB
best_loss: tensor(-0.6056, device='cuda:1')
final loss: -0.6038134098052979
Test:
Test: 0.4614314618108245
0.4614314618108245
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.66it/s]100%|██████████| 1/1 [00:00<00:00,  4.66it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6041353344917297
Epoch 1: -0.6041353344917297
Mem used: -900MB
best_loss: tensor(-0.6017, device='cuda:1')
best_loss: tensor(-0.6034, device='cuda:1')
final loss: -0.6018400192260742
Test:
Test: 0.4514837295565672
0.4514837295565672
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.30it/s]100%|██████████| 1/1 [00:00<00:00,  4.29it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.596156895160675
Epoch 1: -0.596156895160675
Mem used: -900MB
best_loss: tensor(-0.6018, device='cuda:1')
best_loss: tensor(-0.6035, device='cuda:1')
final loss: -0.5993412733078003
Test:
Test: 0.45291687742370595
0.45291687742370595
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.55it/s]100%|██████████| 1/1 [00:00<00:00,  4.54it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5703567862510681
Epoch 1: -0.5703567862510681
Mem used: -900MB
best_loss: tensor(-0.5720, device='cuda:1')
best_loss: tensor(-0.5731, device='cuda:1')
final loss: -0.5714157819747925
Test:
Test: 0.4469735289158658
0.4469735289158658
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.87it/s]100%|██████████| 1/1 [00:00<00:00,  4.87it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.617407500743866
Epoch 1: -0.617407500743866
Mem used: -900MB
best_loss: tensor(-0.6246, device='cuda:1')
final loss: -0.624388575553894
Test:
Test: 0.458649468892261
0.458649468892261
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.29it/s]100%|██████████| 1/1 [00:00<00:00,  5.28it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.5894481539726257
Epoch 1: -0.5894481539726257
Mem used: -900MB
best_loss: tensor(-0.5854, device='cuda:1')
final loss: -0.5830718278884888
Test:
Test: 0.44537177541729894
0.44537177541729894
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.58it/s]100%|██████████| 1/1 [00:00<00:00,  5.57it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5752118229866028
Epoch 1: -0.5752118229866028
Mem used: -900MB
best_loss: tensor(-0.5819, device='cuda:1')
final loss: -0.5792099237442017
Test:
Test: 0.4556145675265554
0.4556145675265554
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.07it/s]100%|██████████| 1/1 [00:00<00:00,  4.07it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6201845407485962
Epoch 1: -0.6201845407485962
Mem used: -900MB
best_loss: tensor(-0.6275, device='cuda:1')
best_loss: tensor(-0.6296, device='cuda:1')
final loss: -0.6223474740982056
Test:
Test: 0.4481537683358624
0.4481537683358624
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.59it/s]100%|██████████| 1/1 [00:00<00:00,  3.58it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6149532794952393
Epoch 1: -0.6149532794952393
Mem used: -900MB
best_loss: tensor(-0.6103, device='cuda:1')
best_loss: tensor(-0.6130, device='cuda:1')
final loss: -0.6102110147476196
Test:
Test: 0.4552773562636992
0.4552773562636992
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.97it/s]100%|██████████| 1/1 [00:00<00:00,  4.96it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5871880054473877
Epoch 1: -0.5871880054473877
Mem used: -900MB
best_loss: tensor(-0.5915, device='cuda:1')
best_loss: tensor(-0.5929, device='cuda:1')
final loss: -0.5895351767539978
Test:
Test: 0.45215815208227955
0.45215815208227955
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.60it/s]100%|██████████| 1/1 [00:00<00:00,  3.59it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.6072602868080139
Epoch 1: -0.6072602868080139
Mem used: -900MB
best_loss: tensor(-0.6036, device='cuda:1')
best_loss: tensor(-0.6038, device='cuda:1')
final loss: -0.6036044955253601
Test:
Test: 0.4594503456415444
0.4594503456415444
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.17it/s]100%|██████████| 1/1 [00:00<00:00,  5.16it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6041353344917297
Epoch 1: -0.6041353344917297
Mem used: -900MB
best_loss: tensor(-0.6017, device='cuda:1')
best_loss: tensor(-0.6034, device='cuda:1')
final loss: -0.6018400192260742
Test:
Test: 0.4514837295565672
0.4514837295565672
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.39it/s]100%|██████████| 1/1 [00:00<00:00,  5.38it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.596156895160675
Epoch 1: -0.596156895160675
Mem used: -900MB
best_loss: tensor(-0.6021, device='cuda:1')
best_loss: tensor(-0.6035, device='cuda:1')
final loss: -0.5993412733078003
Test:
Test: 0.45291687742370595
0.45291687742370595
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.45it/s]100%|██████████| 1/1 [00:00<00:00,  3.44it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5703567862510681
Epoch 1: -0.5703567862510681
Mem used: -900MB
best_loss: tensor(-0.5748, device='cuda:1')
final loss: -0.5694079995155334
Test:
Test: 0.45064070139942675
0.45064070139942675
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.12it/s]100%|██████████| 1/1 [00:00<00:00,  3.12it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.617407500743866
Epoch 1: -0.617407500743866
Mem used: -900MB
best_loss: tensor(-0.6221, device='cuda:1')
best_loss: tensor(-0.6229, device='cuda:1')
final loss: -0.6248910427093506
Test:
Test: 0.4564154442758388
0.4564154442758388
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.15it/s]100%|██████████| 1/1 [00:00<00:00,  4.14it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.5894481539726257
Epoch 1: -0.5894481539726257
Mem used: -900MB
best_loss: tensor(-0.5856, device='cuda:1')
final loss: -0.5833965539932251
Test:
Test: 0.4496712190187152
0.4496712190187152
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.99it/s]100%|██████████| 1/1 [00:00<00:00,  5.97it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5752118229866028
Epoch 1: -0.5752118229866028
Mem used: -900MB
best_loss: tensor(-0.5800, device='cuda:1')
best_loss: tensor(-0.5817, device='cuda:1')
final loss: -0.5810002088546753
Test:
Test: 0.4553195076715562
0.4553195076715562
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.56it/s]100%|██████████| 1/1 [00:00<00:00,  3.56it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6201845407485962
Epoch 1: -0.6201845407485962
Mem used: -900MB
best_loss: tensor(-0.6296, device='cuda:1')
best_loss: tensor(-0.6296, device='cuda:1')
final loss: -0.621796190738678
Test:
Test: 0.447437194402293
0.447437194402293
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.73it/s]100%|██████████| 1/1 [00:00<00:00,  5.72it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6149532794952393
Epoch 1: -0.6149532794952393
Mem used: -900MB
best_loss: tensor(-0.6127, device='cuda:1')
best_loss: tensor(-0.6132, device='cuda:1')
final loss: -0.6107739806175232
Test:
Test: 0.4550244478165571
0.4550244478165571
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.14it/s]100%|██████████| 1/1 [00:00<00:00,  4.14it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5871880054473877
Epoch 1: -0.5871880054473877
Mem used: -900MB
best_loss: tensor(-0.5927, device='cuda:1')
best_loss: tensor(-0.5928, device='cuda:1')
final loss: -0.5895868539810181
Test:
Test: 0.45182094081942337
0.45182094081942337
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.04it/s]100%|██████████| 1/1 [00:00<00:00,  4.03it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011685371399
Epoch 0, Loop Adj 0: -0.6072602868080139
Epoch 1: -0.6072602868080139
Mem used: -900MB
best_loss: tensor(-0.6046, device='cuda:1')
final loss: -0.6039245128631592
Test:
Test: 0.46075703928511214
0.46075703928511214
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.37it/s]100%|██████████| 1/1 [00:00<00:00,  4.36it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6041353344917297
Epoch 1: -0.6041353344917297
Mem used: -900MB
best_loss: tensor(-0.6031, device='cuda:1')
final loss: -0.6019967198371887
Test:
Test: 0.4513151239251391
0.4513151239251391
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.80it/s]100%|██████████| 1/1 [00:00<00:00,  4.79it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388945579529
Epoch 0, Loop Adj 0: -0.596156895160675
Epoch 1: -0.596156895160675
Mem used: -900MB
best_loss: tensor(-0.6037, device='cuda:1')
final loss: -0.6001454591751099
Test:
Test: 0.4522424548979936
0.4522424548979936
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.38it/s]100%|██████████| 1/1 [00:00<00:00,  5.37it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5703567862510681
Epoch 1: -0.5703567862510681
Mem used: -900MB
best_loss: tensor(-0.5729, device='cuda:1')
best_loss: tensor(-0.5732, device='cuda:1')
final loss: -0.5706161260604858
Test:
Test: 0.4469735289158658
0.4469735289158658
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.78it/s]100%|██████████| 1/1 [00:00<00:00,  3.78it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.617407500743866
Epoch 1: -0.617407500743866
Mem used: -900MB
best_loss: tensor(-0.6242, device='cuda:1')
final loss: -0.6245819330215454
Test:
Test: 0.4571320182094082
0.4571320182094082
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.40it/s]100%|██████████| 1/1 [00:00<00:00,  3.39it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.5894481539726257
Epoch 1: -0.5894481539726257
Mem used: -900MB
best_loss: tensor(-0.5852, device='cuda:1')
final loss: -0.5845370292663574
Test:
Test: 0.4462991063901534
0.4462991063901534
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.51it/s]100%|██████████| 1/1 [00:00<00:00,  4.50it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.575211763381958
Epoch 1: -0.575211763381958
Mem used: -900MB
best_loss: tensor(-0.5811, device='cuda:1')
best_loss: tensor(-0.5812, device='cuda:1')
final loss: -0.5807697176933289
Test:
Test: 0.4550665992244141
0.4550665992244141
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.95it/s]100%|██████████| 2/2 [00:00<00:00,  2.65it/s]100%|██████████| 2/2 [00:00<00:00,  2.69it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6201845407485962
Epoch 1, Loop Feat 0: -0.6209899187088013
Epoch 1, Loop Adj 0: -0.6273764371871948
Epoch 2: -0.6273764371871948
Mem used: -900MB
best_loss: tensor(-0.6329, device='cuda:1')
final loss: -0.6242907643318176
Test:
Test: 0.45249536334513574
0.45249536334513574
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.89it/s]100%|██████████| 2/2 [00:00<00:00,  3.88it/s]100%|██████████| 2/2 [00:00<00:00,  4.00it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6149532794952393
Epoch 1, Loop Feat 0: -0.6112198233604431
Epoch 1, Loop Adj 0: -0.6109502911567688
Epoch 2: -0.6109502911567688
Mem used: -900MB
best_loss: tensor(-0.6161, device='cuda:1')
final loss: -0.6141015887260437
Test:
Test: 0.45738492665655034
0.45738492665655034
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.72it/s]100%|██████████| 2/2 [00:00<00:00,  3.87it/s]100%|██████████| 2/2 [00:00<00:00,  3.98it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5871880054473877
Epoch 1, Loop Feat 0: -0.5856947898864746
Epoch 1, Loop Adj 0: -0.5897701382637024
Epoch 2: -0.5897701382637024
Mem used: -900MB
best_loss: tensor(-0.5950, device='cuda:1')
best_loss: tensor(-0.5959, device='cuda:1')
final loss: -0.5934896469116211
Test:
Test: 0.4522846063058506
0.4522846063058506
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.90it/s]100%|██████████| 2/2 [00:00<00:00,  5.21it/s]100%|██████████| 2/2 [00:00<00:00,  5.16it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.6072602868080139
Epoch 1, Loop Feat 0: -0.5997828841209412
Epoch 1, Loop Adj 0: -0.6105490326881409
Epoch 2: -0.6105490326881409
Mem used: -900MB
best_loss: tensor(-0.6069, device='cuda:1')
best_loss: tensor(-0.6072, device='cuda:1')
final loss: -0.6072077751159668
Test:
Test: 0.4599561625358287
0.4599561625358287
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.95it/s]100%|██████████| 2/2 [00:00<00:00,  3.06it/s]100%|██████████| 2/2 [00:00<00:00,  3.24it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6041353344917297
Epoch 1, Loop Feat 0: -0.5973005294799805
Epoch 1, Loop Adj 0: -0.603761613368988
Epoch 2: -0.603761613368988
Mem used: -900MB
best_loss: tensor(-0.6057, device='cuda:1')
best_loss: tensor(-0.6064, device='cuda:1')
final loss: -0.6059104204177856
Test:
Test: 0.4524110605294217
0.4524110605294217
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.72it/s]100%|██████████| 2/2 [00:00<00:00,  3.66it/s]100%|██████████| 2/2 [00:00<00:00,  3.79it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388945579529
Epoch 0, Loop Adj 0: -0.596156895160675
Epoch 1, Loop Feat 0: -0.5959198474884033
Epoch 1, Loop Adj 0: -0.5975973606109619
Epoch 2: -0.5975973606109619
Mem used: -900MB
best_loss: tensor(-0.6068, device='cuda:1')
best_loss: tensor(-0.6072, device='cuda:1')
final loss: -0.6034303307533264
Test:
Test: 0.4527904232001349
0.4527904232001349
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.50it/s]100%|██████████| 2/2 [00:00<00:00,  4.99it/s]100%|██████████| 2/2 [00:00<00:00,  4.91it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5703567862510681
Epoch 1, Loop Feat 0: -0.5703294277191162
Epoch 1, Loop Adj 0: -0.5705909132957458
Epoch 2: -0.5705909132957458
Mem used: -900MB
best_loss: tensor(-0.5772, device='cuda:1')
best_loss: tensor(-0.5776, device='cuda:1')
final loss: -0.5749699473381042
Test:
Test: 0.4462991063901534
0.4462991063901534
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.83it/s]100%|██████████| 2/2 [00:00<00:00,  3.71it/s]100%|██████████| 2/2 [00:00<00:00,  3.54it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.617407500743866
Epoch 1, Loop Feat 0: -0.6214442253112793
Epoch 1, Loop Adj 0: -0.6240640878677368
Epoch 2: -0.6240640878677368
Mem used: -900MB
best_loss: tensor(-0.6255, device='cuda:1')
best_loss: tensor(-0.6255, device='cuda:1')
final loss: -0.6278833746910095
Test:
Test: 0.4559939301972686
0.4559939301972686
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.74it/s]100%|██████████| 2/2 [00:00<00:00,  3.96it/s]100%|██████████| 2/2 [00:00<00:00,  3.93it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.5894481539726257
Epoch 1, Loop Feat 0: -0.5841714143753052
Epoch 1, Loop Adj 0: -0.5821670889854431
Epoch 2: -0.5821670889854431
Mem used: -900MB
best_loss: tensor(-0.5894, device='cuda:1')
final loss: -0.5880458354949951
Test:
Test: 0.4495869162030012
0.4495869162030012
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.07it/s]100%|██████████| 2/2 [00:00<00:00,  3.04it/s]100%|██████████| 2/2 [00:00<00:00,  3.04it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5752118229866028
Epoch 1, Loop Feat 0: -0.575937032699585
Epoch 1, Loop Adj 0: -0.5795210599899292
Epoch 2: -0.5795210599899292
Mem used: -900MB
best_loss: tensor(-0.5848, device='cuda:1')
final loss: -0.5839207768440247
Test:
Test: 0.4579750463665486
0.4579750463665486
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.49it/s]100%|██████████| 2/2 [00:00<00:00,  4.09it/s]100%|██████████| 2/2 [00:00<00:00,  4.25it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6201845407485962
Epoch 1, Loop Feat 0: -0.6209899187088013
Epoch 1, Loop Adj 0: -0.6273764371871948
Epoch 2: -0.6273764371871948
Mem used: -900MB
best_loss: tensor(-0.6355, device='cuda:1')
final loss: -0.6283374428749084
Test:
Test: 0.45274827179227783
0.45274827179227783
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  6.68it/s]100%|██████████| 2/2 [00:00<00:00,  5.56it/s]100%|██████████| 2/2 [00:00<00:00,  5.70it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6149533987045288
Epoch 1, Loop Feat 0: -0.6112198233604431
Epoch 1, Loop Adj 0: -0.6109502911567688
Epoch 2: -0.6109502911567688
Mem used: -900MB
best_loss: tensor(-0.6202, device='cuda:1')
final loss: -0.6189665794372559
Test:
Test: 0.45633114146012477
0.45633114146012477
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.36it/s]100%|██████████| 2/2 [00:00<00:00,  4.79it/s]100%|██████████| 2/2 [00:00<00:00,  4.86it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5871880054473877
Epoch 1, Loop Feat 0: -0.5856948494911194
Epoch 1, Loop Adj 0: -0.5897701382637024
Epoch 2: -0.5897701382637024
Mem used: -900MB
best_loss: tensor(-0.5982, device='cuda:1')
final loss: -0.5970176458358765
Test:
Test: 0.4575535322879784
0.4575535322879784
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.02it/s]100%|██████████| 2/2 [00:00<00:00,  3.65it/s]100%|██████████| 2/2 [00:00<00:00,  3.70it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.6072602868080139
Epoch 1, Loop Feat 0: -0.5997828841209412
Epoch 1, Loop Adj 0: -0.6105490326881409
Epoch 2: -0.6105490326881409
Mem used: -900MB
best_loss: tensor(-0.6104, device='cuda:1')
final loss: -0.6107620596885681
Test:
Test: 0.46493002866295735
0.46493002866295735
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.96it/s]100%|██████████| 2/2 [00:00<00:00,  2.78it/s]100%|██████████| 2/2 [00:00<00:00,  2.91it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6041353344917297
Epoch 1, Loop Feat 0: -0.5973005294799805
Epoch 1, Loop Adj 0: -0.603761613368988
Epoch 2: -0.603761613368988
Mem used: -900MB
best_loss: tensor(-0.6101, device='cuda:1')
final loss: -0.6117492914199829
Test:
Test: 0.4578907435508346
0.4578907435508346
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.34it/s]100%|██████████| 2/2 [00:00<00:00,  2.54it/s]100%|██████████| 2/2 [00:00<00:00,  2.51it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.596156895160675
Epoch 1, Loop Feat 0: -0.5959198474884033
Epoch 1, Loop Adj 0: -0.5975973606109619
Epoch 2: -0.5975973606109619
Mem used: -900MB
best_loss: tensor(-0.6100, device='cuda:1')
final loss: -0.6081340909004211
Test:
Test: 0.4545607823301298
0.4545607823301298
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.47it/s]100%|██████████| 2/2 [00:00<00:00,  3.64it/s]100%|██████████| 2/2 [00:00<00:00,  3.58it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5703567862510681
Epoch 1, Loop Feat 0: -0.5703294277191162
Epoch 1, Loop Adj 0: -0.5705909132957458
Epoch 2: -0.5705909132957458
Mem used: -900MB
best_loss: tensor(-0.5833, device='cuda:1')
final loss: -0.5799965858459473
Test:
Test: 0.4497976732422863
0.4497976732422863
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.40it/s]100%|██████████| 2/2 [00:00<00:00,  3.52it/s]100%|██████████| 2/2 [00:00<00:00,  3.63it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.617407500743866
Epoch 1, Loop Feat 0: -0.6214442253112793
Epoch 1, Loop Adj 0: -0.6240640878677368
Epoch 2: -0.6240640878677368
Mem used: -900MB
best_loss: tensor(-0.6277, device='cuda:1')
final loss: -0.628526508808136
Test:
Test: 0.4589866801551172
0.4589866801551172
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.98it/s]100%|██████████| 2/2 [00:00<00:00,  4.56it/s]100%|██████████| 2/2 [00:00<00:00,  4.62it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.5894481539726257
Epoch 1, Loop Feat 0: -0.5841714143753052
Epoch 1, Loop Adj 0: -0.5821670293807983
Epoch 2: -0.5821670293807983
Mem used: -900MB
best_loss: tensor(-0.5939, device='cuda:1')
final loss: -0.5926995277404785
Test:
Test: 0.4508514584387118
0.4508514584387118
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.57it/s]100%|██████████| 2/2 [00:00<00:00,  3.94it/s]100%|██████████| 2/2 [00:00<00:00,  4.02it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.575211763381958
Epoch 1, Loop Feat 0: -0.575937032699585
Epoch 1, Loop Adj 0: -0.5795210599899292
Epoch 2: -0.5795210599899292
Mem used: -900MB
best_loss: tensor(-0.5884, device='cuda:1')
final loss: -0.5862881541252136
Test:
Test: 0.4563732928679818
0.4563732928679818
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  6.43it/s]100%|██████████| 2/2 [00:00<00:00,  5.35it/s]100%|██████████| 2/2 [00:00<00:00,  5.48it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234632134437561
Epoch 0, Loop Adj 0: -0.6201845407485962
Epoch 1, Loop Feat 0: -0.6212953329086304
Epoch 1, Loop Adj 0: -0.6275753378868103
Epoch 2: -0.6275753378868103
Mem used: -900MB
best_loss: tensor(-0.6321, device='cuda:1')
best_loss: tensor(-0.6324, device='cuda:1')
final loss: -0.6246587634086609
Test:
Test: 0.4479430112965773
0.4479430112965773
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.80it/s]100%|██████████| 2/2 [00:00<00:00,  5.28it/s]100%|██████████| 2/2 [00:00<00:00,  5.20it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6149532794952393
Epoch 1, Loop Feat 0: -0.6114941835403442
Epoch 1, Loop Adj 0: -0.6113775968551636
Epoch 2: -0.6113775968551636
Mem used: -900MB
best_loss: tensor(-0.6160, device='cuda:1')
best_loss: tensor(-0.6161, device='cuda:1')
final loss: -0.6139826774597168
Test:
Test: 0.45536165907941323
0.45536165907941323
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.44it/s]100%|██████████| 2/2 [00:00<00:00,  4.42it/s]100%|██████████| 2/2 [00:00<00:00,  4.24it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5871880054473877
Epoch 1, Loop Feat 0: -0.5859935879707336
Epoch 1, Loop Adj 0: -0.5900279879570007
Epoch 2: -0.5900279879570007
Mem used: -900MB
best_loss: tensor(-0.5955, device='cuda:1')
best_loss: tensor(-0.5958, device='cuda:1')
final loss: -0.5927937030792236
Test:
Test: 0.4527061203844208
0.4527061203844208
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.31it/s]100%|██████████| 2/2 [00:00<00:00,  2.91it/s]100%|██████████| 2/2 [00:00<00:00,  2.96it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011685371399
Epoch 0, Loop Adj 0: -0.6072602868080139
Epoch 1, Loop Feat 0: -0.6000365614891052
Epoch 1, Loop Adj 0: -0.6109310984611511
Epoch 2: -0.6109310984611511
Mem used: -900MB
best_loss: tensor(-0.6077, device='cuda:1')
final loss: -0.6070927977561951
Test:
Test: 0.46079919069296915
0.46079919069296915
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.37it/s]100%|██████████| 2/2 [00:00<00:00,  3.33it/s]100%|██████████| 2/2 [00:00<00:00,  3.14it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6041353344917297
Epoch 1, Loop Feat 0: -0.597811222076416
Epoch 1, Loop Adj 0: -0.6042084693908691
Epoch 2: -0.6042084693908691
Mem used: -900MB
best_loss: tensor(-0.6066, device='cuda:1')
best_loss: tensor(-0.6066, device='cuda:1')
final loss: -0.605374813079834
Test:
Test: 0.4524532119372787
0.4524532119372787
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.17it/s]100%|██████████| 2/2 [00:00<00:00,  4.40it/s]100%|██████████| 2/2 [00:00<00:00,  4.50it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.596156895160675
Epoch 1, Loop Feat 0: -0.5963532328605652
Epoch 1, Loop Adj 0: -0.5979297757148743
Epoch 2: -0.5979297757148743
Mem used: -900MB
best_loss: tensor(-0.6065, device='cuda:1')
best_loss: tensor(-0.6069, device='cuda:1')
final loss: -0.6032093167304993
Test:
Test: 0.4524110605294217
0.4524110605294217
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.31it/s]100%|██████████| 2/2 [00:00<00:00,  4.15it/s]100%|██████████| 2/2 [00:00<00:00,  4.28it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5703567862510681
Epoch 1, Loop Feat 0: -0.5708504915237427
Epoch 1, Loop Adj 0: -0.571079671382904
Epoch 2: -0.571079671382904
Mem used: -900MB
best_loss: tensor(-0.5766, device='cuda:1')
best_loss: tensor(-0.5771, device='cuda:1')
final loss: -0.5753213763237
Test:
Test: 0.4465941662451526
0.4465941662451526
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.41it/s]100%|██████████| 2/2 [00:00<00:00,  3.93it/s]100%|██████████| 2/2 [00:00<00:00,  3.99it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.617407500743866
Epoch 1, Loop Feat 0: -0.6217119693756104
Epoch 1, Loop Adj 0: -0.624354362487793
Epoch 2: -0.624354362487793
Mem used: -900MB
best_loss: tensor(-0.6263, device='cuda:1')
final loss: -0.6278078556060791
Test:
Test: 0.45666835272298095
0.45666835272298095
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.73it/s]100%|██████████| 2/2 [00:00<00:00,  3.70it/s]100%|██████████| 2/2 [00:00<00:00,  3.51it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.5894481539726257
Epoch 1, Loop Feat 0: -0.5845646262168884
Epoch 1, Loop Adj 0: -0.5825525522232056
Epoch 2: -0.5825525522232056
Mem used: -900MB
best_loss: tensor(-0.5887, device='cuda:1')
final loss: -0.5875805616378784
Test:
Test: 0.4469735289158658
0.4469735289158658
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.23it/s]100%|██████████| 2/2 [00:00<00:00,  2.40it/s]100%|██████████| 2/2 [00:00<00:00,  2.48it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.575211763381958
Epoch 1, Loop Feat 0: -0.5762439966201782
Epoch 1, Loop Adj 0: -0.5797444581985474
Epoch 2: -0.5797444581985474
Mem used: -900MB
best_loss: tensor(-0.5845, device='cuda:1')
best_loss: tensor(-0.5845, device='cuda:1')
final loss: -0.5838821530342102
Test:
Test: 0.4557831731579835
0.4557831731579835
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.17it/s]100%|██████████| 1/1 [00:00<00:00,  3.17it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6188040375709534
Epoch 1: -0.6188040375709534
Mem used: -900MB
best_loss: tensor(-0.6230, device='cuda:1')
best_loss: tensor(-0.6238, device='cuda:1')
final loss: -0.6182454824447632
Test:
Test: 0.4496712190187152
0.4496712190187152
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.21it/s]100%|██████████| 1/1 [00:00<00:00,  4.20it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6133822798728943
Epoch 1: -0.6133822798728943
Mem used: -900MB
best_loss: tensor(-0.6054, device='cuda:1')
best_loss: tensor(-0.6071, device='cuda:1')
final loss: -0.6055830121040344
Test:
Test: 0.45510875063227113
0.45510875063227113
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.79it/s]100%|██████████| 1/1 [00:00<00:00,  3.78it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5855416655540466
Epoch 1: -0.5855416655540466
Mem used: -900MB
best_loss: tensor(-0.5858, device='cuda:1')
best_loss: tensor(-0.5865, device='cuda:1')
final loss: -0.5863321423530579
Test:
Test: 0.4532119372787051
0.4532119372787051
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.99it/s]100%|██████████| 1/1 [00:00<00:00,  2.99it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.605486273765564
Epoch 1: -0.605486273765564
Mem used: -900MB
best_loss: tensor(-0.5993, device='cuda:1')
final loss: -0.5999714136123657
Test:
Test: 0.4609677963243972
0.4609677963243972
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.73it/s]100%|██████████| 1/1 [00:00<00:00,  3.73it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6022611856460571
Epoch 1: -0.6022611856460571
Mem used: -900MB
best_loss: tensor(-0.5960, device='cuda:1')
final loss: -0.596182644367218
Test:
Test: 0.45215815208227955
0.45215815208227955
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.60it/s]100%|██████████| 1/1 [00:00<00:00,  5.59it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.5943117141723633
Epoch 1: -0.5943117141723633
Mem used: -900MB
best_loss: tensor(-0.5954, device='cuda:1')
best_loss: tensor(-0.5968, device='cuda:1')
final loss: -0.5951642394065857
Test:
Test: 0.45236890912156463
0.45236890912156463
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.33it/s]100%|██████████| 1/1 [00:00<00:00,  5.32it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5679726004600525
Epoch 1: -0.5679726004600525
Mem used: -900MB
best_loss: tensor(-0.5654, device='cuda:1')
best_loss: tensor(-0.5661, device='cuda:1')
final loss: -0.5652757287025452
Test:
Test: 0.4460461979430113
0.4460461979430113
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.51it/s]100%|██████████| 1/1 [00:00<00:00,  4.50it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6161868572235107
Epoch 1: -0.6161868572235107
Mem used: -900MB
best_loss: tensor(-0.6192, device='cuda:1')
final loss: -0.6205183863639832
Test:
Test: 0.4591974371944023
0.4591974371944023
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.21it/s]100%|██████████| 1/1 [00:00<00:00,  4.20it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.587518572807312
Epoch 1: -0.587518572807312
Mem used: -900MB
best_loss: tensor(-0.5792, device='cuda:1')
final loss: -0.579164981842041
Test:
Test: 0.44503456415444276
0.44503456415444276
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.92it/s]100%|██████████| 1/1 [00:00<00:00,  4.91it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5735430717468262
Epoch 1: -0.5735430717468262
Mem used: -900MB
best_loss: tensor(-0.5757, device='cuda:1')
final loss: -0.5750858783721924
Test:
Test: 0.4554459618951273
0.4554459618951273
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.71it/s]100%|██████████| 1/1 [00:00<00:00,  3.70it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6188040375709534
Epoch 1: -0.6188040375709534
Mem used: -900MB
best_loss: tensor(-0.6225, device='cuda:1')
best_loss: tensor(-0.6241, device='cuda:1')
final loss: -0.6178866028785706
Test:
Test: 0.4503456415444276
0.4503456415444276
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.56it/s]100%|██████████| 1/1 [00:00<00:00,  4.45it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6133822798728943
Epoch 1: -0.6133822798728943
Mem used: -900MB
best_loss: tensor(-0.6052, device='cuda:1')
best_loss: tensor(-0.6067, device='cuda:1')
final loss: -0.6054721474647522
Test:
Test: 0.45624683864441073
0.45624683864441073
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.00it/s]100%|██████████| 1/1 [00:00<00:00,  4.99it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5855416655540466
Epoch 1: -0.5855416655540466
Mem used: -900MB
best_loss: tensor(-0.5863, device='cuda:1')
best_loss: tensor(-0.5877, device='cuda:1')
final loss: -0.5872063040733337
Test:
Test: 0.45557241611869836
0.45557241611869836
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.34it/s]100%|██████████| 1/1 [00:00<00:00,  5.33it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.605486273765564
Epoch 1: -0.605486273765564
Mem used: -900MB
best_loss: tensor(-0.5976, device='cuda:1')
best_loss: tensor(-0.5982, device='cuda:1')
final loss: -0.6018925309181213
Test:
Test: 0.4644242117686731
0.4644242117686731
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.60it/s]100%|██████████| 1/1 [00:00<00:00,  3.60it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6022611856460571
Epoch 1: -0.6022611856460571
Mem used: -900MB
best_loss: tensor(-0.5961, device='cuda:1')
best_loss: tensor(-0.5973, device='cuda:1')
final loss: -0.5974472165107727
Test:
Test: 0.453085483055134
0.453085483055134
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.60it/s]100%|██████████| 1/1 [00:00<00:00,  4.60it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.5943117141723633
Epoch 1: -0.5943117141723633
Mem used: -900MB
best_loss: tensor(-0.5960, device='cuda:1')
best_loss: tensor(-0.5971, device='cuda:1')
final loss: -0.594749927520752
Test:
Test: 0.4533383915022762
0.4533383915022762
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.13it/s]100%|██████████| 1/1 [00:00<00:00,  5.13it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5679726004600525
Epoch 1: -0.5679726004600525
Mem used: -900MB
best_loss: tensor(-0.5686, device='cuda:1')
final loss: -0.5651487708091736
Test:
Test: 0.4497133704265722
0.4497133704265722
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.92it/s]100%|██████████| 1/1 [00:00<00:00,  4.91it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6161868572235107
Epoch 1: -0.6161868572235107
Mem used: -900MB
best_loss: tensor(-0.6173, device='cuda:1')
final loss: -0.6178306341171265
Test:
Test: 0.4616422188501096
0.4616422188501096
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.68it/s]100%|██████████| 1/1 [00:00<00:00,  4.68it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.587518572807312
Epoch 1: -0.587518572807312
Mem used: -900MB
best_loss: tensor(-0.5803, device='cuda:1')
best_loss: tensor(-0.5808, device='cuda:1')
final loss: -0.5801247358322144
Test:
Test: 0.4482380711515765
0.4482380711515765
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.82it/s]100%|██████████| 1/1 [00:00<00:00,  3.82it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5735430717468262
Epoch 1: -0.5735430717468262
Mem used: -900MB
best_loss: tensor(-0.5740, device='cuda:1')
best_loss: tensor(-0.5754, device='cuda:1')
final loss: -0.5768164992332458
Test:
Test: 0.45624683864441073
0.45624683864441073
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.98it/s]100%|██████████| 1/1 [00:00<00:00,  3.97it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6188040375709534
Epoch 1: -0.6188040375709534
Mem used: -900MB
best_loss: tensor(-0.6239, device='cuda:1')
final loss: -0.6183183193206787
Test:
Test: 0.4479430112965773
0.4479430112965773
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.56it/s]100%|██████████| 1/1 [00:00<00:00,  3.55it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6133822798728943
Epoch 1: -0.6133822798728943
Mem used: -900MB
best_loss: tensor(-0.6066, device='cuda:1')
best_loss: tensor(-0.6072, device='cuda:1')
final loss: -0.6062732338905334
Test:
Test: 0.45439217669870174
0.45439217669870174
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.71it/s]100%|██████████| 1/1 [00:00<00:00,  5.69it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5855416655540466
Epoch 1: -0.5855416655540466
Mem used: -900MB
best_loss: tensor(-0.5867, device='cuda:1')
best_loss: tensor(-0.5868, device='cuda:1')
final loss: -0.5854542851448059
Test:
Test: 0.45161018378013823
0.45161018378013823
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.43it/s]100%|██████████| 1/1 [00:00<00:00,  3.42it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011685371399
Epoch 0, Loop Adj 0: -0.605486273765564
Epoch 1: -0.605486273765564
Mem used: -900MB
best_loss: tensor(-0.5982, device='cuda:1')
final loss: -0.5991449356079102
Test:
Test: 0.460546282245827
0.460546282245827
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.65it/s]100%|██████████| 1/1 [00:00<00:00,  5.64it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6022611856460571
Epoch 1: -0.6022611856460571
Mem used: -900MB
best_loss: tensor(-0.5968, device='cuda:1')
best_loss: tensor(-0.5972, device='cuda:1')
final loss: -0.5977225303649902
Test:
Test: 0.45161018378013823
0.45161018378013823
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.83it/s]100%|██████████| 1/1 [00:00<00:00,  4.82it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388945579529
Epoch 0, Loop Adj 0: -0.5943117141723633
Epoch 1: -0.5943117141723633
Mem used: -900MB
best_loss: tensor(-0.5972, device='cuda:1')
final loss: -0.5954468846321106
Test:
Test: 0.4513151239251391
0.4513151239251391
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.66it/s]100%|██████████| 1/1 [00:00<00:00,  3.66it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5679726004600525
Epoch 1: -0.5679726004600525
Mem used: -900MB
best_loss: tensor(-0.5658, device='cuda:1')
best_loss: tensor(-0.5661, device='cuda:1')
final loss: -0.565631628036499
Test:
Test: 0.4458775923115832
0.4458775923115832
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.22it/s]100%|██████████| 1/1 [00:00<00:00,  3.22it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6161868572235107
Epoch 1: -0.6161868572235107
Mem used: -900MB
best_loss: tensor(-0.6187, device='cuda:1')
final loss: -0.6209019422531128
Test:
Test: 0.45700556398583714
0.45700556398583714
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.30it/s]100%|██████████| 1/1 [00:00<00:00,  4.30it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.587518572807312
Epoch 1: -0.587518572807312
Mem used: -900MB
best_loss: tensor(-0.5791, device='cuda:1')
final loss: -0.5797210931777954
Test:
Test: 0.4458354409037262
0.4458354409037262
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.05it/s]100%|██████████| 1/1 [00:00<00:00,  3.05it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5735430717468262
Epoch 1: -0.5735430717468262
Mem used: -900MB
best_loss: tensor(-0.5749, device='cuda:1')
best_loss: tensor(-0.5749, device='cuda:1')
final loss: -0.5759304761886597
Test:
Test: 0.4542235710672736
0.4542235710672736
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.51it/s]100%|██████████| 2/2 [00:00<00:00,  5.59it/s]100%|██████████| 2/2 [00:00<00:00,  5.58it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6188040375709534
Epoch 1, Loop Feat 0: -0.6184613704681396
Epoch 1, Loop Adj 0: -0.6237938404083252
Epoch 2: -0.6237938404083252
Mem used: -900MB
best_loss: tensor(-0.6252, device='cuda:1')
final loss: -0.6180257797241211
Test:
Test: 0.4496712190187152
0.4496712190187152
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.99it/s]100%|██████████| 2/2 [00:00<00:00,  3.02it/s]100%|██████████| 2/2 [00:00<00:00,  3.02it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6133822798728943
Epoch 1, Loop Feat 0: -0.6084011197090149
Epoch 1, Loop Adj 0: -0.6062723398208618
Epoch 2: -0.6062723398208618
Mem used: -900MB
best_loss: tensor(-0.6076, device='cuda:1')
final loss: -0.6066401600837708
Test:
Test: 0.454897993592986
0.454897993592986
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  6.67it/s]100%|██████████| 2/2 [00:00<00:00,  3.11it/s]100%|██████████| 2/2 [00:00<00:00,  3.37it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5855416655540466
Epoch 1, Loop Feat 0: -0.5828876495361328
Epoch 1, Loop Adj 0: -0.5853261947631836
Epoch 2: -0.5853261947631836
Mem used: -900MB
best_loss: tensor(-0.5869, device='cuda:1')
final loss: -0.5865128636360168
Test:
Test: 0.4554038104872703
0.4554038104872703
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.67it/s]100%|██████████| 2/2 [00:00<00:00,  2.99it/s]100%|██████████| 2/2 [00:00<00:00,  2.94it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.605486273765564
Epoch 1, Loop Feat 0: -0.5968653559684753
Epoch 1, Loop Adj 0: -0.6055047512054443
Epoch 2: -0.6055047512054443
Mem used: -900MB
best_loss: tensor(-0.5992, device='cuda:1')
final loss: -0.599740207195282
Test:
Test: 0.46303321530939134
0.46303321530939134
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.06it/s]100%|██████████| 2/2 [00:00<00:00,  3.21it/s]100%|██████████| 2/2 [00:00<00:00,  3.31it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6022611856460571
Epoch 1, Loop Feat 0: -0.5934062004089355
Epoch 1, Loop Adj 0: -0.5982517600059509
Epoch 2: -0.5982517600059509
Mem used: -900MB
best_loss: tensor(-0.5972, device='cuda:1')
best_loss: tensor(-0.5976, device='cuda:1')
final loss: -0.5982930660247803
Test:
Test: 0.4518630922272804
0.4518630922272804
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.32it/s]100%|██████████| 2/2 [00:00<00:00,  5.04it/s]100%|██████████| 2/2 [00:00<00:00,  5.07it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388945579529
Epoch 0, Loop Adj 0: -0.5943117141723633
Epoch 1, Loop Feat 0: -0.592395544052124
Epoch 1, Loop Adj 0: -0.5925779938697815
Epoch 2: -0.5925779938697815
Mem used: -900MB
best_loss: tensor(-0.5975, device='cuda:1')
final loss: -0.5958216190338135
Test:
Test: 0.45329624009441916
0.45329624009441916
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.80it/s]100%|██████████| 2/2 [00:00<00:00,  3.49it/s]100%|██████████| 2/2 [00:00<00:00,  3.71it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5679726004600525
Epoch 1, Loop Feat 0: -0.5659083724021912
Epoch 1, Loop Adj 0: -0.5640554428100586
Epoch 2: -0.5640554428100586
Mem used: -900MB
best_loss: tensor(-0.5672, device='cuda:1')
final loss: -0.5662242770195007
Test:
Test: 0.4481116169280054
0.4481116169280054
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.62it/s]100%|██████████| 2/2 [00:00<00:00,  3.33it/s]100%|██████████| 2/2 [00:00<00:00,  3.54it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6161868572235107
Epoch 1, Loop Feat 0: -0.6191951632499695
Epoch 1, Loop Adj 0: -0.6205320954322815
Epoch 2: -0.6205320954322815
Mem used: -900MB
best_loss: tensor(-0.6185, device='cuda:1')
final loss: -0.6202523112297058
Test:
Test: 0.45856516607654696
0.45856516607654696
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.45it/s]100%|██████████| 2/2 [00:00<00:00,  5.19it/s]100%|██████████| 2/2 [00:00<00:00,  5.06it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.587518572807312
Epoch 1, Loop Feat 0: -0.5805421471595764
Epoch 1, Loop Adj 0: -0.5767501592636108
Epoch 2: -0.5767501592636108
Mem used: -900MB
best_loss: tensor(-0.5813, device='cuda:1')
final loss: -0.5804532170295715
Test:
Test: 0.4483223739672905
0.4483223739672905
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.36it/s]100%|██████████| 2/2 [00:00<00:00,  4.74it/s]100%|██████████| 2/2 [00:00<00:00,  4.82it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5735430717468262
Epoch 1, Loop Feat 0: -0.573161780834198
Epoch 1, Loop Adj 0: -0.5752061605453491
Epoch 2: -0.5752061605453491
Mem used: -900MB
best_loss: tensor(-0.5764, device='cuda:1')
final loss: -0.5766788125038147
Test:
Test: 0.4576799865115495
0.4576799865115495
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.88it/s]100%|██████████| 2/2 [00:00<00:00,  5.06it/s]100%|██████████| 2/2 [00:00<00:00,  5.03it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6188040375709534
Epoch 1, Loop Feat 0: -0.61455237865448
Epoch 1, Loop Adj 0: -0.6197686791419983
Epoch 2: -0.6197686791419983
Mem used: -900MB
best_loss: tensor(-0.6289, device='cuda:1')
final loss: -0.6243554353713989
Test:
Test: 0.45021918732085653
0.45021918732085653
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.84it/s]100%|██████████| 2/2 [00:00<00:00,  3.99it/s]100%|██████████| 2/2 [00:00<00:00,  4.09it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6133822798728943
Epoch 1, Loop Feat 0: -0.6040301322937012
Epoch 1, Loop Adj 0: -0.6016273498535156
Epoch 2: -0.6016273498535156
Mem used: -900MB
best_loss: tensor(-0.6118, device='cuda:1')
final loss: -0.6116277575492859
Test:
Test: 0.45700556398583714
0.45700556398583714
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.50it/s]100%|██████████| 2/2 [00:00<00:00,  3.33it/s]100%|██████████| 2/2 [00:00<00:00,  3.35it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5855416655540466
Epoch 1, Loop Feat 0: -0.5795139074325562
Epoch 1, Loop Adj 0: -0.5809864401817322
Epoch 2: -0.5809864401817322
Mem used: -900MB
best_loss: tensor(-0.5922, device='cuda:1')
final loss: -0.5922779440879822
Test:
Test: 0.45666835272298095
0.45666835272298095
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.79it/s]100%|██████████| 2/2 [00:00<00:00,  4.77it/s]100%|██████████| 2/2 [00:00<00:00,  4.77it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.605486273765564
Epoch 1, Loop Feat 0: -0.5931122899055481
Epoch 1, Loop Adj 0: -0.6009201407432556
Epoch 2: -0.6009201407432556
Mem used: -900MB
best_loss: tensor(-0.6027, device='cuda:1')
final loss: -0.604596734046936
Test:
Test: 0.4639605462822458
0.4639605462822458
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  6.04it/s]100%|██████████| 2/2 [00:00<00:00,  4.72it/s]100%|██████████| 2/2 [00:00<00:00,  4.88it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6022611856460571
Epoch 1, Loop Feat 0: -0.5877844095230103
Epoch 1, Loop Adj 0: -0.5934791564941406
Epoch 2: -0.5934791564941406
Mem used: -900MB
best_loss: tensor(-0.6025, device='cuda:1')
final loss: -0.6036350727081299
Test:
Test: 0.4561625358286967
0.4561625358286967
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.75it/s]100%|██████████| 2/2 [00:00<00:00,  3.55it/s]100%|██████████| 2/2 [00:00<00:00,  3.58it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.5943117141723633
Epoch 1, Loop Feat 0: -0.5884494781494141
Epoch 1, Loop Adj 0: -0.5887100696563721
Epoch 2: -0.5887100696563721
Mem used: -900MB
best_loss: tensor(-0.6017, device='cuda:1')
final loss: -0.6015613079071045
Test:
Test: 0.45287472601584894
0.45287472601584894
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.81it/s]100%|██████████| 2/2 [00:00<00:00,  4.97it/s]100%|██████████| 2/2 [00:00<00:00,  5.07it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5679726004600525
Epoch 1, Loop Feat 0: -0.5611789226531982
Epoch 1, Loop Adj 0: -0.5593156814575195
Epoch 2: -0.5593156814575195
Mem used: -900MB
best_loss: tensor(-0.5749, device='cuda:1')
final loss: -0.5717458128929138
Test:
Test: 0.45026133872871354
0.45026133872871354
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.67it/s]100%|██████████| 2/2 [00:00<00:00,  3.81it/s]100%|██████████| 2/2 [00:00<00:00,  3.92it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6161868572235107
Epoch 1, Loop Feat 0: -0.6157527565956116
Epoch 1, Loop Adj 0: -0.6167011857032776
Epoch 2: -0.6167011857032776
Mem used: -900MB
best_loss: tensor(-0.6207, device='cuda:1')
final loss: -0.6218757629394531
Test:
Test: 0.46037767661439893
0.46037767661439893
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.68it/s]100%|██████████| 2/2 [00:00<00:00,  3.99it/s]100%|██████████| 2/2 [00:00<00:00,  4.08it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.587518572807312
Epoch 1, Loop Feat 0: -0.5757022500038147
Epoch 1, Loop Adj 0: -0.5727511644363403
Epoch 2: -0.5727511644363403
Mem used: -900MB
best_loss: tensor(-0.5866, device='cuda:1')
final loss: -0.5866296291351318
Test:
Test: 0.4471842859551509
0.4471842859551509
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.80it/s]100%|██████████| 2/2 [00:00<00:00,  4.38it/s]100%|██████████| 2/2 [00:00<00:00,  4.44it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5735430717468262
Epoch 1, Loop Feat 0: -0.5702677965164185
Epoch 1, Loop Adj 0: -0.5714113116264343
Epoch 2: -0.5714113116264343
Mem used: -900MB
best_loss: tensor(-0.5806, device='cuda:1')
final loss: -0.5806707739830017
Test:
Test: 0.45595177878941157
0.45595177878941157
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.27it/s]100%|██████████| 2/2 [00:00<00:00,  5.55it/s]100%|██████████| 2/2 [00:00<00:00,  5.50it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6188040375709534
Epoch 1, Loop Feat 0: -0.6198786497116089
Epoch 1, Loop Adj 0: -0.6248456239700317
Epoch 2: -0.6248456239700317
Mem used: -900MB
best_loss: tensor(-0.6241, device='cuda:1')
best_loss: tensor(-0.6242, device='cuda:1')
final loss: -0.6182751059532166
Test:
Test: 0.4479008598887203
0.4479008598887203
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.31it/s]100%|██████████| 2/2 [00:00<00:00,  3.39it/s]100%|██████████| 2/2 [00:00<00:00,  3.37it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6133822798728943
Epoch 1, Loop Feat 0: -0.6099706888198853
Epoch 1, Loop Adj 0: -0.6082856059074402
Epoch 2: -0.6082856059074402
Mem used: -900MB
best_loss: tensor(-0.6075, device='cuda:1')
final loss: -0.6076453924179077
Test:
Test: 0.4546872365537009
0.4546872365537009
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.14it/s]100%|██████████| 2/2 [00:00<00:00,  4.74it/s]100%|██████████| 2/2 [00:00<00:00,  4.64it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5855416655540466
Epoch 1, Loop Feat 0: -0.5842998027801514
Epoch 1, Loop Adj 0: -0.5867156982421875
Epoch 2: -0.5867156982421875
Mem used: -900MB
best_loss: tensor(-0.5866, device='cuda:1')
best_loss: tensor(-0.5870, device='cuda:1')
final loss: -0.5854226350784302
Test:
Test: 0.45144157814871017
0.45144157814871017
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.41it/s]100%|██████████| 2/2 [00:00<00:00,  3.72it/s]100%|██████████| 2/2 [00:00<00:00,  3.90it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.605486273765564
Epoch 1, Loop Feat 0: -0.5982363224029541
Epoch 1, Loop Adj 0: -0.6073673963546753
Epoch 2: -0.6073673963546753
Mem used: -900MB
best_loss: tensor(-0.5983, device='cuda:1')
final loss: -0.5989599227905273
Test:
Test: 0.46046197943011297
0.46046197943011297
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.77it/s]100%|██████████| 2/2 [00:00<00:00,  4.04it/s]100%|██████████| 2/2 [00:00<00:00,  4.23it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6022611856460571
Epoch 1, Loop Feat 0: -0.5958378911018372
Epoch 1, Loop Adj 0: -0.6004064679145813
Epoch 2: -0.6004064679145813
Mem used: -900MB
best_loss: tensor(-0.5975, device='cuda:1')
final loss: -0.5975754261016846
Test:
Test: 0.4520738492665655
0.4520738492665655
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.86it/s]100%|██████████| 2/2 [00:00<00:00,  5.03it/s]100%|██████████| 2/2 [00:00<00:00,  5.00it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.5943117141723633
Epoch 1, Loop Feat 0: -0.5944815874099731
Epoch 1, Loop Adj 0: -0.594268798828125
Epoch 2: -0.594268798828125
Mem used: -900MB
best_loss: tensor(-0.5971, device='cuda:1')
best_loss: tensor(-0.5974, device='cuda:1')
final loss: -0.5952652096748352
Test:
Test: 0.4515680323722812
0.4515680323722812
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.16it/s]100%|██████████| 2/2 [00:00<00:00,  3.24it/s]100%|██████████| 2/2 [00:00<00:00,  3.35it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5679726004600525
Epoch 1, Loop Feat 0: -0.5683599710464478
Epoch 1, Loop Adj 0: -0.5663236379623413
Epoch 2: -0.5663236379623413
Mem used: -900MB
best_loss: tensor(-0.5661, device='cuda:1')
best_loss: tensor(-0.5667, device='cuda:1')
final loss: -0.5664464831352234
Test:
Test: 0.44570898668015513
0.44570898668015513
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.28it/s]100%|██████████| 2/2 [00:00<00:00,  3.76it/s]100%|██████████| 2/2 [00:00<00:00,  3.82it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6161868572235107
Epoch 1, Loop Feat 0: -0.6204537749290466
Epoch 1, Loop Adj 0: -0.6219577193260193
Epoch 2: -0.6219577193260193
Mem used: -900MB
best_loss: tensor(-0.6185, device='cuda:1')
final loss: -0.6220199465751648
Test:
Test: 0.456752655538695
0.456752655538695
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.07it/s]100%|██████████| 2/2 [00:00<00:00,  2.16it/s]100%|██████████| 2/2 [00:00<00:00,  2.14it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.587518572807312
Epoch 1, Loop Feat 0: -0.5825225114822388
Epoch 1, Loop Adj 0: -0.5785605907440186
Epoch 2: -0.5785605907440186
Mem used: -900MB
best_loss: tensor(-0.5794, device='cuda:1')
best_loss: tensor(-0.5796, device='cuda:1')
final loss: -0.5798912644386292
Test:
Test: 0.44570898668015513
0.44570898668015513
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.28it/s]100%|██████████| 2/2 [00:00<00:00,  3.93it/s]100%|██████████| 2/2 [00:00<00:00,  3.81it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5735430717468262
Epoch 1, Loop Feat 0: -0.574459433555603
Epoch 1, Loop Adj 0: -0.5763569474220276
Epoch 2: -0.5763569474220276
Mem used: -900MB
best_loss: tensor(-0.5753, device='cuda:1')
final loss: -0.5770798921585083
Test:
Test: 0.4546450851458439
0.4546450851458439
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.58it/s]100%|██████████| 1/1 [00:00<00:00,  2.58it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6188040375709534
Epoch 1: -0.6188040375709534
Mem used: -900MB
best_loss: tensor(-0.6230, device='cuda:1')
best_loss: tensor(-0.6238, device='cuda:1')
final loss: -0.618044376373291
Test:
Test: 0.449291856348002
0.449291856348002
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.77it/s]100%|██████████| 1/1 [00:00<00:00,  3.77it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6133822798728943
Epoch 1: -0.6133822798728943
Mem used: -900MB
best_loss: tensor(-0.6054, device='cuda:1')
best_loss: tensor(-0.6069, device='cuda:1')
final loss: -0.6059854626655579
Test:
Test: 0.4552773562636992
0.4552773562636992
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.97it/s]100%|██████████| 1/1 [00:00<00:00,  3.97it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5855416655540466
Epoch 1: -0.5855416655540466
Mem used: -900MB
best_loss: tensor(-0.5858, device='cuda:1')
best_loss: tensor(-0.5865, device='cuda:1')
final loss: -0.5859455466270447
Test:
Test: 0.4526218175687068
0.4526218175687068
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.05it/s]100%|██████████| 1/1 [00:00<00:00,  4.04it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011685371399
Epoch 0, Loop Adj 0: -0.605486273765564
Epoch 1: -0.605486273765564
Mem used: -900MB
best_loss: tensor(-0.5993, device='cuda:1')
final loss: -0.5999714136123657
Test:
Test: 0.4609677963243972
0.4609677963243972
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.24it/s]100%|██████████| 1/1 [00:00<00:00,  4.24it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6022611856460571
Epoch 1: -0.6022611856460571
Mem used: -900MB
best_loss: tensor(-0.5960, device='cuda:1')
final loss: -0.596182644367218
Test:
Test: 0.45215815208227955
0.45215815208227955
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.28it/s]100%|██████████| 1/1 [00:00<00:00,  4.27it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388945579529
Epoch 0, Loop Adj 0: -0.5943117141723633
Epoch 1: -0.5943117141723633
Mem used: -900MB
best_loss: tensor(-0.5954, device='cuda:1')
best_loss: tensor(-0.5967, device='cuda:1')
final loss: -0.5956339836120605
Test:
Test: 0.4518630922272804
0.4518630922272804
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  6.14it/s]100%|██████████| 1/1 [00:00<00:00,  6.13it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5679726004600525
Epoch 1: -0.5679726004600525
Mem used: -900MB
best_loss: tensor(-0.5654, device='cuda:1')
best_loss: tensor(-0.5659, device='cuda:1')
final loss: -0.5652561783790588
Test:
Test: 0.44617265216658236
0.44617265216658236
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.35it/s]100%|██████████| 1/1 [00:00<00:00,  3.35it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6161868572235107
Epoch 1: -0.6161868572235107
Mem used: -900MB
best_loss: tensor(-0.6192, device='cuda:1')
final loss: -0.6206696629524231
Test:
Test: 0.45923958860225933
0.45923958860225933
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.98it/s]100%|██████████| 1/1 [00:00<00:00,  3.90it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.587518572807312
Epoch 1: -0.587518572807312
Mem used: -900MB
best_loss: tensor(-0.5792, device='cuda:1')
final loss: -0.579164981842041
Test:
Test: 0.44503456415444276
0.44503456415444276
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.83it/s]100%|██████████| 1/1 [00:00<00:00,  4.82it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5735430717468262
Epoch 1: -0.5735430717468262
Mem used: -900MB
best_loss: tensor(-0.5757, device='cuda:1')
final loss: -0.5750858783721924
Test:
Test: 0.4554459618951273
0.4554459618951273
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  6.60it/s]100%|██████████| 1/1 [00:00<00:00,  6.59it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6188040375709534
Epoch 1: -0.6188040375709534
Mem used: -900MB
best_loss: tensor(-0.6225, device='cuda:1')
best_loss: tensor(-0.6244, device='cuda:1')
final loss: -0.6185886859893799
Test:
Test: 0.4512729725172821
0.4512729725172821
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.68it/s]100%|██████████| 1/1 [00:00<00:00,  4.68it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6133822798728943
Epoch 1: -0.6133822798728943
Mem used: -900MB
best_loss: tensor(-0.6052, device='cuda:1')
best_loss: tensor(-0.6068, device='cuda:1')
final loss: -0.606514573097229
Test:
Test: 0.4550665992244141
0.4550665992244141
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.45it/s]100%|██████████| 1/1 [00:00<00:00,  4.44it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5855416655540466
Epoch 1: -0.5855416655540466
Mem used: -900MB
best_loss: tensor(-0.5863, device='cuda:1')
best_loss: tensor(-0.5866, device='cuda:1')
final loss: -0.5862042307853699
Test:
Test: 0.4537177541729894
0.4537177541729894
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.74it/s]100%|██████████| 1/1 [00:00<00:00,  4.73it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.605486273765564
Epoch 1: -0.605486273765564
Mem used: -900MB
best_loss: tensor(-0.5976, device='cuda:1')
final loss: -0.6007784605026245
Test:
Test: 0.46459281740010117
0.46459281740010117
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.12it/s]100%|██████████| 1/1 [00:00<00:00,  5.11it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6022611856460571
Epoch 1: -0.6022611856460571
Mem used: -900MB
best_loss: tensor(-0.5961, device='cuda:1')
best_loss: tensor(-0.5974, device='cuda:1')
final loss: -0.5976240038871765
Test:
Test: 0.45274827179227783
0.45274827179227783
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.08it/s]100%|██████████| 1/1 [00:00<00:00,  3.07it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.5943117141723633
Epoch 1: -0.5943117141723633
Mem used: -900MB
best_loss: tensor(-0.5960, device='cuda:1')
best_loss: tensor(-0.5964, device='cuda:1')
final loss: -0.5949875116348267
Test:
Test: 0.45220030349013657
0.45220030349013657
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.36it/s]100%|██████████| 1/1 [00:00<00:00,  3.36it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5679726004600525
Epoch 1: -0.5679726004600525
Mem used: -900MB
best_loss: tensor(-0.5686, device='cuda:1')
final loss: -0.5651487708091736
Test:
Test: 0.4497133704265722
0.4497133704265722
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.95it/s]100%|██████████| 1/1 [00:00<00:00,  4.95it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6161868572235107
Epoch 1: -0.6161868572235107
Mem used: -900MB
best_loss: tensor(-0.6173, device='cuda:1')
best_loss: tensor(-0.6180, device='cuda:1')
final loss: -0.6211249828338623
Test:
Test: 0.45738492665655034
0.45738492665655034
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.92it/s]100%|██████████| 1/1 [00:00<00:00,  2.92it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.587518572807312
Epoch 1: -0.587518572807312
Mem used: -900MB
best_loss: tensor(-0.5803, device='cuda:1')
final loss: -0.5792266130447388
Test:
Test: 0.4486174338222897
0.4486174338222897
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.85it/s]100%|██████████| 1/1 [00:00<00:00,  3.85it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5735430717468262
Epoch 1: -0.5735430717468262
Mem used: -900MB
best_loss: tensor(-0.5740, device='cuda:1')
best_loss: tensor(-0.5753, device='cuda:1')
final loss: -0.5765686631202698
Test:
Test: 0.4549822964087
0.4549822964087
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.83it/s]100%|██████████| 1/1 [00:00<00:00,  4.83it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6188040375709534
Epoch 1: -0.6188040375709534
Mem used: -900MB
best_loss: tensor(-0.6239, device='cuda:1')
final loss: -0.6183183193206787
Test:
Test: 0.4479430112965773
0.4479430112965773
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.80it/s]100%|██████████| 1/1 [00:00<00:00,  5.78it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194772720337
Epoch 0, Loop Adj 0: -0.6133822798728943
Epoch 1: -0.6133822798728943
Mem used: -900MB
best_loss: tensor(-0.6068, device='cuda:1')
best_loss: tensor(-0.6074, device='cuda:1')
final loss: -0.6070554852485657
Test:
Test: 0.4544764795144158
0.4544764795144158
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.66it/s]100%|██████████| 1/1 [00:00<00:00,  4.65it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5855416655540466
Epoch 1: -0.5855416655540466
Mem used: -900MB
best_loss: tensor(-0.5867, device='cuda:1')
best_loss: tensor(-0.5867, device='cuda:1')
final loss: -0.5851625800132751
Test:
Test: 0.45161018378013823
0.45161018378013823
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.16it/s]100%|██████████| 1/1 [00:00<00:00,  2.16it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.605486273765564
Epoch 1: -0.605486273765564
Mem used: -900MB
best_loss: tensor(-0.5982, device='cuda:1')
final loss: -0.5991449356079102
Test:
Test: 0.460546282245827
0.460546282245827
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.21it/s]100%|██████████| 1/1 [00:00<00:00,  2.21it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6022611856460571
Epoch 1: -0.6022611856460571
Mem used: -900MB
best_loss: tensor(-0.5968, device='cuda:1')
best_loss: tensor(-0.5972, device='cuda:1')
final loss: -0.5973913669586182
Test:
Test: 0.45161018378013823
0.45161018378013823
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.95it/s]100%|██████████| 1/1 [00:00<00:00,  3.95it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.5943117141723633
Epoch 1: -0.5943117141723633
Mem used: -900MB
best_loss: tensor(-0.5972, device='cuda:1')
best_loss: tensor(-0.5972, device='cuda:1')
final loss: -0.5951834321022034
Test:
Test: 0.4513151239251391
0.4513151239251391
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.85it/s]100%|██████████| 1/1 [00:00<00:00,  5.84it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5679726004600525
Epoch 1: -0.5679726004600525
Mem used: -900MB
best_loss: tensor(-0.5658, device='cuda:1')
best_loss: tensor(-0.5662, device='cuda:1')
final loss: -0.5655384063720703
Test:
Test: 0.4458775923115832
0.4458775923115832
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  6.03it/s]100%|██████████| 1/1 [00:00<00:00,  6.02it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6161868572235107
Epoch 1: -0.6161868572235107
Mem used: -900MB
best_loss: tensor(-0.6187, device='cuda:1')
final loss: -0.6209019422531128
Test:
Test: 0.45700556398583714
0.45700556398583714
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  6.12it/s]100%|██████████| 1/1 [00:00<00:00,  6.11it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.587518572807312
Epoch 1: -0.587518572807312
Mem used: -900MB
best_loss: tensor(-0.5791, device='cuda:1')
best_loss: tensor(-0.5791, device='cuda:1')
final loss: -0.5795959830284119
Test:
Test: 0.4451610183780138
0.4451610183780138
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.69it/s]100%|██████████| 1/1 [00:00<00:00,  5.68it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5735430717468262
Epoch 1: -0.5735430717468262
Mem used: -900MB
best_loss: tensor(-0.5749, device='cuda:1')
best_loss: tensor(-0.5751, device='cuda:1')
final loss: -0.5763502717018127
Test:
Test: 0.4546450851458439
0.4546450851458439
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.40it/s]100%|██████████| 2/2 [00:00<00:00,  3.17it/s]100%|██████████| 2/2 [00:00<00:00,  3.20it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6188040375709534
Epoch 1, Loop Feat 0: -0.6186150312423706
Epoch 1, Loop Adj 0: -0.6239060163497925
Epoch 2: -0.6239060163497925
Mem used: -900MB
best_loss: tensor(-0.6251, device='cuda:1')
final loss: -0.6184240579605103
Test:
Test: 0.4500505816894284
0.4500505816894284
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.80it/s]100%|██████████| 2/2 [00:00<00:00,  4.92it/s]100%|██████████| 2/2 [00:00<00:00,  4.90it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6133822798728943
Epoch 1, Loop Feat 0: -0.6085668802261353
Epoch 1, Loop Adj 0: -0.6064655780792236
Epoch 2: -0.6064655780792236
Mem used: -900MB
best_loss: tensor(-0.6074, device='cuda:1')
final loss: -0.6073256731033325
Test:
Test: 0.4552773562636992
0.4552773562636992
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.28it/s]100%|██████████| 2/2 [00:00<00:00,  3.49it/s]100%|██████████| 2/2 [00:00<00:00,  3.44it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5855416655540466
Epoch 1, Loop Feat 0: -0.5830382704734802
Epoch 1, Loop Adj 0: -0.5854820609092712
Epoch 2: -0.5854820609092712
Mem used: -900MB
best_loss: tensor(-0.5872, device='cuda:1')
final loss: -0.5867749452590942
Test:
Test: 0.45519305344798516
0.45519305344798516
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.12it/s]100%|██████████| 2/2 [00:00<00:00,  4.30it/s]100%|██████████| 2/2 [00:00<00:00,  4.41it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.605486273765564
Epoch 1, Loop Feat 0: -0.5970000624656677
Epoch 1, Loop Adj 0: -0.6057031750679016
Epoch 2: -0.6057031750679016
Mem used: -900MB
best_loss: tensor(-0.5991, device='cuda:1')
final loss: -0.599633514881134
Test:
Test: 0.4634968807958186
0.4634968807958186
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.81it/s]100%|██████████| 2/2 [00:00<00:00,  3.81it/s]100%|██████████| 2/2 [00:00<00:00,  3.81it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6022611856460571
Epoch 1, Loop Feat 0: -0.5936329960823059
Epoch 1, Loop Adj 0: -0.5984508395195007
Epoch 2: -0.5984508395195007
Mem used: -900MB
best_loss: tensor(-0.5968, device='cuda:1')
best_loss: tensor(-0.5974, device='cuda:1')
final loss: -0.597650408744812
Test:
Test: 0.45177878941156635
0.45177878941156635
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.93it/s]100%|██████████| 2/2 [00:00<00:00,  4.19it/s]100%|██████████| 2/2 [00:00<00:00,  4.38it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.5943117141723633
Epoch 1, Loop Feat 0: -0.5925889611244202
Epoch 1, Loop Adj 0: -0.5927327871322632
Epoch 2: -0.5927327871322632
Mem used: -900MB
best_loss: tensor(-0.5977, device='cuda:1')
final loss: -0.5964126586914062
Test:
Test: 0.45367560276513236
0.45367560276513236
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.49it/s]100%|██████████| 2/2 [00:00<00:00,  3.47it/s]100%|██████████| 2/2 [00:00<00:00,  3.47it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5679726004600525
Epoch 1, Loop Feat 0: -0.566143810749054
Epoch 1, Loop Adj 0: -0.5642701387405396
Epoch 2: -0.5642701387405396
Mem used: -900MB
best_loss: tensor(-0.5676, device='cuda:1')
final loss: -0.5660728812217712
Test:
Test: 0.4478587084808633
0.4478587084808633
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.05it/s]100%|██████████| 2/2 [00:00<00:00,  4.80it/s]100%|██████████| 2/2 [00:00<00:00,  4.67it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6161868572235107
Epoch 1, Loop Feat 0: -0.6193302273750305
Epoch 1, Loop Adj 0: -0.620660126209259
Epoch 2: -0.620660126209259
Mem used: -900MB
best_loss: tensor(-0.6186, device='cuda:1')
final loss: -0.6197695732116699
Test:
Test: 0.4583122576294048
0.4583122576294048
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.62it/s]100%|██████████| 2/2 [00:00<00:00,  4.82it/s]100%|██████████| 2/2 [00:00<00:00,  4.92it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.587518572807312
Epoch 1, Loop Feat 0: -0.5807157158851624
Epoch 1, Loop Adj 0: -0.576926052570343
Epoch 2: -0.576926052570343
Mem used: -900MB
best_loss: tensor(-0.5813, device='cuda:1')
final loss: -0.58050936460495
Test:
Test: 0.4487017366380037
0.4487017366380037
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.17it/s]100%|██████████| 2/2 [00:00<00:00,  5.46it/s]100%|██████████| 2/2 [00:00<00:00,  5.41it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5735430717468262
Epoch 1, Loop Feat 0: -0.5732743740081787
Epoch 1, Loop Adj 0: -0.575319230556488
Epoch 2: -0.575319230556488
Mem used: -900MB
best_loss: tensor(-0.5762, device='cuda:1')
final loss: -0.5768190622329712
Test:
Test: 0.45776428932726354
0.45776428932726354
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.28it/s]100%|██████████| 2/2 [00:00<00:00,  3.64it/s]100%|██████████| 2/2 [00:00<00:00,  3.58it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6188040375709534
Epoch 1, Loop Feat 0: -0.616495668888092
Epoch 1, Loop Adj 0: -0.6221702694892883
Epoch 2: -0.6221702694892883
Mem used: -900MB
best_loss: tensor(-0.6287, device='cuda:1')
final loss: -0.6231531500816345
Test:
Test: 0.451188669701568
0.451188669701568
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  6.73it/s]100%|██████████| 2/2 [00:00<00:00,  5.96it/s]100%|██████████| 2/2 [00:00<00:00,  6.06it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6133822798728943
Epoch 1, Loop Feat 0: -0.6065012812614441
Epoch 1, Loop Adj 0: -0.6042141318321228
Epoch 2: -0.6042141318321228
Mem used: -900MB
best_loss: tensor(-0.6123, device='cuda:1')
final loss: -0.6120578050613403
Test:
Test: 0.4556567189344124
0.4556567189344124
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.70it/s]100%|██████████| 2/2 [00:00<00:00,  4.67it/s]100%|██████████| 2/2 [00:00<00:00,  4.67it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5855416655540466
Epoch 1, Loop Feat 0: -0.5814034938812256
Epoch 1, Loop Adj 0: -0.5834861397743225
Epoch 2: -0.5834861397743225
Mem used: -900MB
best_loss: tensor(-0.5913, device='cuda:1')
final loss: -0.5923373699188232
Test:
Test: 0.45662620131512394
0.45662620131512394
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.19it/s]100%|██████████| 2/2 [00:00<00:00,  3.13it/s]100%|██████████| 2/2 [00:00<00:00,  3.25it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011685371399
Epoch 0, Loop Adj 0: -0.605486273765564
Epoch 1, Loop Feat 0: -0.5951335430145264
Epoch 1, Loop Adj 0: -0.6034094095230103
Epoch 2: -0.6034094095230103
Mem used: -900MB
best_loss: tensor(-0.6031, device='cuda:1')
final loss: -0.6052346229553223
Test:
Test: 0.46252739841510704
0.46252739841510704
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.42it/s]100%|██████████| 2/2 [00:00<00:00,  3.99it/s]100%|██████████| 2/2 [00:00<00:00,  3.89it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6022611856460571
Epoch 1, Loop Feat 0: -0.5909721851348877
Epoch 1, Loop Adj 0: -0.5961863994598389
Epoch 2: -0.5961863994598389
Mem used: -900MB
best_loss: tensor(-0.6018, device='cuda:1')
final loss: -0.6049413084983826
Test:
Test: 0.4563732928679818
0.4563732928679818
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.20it/s]100%|██████████| 2/2 [00:00<00:00,  2.63it/s]100%|██████████| 2/2 [00:00<00:00,  2.83it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.5943117141723633
Epoch 1, Loop Feat 0: -0.5904684662818909
Epoch 1, Loop Adj 0: -0.5909179449081421
Epoch 2: -0.5909179449081421
Mem used: -900MB
best_loss: tensor(-0.6013, device='cuda:1')
final loss: -0.6006151437759399
Test:
Test: 0.4556988703422694
0.4556988703422694
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.70it/s]100%|██████████| 2/2 [00:00<00:00,  2.75it/s]100%|██████████| 2/2 [00:00<00:00,  2.74it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5679726004600525
Epoch 1, Loop Feat 0: -0.5638425946235657
Epoch 1, Loop Adj 0: -0.5619735717773438
Epoch 2: -0.5619735717773438
Mem used: -900MB
best_loss: tensor(-0.5736, device='cuda:1')
final loss: -0.571259617805481
Test:
Test: 0.4496712190187152
0.4496712190187152
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.03it/s]100%|██████████| 2/2 [00:00<00:00,  2.85it/s]100%|██████████| 2/2 [00:00<00:00,  2.98it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6161868572235107
Epoch 1, Loop Feat 0: -0.6177434921264648
Epoch 1, Loop Adj 0: -0.6188254952430725
Epoch 2: -0.6188254952430725
Mem used: -900MB
best_loss: tensor(-0.6210, device='cuda:1')
final loss: -0.6226397752761841
Test:
Test: 0.46084134210082617
0.46084134210082617
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.73it/s]100%|██████████| 2/2 [00:00<00:00,  4.05it/s]100%|██████████| 2/2 [00:00<00:00,  4.14it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.587518572807312
Epoch 1, Loop Feat 0: -0.5786845684051514
Epoch 1, Loop Adj 0: -0.5751245021820068
Epoch 2: -0.5751245021820068
Mem used: -900MB
best_loss: tensor(-0.5868, device='cuda:1')
final loss: -0.585705041885376
Test:
Test: 0.4499662788737144
0.4499662788737144
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.56it/s]100%|██████████| 2/2 [00:00<00:00,  5.01it/s]100%|██████████| 2/2 [00:00<00:00,  4.93it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5735430717468262
Epoch 1, Loop Feat 0: -0.5718094706535339
Epoch 1, Loop Adj 0: -0.5736799836158752
Epoch 2: -0.5736799836158752
Mem used: -900MB
best_loss: tensor(-0.5809, device='cuda:1')
final loss: -0.5804338455200195
Test:
Test: 0.45519305344798516
0.45519305344798516
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.13it/s]100%|██████████| 2/2 [00:00<00:00,  5.12it/s]100%|██████████| 2/2 [00:00<00:00,  5.12it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6188040375709534
Epoch 1, Loop Feat 0: -0.6199139356613159
Epoch 1, Loop Adj 0: -0.6248655319213867
Epoch 2: -0.6248655319213867
Mem used: -900MB
best_loss: tensor(-0.6239, device='cuda:1')
best_loss: tensor(-0.6242, device='cuda:1')
final loss: -0.6178084015846252
Test:
Test: 0.4479008598887203
0.4479008598887203
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.24it/s]100%|██████████| 2/2 [00:00<00:00,  3.38it/s]100%|██████████| 2/2 [00:00<00:00,  3.48it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6133822798728943
Epoch 1, Loop Feat 0: -0.610005259513855
Epoch 1, Loop Adj 0: -0.6083383560180664
Epoch 2: -0.6083383560180664
Mem used: -900MB
best_loss: tensor(-0.6075, device='cuda:1')
best_loss: tensor(-0.6076, device='cuda:1')
final loss: -0.6070345640182495
Test:
Test: 0.4543078738829877
0.4543078738829877
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.26it/s]100%|██████████| 2/2 [00:00<00:00,  3.43it/s]100%|██████████| 2/2 [00:00<00:00,  3.40it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5855416655540466
Epoch 1, Loop Feat 0: -0.5843355655670166
Epoch 1, Loop Adj 0: -0.5867447853088379
Epoch 2: -0.5867447853088379
Mem used: -900MB
best_loss: tensor(-0.5867, device='cuda:1')
best_loss: tensor(-0.5870, device='cuda:1')
final loss: -0.5853047966957092
Test:
Test: 0.45144157814871017
0.45144157814871017
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.83it/s]100%|██████████| 2/2 [00:00<00:00,  4.77it/s]100%|██████████| 2/2 [00:00<00:00,  4.59it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.605486273765564
Epoch 1, Loop Feat 0: -0.5982610583305359
Epoch 1, Loop Adj 0: -0.607414186000824
Epoch 2: -0.607414186000824
Mem used: -900MB
best_loss: tensor(-0.5983, device='cuda:1')
final loss: -0.5993945002555847
Test:
Test: 0.460588433653684
0.460588433653684
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.19it/s]100%|██████████| 2/2 [00:00<00:00,  4.19it/s]100%|██████████| 2/2 [00:00<00:00,  4.19it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6022611856460571
Epoch 1, Loop Feat 0: -0.5959020256996155
Epoch 1, Loop Adj 0: -0.6004642248153687
Epoch 2: -0.6004642248153687
Mem used: -900MB
best_loss: tensor(-0.5975, device='cuda:1')
final loss: -0.597822904586792
Test:
Test: 0.4520738492665655
0.4520738492665655
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.83it/s]100%|██████████| 2/2 [00:00<00:00,  5.42it/s]100%|██████████| 2/2 [00:00<00:00,  5.48it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388945579529
Epoch 0, Loop Adj 0: -0.5943117141723633
Epoch 1, Loop Feat 0: -0.5945382118225098
Epoch 1, Loop Adj 0: -0.5943083763122559
Epoch 2: -0.5943083763122559
Mem used: -900MB
best_loss: tensor(-0.5970, device='cuda:1')
best_loss: tensor(-0.5974, device='cuda:1')
final loss: -0.5952337980270386
Test:
Test: 0.4514837295565672
0.4514837295565672
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.82it/s]100%|██████████| 2/2 [00:00<00:00,  3.04it/s]100%|██████████| 2/2 [00:00<00:00,  3.00it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5679726004600525
Epoch 1, Loop Feat 0: -0.5684298872947693
Epoch 1, Loop Adj 0: -0.5663856863975525
Epoch 2: -0.5663856863975525
Mem used: -900MB
best_loss: tensor(-0.5660, device='cuda:1')
best_loss: tensor(-0.5664, device='cuda:1')
final loss: -0.5663034915924072
Test:
Test: 0.4458354409037262
0.4458354409037262
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.87it/s]100%|██████████| 2/2 [00:00<00:00,  3.58it/s]100%|██████████| 2/2 [00:00<00:00,  3.62it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6161868572235107
Epoch 1, Loop Feat 0: -0.6204865574836731
Epoch 1, Loop Adj 0: -0.6219882369041443
Epoch 2: -0.6219882369041443
Mem used: -900MB
best_loss: tensor(-0.6185, device='cuda:1')
final loss: -0.6221200227737427
Test:
Test: 0.456752655538695
0.456752655538695
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.93it/s]100%|██████████| 2/2 [00:00<00:00,  3.16it/s]100%|██████████| 2/2 [00:00<00:00,  3.12it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.587518572807312
Epoch 1, Loop Feat 0: -0.5825737118721008
Epoch 1, Loop Adj 0: -0.578614354133606
Epoch 2: -0.578614354133606
Mem used: -900MB
best_loss: tensor(-0.5794, device='cuda:1')
best_loss: tensor(-0.5795, device='cuda:1')
final loss: -0.5801408290863037
Test:
Test: 0.4456246838644411
0.4456246838644411
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.99it/s]100%|██████████| 2/2 [00:00<00:00,  5.41it/s]100%|██████████| 2/2 [00:00<00:00,  5.34it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5735430717468262
Epoch 1, Loop Feat 0: -0.5745006203651428
Epoch 1, Loop Adj 0: -0.5763763785362244
Epoch 2: -0.5763763785362244
Mem used: -900MB
best_loss: tensor(-0.5753, device='cuda:1')
best_loss: tensor(-0.5754, device='cuda:1')
final loss: -0.5765278339385986
Test:
Test: 0.45443432810655876
0.45443432810655876
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.83it/s]100%|██████████| 1/1 [00:00<00:00,  3.82it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6188040375709534
Epoch 1: -0.6188040375709534
Mem used: -900MB
best_loss: tensor(-0.6230, device='cuda:1')
best_loss: tensor(-0.6239, device='cuda:1')
final loss: -0.6183469295501709
Test:
Test: 0.44840667678300455
0.44840667678300455
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.99it/s]100%|██████████| 1/1 [00:00<00:00,  2.99it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6133822798728943
Epoch 1: -0.6133822798728943
Mem used: -900MB
best_loss: tensor(-0.6054, device='cuda:1')
best_loss: tensor(-0.6073, device='cuda:1')
final loss: -0.6065799593925476
Test:
Test: 0.4546450851458439
0.4546450851458439
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.66it/s]100%|██████████| 1/1 [00:00<00:00,  4.65it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5855416655540466
Epoch 1: -0.5855416655540466
Mem used: -900MB
best_loss: tensor(-0.5858, device='cuda:1')
best_loss: tensor(-0.5869, device='cuda:1')
final loss: -0.5857683420181274
Test:
Test: 0.45198954645085143
0.45198954645085143
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  6.81it/s]100%|██████████| 1/1 [00:00<00:00,  6.79it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.605486273765564
Epoch 1: -0.605486273765564
Mem used: -900MB
best_loss: tensor(-0.5993, device='cuda:1')
final loss: -0.5999714136123657
Test:
Test: 0.4609677963243972
0.4609677963243972
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.35it/s]100%|██████████| 1/1 [00:00<00:00,  4.34it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6022611856460571
Epoch 1: -0.6022611856460571
Mem used: -900MB
best_loss: tensor(-0.5960, device='cuda:1')
best_loss: tensor(-0.5973, device='cuda:1')
final loss: -0.5973454713821411
Test:
Test: 0.45144157814871017
0.45144157814871017
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.63it/s]100%|██████████| 1/1 [00:00<00:00,  3.63it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.5943117141723633
Epoch 1: -0.5943117141723633
Mem used: -900MB
best_loss: tensor(-0.5954, device='cuda:1')
best_loss: tensor(-0.5970, device='cuda:1')
final loss: -0.5943858623504639
Test:
Test: 0.4519473950429944
0.4519473950429944
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.98it/s]100%|██████████| 1/1 [00:00<00:00,  2.97it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5679726004600525
Epoch 1: -0.5679726004600525
Mem used: -900MB
best_loss: tensor(-0.5654, device='cuda:1')
best_loss: tensor(-0.5660, device='cuda:1')
final loss: -0.5661796927452087
Test:
Test: 0.44608834935086833
0.44608834935086833
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.81it/s]100%|██████████| 1/1 [00:00<00:00,  4.80it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6161868572235107
Epoch 1: -0.6161868572235107
Mem used: -900MB
best_loss: tensor(-0.6192, device='cuda:1')
final loss: -0.6206066608428955
Test:
Test: 0.4591974371944023
0.4591974371944023
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.61it/s]100%|██████████| 1/1 [00:00<00:00,  4.60it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.587518572807312
Epoch 1: -0.587518572807312
Mem used: -900MB
best_loss: tensor(-0.5792, device='cuda:1')
final loss: -0.579164981842041
Test:
Test: 0.44503456415444276
0.44503456415444276
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.32it/s]100%|██████████| 1/1 [00:00<00:00,  4.32it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5735430717468262
Epoch 1: -0.5735430717468262
Mem used: -900MB
best_loss: tensor(-0.5757, device='cuda:1')
final loss: -0.5750858783721924
Test:
Test: 0.4554459618951273
0.4554459618951273
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.01it/s]100%|██████████| 1/1 [00:00<00:00,  5.00it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6188040375709534
Epoch 1: -0.6188040375709534
Mem used: -900MB
best_loss: tensor(-0.6225, device='cuda:1')
best_loss: tensor(-0.6239, device='cuda:1')
final loss: -0.6183469295501709
Test:
Test: 0.44840667678300455
0.44840667678300455
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.91it/s]100%|██████████| 1/1 [00:00<00:00,  4.90it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6133822798728943
Epoch 1: -0.6133822798728943
Mem used: -900MB
best_loss: tensor(-0.6052, device='cuda:1')
best_loss: tensor(-0.6073, device='cuda:1')
final loss: -0.6065799593925476
Test:
Test: 0.4546450851458439
0.4546450851458439
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.65it/s]100%|██████████| 1/1 [00:00<00:00,  3.64it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5855416655540466
Epoch 1: -0.5855416655540466
Mem used: -900MB
best_loss: tensor(-0.5863, device='cuda:1')
best_loss: tensor(-0.5869, device='cuda:1')
final loss: -0.5857683420181274
Test:
Test: 0.45198954645085143
0.45198954645085143
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.74it/s]100%|██████████| 1/1 [00:00<00:00,  4.69it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.605486273765564
Epoch 1: -0.605486273765564
Mem used: -900MB
best_loss: tensor(-0.5976, device='cuda:1')
final loss: -0.6007784605026245
Test:
Test: 0.46459281740010117
0.46459281740010117
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.35it/s]100%|██████████| 1/1 [00:00<00:00,  4.35it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6022611856460571
Epoch 1: -0.6022611856460571
Mem used: -900MB
best_loss: tensor(-0.5961, device='cuda:1')
best_loss: tensor(-0.5973, device='cuda:1')
final loss: -0.5973454713821411
Test:
Test: 0.45144157814871017
0.45144157814871017
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.46it/s]100%|██████████| 1/1 [00:00<00:00,  4.45it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388945579529
Epoch 0, Loop Adj 0: -0.5943117141723633
Epoch 1: -0.5943117141723633
Mem used: -900MB
best_loss: tensor(-0.5960, device='cuda:1')
best_loss: tensor(-0.5970, device='cuda:1')
final loss: -0.5943858623504639
Test:
Test: 0.4519473950429944
0.4519473950429944
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.14it/s]100%|██████████| 1/1 [00:00<00:00,  3.14it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5679726004600525
Epoch 1: -0.5679726004600525
Mem used: -900MB
best_loss: tensor(-0.5686, device='cuda:1')
final loss: -0.5651487708091736
Test:
Test: 0.4497133704265722
0.4497133704265722
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.63it/s]100%|██████████| 1/1 [00:00<00:00,  4.63it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6161868572235107
Epoch 1: -0.6161868572235107
Mem used: -900MB
best_loss: tensor(-0.6173, device='cuda:1')
best_loss: tensor(-0.6175, device='cuda:1')
final loss: -0.6209471821784973
Test:
Test: 0.4561625358286967
0.4561625358286967
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.91it/s]100%|██████████| 1/1 [00:00<00:00,  3.90it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.587518572807312
Epoch 1: -0.587518572807312
Mem used: -900MB
best_loss: tensor(-0.5803, device='cuda:1')
final loss: -0.579226553440094
Test:
Test: 0.4486174338222897
0.4486174338222897
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.39it/s]100%|██████████| 1/1 [00:00<00:00,  4.39it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5735430717468262
Epoch 1: -0.5735430717468262
Mem used: -900MB
best_loss: tensor(-0.5740, device='cuda:1')
best_loss: tensor(-0.5755, device='cuda:1')
final loss: -0.576477587223053
Test:
Test: 0.4550244478165571
0.4550244478165571
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.43it/s]100%|██████████| 1/1 [00:00<00:00,  3.43it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6188040375709534
Epoch 1: -0.6188040375709534
Mem used: -900MB
best_loss: tensor(-0.6239, device='cuda:1')
best_loss: tensor(-0.6240, device='cuda:1')
final loss: -0.6177884340286255
Test:
Test: 0.4475636486258641
0.4475636486258641
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.83it/s]100%|██████████| 1/1 [00:00<00:00,  3.83it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6133822798728943
Epoch 1: -0.6133822798728943
Mem used: -900MB
best_loss: tensor(-0.6068, device='cuda:1')
best_loss: tensor(-0.6073, device='cuda:1')
final loss: -0.6065962910652161
Test:
Test: 0.45443432810655876
0.45443432810655876
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.15it/s]100%|██████████| 1/1 [00:00<00:00,  3.14it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5855416655540466
Epoch 1: -0.5855416655540466
Mem used: -900MB
best_loss: tensor(-0.5867, device='cuda:1')
best_loss: tensor(-0.5868, device='cuda:1')
final loss: -0.5852519273757935
Test:
Test: 0.4516523351879953
0.4516523351879953
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.43it/s]100%|██████████| 1/1 [00:00<00:00,  3.43it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.605486273765564
Epoch 1: -0.605486273765564
Mem used: -900MB
best_loss: tensor(-0.5982, device='cuda:1')
final loss: -0.5991449356079102
Test:
Test: 0.460546282245827
0.460546282245827
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.09it/s]100%|██████████| 1/1 [00:00<00:00,  3.08it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6022611856460571
Epoch 1: -0.6022611856460571
Mem used: -900MB
best_loss: tensor(-0.5968, device='cuda:1')
final loss: -0.5974825024604797
Test:
Test: 0.4513151239251391
0.4513151239251391
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.11it/s]100%|██████████| 1/1 [00:00<00:00,  3.10it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.5943117141723633
Epoch 1: -0.5943117141723633
Mem used: -900MB
best_loss: tensor(-0.5972, device='cuda:1')
best_loss: tensor(-0.5972, device='cuda:1')
final loss: -0.5950071215629578
Test:
Test: 0.4513151239251391
0.4513151239251391
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.56it/s]100%|██████████| 1/1 [00:00<00:00,  5.55it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5679726004600525
Epoch 1: -0.5679726004600525
Mem used: -900MB
best_loss: tensor(-0.5658, device='cuda:1')
best_loss: tensor(-0.5661, device='cuda:1')
final loss: -0.5653744339942932
Test:
Test: 0.4459618951272972
0.4459618951272972
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.76it/s]100%|██████████| 1/1 [00:00<00:00,  2.76it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6161868572235107
Epoch 1: -0.6161868572235107
Mem used: -900MB
best_loss: tensor(-0.6187, device='cuda:1')
final loss: -0.6209019422531128
Test:
Test: 0.45700556398583714
0.45700556398583714
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.92it/s]100%|██████████| 1/1 [00:00<00:00,  3.92it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.587518572807312
Epoch 1: -0.587518572807312
Mem used: -900MB
best_loss: tensor(-0.5791, device='cuda:1')
final loss: -0.5795223712921143
Test:
Test: 0.4459197437194402
0.4459197437194402
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.71it/s]100%|██████████| 1/1 [00:00<00:00,  3.71it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5735430717468262
Epoch 1: -0.5735430717468262
Mem used: -900MB
best_loss: tensor(-0.5749, device='cuda:1')
best_loss: tensor(-0.5750, device='cuda:1')
final loss: -0.5762936472892761
Test:
Test: 0.4546450851458439
0.4546450851458439
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.80it/s]100%|██████████| 2/2 [00:00<00:00,  4.40it/s]100%|██████████| 2/2 [00:00<00:00,  4.45it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6188040375709534
Epoch 1, Loop Feat 0: -0.6196312308311462
Epoch 1, Loop Adj 0: -0.6246758699417114
Epoch 2: -0.6246758699417114
Mem used: -900MB
best_loss: tensor(-0.6253, device='cuda:1')
final loss: -0.6179130673408508
Test:
Test: 0.4519052436351374
0.4519052436351374
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.01it/s]100%|██████████| 2/2 [00:00<00:00,  3.21it/s]100%|██████████| 2/2 [00:00<00:00,  3.18it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6133822798728943
Epoch 1, Loop Feat 0: -0.6097511053085327
Epoch 1, Loop Adj 0: -0.6079535484313965
Epoch 2: -0.6079535484313965
Mem used: -900MB
best_loss: tensor(-0.6076, device='cuda:1')
final loss: -0.6063641309738159
Test:
Test: 0.4560782330129826
0.4560782330129826
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.48it/s]100%|██████████| 2/2 [00:00<00:00,  2.51it/s]100%|██████████| 2/2 [00:00<00:00,  2.62it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5855416655540466
Epoch 1, Loop Feat 0: -0.5840636491775513
Epoch 1, Loop Adj 0: -0.5865162014961243
Epoch 2: -0.5865162014961243
Mem used: -900MB
best_loss: tensor(-0.5863, device='cuda:1')
best_loss: tensor(-0.5871, device='cuda:1')
final loss: -0.5862346291542053
Test:
Test: 0.45135727533299613
0.45135727533299613
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.07it/s]100%|██████████| 2/2 [00:00<00:00,  3.37it/s]100%|██████████| 2/2 [00:00<00:00,  3.45it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.605486273765564
Epoch 1, Loop Feat 0: -0.598021388053894
Epoch 1, Loop Adj 0: -0.607057511806488
Epoch 2: -0.607057511806488
Mem used: -900MB
best_loss: tensor(-0.5979, device='cuda:1')
final loss: -0.5996420383453369
Test:
Test: 0.4640026976901028
0.4640026976901028
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.26it/s]100%|██████████| 2/2 [00:00<00:00,  3.95it/s]100%|██████████| 2/2 [00:00<00:00,  4.06it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6022611856460571
Epoch 1, Loop Feat 0: -0.5954406261444092
Epoch 1, Loop Adj 0: -0.6000458002090454
Epoch 2: -0.6000458002090454
Mem used: -900MB
best_loss: tensor(-0.5967, device='cuda:1')
best_loss: tensor(-0.5971, device='cuda:1')
final loss: -0.5982294678688049
Test:
Test: 0.451104366885854
0.451104366885854
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.76it/s]100%|██████████| 2/2 [00:00<00:00,  3.19it/s]100%|██████████| 2/2 [00:00<00:00,  3.26it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388945579529
Epoch 0, Loop Adj 0: -0.5943117141723633
Epoch 1, Loop Feat 0: -0.5941409468650818
Epoch 1, Loop Adj 0: -0.5939995050430298
Epoch 2: -0.5939995050430298
Mem used: -900MB
best_loss: tensor(-0.5982, device='cuda:1')
final loss: -0.595902681350708
Test:
Test: 0.45295902883156297
0.45295902883156297
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.35it/s]100%|██████████| 2/2 [00:00<00:00,  3.30it/s]100%|██████████| 2/2 [00:00<00:00,  3.30it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5679726004600525
Epoch 1, Loop Feat 0: -0.56795734167099
Epoch 1, Loop Adj 0: -0.565947949886322
Epoch 2: -0.565947949886322
Mem used: -900MB
best_loss: tensor(-0.5670, device='cuda:1')
best_loss: tensor(-0.5670, device='cuda:1')
final loss: -0.5657665133476257
Test:
Test: 0.44549822964087
0.44549822964087
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.66it/s]100%|██████████| 2/2 [00:00<00:00,  2.88it/s]100%|██████████| 2/2 [00:00<00:00,  2.97it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6161868572235107
Epoch 1, Loop Feat 0: -0.6202381253242493
Epoch 1, Loop Adj 0: -0.6217098832130432
Epoch 2: -0.6217098832130432
Mem used: -900MB
best_loss: tensor(-0.6180, device='cuda:1')
final loss: -0.6196473240852356
Test:
Test: 0.4580593491822627
0.4580593491822627
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.37it/s]100%|██████████| 2/2 [00:00<00:00,  3.05it/s]100%|██████████| 2/2 [00:00<00:00,  3.09it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.587518572807312
Epoch 1, Loop Feat 0: -0.582222044467926
Epoch 1, Loop Adj 0: -0.5782745480537415
Epoch 2: -0.5782745480537415
Mem used: -900MB
best_loss: tensor(-0.5806, device='cuda:1')
final loss: -0.5803989171981812
Test:
Test: 0.4485331310065756
0.4485331310065756
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.44it/s]100%|██████████| 2/2 [00:00<00:00,  5.37it/s]100%|██████████| 2/2 [00:00<00:00,  5.38it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5735430717468262
Epoch 1, Loop Feat 0: -0.5742257237434387
Epoch 1, Loop Adj 0: -0.576178252696991
Epoch 2: -0.576178252696991
Mem used: -900MB
best_loss: tensor(-0.5756, device='cuda:1')
best_loss: tensor(-0.5758, device='cuda:1')
final loss: -0.5761512517929077
Test:
Test: 0.4545186309222728
0.4545186309222728
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.61it/s]100%|██████████| 2/2 [00:00<00:00,  5.33it/s]100%|██████████| 2/2 [00:00<00:00,  5.36it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6188040375709534
Epoch 1, Loop Feat 0: -0.6196312308311462
Epoch 1, Loop Adj 0: -0.6246758699417114
Epoch 2: -0.6246758699417114
Mem used: -900MB
best_loss: tensor(-0.6284, device='cuda:1')
final loss: -0.6217328310012817
Test:
Test: 0.4524110605294217
0.4524110605294217
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.00it/s]100%|██████████| 2/2 [00:00<00:00,  2.83it/s]100%|██████████| 2/2 [00:00<00:00,  2.96it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6133822798728943
Epoch 1, Loop Feat 0: -0.6097511053085327
Epoch 1, Loop Adj 0: -0.6079535484313965
Epoch 2: -0.6079535484313965
Mem used: -900MB
best_loss: tensor(-0.6125, device='cuda:1')
final loss: -0.6130097508430481
Test:
Test: 0.45595177878941157
0.45595177878941157
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.28it/s]100%|██████████| 2/2 [00:00<00:00,  5.37it/s]100%|██████████| 2/2 [00:00<00:00,  5.35it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5855416655540466
Epoch 1, Loop Feat 0: -0.5840636491775513
Epoch 1, Loop Adj 0: -0.5865162014961243
Epoch 2: -0.5865162014961243
Mem used: -900MB
best_loss: tensor(-0.5902, device='cuda:1')
final loss: -0.5910762548446655
Test:
Test: 0.45649974709155283
0.45649974709155283
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.64it/s]100%|██████████| 2/2 [00:00<00:00,  4.21it/s]100%|██████████| 2/2 [00:00<00:00,  4.11it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011685371399
Epoch 0, Loop Adj 0: -0.605486273765564
Epoch 1, Loop Feat 0: -0.598021388053894
Epoch 1, Loop Adj 0: -0.607057511806488
Epoch 2: -0.607057511806488
Mem used: -900MB
best_loss: tensor(-0.6016, device='cuda:1')
final loss: -0.6032186150550842
Test:
Test: 0.4635811836115326
0.4635811836115326
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.37it/s]100%|██████████| 2/2 [00:00<00:00,  4.15it/s]100%|██████████| 2/2 [00:00<00:00,  4.29it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6022611856460571
Epoch 1, Loop Feat 0: -0.5954406261444092
Epoch 1, Loop Adj 0: -0.6000458002090454
Epoch 2: -0.6000458002090454
Mem used: -900MB
best_loss: tensor(-0.6014, device='cuda:1')
final loss: -0.6045324206352234
Test:
Test: 0.45671050413083797
0.45671050413083797
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.76it/s]100%|██████████| 2/2 [00:00<00:00,  2.43it/s]100%|██████████| 2/2 [00:00<00:00,  2.47it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.5943117141723633
Epoch 1, Loop Feat 0: -0.5941409468650818
Epoch 1, Loop Adj 0: -0.5939995050430298
Epoch 2: -0.5939995050430298
Mem used: -900MB
best_loss: tensor(-0.6013, device='cuda:1')
final loss: -0.6013538837432861
Test:
Test: 0.45405496543584556
0.45405496543584556
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.19it/s]100%|██████████| 2/2 [00:00<00:00,  3.68it/s]100%|██████████| 2/2 [00:00<00:00,  3.75it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5679726004600525
Epoch 1, Loop Feat 0: -0.56795734167099
Epoch 1, Loop Adj 0: -0.5659478902816772
Epoch 2: -0.5659478902816772
Mem used: -900MB
best_loss: tensor(-0.5736, device='cuda:1')
final loss: -0.5715342164039612
Test:
Test: 0.4485752824144326
0.4485752824144326
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.01it/s]100%|██████████| 2/2 [00:00<00:00,  3.04it/s]100%|██████████| 2/2 [00:00<00:00,  3.16it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6161868572235107
Epoch 1, Loop Feat 0: -0.6202381253242493
Epoch 1, Loop Adj 0: -0.6217098832130432
Epoch 2: -0.6217098832130432
Mem used: -900MB
best_loss: tensor(-0.6205, device='cuda:1')
final loss: -0.6224659085273743
Test:
Test: 0.4584808632608329
0.4584808632608329
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.37it/s]100%|██████████| 2/2 [00:00<00:00,  3.91it/s]100%|██████████| 2/2 [00:00<00:00,  3.97it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.587518572807312
Epoch 1, Loop Feat 0: -0.582222044467926
Epoch 1, Loop Adj 0: -0.5782745480537415
Epoch 2: -0.5782745480537415
Mem used: -900MB
best_loss: tensor(-0.5855, device='cuda:1')
final loss: -0.5854661464691162
Test:
Test: 0.4504299443601416
0.4504299443601416
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.16it/s]100%|██████████| 2/2 [00:00<00:00,  4.40it/s]100%|██████████| 2/2 [00:00<00:00,  4.49it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5735430717468262
Epoch 1, Loop Feat 0: -0.5742257237434387
Epoch 1, Loop Adj 0: -0.576178252696991
Epoch 2: -0.576178252696991
Mem used: -900MB
best_loss: tensor(-0.5798, device='cuda:1')
final loss: -0.5800902247428894
Test:
Test: 0.45519305344798516
0.45519305344798516
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.50it/s]100%|██████████| 2/2 [00:00<00:00,  4.79it/s]100%|██████████| 2/2 [00:00<00:00,  4.74it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.6188040375709534
Epoch 1, Loop Feat 0: -0.619934618473053
Epoch 1, Loop Adj 0: -0.6248786449432373
Epoch 2: -0.6248786449432373
Mem used: -900MB
best_loss: tensor(-0.6239, device='cuda:1')
best_loss: tensor(-0.6242, device='cuda:1')
final loss: -0.6180777549743652
Test:
Test: 0.4479008598887203
0.4479008598887203
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.24it/s]100%|██████████| 2/2 [00:00<00:00,  3.07it/s]100%|██████████| 2/2 [00:00<00:00,  3.09it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6133822798728943
Epoch 1, Loop Feat 0: -0.6100248098373413
Epoch 1, Loop Adj 0: -0.6083700656890869
Epoch 2: -0.6083700656890869
Mem used: -900MB
best_loss: tensor(-0.6075, device='cuda:1')
best_loss: tensor(-0.6076, device='cuda:1')
final loss: -0.6069179773330688
Test:
Test: 0.4543078738829877
0.4543078738829877
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.87it/s]100%|██████████| 2/2 [00:00<00:00,  2.81it/s]100%|██████████| 2/2 [00:00<00:00,  2.93it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5855416655540466
Epoch 1, Loop Feat 0: -0.5843591094017029
Epoch 1, Loop Adj 0: -0.5867623686790466
Epoch 2: -0.5867623686790466
Mem used: -900MB
best_loss: tensor(-0.5867, device='cuda:1')
best_loss: tensor(-0.5870, device='cuda:1')
final loss: -0.5855119824409485
Test:
Test: 0.45161018378013823
0.45161018378013823
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.19it/s]100%|██████████| 2/2 [00:00<00:00,  2.51it/s]100%|██████████| 2/2 [00:00<00:00,  2.45it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.605486273765564
Epoch 1, Loop Feat 0: -0.5982760787010193
Epoch 1, Loop Adj 0: -0.6074422597885132
Epoch 2: -0.6074422597885132
Mem used: -900MB
best_loss: tensor(-0.5983, device='cuda:1')
final loss: -0.5990341305732727
Test:
Test: 0.4606727364693981
0.4606727364693981
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.98it/s]100%|██████████| 2/2 [00:00<00:00,  2.23it/s]100%|██████████| 2/2 [00:00<00:00,  2.32it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6022611856460571
Epoch 1, Loop Feat 0: -0.595940113067627
Epoch 1, Loop Adj 0: -0.600498616695404
Epoch 2: -0.600498616695404
Mem used: -900MB
best_loss: tensor(-0.5975, device='cuda:1')
best_loss: tensor(-0.5975, device='cuda:1')
final loss: -0.5976418256759644
Test:
Test: 0.45139942674085315
0.45139942674085315
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.61it/s]100%|██████████| 2/2 [00:00<00:00,  2.81it/s]100%|██████████| 2/2 [00:00<00:00,  2.78it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.5943117141723633
Epoch 1, Loop Feat 0: -0.5945708155632019
Epoch 1, Loop Adj 0: -0.5943315029144287
Epoch 2: -0.5943315029144287
Mem used: -900MB
best_loss: tensor(-0.5970, device='cuda:1')
best_loss: tensor(-0.5974, device='cuda:1')
final loss: -0.5950325131416321
Test:
Test: 0.451104366885854
0.451104366885854
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  6.28it/s]100%|██████████| 2/2 [00:00<00:00,  5.62it/s]100%|██████████| 2/2 [00:00<00:00,  5.70it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5679726004600525
Epoch 1, Loop Feat 0: -0.5684732794761658
Epoch 1, Loop Adj 0: -0.566423773765564
Epoch 2: -0.566423773765564
Mem used: -900MB
best_loss: tensor(-0.5660, device='cuda:1')
best_loss: tensor(-0.5665, device='cuda:1')
final loss: -0.5663638114929199
Test:
Test: 0.44575113808801214
0.44575113808801214
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.76it/s]100%|██████████| 2/2 [00:00<00:00,  5.24it/s]100%|██████████| 2/2 [00:00<00:00,  5.16it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.6161868572235107
Epoch 1, Loop Feat 0: -0.6205067038536072
Epoch 1, Loop Adj 0: -0.6220057606697083
Epoch 2: -0.6220057606697083
Mem used: -900MB
best_loss: tensor(-0.6185, device='cuda:1')
final loss: -0.6215539574623108
Test:
Test: 0.456752655538695
0.456752655538695
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.35it/s]100%|██████████| 2/2 [00:00<00:00,  4.65it/s]100%|██████████| 2/2 [00:00<00:00,  4.60it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.587518572807312
Epoch 1, Loop Feat 0: -0.582606315612793
Epoch 1, Loop Adj 0: -0.578648567199707
Epoch 2: -0.578648567199707
Mem used: -900MB
best_loss: tensor(-0.5794, device='cuda:1')
final loss: -0.5796898603439331
Test:
Test: 0.4466784690608666
0.4466784690608666
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.16it/s]100%|██████████| 2/2 [00:00<00:00,  2.71it/s]100%|██████████| 2/2 [00:00<00:00,  2.86it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5735430717468262
Epoch 1, Loop Feat 0: -0.5745255947113037
Epoch 1, Loop Adj 0: -0.576388418674469
Epoch 2: -0.576388418674469
Mem used: -900MB
best_loss: tensor(-0.5753, device='cuda:1')
best_loss: tensor(-0.5754, device='cuda:1')
final loss: -0.5763817429542542
Test:
Test: 0.4544764795144158
0.4544764795144158
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  6.78it/s]100%|██████████| 1/1 [00:00<00:00,  6.76it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.618665337562561
Epoch 1: -0.618665337562561
Mem used: -900MB
best_loss: tensor(-0.6225, device='cuda:1')
best_loss: tensor(-0.6232, device='cuda:1')
final loss: -0.6178604960441589
Test:
Test: 0.4497133704265722
0.4497133704265722
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.69it/s]100%|██████████| 1/1 [00:00<00:00,  3.69it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6132241487503052
Epoch 1: -0.6132241487503052
Mem used: -900MB
best_loss: tensor(-0.6048, device='cuda:1')
best_loss: tensor(-0.6066, device='cuda:1')
final loss: -0.6051325798034668
Test:
Test: 0.454940145000843
0.454940145000843
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.84it/s]100%|██████████| 1/1 [00:00<00:00,  4.83it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5853759050369263
Epoch 1: -0.5853759050369263
Mem used: -900MB
best_loss: tensor(-0.5852, device='cuda:1')
best_loss: tensor(-0.5859, device='cuda:1')
final loss: -0.5858328342437744
Test:
Test: 0.4533805429101332
0.4533805429101332
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.37it/s]100%|██████████| 1/1 [00:00<00:00,  4.36it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.6053077578544617
Epoch 1: -0.6053077578544617
Mem used: -900MB
best_loss: tensor(-0.5987, device='cuda:1')
final loss: -0.5990052819252014
Test:
Test: 0.46100994773225423
0.46100994773225423
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.92it/s]100%|██████████| 1/1 [00:00<00:00,  4.92it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6020720601081848
Epoch 1: -0.6020720601081848
Mem used: -900MB
best_loss: tensor(-0.5954, device='cuda:1')
final loss: -0.5958775877952576
Test:
Test: 0.45215815208227955
0.45215815208227955
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.21it/s]100%|██████████| 1/1 [00:00<00:00,  4.21it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.5941256880760193
Epoch 1: -0.5941256880760193
Mem used: -900MB
best_loss: tensor(-0.5948, device='cuda:1')
best_loss: tensor(-0.5961, device='cuda:1')
final loss: -0.5950040221214294
Test:
Test: 0.45236890912156463
0.45236890912156463
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.48it/s]100%|██████████| 1/1 [00:00<00:00,  4.47it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5677321553230286
Epoch 1: -0.5677321553230286
Mem used: -900MB
best_loss: tensor(-0.5646, device='cuda:1')
best_loss: tensor(-0.5654, device='cuda:1')
final loss: -0.5647878646850586
Test:
Test: 0.44617265216658236
0.44617265216658236
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.83it/s]100%|██████████| 1/1 [00:00<00:00,  2.83it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.616064190864563
Epoch 1: -0.616064190864563
Mem used: -900MB
best_loss: tensor(-0.6186, device='cuda:1')
final loss: -0.6203303933143616
Test:
Test: 0.4590288315629742
0.4590288315629742
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.71it/s]100%|██████████| 1/1 [00:00<00:00,  3.71it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.5873245000839233
Epoch 1: -0.5873245000839233
Mem used: -900MB
best_loss: tensor(-0.5787, device='cuda:1')
final loss: -0.5784153342247009
Test:
Test: 0.4449081099308717
0.4449081099308717
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  6.20it/s]100%|██████████| 1/1 [00:00<00:00,  6.19it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5733749866485596
Epoch 1: -0.5733749866485596
Mem used: -900MB
best_loss: tensor(-0.5751, device='cuda:1')
final loss: -0.5744606852531433
Test:
Test: 0.4553195076715562
0.4553195076715562
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.87it/s]100%|██████████| 1/1 [00:00<00:00,  3.87it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.618665337562561
Epoch 1: -0.618665337562561
Mem used: -900MB
best_loss: tensor(-0.6219, device='cuda:1')
best_loss: tensor(-0.6236, device='cuda:1')
final loss: -0.6182848215103149
Test:
Test: 0.4503456415444276
0.4503456415444276
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.06it/s]100%|██████████| 1/1 [00:00<00:00,  3.98it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6132241487503052
Epoch 1: -0.6132241487503052
Mem used: -900MB
best_loss: tensor(-0.6047, device='cuda:1')
best_loss: tensor(-0.6062, device='cuda:1')
final loss: -0.6051281690597534
Test:
Test: 0.45612038442083963
0.45612038442083963
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.67it/s]100%|██████████| 1/1 [00:00<00:00,  3.67it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5853759050369263
Epoch 1: -0.5853759050369263
Mem used: -900MB
best_loss: tensor(-0.5856, device='cuda:1')
best_loss: tensor(-0.5871, device='cuda:1')
final loss: -0.5869153141975403
Test:
Test: 0.45595177878941157
0.45595177878941157
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.59it/s]100%|██████████| 1/1 [00:00<00:00,  5.58it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.6053077578544617
Epoch 1: -0.6053077578544617
Mem used: -900MB
best_loss: tensor(-0.5971, device='cuda:1')
best_loss: tensor(-0.5977, device='cuda:1')
final loss: -0.6007617115974426
Test:
Test: 0.464339908952959
0.464339908952959
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.80it/s]100%|██████████| 1/1 [00:00<00:00,  3.79it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6020720601081848
Epoch 1: -0.6020720601081848
Mem used: -900MB
best_loss: tensor(-0.5956, device='cuda:1')
best_loss: tensor(-0.5967, device='cuda:1')
final loss: -0.5965617299079895
Test:
Test: 0.4527904232001349
0.4527904232001349
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.38it/s]100%|██████████| 1/1 [00:00<00:00,  3.38it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.5941256880760193
Epoch 1: -0.5941256880760193
Mem used: -900MB
best_loss: tensor(-0.5955, device='cuda:1')
best_loss: tensor(-0.5965, device='cuda:1')
final loss: -0.5943013429641724
Test:
Test: 0.4534226943179902
0.4534226943179902
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.67it/s]100%|██████████| 1/1 [00:00<00:00,  4.67it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5677321553230286
Epoch 1: -0.5677321553230286
Mem used: -900MB
best_loss: tensor(-0.5681, device='cuda:1')
final loss: -0.564651370048523
Test:
Test: 0.4500505816894284
0.4500505816894284
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.54it/s]100%|██████████| 1/1 [00:00<00:00,  3.53it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.616064190864563
Epoch 1: -0.616064190864563
Mem used: -900MB
best_loss: tensor(-0.6169, device='cuda:1')
final loss: -0.6166911721229553
Test:
Test: 0.4618108244815377
0.4618108244815377
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.36it/s]100%|██████████| 1/1 [00:00<00:00,  4.35it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.5873245000839233
Epoch 1: -0.5873245000839233
Mem used: -900MB
best_loss: tensor(-0.5798, device='cuda:1')
best_loss: tensor(-0.5802, device='cuda:1')
final loss: -0.5799591541290283
Test:
Test: 0.44798516270443434
0.44798516270443434
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.35it/s]100%|██████████| 1/1 [00:00<00:00,  4.34it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5733749866485596
Epoch 1: -0.5733749866485596
Mem used: -900MB
best_loss: tensor(-0.5734, device='cuda:1')
best_loss: tensor(-0.5747, device='cuda:1')
final loss: -0.5766406059265137
Test:
Test: 0.4564154442758388
0.4564154442758388
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.97it/s]100%|██████████| 1/1 [00:00<00:00,  3.97it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.618665337562561
Epoch 1: -0.618665337562561
Mem used: -900MB
best_loss: tensor(-0.6234, device='cuda:1')
final loss: -0.6179167032241821
Test:
Test: 0.4479430112965773
0.4479430112965773
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.34it/s]100%|██████████| 1/1 [00:00<00:00,  4.33it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6132241487503052
Epoch 1: -0.6132241487503052
Mem used: -900MB
best_loss: tensor(-0.6063, device='cuda:1')
best_loss: tensor(-0.6066, device='cuda:1')
final loss: -0.6058509349822998
Test:
Test: 0.4542657224751307
0.4542657224751307
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.21it/s]100%|██████████| 1/1 [00:00<00:00,  4.20it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5853759050369263
Epoch 1: -0.5853759050369263
Mem used: -900MB
best_loss: tensor(-0.5861, device='cuda:1')
best_loss: tensor(-0.5862, device='cuda:1')
final loss: -0.5850182175636292
Test:
Test: 0.45173663800370933
0.45173663800370933
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.21it/s]100%|██████████| 1/1 [00:00<00:00,  3.21it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.6053077578544617
Epoch 1: -0.6053077578544617
Mem used: -900MB
best_loss: tensor(-0.5976, device='cuda:1')
final loss: -0.5986795425415039
Test:
Test: 0.460588433653684
0.460588433653684
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.67it/s]100%|██████████| 1/1 [00:00<00:00,  3.66it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6020720601081848
Epoch 1: -0.6020720601081848
Mem used: -900MB
best_loss: tensor(-0.5961, device='cuda:1')
best_loss: tensor(-0.5965, device='cuda:1')
final loss: -0.5972645282745361
Test:
Test: 0.4516523351879953
0.4516523351879953
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.96it/s]100%|██████████| 1/1 [00:00<00:00,  4.95it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388945579529
Epoch 0, Loop Adj 0: -0.5941256880760193
Epoch 1: -0.5941256880760193
Mem used: -900MB
best_loss: tensor(-0.5965, device='cuda:1')
final loss: -0.5949772596359253
Test:
Test: 0.4513151239251391
0.4513151239251391
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.47it/s]100%|██████████| 1/1 [00:00<00:00,  2.46it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5677321553230286
Epoch 1: -0.5677321553230286
Mem used: -900MB
best_loss: tensor(-0.5651, device='cuda:1')
best_loss: tensor(-0.5654, device='cuda:1')
final loss: -0.5651035308837891
Test:
Test: 0.4460040465351543
0.4460040465351543
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.20it/s]100%|██████████| 1/1 [00:00<00:00,  4.20it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.616064190864563
Epoch 1: -0.616064190864563
Mem used: -900MB
best_loss: tensor(-0.6182, device='cuda:1')
final loss: -0.6205228567123413
Test:
Test: 0.4569212611701231
0.4569212611701231
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.76it/s]100%|██████████| 1/1 [00:00<00:00,  4.76it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.5873245000839233
Epoch 1: -0.5873245000839233
Mem used: -900MB
best_loss: tensor(-0.5785, device='cuda:1')
final loss: -0.5790691375732422
Test:
Test: 0.44575113808801214
0.44575113808801214
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.46it/s]100%|██████████| 1/1 [00:00<00:00,  4.46it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5733749866485596
Epoch 1: -0.5733749866485596
Mem used: -900MB
best_loss: tensor(-0.5743, device='cuda:1')
best_loss: tensor(-0.5745, device='cuda:1')
final loss: -0.5756557583808899
Test:
Test: 0.454897993592986
0.454897993592986
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.49it/s]100%|██████████| 2/2 [00:00<00:00,  3.49it/s]100%|██████████| 2/2 [00:00<00:00,  3.49it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.618665337562561
Epoch 1, Loop Feat 0: -0.6183283925056458
Epoch 1, Loop Adj 0: -0.6235206127166748
Epoch 2: -0.6235206127166748
Mem used: -900MB
best_loss: tensor(-0.6244, device='cuda:1')
final loss: -0.6174219846725464
Test:
Test: 0.4498398246501433
0.4498398246501433
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.09it/s]100%|██████████| 2/2 [00:00<00:00,  3.39it/s]100%|██████████| 2/2 [00:00<00:00,  3.47it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6132241487503052
Epoch 1, Loop Feat 0: -0.6082445979118347
Epoch 1, Loop Adj 0: -0.6059648990631104
Epoch 2: -0.6059648990631104
Mem used: -900MB
best_loss: tensor(-0.6068, device='cuda:1')
final loss: -0.6057443618774414
Test:
Test: 0.4549822964087
0.4549822964087
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.55it/s]100%|██████████| 2/2 [00:00<00:00,  4.49it/s]100%|██████████| 2/2 [00:00<00:00,  4.50it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5853759050369263
Epoch 1, Loop Feat 0: -0.5827266573905945
Epoch 1, Loop Adj 0: -0.584991991519928
Epoch 2: -0.584991991519928
Mem used: -900MB
best_loss: tensor(-0.5860, device='cuda:1')
final loss: -0.5855491161346436
Test:
Test: 0.4554038104872703
0.4554038104872703
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.70it/s]100%|██████████| 2/2 [00:00<00:00,  4.04it/s]100%|██████████| 2/2 [00:00<00:00,  3.98it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.6053077578544617
Epoch 1, Loop Feat 0: -0.5966848731040955
Epoch 1, Loop Adj 0: -0.6051557660102844
Epoch 2: -0.6051557660102844
Mem used: -900MB
best_loss: tensor(-0.5983, device='cuda:1')
final loss: -0.5984742641448975
Test:
Test: 0.4631596695329624
0.4631596695329624
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.47it/s]100%|██████████| 2/2 [00:00<00:00,  3.90it/s]100%|██████████| 2/2 [00:00<00:00,  3.82it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6020720601081848
Epoch 1, Loop Feat 0: -0.5932109951972961
Epoch 1, Loop Adj 0: -0.5978803634643555
Epoch 2: -0.5978803634643555
Mem used: -900MB
best_loss: tensor(-0.5962, device='cuda:1')
best_loss: tensor(-0.5968, device='cuda:1')
final loss: -0.5975750684738159
Test:
Test: 0.45177878941156635
0.45177878941156635
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.32it/s]100%|██████████| 2/2 [00:00<00:00,  2.72it/s]100%|██████████| 2/2 [00:00<00:00,  2.79it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.5941256880760193
Epoch 1, Loop Feat 0: -0.5922117829322815
Epoch 1, Loop Adj 0: -0.5922175049781799
Epoch 2: -0.5922175049781799
Mem used: -900MB
best_loss: tensor(-0.5967, device='cuda:1')
final loss: -0.59501713514328
Test:
Test: 0.4531697858708481
0.4531697858708481
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.33it/s]100%|██████████| 2/2 [00:00<00:00,  4.92it/s]100%|██████████| 2/2 [00:00<00:00,  4.82it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5677321553230286
Epoch 1, Loop Feat 0: -0.5656625032424927
Epoch 1, Loop Adj 0: -0.5635989308357239
Epoch 2: -0.5635989308357239
Mem used: -900MB
best_loss: tensor(-0.5661, device='cuda:1')
final loss: -0.5655721426010132
Test:
Test: 0.44802731411229135
0.44802731411229135
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.33it/s]100%|██████████| 2/2 [00:00<00:00,  3.82it/s]100%|██████████| 2/2 [00:00<00:00,  3.74it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.616064190864563
Epoch 1, Loop Feat 0: -0.6190803050994873
Epoch 1, Loop Adj 0: -0.6202903985977173
Epoch 2: -0.6202903985977173
Mem used: -900MB
best_loss: tensor(-0.6176, device='cuda:1')
final loss: -0.6192142963409424
Test:
Test: 0.4582279548136908
0.4582279548136908
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.65it/s]100%|██████████| 2/2 [00:00<00:00,  3.77it/s]100%|██████████| 2/2 [00:00<00:00,  3.75it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.5873245000839233
Epoch 1, Loop Feat 0: -0.5803537368774414
Epoch 1, Loop Adj 0: -0.5763674974441528
Epoch 2: -0.5763674974441528
Mem used: -900MB
best_loss: tensor(-0.5804, device='cuda:1')
final loss: -0.5792509913444519
Test:
Test: 0.4481537683358624
0.4481537683358624
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.66it/s]100%|██████████| 2/2 [00:00<00:00,  3.89it/s]100%|██████████| 2/2 [00:00<00:00,  3.99it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5733749866485596
Epoch 1, Loop Feat 0: -0.5729880928993225
Epoch 1, Loop Adj 0: -0.5748658776283264
Epoch 2: -0.5748658776283264
Mem used: -900MB
best_loss: tensor(-0.5755, device='cuda:1')
final loss: -0.5757420063018799
Test:
Test: 0.45776428932726354
0.45776428932726354
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.14it/s]100%|██████████| 2/2 [00:00<00:00,  4.23it/s]100%|██████████| 2/2 [00:00<00:00,  4.21it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.618665337562561
Epoch 1, Loop Feat 0: -0.6144731044769287
Epoch 1, Loop Adj 0: -0.6195201873779297
Epoch 2: -0.6195201873779297
Mem used: -900MB
best_loss: tensor(-0.6280, device='cuda:1')
final loss: -0.6234527230262756
Test:
Test: 0.4497976732422863
0.4497976732422863
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.73it/s]100%|██████████| 2/2 [00:00<00:00,  3.58it/s]100%|██████████| 2/2 [00:00<00:00,  3.71it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6132241487503052
Epoch 1, Loop Feat 0: -0.603841245174408
Epoch 1, Loop Adj 0: -0.6013172268867493
Epoch 2: -0.6013172268867493
Mem used: -900MB
best_loss: tensor(-0.6111, device='cuda:1')
final loss: -0.6112616062164307
Test:
Test: 0.45671050413083797
0.45671050413083797
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.10it/s]100%|██████████| 2/2 [00:00<00:00,  3.61it/s]100%|██████████| 2/2 [00:00<00:00,  3.77it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5853759050369263
Epoch 1, Loop Feat 0: -0.5793535113334656
Epoch 1, Loop Adj 0: -0.5806418061256409
Epoch 2: -0.5806418061256409
Mem used: -900MB
best_loss: tensor(-0.5914, device='cuda:1')
final loss: -0.5914580821990967
Test:
Test: 0.4569634125779801
0.4569634125779801
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  6.46it/s]100%|██████████| 2/2 [00:00<00:00,  6.08it/s]100%|██████████| 2/2 [00:00<00:00,  6.13it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.6053077578544617
Epoch 1, Loop Feat 0: -0.59295254945755
Epoch 1, Loop Adj 0: -0.6005812883377075
Epoch 2: -0.6005812883377075
Mem used: -900MB
best_loss: tensor(-0.6020, device='cuda:1')
final loss: -0.6041346192359924
Test:
Test: 0.4640448490979599
0.4640448490979599
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.92it/s]100%|██████████| 2/2 [00:00<00:00,  4.26it/s]100%|██████████| 2/2 [00:00<00:00,  3.99it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6020720601081848
Epoch 1, Loop Feat 0: -0.5875487923622131
Epoch 1, Loop Adj 0: -0.5931485891342163
Epoch 2: -0.5931485891342163
Mem used: -900MB
best_loss: tensor(-0.6017, device='cuda:1')
final loss: -0.6030704975128174
Test:
Test: 0.45586747597369753
0.45586747597369753
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.38it/s]100%|██████████| 2/2 [00:00<00:00,  2.97it/s]100%|██████████| 2/2 [00:00<00:00,  3.03it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.5941256880760193
Epoch 1, Loop Feat 0: -0.5883040428161621
Epoch 1, Loop Adj 0: -0.5883733034133911
Epoch 2: -0.5883733034133911
Mem used: -900MB
best_loss: tensor(-0.6006, device='cuda:1')
final loss: -0.6009173393249512
Test:
Test: 0.4533383915022762
0.4533383915022762
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.70it/s]100%|██████████| 2/2 [00:00<00:00,  3.12it/s]100%|██████████| 2/2 [00:00<00:00,  3.20it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5677321553230286
Epoch 1, Loop Feat 0: -0.5608686804771423
Epoch 1, Loop Adj 0: -0.5588618516921997
Epoch 2: -0.5588618516921997
Mem used: -900MB
best_loss: tensor(-0.5739, device='cuda:1')
final loss: -0.5710179805755615
Test:
Test: 0.45102006407013995
0.45102006407013995
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.96it/s]100%|██████████| 2/2 [00:00<00:00,  3.00it/s]100%|██████████| 2/2 [00:00<00:00,  3.11it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.616064190864563
Epoch 1, Loop Feat 0: -0.6156612634658813
Epoch 1, Loop Adj 0: -0.616439700126648
Epoch 2: -0.616439700126648
Mem used: -900MB
best_loss: tensor(-0.6200, device='cuda:1')
final loss: -0.6215465664863586
Test:
Test: 0.46037767661439893
0.46037767661439893
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.90it/s]100%|██████████| 2/2 [00:00<00:00,  2.86it/s]100%|██████████| 2/2 [00:00<00:00,  3.05it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.5873245000839233
Epoch 1, Loop Feat 0: -0.5755566358566284
Epoch 1, Loop Adj 0: -0.5723411440849304
Epoch 2: -0.5723411440849304
Mem used: -900MB
best_loss: tensor(-0.5856, device='cuda:1')
final loss: -0.5857067704200745
Test:
Test: 0.447437194402293
0.447437194402293
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.38it/s]100%|██████████| 2/2 [00:00<00:00,  2.89it/s]100%|██████████| 2/2 [00:00<00:00,  2.95it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5733749866485596
Epoch 1, Loop Feat 0: -0.5701494216918945
Epoch 1, Loop Adj 0: -0.5711219906806946
Epoch 2: -0.5711219906806946
Mem used: -900MB
best_loss: tensor(-0.5797, device='cuda:1')
final loss: -0.579494297504425
Test:
Test: 0.4556988703422694
0.4556988703422694
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.32it/s]100%|██████████| 2/2 [00:00<00:00,  2.42it/s]100%|██████████| 2/2 [00:00<00:00,  2.52it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.618665337562561
Epoch 1, Loop Feat 0: -0.6197414994239807
Epoch 1, Loop Adj 0: -0.6245713233947754
Epoch 2: -0.6245713233947754
Mem used: -900MB
best_loss: tensor(-0.6232, device='cuda:1')
best_loss: tensor(-0.6234, device='cuda:1')
final loss: -0.617596447467804
Test:
Test: 0.4478165570730062
0.4478165570730062
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.03it/s]100%|██████████| 2/2 [00:00<00:00,  4.95it/s]100%|██████████| 2/2 [00:00<00:00,  4.96it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6132241487503052
Epoch 1, Loop Feat 0: -0.6098227500915527
Epoch 1, Loop Adj 0: -0.6079810857772827
Epoch 2: -0.6079810857772827
Mem used: -900MB
best_loss: tensor(-0.6066, device='cuda:1')
final loss: -0.6069321632385254
Test:
Test: 0.4545186309222728
0.4545186309222728
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.58it/s]100%|██████████| 2/2 [00:00<00:00,  2.34it/s]100%|██████████| 2/2 [00:00<00:00,  2.47it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5853759050369263
Epoch 1, Loop Feat 0: -0.5841354727745056
Epoch 1, Loop Adj 0: -0.5863848328590393
Epoch 2: -0.5863848328590393
Mem used: -900MB
best_loss: tensor(-0.5857, device='cuda:1')
best_loss: tensor(-0.5861, device='cuda:1')
final loss: -0.5846853852272034
Test:
Test: 0.45139942674085315
0.45139942674085315
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.82it/s]100%|██████████| 2/2 [00:00<00:00,  3.29it/s]100%|██████████| 2/2 [00:00<00:00,  3.36it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011685371399
Epoch 0, Loop Adj 0: -0.6053077578544617
Epoch 1, Loop Feat 0: -0.5980588793754578
Epoch 1, Loop Adj 0: -0.6070131063461304
Epoch 2: -0.6070131063461304
Mem used: -900MB
best_loss: tensor(-0.5973, device='cuda:1')
final loss: -0.5981723666191101
Test:
Test: 0.460588433653684
0.460588433653684
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.01it/s]100%|██████████| 2/2 [00:00<00:00,  4.82it/s]100%|██████████| 2/2 [00:00<00:00,  4.85it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6020720601081848
Epoch 1, Loop Feat 0: -0.5956498980522156
Epoch 1, Loop Adj 0: -0.6000295281410217
Epoch 2: -0.6000295281410217
Mem used: -900MB
best_loss: tensor(-0.5966, device='cuda:1')
final loss: -0.5967934727668762
Test:
Test: 0.45198954645085143
0.45198954645085143
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.82it/s]100%|██████████| 2/2 [00:00<00:00,  4.90it/s]100%|██████████| 2/2 [00:00<00:00,  4.88it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.5941256880760193
Epoch 1, Loop Feat 0: -0.5943003296852112
Epoch 1, Loop Adj 0: -0.5939019918441772
Epoch 2: -0.5939019918441772
Mem used: -900MB
best_loss: tensor(-0.5962, device='cuda:1')
best_loss: tensor(-0.5965, device='cuda:1')
final loss: -0.594464898109436
Test:
Test: 0.45173663800370933
0.45173663800370933
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  6.04it/s]100%|██████████| 2/2 [00:00<00:00,  2.88it/s]100%|██████████| 2/2 [00:00<00:00,  3.12it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5677321553230286
Epoch 1, Loop Feat 0: -0.5681204199790955
Epoch 1, Loop Adj 0: -0.5658497214317322
Epoch 2: -0.5658497214317322
Mem used: -900MB
best_loss: tensor(-0.5649, device='cuda:1')
best_loss: tensor(-0.5656, device='cuda:1')
final loss: -0.5655380487442017
Test:
Test: 0.44575113808801214
0.44575113808801214
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.35it/s]100%|██████████| 2/2 [00:00<00:00,  3.39it/s]100%|██████████| 2/2 [00:00<00:00,  3.39it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.616064190864563
Epoch 1, Loop Feat 0: -0.6203329563140869
Epoch 1, Loop Adj 0: -0.621719479560852
Epoch 2: -0.621719479560852
Mem used: -900MB
best_loss: tensor(-0.6177, device='cuda:1')
final loss: -0.6213873624801636
Test:
Test: 0.45649974709155283
0.45649974709155283
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.26it/s]100%|██████████| 2/2 [00:00<00:00,  3.06it/s]100%|██████████| 2/2 [00:00<00:00,  3.09it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.5873245000839233
Epoch 1, Loop Feat 0: -0.5823248624801636
Epoch 1, Loop Adj 0: -0.5781656503677368
Epoch 2: -0.5781656503677368
Mem used: -900MB
best_loss: tensor(-0.5784, device='cuda:1')
best_loss: tensor(-0.5787, device='cuda:1')
final loss: -0.578924834728241
Test:
Test: 0.44549822964087
0.44549822964087
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.21it/s]100%|██████████| 2/2 [00:00<00:00,  2.90it/s]100%|██████████| 2/2 [00:00<00:00,  2.95it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5733749866485596
Epoch 1, Loop Feat 0: -0.5742865800857544
Epoch 1, Loop Adj 0: -0.5760161876678467
Epoch 2: -0.5760161876678467
Mem used: -900MB
best_loss: tensor(-0.5743, device='cuda:1')
final loss: -0.5763204097747803
Test:
Test: 0.4546872365537009
0.4546872365537009
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.12it/s]100%|██████████| 1/1 [00:00<00:00,  4.11it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.618665337562561
Epoch 1: -0.618665337562561
Mem used: -900MB
best_loss: tensor(-0.6225, device='cuda:1')
best_loss: tensor(-0.6233, device='cuda:1')
final loss: -0.6172817349433899
Test:
Test: 0.449334007755859
0.449334007755859
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.50it/s]100%|██████████| 1/1 [00:00<00:00,  4.49it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6132241487503052
Epoch 1: -0.6132241487503052
Mem used: -900MB
best_loss: tensor(-0.6048, device='cuda:1')
best_loss: tensor(-0.6064, device='cuda:1')
final loss: -0.6059828400611877
Test:
Test: 0.4550665992244141
0.4550665992244141
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.05it/s]100%|██████████| 1/1 [00:00<00:00,  5.04it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5853759050369263
Epoch 1: -0.5853759050369263
Mem used: -900MB
best_loss: tensor(-0.5852, device='cuda:1')
best_loss: tensor(-0.5859, device='cuda:1')
final loss: -0.5854731798171997
Test:
Test: 0.45274827179227783
0.45274827179227783
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.83it/s]100%|██████████| 1/1 [00:00<00:00,  4.83it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.6053077578544617
Epoch 1: -0.6053077578544617
Mem used: -900MB
best_loss: tensor(-0.5987, device='cuda:1')
final loss: -0.5990052819252014
Test:
Test: 0.46100994773225423
0.46100994773225423
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.48it/s]100%|██████████| 1/1 [00:00<00:00,  3.48it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6020720601081848
Epoch 1: -0.6020720601081848
Mem used: -900MB
best_loss: tensor(-0.5954, device='cuda:1')
final loss: -0.5958775877952576
Test:
Test: 0.45215815208227955
0.45215815208227955
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.97it/s]100%|██████████| 1/1 [00:00<00:00,  3.97it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388945579529
Epoch 0, Loop Adj 0: -0.5941256880760193
Epoch 1: -0.5941256880760193
Mem used: -900MB
best_loss: tensor(-0.5948, device='cuda:1')
best_loss: tensor(-0.5960, device='cuda:1')
final loss: -0.5955687165260315
Test:
Test: 0.4519052436351374
0.4519052436351374
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.36it/s]100%|██████████| 1/1 [00:00<00:00,  3.35it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5677321553230286
Epoch 1: -0.5677321553230286
Mem used: -900MB
best_loss: tensor(-0.5646, device='cuda:1')
best_loss: tensor(-0.5652, device='cuda:1')
final loss: -0.5650708675384521
Test:
Test: 0.4463412577980104
0.4463412577980104
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.82it/s]100%|██████████| 1/1 [00:00<00:00,  2.82it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.616064190864563
Epoch 1: -0.616064190864563
Mem used: -900MB
best_loss: tensor(-0.6186, device='cuda:1')
final loss: -0.6203303933143616
Test:
Test: 0.4590288315629742
0.4590288315629742
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.31it/s]100%|██████████| 1/1 [00:00<00:00,  4.30it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.5873245000839233
Epoch 1: -0.5873245000839233
Mem used: -900MB
best_loss: tensor(-0.5787, device='cuda:1')
final loss: -0.5784153342247009
Test:
Test: 0.4449081099308717
0.4449081099308717
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.90it/s]100%|██████████| 1/1 [00:00<00:00,  3.90it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5733749866485596
Epoch 1: -0.5733749866485596
Mem used: -900MB
best_loss: tensor(-0.5751, device='cuda:1')
final loss: -0.5744606852531433
Test:
Test: 0.4553195076715562
0.4553195076715562
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.42it/s]100%|██████████| 1/1 [00:00<00:00,  3.41it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.618665337562561
Epoch 1: -0.618665337562561
Mem used: -900MB
best_loss: tensor(-0.6219, device='cuda:1')
best_loss: tensor(-0.6238, device='cuda:1')
final loss: -0.6179391145706177
Test:
Test: 0.45106221547799696
0.45106221547799696
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.53it/s]100%|██████████| 1/1 [00:00<00:00,  4.52it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6132241487503052
Epoch 1: -0.6132241487503052
Mem used: -900MB
best_loss: tensor(-0.6047, device='cuda:1')
best_loss: tensor(-0.6063, device='cuda:1')
final loss: -0.6063807606697083
Test:
Test: 0.454897993592986
0.454897993592986
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.35it/s]100%|██████████| 1/1 [00:00<00:00,  2.35it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5853759050369263
Epoch 1: -0.5853759050369263
Mem used: -900MB
best_loss: tensor(-0.5856, device='cuda:1')
best_loss: tensor(-0.5860, device='cuda:1')
final loss: -0.5855672955513
Test:
Test: 0.4539706626201315
0.4539706626201315
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.28it/s]100%|██████████| 1/1 [00:00<00:00,  5.27it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.6053077578544617
Epoch 1: -0.6053077578544617
Mem used: -900MB
best_loss: tensor(-0.5971, device='cuda:1')
final loss: -0.6008517146110535
Test:
Test: 0.46455066599224415
0.46455066599224415
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.31it/s]100%|██████████| 1/1 [00:00<00:00,  3.31it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6020720601081848
Epoch 1: -0.6020720601081848
Mem used: -900MB
best_loss: tensor(-0.5956, device='cuda:1')
best_loss: tensor(-0.5968, device='cuda:1')
final loss: -0.5970051288604736
Test:
Test: 0.45274827179227783
0.45274827179227783
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.59it/s]100%|██████████| 1/1 [00:00<00:00,  3.59it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.5941256880760193
Epoch 1: -0.5941256880760193
Mem used: -900MB
best_loss: tensor(-0.5955, device='cuda:1')
best_loss: tensor(-0.5958, device='cuda:1')
final loss: -0.5943037867546082
Test:
Test: 0.4522424548979936
0.4522424548979936
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.91it/s]100%|██████████| 1/1 [00:00<00:00,  5.90it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5677321553230286
Epoch 1: -0.5677321553230286
Mem used: -900MB
best_loss: tensor(-0.5681, device='cuda:1')
final loss: -0.564651370048523
Test:
Test: 0.4500505816894284
0.4500505816894284
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.78it/s]100%|██████████| 1/1 [00:00<00:00,  4.78it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.616064190864563
Epoch 1: -0.616064190864563
Mem used: -900MB
best_loss: tensor(-0.6169, device='cuda:1')
best_loss: tensor(-0.6176, device='cuda:1')
final loss: -0.6206259727478027
Test:
Test: 0.4573006238408363
0.4573006238408363
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.79it/s]100%|██████████| 1/1 [00:00<00:00,  2.79it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.5873245000839233
Epoch 1: -0.5873245000839233
Mem used: -900MB
best_loss: tensor(-0.5798, device='cuda:1')
final loss: -0.578973114490509
Test:
Test: 0.44840667678300455
0.44840667678300455
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.61it/s]100%|██████████| 1/1 [00:00<00:00,  3.61it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5733749866485596
Epoch 1: -0.5733749866485596
Mem used: -900MB
best_loss: tensor(-0.5734, device='cuda:1')
best_loss: tensor(-0.5746, device='cuda:1')
final loss: -0.5758723616600037
Test:
Test: 0.4550665992244141
0.4550665992244141
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  2.98it/s]100%|██████████| 1/1 [00:00<00:00,  2.98it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.618665337562561
Epoch 1: -0.618665337562561
Mem used: -900MB
best_loss: tensor(-0.6234, device='cuda:1')
final loss: -0.6179167032241821
Test:
Test: 0.4479430112965773
0.4479430112965773
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.51it/s]100%|██████████| 1/1 [00:00<00:00,  3.50it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6132241487503052
Epoch 1: -0.6132241487503052
Mem used: -900MB
best_loss: tensor(-0.6063, device='cuda:1')
best_loss: tensor(-0.6068, device='cuda:1')
final loss: -0.6062360405921936
Test:
Test: 0.45435002529084473
0.45435002529084473
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.28it/s]100%|██████████| 1/1 [00:00<00:00,  3.28it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5853759050369263
Epoch 1: -0.5853759050369263
Mem used: -900MB
best_loss: tensor(-0.5861, device='cuda:1')
best_loss: tensor(-0.5861, device='cuda:1')
final loss: -0.5847268104553223
Test:
Test: 0.45173663800370933
0.45173663800370933
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.51it/s]100%|██████████| 1/1 [00:00<00:00,  5.50it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011685371399
Epoch 0, Loop Adj 0: -0.6053077578544617
Epoch 1: -0.6053077578544617
Mem used: -900MB
best_loss: tensor(-0.5976, device='cuda:1')
final loss: -0.5986795425415039
Test:
Test: 0.460588433653684
0.460588433653684
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.84it/s]100%|██████████| 1/1 [00:00<00:00,  4.72it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6020720601081848
Epoch 1: -0.6020720601081848
Mem used: -900MB
best_loss: tensor(-0.5961, device='cuda:1')
best_loss: tensor(-0.5966, device='cuda:1')
final loss: -0.5969343185424805
Test:
Test: 0.4516523351879953
0.4516523351879953
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.01it/s]100%|██████████| 1/1 [00:00<00:00,  4.01it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388945579529
Epoch 0, Loop Adj 0: -0.5941256880760193
Epoch 1: -0.5941256880760193
Mem used: -900MB
best_loss: tensor(-0.5965, device='cuda:1')
best_loss: tensor(-0.5966, device='cuda:1')
final loss: -0.5947129726409912
Test:
Test: 0.4513151239251391
0.4513151239251391
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.87it/s]100%|██████████| 1/1 [00:00<00:00,  3.86it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5677321553230286
Epoch 1: -0.5677321553230286
Mem used: -900MB
best_loss: tensor(-0.5651, device='cuda:1')
best_loss: tensor(-0.5655, device='cuda:1')
final loss: -0.5650107264518738
Test:
Test: 0.4460040465351543
0.4460040465351543
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.24it/s]100%|██████████| 1/1 [00:00<00:00,  4.23it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.616064190864563
Epoch 1: -0.616064190864563
Mem used: -900MB
best_loss: tensor(-0.6182, device='cuda:1')
final loss: -0.6205228567123413
Test:
Test: 0.4569212611701231
0.4569212611701231
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.70it/s]100%|██████████| 1/1 [00:00<00:00,  3.70it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.5873245000839233
Epoch 1: -0.5873245000839233
Mem used: -900MB
best_loss: tensor(-0.5784, device='cuda:1')
final loss: -0.5792679786682129
Test:
Test: 0.4456668352722981
0.4456668352722981
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.64it/s]100%|██████████| 1/1 [00:00<00:00,  3.64it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5733749866485596
Epoch 1: -0.5733749866485596
Mem used: -900MB
best_loss: tensor(-0.5743, device='cuda:1')
best_loss: tensor(-0.5745, device='cuda:1')
final loss: -0.5759028196334839
Test:
Test: 0.4546872365537009
0.4546872365537009
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.39it/s]100%|██████████| 2/2 [00:00<00:00,  4.54it/s]100%|██████████| 2/2 [00:00<00:00,  4.52it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.618665337562561
Epoch 1, Loop Feat 0: -0.618486225605011
Epoch 1, Loop Adj 0: -0.6236377954483032
Epoch 2: -0.6236377954483032
Mem used: -900MB
best_loss: tensor(-0.6244, device='cuda:1')
final loss: -0.6177946329116821
Test:
Test: 0.4500927330972854
0.4500927330972854
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.55it/s]100%|██████████| 2/2 [00:00<00:00,  4.63it/s]100%|██████████| 2/2 [00:00<00:00,  4.61it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6132241487503052
Epoch 1, Loop Feat 0: -0.6084112524986267
Epoch 1, Loop Adj 0: -0.6061565279960632
Epoch 2: -0.6061565279960632
Mem used: -900MB
best_loss: tensor(-0.6065, device='cuda:1')
final loss: -0.6053910255432129
Test:
Test: 0.45536165907941323
0.45536165907941323
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.60it/s]100%|██████████| 2/2 [00:00<00:00,  3.21it/s]100%|██████████| 2/2 [00:00<00:00,  3.26it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5853759050369263
Epoch 1, Loop Feat 0: -0.5828679800033569
Epoch 1, Loop Adj 0: -0.5851454734802246
Epoch 2: -0.5851454734802246
Mem used: -900MB
best_loss: tensor(-0.5862, device='cuda:1')
final loss: -0.5860326290130615
Test:
Test: 0.4554459618951273
0.4554459618951273
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.83it/s]100%|██████████| 2/2 [00:00<00:00,  3.19it/s]100%|██████████| 2/2 [00:00<00:00,  3.22it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.6053077578544617
Epoch 1, Loop Feat 0: -0.5968161821365356
Epoch 1, Loop Adj 0: -0.6053473353385925
Epoch 2: -0.6053473353385925
Mem used: -900MB
best_loss: tensor(-0.5982, device='cuda:1')
final loss: -0.5987659692764282
Test:
Test: 0.4634968807958186
0.4634968807958186
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.14it/s]100%|██████████| 2/2 [00:00<00:00,  3.69it/s]100%|██████████| 2/2 [00:00<00:00,  3.75it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6020720601081848
Epoch 1, Loop Feat 0: -0.593436598777771
Epoch 1, Loop Adj 0: -0.5980798006057739
Epoch 2: -0.5980798006057739
Mem used: -900MB
best_loss: tensor(-0.5959, device='cuda:1')
best_loss: tensor(-0.5966, device='cuda:1')
final loss: -0.5971016883850098
Test:
Test: 0.4516523351879953
0.4516523351879953
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.29it/s]100%|██████████| 2/2 [00:00<00:00,  3.38it/s]100%|██████████| 2/2 [00:00<00:00,  3.36it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.5941256880760193
Epoch 1, Loop Feat 0: -0.5923965573310852
Epoch 1, Loop Adj 0: -0.5923597812652588
Epoch 2: -0.5923597812652588
Mem used: -900MB
best_loss: tensor(-0.5967, device='cuda:1')
final loss: -0.5953934192657471
Test:
Test: 0.4538442083965604
0.4538442083965604
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.17it/s]100%|██████████| 2/2 [00:00<00:00,  4.80it/s]100%|██████████| 2/2 [00:00<00:00,  4.69it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5677321553230286
Epoch 1, Loop Feat 0: -0.5658949613571167
Epoch 1, Loop Adj 0: -0.563812255859375
Epoch 2: -0.563812255859375
Mem used: -900MB
best_loss: tensor(-0.5664, device='cuda:1')
final loss: -0.565147876739502
Test:
Test: 0.4478587084808633
0.4478587084808633
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.81it/s]100%|██████████| 2/2 [00:00<00:00,  3.35it/s]100%|██████████| 2/2 [00:00<00:00,  3.41it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.616064190864563
Epoch 1, Loop Feat 0: -0.619217574596405
Epoch 1, Loop Adj 0: -0.6204181909561157
Epoch 2: -0.6204181909561157
Mem used: -900MB
best_loss: tensor(-0.6176, device='cuda:1')
final loss: -0.6193225979804993
Test:
Test: 0.45801719777440564
0.45801719777440564
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.69it/s]100%|██████████| 2/2 [00:00<00:00,  4.78it/s]100%|██████████| 2/2 [00:00<00:00,  4.76it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.5873245000839233
Epoch 1, Loop Feat 0: -0.580527663230896
Epoch 1, Loop Adj 0: -0.5765384435653687
Epoch 2: -0.5765384435653687
Mem used: -900MB
best_loss: tensor(-0.5804, device='cuda:1')
final loss: -0.579664409160614
Test:
Test: 0.4484909795987186
0.4484909795987186
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.32it/s]100%|██████████| 2/2 [00:00<00:00,  3.10it/s]100%|██████████| 2/2 [00:00<00:00,  3.13it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5733749866485596
Epoch 1, Loop Feat 0: -0.5731074213981628
Epoch 1, Loop Adj 0: -0.5749830603599548
Epoch 2: -0.5749830603599548
Mem used: -900MB
best_loss: tensor(-0.5752, device='cuda:1')
final loss: -0.5761479735374451
Test:
Test: 0.4576799865115495
0.4576799865115495
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.97it/s]100%|██████████| 2/2 [00:00<00:00,  3.38it/s]100%|██████████| 2/2 [00:00<00:00,  3.55it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.618665337562561
Epoch 1, Loop Feat 0: -0.6163864135742188
Epoch 1, Loop Adj 0: -0.6219055652618408
Epoch 2: -0.6219055652618408
Mem used: -900MB
best_loss: tensor(-0.6280, device='cuda:1')
final loss: -0.6229968070983887
Test:
Test: 0.4512729725172821
0.4512729725172821
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.93it/s]100%|██████████| 2/2 [00:00<00:00,  4.82it/s]100%|██████████| 2/2 [00:00<00:00,  4.66it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6132241487503052
Epoch 1, Loop Feat 0: -0.6063365936279297
Epoch 1, Loop Adj 0: -0.6038958430290222
Epoch 2: -0.6038958430290222
Mem used: -900MB
best_loss: tensor(-0.6116, device='cuda:1')
final loss: -0.6116657853126526
Test:
Test: 0.4554038104872703
0.4554038104872703
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.90it/s]100%|██████████| 2/2 [00:00<00:00,  4.66it/s]100%|██████████| 2/2 [00:00<00:00,  4.52it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5853759050369263
Epoch 1, Loop Feat 0: -0.5812304019927979
Epoch 1, Loop Adj 0: -0.583142876625061
Epoch 2: -0.583142876625061
Mem used: -900MB
best_loss: tensor(-0.5905, device='cuda:1')
final loss: -0.5915892720222473
Test:
Test: 0.45708986680155117
0.45708986680155117
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.33it/s]100%|██████████| 2/2 [00:00<00:00,  4.53it/s]100%|██████████| 2/2 [00:00<00:00,  4.30it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.6053077578544617
Epoch 1, Loop Feat 0: -0.5949558019638062
Epoch 1, Loop Adj 0: -0.6030681729316711
Epoch 2: -0.6030681729316711
Mem used: -900MB
best_loss: tensor(-0.6025, device='cuda:1')
final loss: -0.6040829420089722
Test:
Test: 0.46265385263867814
0.46265385263867814
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.34it/s]100%|██████████| 2/2 [00:00<00:00,  4.04it/s]100%|██████████| 2/2 [00:00<00:00,  4.08it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6020720601081848
Epoch 1, Loop Feat 0: -0.5907715559005737
Epoch 1, Loop Adj 0: -0.5958408713340759
Epoch 2: -0.5958408713340759
Mem used: -900MB
best_loss: tensor(-0.6014, device='cuda:1')
final loss: -0.6040732264518738
Test:
Test: 0.45595177878941157
0.45595177878941157
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.14it/s]100%|██████████| 2/2 [00:00<00:00,  2.88it/s]100%|██████████| 2/2 [00:00<00:00,  3.01it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.5941256880760193
Epoch 1, Loop Feat 0: -0.5902934074401855
Epoch 1, Loop Adj 0: -0.5905591249465942
Epoch 2: -0.5905591249465942
Mem used: -900MB
best_loss: tensor(-0.6003, device='cuda:1')
final loss: -0.5998156070709229
Test:
Test: 0.45590962738155455
0.45590962738155455
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.23it/s]100%|██████████| 2/2 [00:00<00:00,  4.98it/s]100%|██████████| 2/2 [00:00<00:00,  4.85it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5677321553230286
Epoch 1, Loop Feat 0: -0.5635715126991272
Epoch 1, Loop Adj 0: -0.5615190267562866
Epoch 2: -0.5615190267562866
Mem used: -900MB
best_loss: tensor(-0.5727, device='cuda:1')
final loss: -0.5704814791679382
Test:
Test: 0.4500505816894284
0.4500505816894284
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.27it/s]100%|██████████| 2/2 [00:00<00:00,  4.18it/s]100%|██████████| 2/2 [00:00<00:00,  4.31it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.616064190864563
Epoch 1, Loop Feat 0: -0.6176415085792542
Epoch 1, Loop Adj 0: -0.6185787320137024
Epoch 2: -0.6185787320137024
Mem used: -900MB
best_loss: tensor(-0.6204, device='cuda:1')
final loss: -0.622279167175293
Test:
Test: 0.4610942505479683
0.4610942505479683
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.10it/s]100%|██████████| 2/2 [00:00<00:00,  3.19it/s]100%|██████████| 2/2 [00:00<00:00,  3.30it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.5873245000839233
Epoch 1, Loop Feat 0: -0.5785261392593384
Epoch 1, Loop Adj 0: -0.5747286081314087
Epoch 2: -0.5747286081314087
Mem used: -900MB
best_loss: tensor(-0.5857, device='cuda:1')
final loss: -0.5849063396453857
Test:
Test: 0.4496712190187152
0.4496712190187152
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.94it/s]100%|██████████| 2/2 [00:00<00:00,  3.05it/s]100%|██████████| 2/2 [00:00<00:00,  3.16it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5733749866485596
Epoch 1, Loop Feat 0: -0.5716651678085327
Epoch 1, Loop Adj 0: -0.5733583569526672
Epoch 2: -0.5733583569526672
Mem used: -900MB
best_loss: tensor(-0.5801, device='cuda:1')
final loss: -0.5794968008995056
Test:
Test: 0.454855842185129
0.454855842185129
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.24it/s]100%|██████████| 2/2 [00:00<00:00,  4.20it/s]100%|██████████| 2/2 [00:00<00:00,  4.33it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.618665337562561
Epoch 1, Loop Feat 0: -0.6197765469551086
Epoch 1, Loop Adj 0: -0.624591052532196
Epoch 2: -0.624591052532196
Mem used: -900MB
best_loss: tensor(-0.6231, device='cuda:1')
best_loss: tensor(-0.6233, device='cuda:1')
final loss: -0.6171298623085022
Test:
Test: 0.4478165570730062
0.4478165570730062
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.93it/s]100%|██████████| 2/2 [00:00<00:00,  5.48it/s]100%|██████████| 2/2 [00:00<00:00,  5.39it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6132241487503052
Epoch 1, Loop Feat 0: -0.6098567247390747
Epoch 1, Loop Adj 0: -0.6080336570739746
Epoch 2: -0.6080336570739746
Mem used: -900MB
best_loss: tensor(-0.6067, device='cuda:1')
best_loss: tensor(-0.6068, device='cuda:1')
final loss: -0.6062368154525757
Test:
Test: 0.4541814196594166
0.4541814196594166
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  6.04it/s]100%|██████████| 2/2 [00:00<00:00,  4.74it/s]100%|██████████| 2/2 [00:00<00:00,  4.89it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5853759050369263
Epoch 1, Loop Feat 0: -0.5841715931892395
Epoch 1, Loop Adj 0: -0.5864133834838867
Epoch 2: -0.5864133834838867
Mem used: -900MB
best_loss: tensor(-0.5858, device='cuda:1')
best_loss: tensor(-0.5861, device='cuda:1')
final loss: -0.5845666527748108
Test:
Test: 0.45139942674085315
0.45139942674085315
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.50it/s]100%|██████████| 2/2 [00:00<00:00,  2.83it/s]100%|██████████| 2/2 [00:00<00:00,  2.99it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011685371399
Epoch 0, Loop Adj 0: -0.6053077578544617
Epoch 1, Loop Feat 0: -0.5980829000473022
Epoch 1, Loop Adj 0: -0.6070597767829895
Epoch 2: -0.6070597767829895
Mem used: -900MB
best_loss: tensor(-0.5973, device='cuda:1')
final loss: -0.598002552986145
Test:
Test: 0.46079919069296915
0.46079919069296915
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.54it/s]100%|██████████| 2/2 [00:00<00:00,  3.34it/s]100%|██████████| 2/2 [00:00<00:00,  3.19it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6020720601081848
Epoch 1, Loop Feat 0: -0.5957136750221252
Epoch 1, Loop Adj 0: -0.6000871062278748
Epoch 2: -0.6000871062278748
Mem used: -900MB
best_loss: tensor(-0.5966, device='cuda:1')
final loss: -0.5970411896705627
Test:
Test: 0.45198954645085143
0.45198954645085143
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.94it/s]100%|██████████| 2/2 [00:00<00:00,  3.71it/s]100%|██████████| 2/2 [00:00<00:00,  3.57it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.5941256880760193
Epoch 1, Loop Feat 0: -0.5943578481674194
Epoch 1, Loop Adj 0: -0.5939422249794006
Epoch 2: -0.5939422249794006
Mem used: -900MB
best_loss: tensor(-0.5960, device='cuda:1')
best_loss: tensor(-0.5965, device='cuda:1')
final loss: -0.5944334864616394
Test:
Test: 0.4516523351879953
0.4516523351879953
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.62it/s]100%|██████████| 2/2 [00:00<00:00,  3.78it/s]100%|██████████| 2/2 [00:00<00:00,  3.75it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5677321553230286
Epoch 1, Loop Feat 0: -0.5681905150413513
Epoch 1, Loop Adj 0: -0.5659113526344299
Epoch 2: -0.5659113526344299
Mem used: -900MB
best_loss: tensor(-0.5649, device='cuda:1')
best_loss: tensor(-0.5653, device='cuda:1')
final loss: -0.5653948783874512
Test:
Test: 0.4458775923115832
0.4458775923115832
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  6.26it/s]100%|██████████| 2/2 [00:00<00:00,  5.86it/s]100%|██████████| 2/2 [00:00<00:00,  5.92it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.616064190864563
Epoch 1, Loop Feat 0: -0.6203657984733582
Epoch 1, Loop Adj 0: -0.6217500567436218
Epoch 2: -0.6217500567436218
Mem used: -900MB
best_loss: tensor(-0.6177, device='cuda:1')
final loss: -0.6214880347251892
Test:
Test: 0.45649974709155283
0.45649974709155283
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.89it/s]100%|██████████| 2/2 [00:00<00:00,  3.56it/s]100%|██████████| 2/2 [00:00<00:00,  3.44it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.5873245000839233
Epoch 1, Loop Feat 0: -0.5823768973350525
Epoch 1, Loop Adj 0: -0.578219473361969
Epoch 2: -0.578219473361969
Mem used: -900MB
best_loss: tensor(-0.5784, device='cuda:1')
best_loss: tensor(-0.5785, device='cuda:1')
final loss: -0.579217255115509
Test:
Test: 0.44541392682515596
0.44541392682515596
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.78it/s]100%|██████████| 2/2 [00:00<00:00,  3.73it/s]100%|██████████| 2/2 [00:00<00:00,  3.73it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5733749866485596
Epoch 1, Loop Feat 0: -0.5743273496627808
Epoch 1, Loop Adj 0: -0.5760354399681091
Epoch 2: -0.5760354399681091
Mem used: -900MB
best_loss: tensor(-0.5744, device='cuda:1')
final loss: -0.5762887001037598
Test:
Test: 0.4546872365537009
0.4546872365537009
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.27it/s]100%|██████████| 1/1 [00:00<00:00,  3.26it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.618665337562561
Epoch 1: -0.618665337562561
Mem used: -900MB
best_loss: tensor(-0.6225, device='cuda:1')
best_loss: tensor(-0.6234, device='cuda:1')
final loss: -0.6179444789886475
Test:
Test: 0.44836452537514754
0.44836452537514754
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.42it/s]100%|██████████| 1/1 [00:00<00:00,  4.42it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6132241487503052
Epoch 1: -0.6132241487503052
Mem used: -900MB
best_loss: tensor(-0.6048, device='cuda:1')
best_loss: tensor(-0.6067, device='cuda:1')
final loss: -0.6061592102050781
Test:
Test: 0.4545186309222728
0.4545186309222728
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.32it/s]100%|██████████| 1/1 [00:00<00:00,  3.32it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5853759050369263
Epoch 1: -0.5853759050369263
Mem used: -900MB
best_loss: tensor(-0.5852, device='cuda:1')
best_loss: tensor(-0.5863, device='cuda:1')
final loss: -0.5853328108787537
Test:
Test: 0.45211600067442254
0.45211600067442254
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.07it/s]100%|██████████| 1/1 [00:00<00:00,  4.06it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.6053077578544617
Epoch 1: -0.6053077578544617
Mem used: -900MB
best_loss: tensor(-0.5987, device='cuda:1')
final loss: -0.5990052819252014
Test:
Test: 0.46100994773225423
0.46100994773225423
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.98it/s]100%|██████████| 1/1 [00:00<00:00,  5.97it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6020720601081848
Epoch 1: -0.6020720601081848
Mem used: -900MB
best_loss: tensor(-0.5954, device='cuda:1')
best_loss: tensor(-0.5967, device='cuda:1')
final loss: -0.5968881845474243
Test:
Test: 0.4514837295565672
0.4514837295565672
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.48it/s]100%|██████████| 1/1 [00:00<00:00,  4.47it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.5941256880760193
Epoch 1: -0.5941256880760193
Mem used: -900MB
best_loss: tensor(-0.5948, device='cuda:1')
best_loss: tensor(-0.5963, device='cuda:1')
final loss: -0.5939170122146606
Test:
Test: 0.4519473950429944
0.4519473950429944
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.99it/s]100%|██████████| 1/1 [00:00<00:00,  4.98it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5677321553230286
Epoch 1: -0.5677321553230286
Mem used: -900MB
best_loss: tensor(-0.5646, device='cuda:1')
best_loss: tensor(-0.5653, device='cuda:1')
final loss: -0.5656532049179077
Test:
Test: 0.4462148035744394
0.4462148035744394
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.42it/s]100%|██████████| 1/1 [00:00<00:00,  3.42it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.616064190864563
Epoch 1: -0.616064190864563
Mem used: -900MB
best_loss: tensor(-0.6186, device='cuda:1')
final loss: -0.6201663017272949
Test:
Test: 0.4590288315629742
0.4590288315629742
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.36it/s]100%|██████████| 1/1 [00:00<00:00,  3.36it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.5873245000839233
Epoch 1: -0.5873245000839233
Mem used: -900MB
best_loss: tensor(-0.5787, device='cuda:1')
final loss: -0.5784153342247009
Test:
Test: 0.4449081099308717
0.4449081099308717
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.42it/s]100%|██████████| 1/1 [00:00<00:00,  3.42it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5733749866485596
Epoch 1: -0.5733749866485596
Mem used: -900MB
best_loss: tensor(-0.5751, device='cuda:1')
final loss: -0.5744606852531433
Test:
Test: 0.4553195076715562
0.4553195076715562
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.81it/s]100%|██████████| 1/1 [00:00<00:00,  4.80it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.618665337562561
Epoch 1: -0.618665337562561
Mem used: -900MB
best_loss: tensor(-0.6219, device='cuda:1')
best_loss: tensor(-0.6234, device='cuda:1')
final loss: -0.6179444789886475
Test:
Test: 0.44836452537514754
0.44836452537514754
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.02it/s]100%|██████████| 1/1 [00:00<00:00,  4.01it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6132241487503052
Epoch 1: -0.6132241487503052
Mem used: -900MB
best_loss: tensor(-0.6047, device='cuda:1')
best_loss: tensor(-0.6067, device='cuda:1')
final loss: -0.6061592102050781
Test:
Test: 0.4545186309222728
0.4545186309222728
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.17it/s]100%|██████████| 1/1 [00:00<00:00,  3.17it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5853759050369263
Epoch 1: -0.5853759050369263
Mem used: -900MB
best_loss: tensor(-0.5856, device='cuda:1')
best_loss: tensor(-0.5863, device='cuda:1')
final loss: -0.5853328704833984
Test:
Test: 0.45211600067442254
0.45211600067442254
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.45it/s]100%|██████████| 1/1 [00:00<00:00,  4.44it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.6053077578544617
Epoch 1: -0.6053077578544617
Mem used: -900MB
best_loss: tensor(-0.5971, device='cuda:1')
final loss: -0.6008517146110535
Test:
Test: 0.46455066599224415
0.46455066599224415
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  6.17it/s]100%|██████████| 1/1 [00:00<00:00,  6.16it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6020720601081848
Epoch 1: -0.6020720601081848
Mem used: -900MB
best_loss: tensor(-0.5956, device='cuda:1')
best_loss: tensor(-0.5967, device='cuda:1')
final loss: -0.5968881845474243
Test:
Test: 0.4514837295565672
0.4514837295565672
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.16it/s]100%|██████████| 1/1 [00:00<00:00,  4.15it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.5941256880760193
Epoch 1: -0.5941256880760193
Mem used: -900MB
best_loss: tensor(-0.5955, device='cuda:1')
best_loss: tensor(-0.5963, device='cuda:1')
final loss: -0.5939170122146606
Test:
Test: 0.4519473950429944
0.4519473950429944
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.75it/s]100%|██████████| 1/1 [00:00<00:00,  3.75it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5677321553230286
Epoch 1: -0.5677321553230286
Mem used: -900MB
best_loss: tensor(-0.5681, device='cuda:1')
final loss: -0.564651370048523
Test:
Test: 0.4500505816894284
0.4500505816894284
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.69it/s]100%|██████████| 1/1 [00:00<00:00,  4.68it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.616064190864563
Epoch 1: -0.616064190864563
Mem used: -900MB
best_loss: tensor(-0.6169, device='cuda:1')
best_loss: tensor(-0.6169, device='cuda:1')
final loss: -0.6205690503120422
Test:
Test: 0.4560360816051256
0.4560360816051256
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.14it/s]100%|██████████| 1/1 [00:00<00:00,  4.13it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.5873245000839233
Epoch 1: -0.5873245000839233
Mem used: -900MB
best_loss: tensor(-0.5798, device='cuda:1')
final loss: -0.578973114490509
Test:
Test: 0.44840667678300455
0.44840667678300455
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.08it/s]100%|██████████| 1/1 [00:00<00:00,  4.08it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5733749866485596
Epoch 1: -0.5733749866485596
Mem used: -900MB
best_loss: tensor(-0.5734, device='cuda:1')
best_loss: tensor(-0.5749, device='cuda:1')
final loss: -0.5759196281433105
Test:
Test: 0.4550244478165571
0.4550244478165571
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.78it/s]100%|██████████| 1/1 [00:00<00:00,  4.77it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.618665337562561
Epoch 1: -0.618665337562561
Mem used: -900MB
best_loss: tensor(-0.6234, device='cuda:1')
best_loss: tensor(-0.6234, device='cuda:1')
final loss: -0.6173851490020752
Test:
Test: 0.4475636486258641
0.4475636486258641
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.88it/s]100%|██████████| 1/1 [00:00<00:00,  3.87it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6132241487503052
Epoch 1: -0.6132241487503052
Mem used: -900MB
best_loss: tensor(-0.6063, device='cuda:1')
best_loss: tensor(-0.6068, device='cuda:1')
final loss: -0.6061744093894958
Test:
Test: 0.4542657224751307
0.4542657224751307
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.53it/s]100%|██████████| 1/1 [00:00<00:00,  4.52it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5853759050369263
Epoch 1: -0.5853759050369263
Mem used: -900MB
best_loss: tensor(-0.5861, device='cuda:1')
best_loss: tensor(-0.5862, device='cuda:1')
final loss: -0.584815502166748
Test:
Test: 0.45177878941156635
0.45177878941156635
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  4.52it/s]100%|██████████| 1/1 [00:00<00:00,  4.52it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011685371399
Epoch 0, Loop Adj 0: -0.6053077578544617
Epoch 1: -0.6053077578544617
Mem used: -900MB
best_loss: tensor(-0.5976, device='cuda:1')
final loss: -0.5986795425415039
Test:
Test: 0.460588433653684
0.460588433653684
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.51it/s]100%|██████████| 1/1 [00:00<00:00,  3.51it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6020720601081848
Epoch 1: -0.6020720601081848
Mem used: -900MB
best_loss: tensor(-0.5961, device='cuda:1')
final loss: -0.5970257520675659
Test:
Test: 0.4513151239251391
0.4513151239251391
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.58it/s]100%|██████████| 1/1 [00:00<00:00,  3.58it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.5941256880760193
Epoch 1: -0.5941256880760193
Mem used: -900MB
best_loss: tensor(-0.5965, device='cuda:1')
best_loss: tensor(-0.5966, device='cuda:1')
final loss: -0.5945377349853516
Test:
Test: 0.4513151239251391
0.4513151239251391
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  5.12it/s]100%|██████████| 1/1 [00:00<00:00,  5.11it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5677321553230286
Epoch 1: -0.5677321553230286
Mem used: -900MB
best_loss: tensor(-0.5651, device='cuda:1')
best_loss: tensor(-0.5654, device='cuda:1')
final loss: -0.5648462176322937
Test:
Test: 0.4459618951272972
0.4459618951272972
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.60it/s]100%|██████████| 1/1 [00:00<00:00,  3.60it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.616064190864563
Epoch 1: -0.616064190864563
Mem used: -900MB
best_loss: tensor(-0.6182, device='cuda:1')
final loss: -0.6205228567123413
Test:
Test: 0.4569212611701231
0.4569212611701231
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.28it/s]100%|██████████| 1/1 [00:00<00:00,  3.28it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.5873245000839233
Epoch 1: -0.5873245000839233
Mem used: -900MB
best_loss: tensor(-0.5785, device='cuda:1')
final loss: -0.5790691375732422
Test:
Test: 0.44575113808801214
0.44575113808801214
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=5, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/1 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
100%|██████████| 1/1 [00:00<00:00,  3.76it/s]100%|██████████| 1/1 [00:00<00:00,  3.75it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5733749866485596
Epoch 1: -0.5733749866485596
Mem used: -900MB
best_loss: tensor(-0.5743, device='cuda:1')
best_loss: tensor(-0.5744, device='cuda:1')
final loss: -0.5758461952209473
Test:
Test: 0.4546872365537009
0.4546872365537009
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.98it/s]100%|██████████| 2/2 [00:00<00:00,  3.51it/s]100%|██████████| 2/2 [00:00<00:00,  3.42it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.618665337562561
Epoch 1, Loop Feat 0: -0.6194968819618225
Epoch 1, Loop Adj 0: -0.6244016885757446
Epoch 2: -0.6244016885757446
Mem used: -900MB
best_loss: tensor(-0.6242, device='cuda:1')
final loss: -0.6174253225326538
Test:
Test: 0.45161018378013823
0.45161018378013823
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.95it/s]100%|██████████| 2/2 [00:00<00:00,  4.62it/s]100%|██████████| 2/2 [00:00<00:00,  4.50it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6132241487503052
Epoch 1, Loop Feat 0: -0.6096013784408569
Epoch 1, Loop Adj 0: -0.607648491859436
Epoch 2: -0.607648491859436
Mem used: -900MB
best_loss: tensor(-0.6067, device='cuda:1')
final loss: -0.6063289046287537
Test:
Test: 0.45595177878941157
0.45595177878941157
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.27it/s]100%|██████████| 2/2 [00:00<00:00,  4.42it/s]100%|██████████| 2/2 [00:00<00:00,  4.40it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5853759050369263
Epoch 1, Loop Feat 0: -0.5838968753814697
Epoch 1, Loop Adj 0: -0.586184561252594
Epoch 2: -0.586184561252594
Mem used: -900MB
best_loss: tensor(-0.5855, device='cuda:1')
best_loss: tensor(-0.5862, device='cuda:1')
final loss: -0.585498571395874
Test:
Test: 0.45135727533299613
0.45135727533299613
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.44it/s]100%|██████████| 2/2 [00:00<00:00,  3.70it/s]100%|██████████| 2/2 [00:00<00:00,  3.79it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.6053077578544617
Epoch 1, Loop Feat 0: -0.5978391766548157
Epoch 1, Loop Adj 0: -0.606702446937561
Epoch 2: -0.606702446937561
Mem used: -900MB
best_loss: tensor(-0.5968, device='cuda:1')
final loss: -0.5986563563346863
Test:
Test: 0.46412915191367393
0.46412915191367393
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.36it/s]100%|██████████| 2/2 [00:00<00:00,  3.56it/s]100%|██████████| 2/2 [00:00<00:00,  3.53it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6020720601081848
Epoch 1, Loop Feat 0: -0.5952524542808533
Epoch 1, Loop Adj 0: -0.5996696949005127
Epoch 2: -0.5996696949005127
Mem used: -900MB
best_loss: tensor(-0.5958, device='cuda:1')
best_loss: tensor(-0.5962, device='cuda:1')
final loss: -0.5973289608955383
Test:
Test: 0.45102006407013995
0.45102006407013995
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.06it/s]100%|██████████| 2/2 [00:00<00:00,  2.44it/s]100%|██████████| 2/2 [00:00<00:00,  2.52it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.5941256880760193
Epoch 1, Loop Feat 0: -0.5939579010009766
Epoch 1, Loop Adj 0: -0.5936270356178284
Epoch 2: -0.5936270356178284
Mem used: -900MB
best_loss: tensor(-0.5974, device='cuda:1')
final loss: -0.5945807099342346
Test:
Test: 0.4531697858708481
0.4531697858708481
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.26it/s]100%|██████████| 2/2 [00:00<00:00,  4.57it/s]100%|██████████| 2/2 [00:00<00:00,  4.52it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5677321553230286
Epoch 1, Loop Feat 0: -0.5677167177200317
Epoch 1, Loop Adj 0: -0.5654776692390442
Epoch 2: -0.5654776692390442
Mem used: -900MB
best_loss: tensor(-0.5659, device='cuda:1')
best_loss: tensor(-0.5660, device='cuda:1')
final loss: -0.5651191473007202
Test:
Test: 0.445582532456584
0.445582532456584
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.16it/s]100%|██████████| 2/2 [00:00<00:00,  4.01it/s]100%|██████████| 2/2 [00:00<00:00,  4.03it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.616064190864563
Epoch 1, Loop Feat 0: -0.6201191544532776
Epoch 1, Loop Adj 0: -0.6214717030525208
Epoch 2: -0.6214717030525208
Mem used: -900MB
best_loss: tensor(-0.6172, device='cuda:1')
final loss: -0.6189668774604797
Test:
Test: 0.4577221379194065
0.4577221379194065
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.02it/s]100%|██████████| 2/2 [00:00<00:00,  4.10it/s]100%|██████████| 2/2 [00:00<00:00,  4.21it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.5873245000839233
Epoch 1, Loop Feat 0: -0.5820241570472717
Epoch 1, Loop Adj 0: -0.5778800845146179
Epoch 2: -0.5778800845146179
Mem used: -900MB
best_loss: tensor(-0.5796, device='cuda:1')
final loss: -0.5795648694038391
Test:
Test: 0.4483223739672905
0.4483223739672905
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 511
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.29it/s]100%|██████████| 2/2 [00:00<00:00,  2.99it/s]100%|██████████| 2/2 [00:00<00:00,  3.03it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5733749866485596
Epoch 1, Loop Feat 0: -0.574054479598999
Epoch 1, Loop Adj 0: -0.575840413570404
Epoch 2: -0.575840413570404
Mem used: -900MB
best_loss: tensor(-0.5747, device='cuda:1')
best_loss: tensor(-0.5748, device='cuda:1')
final loss: -0.5753947496414185
Test:
Test: 0.4545186309222728
0.4545186309222728
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.18it/s]100%|██████████| 2/2 [00:00<00:00,  2.85it/s]100%|██████████| 2/2 [00:00<00:00,  2.99it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.618665337562561
Epoch 1, Loop Feat 0: -0.6194968819618225
Epoch 1, Loop Adj 0: -0.6244016885757446
Epoch 2: -0.6244016885757446
Mem used: -900MB
best_loss: tensor(-0.6276, device='cuda:1')
final loss: -0.621332049369812
Test:
Test: 0.45249536334513574
0.45249536334513574
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.84it/s]100%|██████████| 2/2 [00:00<00:00,  2.65it/s]100%|██████████| 2/2 [00:00<00:00,  2.67it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6132241487503052
Epoch 1, Loop Feat 0: -0.6096013784408569
Epoch 1, Loop Adj 0: -0.607648491859436
Epoch 2: -0.607648491859436
Mem used: -900MB
best_loss: tensor(-0.6116, device='cuda:1')
final loss: -0.6122629046440125
Test:
Test: 0.45557241611869836
0.45557241611869836
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.46it/s]100%|██████████| 2/2 [00:01<00:00,  1.82it/s]100%|██████████| 2/2 [00:01<00:00,  1.96it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5853759050369263
Epoch 1, Loop Feat 0: -0.5838968753814697
Epoch 1, Loop Adj 0: -0.586184561252594
Epoch 2: -0.586184561252594
Mem used: -900MB
best_loss: tensor(-0.5894, device='cuda:1')
final loss: -0.589311957359314
Test:
Test: 0.4569634125779801
0.4569634125779801
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.38it/s]100%|██████████| 2/2 [00:00<00:00,  4.00it/s]100%|██████████| 2/2 [00:00<00:00,  4.05it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.6053077578544617
Epoch 1, Loop Feat 0: -0.5978391766548157
Epoch 1, Loop Adj 0: -0.606702446937561
Epoch 2: -0.606702446937561
Mem used: -900MB
best_loss: tensor(-0.6007, device='cuda:1')
final loss: -0.6028976440429688
Test:
Test: 0.4634968807958186
0.4634968807958186
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.47it/s]100%|██████████| 2/2 [00:00<00:00,  3.80it/s]100%|██████████| 2/2 [00:00<00:00,  3.88it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6020720601081848
Epoch 1, Loop Feat 0: -0.5952524542808533
Epoch 1, Loop Adj 0: -0.5996696949005127
Epoch 2: -0.5996696949005127
Mem used: -900MB
best_loss: tensor(-0.6006, device='cuda:1')
final loss: -0.6034862399101257
Test:
Test: 0.4564575956836958
0.4564575956836958
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.92it/s]100%|██████████| 2/2 [00:00<00:00,  3.52it/s]100%|██████████| 2/2 [00:00<00:00,  3.41it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.5941256880760193
Epoch 1, Loop Feat 0: -0.5939579010009766
Epoch 1, Loop Adj 0: -0.5936270356178284
Epoch 2: -0.5936270356178284
Mem used: -900MB
best_loss: tensor(-0.6004, device='cuda:1')
final loss: -0.6004441976547241
Test:
Test: 0.4543078738829877
0.4543078738829877
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.66it/s]100%|██████████| 2/2 [00:00<00:00,  2.98it/s]100%|██████████| 2/2 [00:00<00:00,  3.07it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5677321553230286
Epoch 1, Loop Feat 0: -0.5677167177200317
Epoch 1, Loop Adj 0: -0.5654776692390442
Epoch 2: -0.5654776692390442
Mem used: -900MB
best_loss: tensor(-0.5723, device='cuda:1')
final loss: -0.5707264542579651
Test:
Test: 0.449207553532288
0.449207553532288
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.24it/s]100%|██████████| 2/2 [00:00<00:00,  3.13it/s]100%|██████████| 2/2 [00:00<00:00,  3.14it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.616064190864563
Epoch 1, Loop Feat 0: -0.6201191544532776
Epoch 1, Loop Adj 0: -0.6214717030525208
Epoch 2: -0.6214717030525208
Mem used: -900MB
best_loss: tensor(-0.6198, device='cuda:1')
final loss: -0.6219948530197144
Test:
Test: 0.4584808632608329
0.4584808632608329
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.61it/s]100%|██████████| 2/2 [00:00<00:00,  3.21it/s]100%|██████████| 2/2 [00:00<00:00,  3.26it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.5873245000839233
Epoch 1, Loop Feat 0: -0.5820241570472717
Epoch 1, Loop Adj 0: -0.5778800845146179
Epoch 2: -0.5778800845146179
Mem used: -900MB
best_loss: tensor(-0.5846, device='cuda:1')
final loss: -0.5852641463279724
Test:
Test: 0.4501770359129995
0.4501770359129995
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 2557
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.20it/s]100%|██████████| 2/2 [00:00<00:00,  4.43it/s]100%|██████████| 2/2 [00:00<00:00,  4.53it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5733749866485596
Epoch 1, Loop Feat 0: -0.574054479598999
Epoch 1, Loop Adj 0: -0.575840413570404
Epoch 2: -0.575840413570404
Mem used: -900MB
best_loss: tensor(-0.5791, device='cuda:1')
final loss: -0.5792468786239624
Test:
Test: 0.454855842185129
0.454855842185129
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4077676746317051, 0.39058566382389104, 0.348785054420509]
flatten test: 0.37854279430345195
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.62it/s]100%|██████████| 2/2 [00:00<00:00,  3.80it/s]100%|██████████| 2/2 [00:00<00:00,  3.99it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6234631538391113
Epoch 0, Loop Adj 0: -0.618665337562561
Epoch 1, Loop Feat 0: -0.6197972893714905
Epoch 1, Loop Adj 0: -0.6246045827865601
Epoch 2: -0.6246045827865601
Mem used: -900MB
best_loss: tensor(-0.6231, device='cuda:1')
best_loss: tensor(-0.6234, device='cuda:1')
final loss: -0.6173192262649536
Test:
Test: 0.4478165570730062
0.4478165570730062
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4228871502079368, 0.3991725376163619, 0.36989486245705]
flatten test: 0.3933223104400318
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.97it/s]100%|██████████| 2/2 [00:00<00:00,  3.96it/s]100%|██████████| 2/2 [00:00<00:00,  4.08it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.6066194176673889
Epoch 0, Loop Adj 0: -0.6132241487503052
Epoch 1, Loop Feat 0: -0.609876275062561
Epoch 1, Loop Adj 0: -0.6080647110939026
Epoch 2: -0.6080647110939026
Mem used: -900MB
best_loss: tensor(-0.6066, device='cuda:1')
best_loss: tensor(-0.6068, device='cuda:1')
final loss: -0.6062033772468567
Test:
Test: 0.4541814196594166
0.4541814196594166
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42190033128920845, 0.4055346304716926, 0.3767668662428245]
flatten test: 0.39825141555787796
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.71it/s]100%|██████████| 2/2 [00:00<00:00,  2.73it/s]100%|██████████| 2/2 [00:00<00:00,  2.92it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5858209133148193
Epoch 0, Loop Adj 0: -0.5853759050369263
Epoch 1, Loop Feat 0: -0.5841944217681885
Epoch 1, Loop Adj 0: -0.5864307284355164
Epoch 2: -0.5864307284355164
Mem used: -900MB
best_loss: tensor(-0.5857, device='cuda:1')
best_loss: tensor(-0.5861, device='cuda:1')
final loss: -0.5847744345664978
Test:
Test: 0.4515680323722812
0.4515680323722812
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.42863184605624866, 0.4032122714232743, 0.36847519700430015]
flatten test: 0.39566987474457566
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  5.32it/s]100%|██████████| 2/2 [00:00<00:00,  3.76it/s]100%|██████████| 2/2 [00:00<00:00,  3.93it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5972011089324951
Epoch 0, Loop Adj 0: -0.6053077578544617
Epoch 1, Loop Feat 0: -0.59809809923172
Epoch 1, Loop Adj 0: -0.6070877313613892
Epoch 2: -0.6070877313613892
Mem used: -900MB
best_loss: tensor(-0.5973, device='cuda:1')
final loss: -0.5982460975646973
Test:
Test: 0.46079919069296915
0.46079919069296915
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4177415944174244, 0.389317148377276, 0.34728308952122294]
flatten test: 0.37967368076245145
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.48it/s]100%|██████████| 2/2 [00:00<00:00,  2.49it/s]100%|██████████| 2/2 [00:00<00:00,  2.49it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5963166356086731
Epoch 0, Loop Adj 0: -0.6020720601081848
Epoch 1, Loop Feat 0: -0.5957515239715576
Epoch 1, Loop Adj 0: -0.6001214981079102
Epoch 2: -0.6001214981079102
Mem used: -900MB
best_loss: tensor(-0.5966, device='cuda:1')
final loss: -0.597041130065918
Test:
Test: 0.45198954645085143
0.45198954645085143
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4139352928737577, 0.3781737280693195, 0.3578174186778594]
flatten test: 0.37837121153036235
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.24it/s]100%|██████████| 2/2 [00:00<00:00,  2.86it/s]100%|██████████| 2/2 [00:00<00:00,  2.91it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5961388349533081
Epoch 0, Loop Adj 0: -0.5941256880760193
Epoch 1, Loop Feat 0: -0.5943901538848877
Epoch 1, Loop Adj 0: -0.593964695930481
Epoch 2: -0.593964695930481
Mem used: -900MB
best_loss: tensor(-0.5960, device='cuda:1')
best_loss: tensor(-0.5964, device='cuda:1')
final loss: -0.5942232012748718
Test:
Test: 0.4512729725172821
0.4512729725172821
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.38662155494466766, 0.3525302004254406, 0.3214822130321174]
flatten test: 0.34830523015489245
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  3.06it/s]100%|██████████| 2/2 [00:00<00:00,  2.84it/s]100%|██████████| 2/2 [00:00<00:00,  2.87it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5650188326835632
Epoch 0, Loop Adj 0: -0.5677321553230286
Epoch 1, Loop Feat 0: -0.5682334899902344
Epoch 1, Loop Adj 0: -0.5659493207931519
Epoch 2: -0.5659493207931519
Mem used: -900MB
best_loss: tensor(-0.5649, device='cuda:1')
best_loss: tensor(-0.5654, device='cuda:1')
final loss: -0.5654544830322266
Test:
Test: 0.44579328949586916
0.44579328949586916
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4172481849580602, 0.3918346636482504, 0.35977203053309464]
flatten test: 0.3853047154065732
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.19it/s]100%|██████████| 2/2 [00:00<00:00,  2.97it/s]100%|██████████| 2/2 [00:00<00:00,  3.11it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.617710292339325
Epoch 0, Loop Adj 0: -0.616064190864563
Epoch 1, Loop Feat 0: -0.6203858852386475
Epoch 1, Loop Adj 0: -0.6217678189277649
Epoch 2: -0.6217678189277649
Mem used: -900MB
best_loss: tensor(-0.6177, device='cuda:1')
final loss: -0.6209222078323364
Test:
Test: 0.45649974709155283
0.45649974709155283
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.39610206527102276, 0.3689623543646689, 0.3560274057156966]
flatten test: 0.37006504546943486
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  2.87it/s]100%|██████████| 2/2 [00:00<00:00,  2.42it/s]100%|██████████| 2/2 [00:00<00:00,  2.48it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.57817143201828
Epoch 0, Loop Adj 0: -0.5873245000839233
Epoch 1, Loop Feat 0: -0.5824087858200073
Epoch 1, Loop Adj 0: -0.578253448009491
Epoch 2: -0.578253448009491
Mem used: -900MB
best_loss: tensor(-0.5785, device='cuda:1')
final loss: -0.5786519050598145
Test:
Test: 0.4463834092058675
0.4463834092058675
/home/yy/tta/GTrans/gtransform_adj.py:136: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  edge_index_id = (2*self.n - row-1)*row//2 + col - row -1 # // is important to get the correct result
/home/yy/tta/GTrans/gtransform_adj.py:341: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  + (n - row_idx) * ((n - row_idx) - 1) // 2
===========
Namespace(dataset='ogb-arxiv', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=5, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='ogb-arxiv', device=0, directed=False, display_step=100, dropout=0.0, epochs=10, gat_heads=2, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=5, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.0)
Train num nodes 17401 | target nodes 17401 | num classes 40 | num node feats 128
Val num nodes 41125 | target nodes 23724 | num classes 40 | num node feats 128
GCN(
  (layers): ModuleList(
    (0): GCNConv(128, 32)
    (1): GCNConv(32, 32)
    (2): GCNConv(32, 32)
    (3): GCNConv(32, 32)
    (4): GCNConv(32, 40)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.4087544935504335, 0.38158896196405223, 0.3565006275332798]
flatten test: 0.3780904397198521
using validation as test...
====learning on this graph===
n_perturbations: 25
  0%|          | 0/2 [00:00<?, ?it/s]/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
 50%|█████     | 1/2 [00:00<00:00,  4.21it/s]100%|██████████| 2/2 [00:00<00:00,  4.39it/s]100%|██████████| 2/2 [00:00<00:00,  4.36it/s]
/home/yy/miniconda3/envs/torch1121/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead
  warnings.warn(out)
Epoch 0, Loop Feat 0: -0.5740866661071777
Epoch 0, Loop Adj 0: -0.5733749866485596
Epoch 1, Loop Feat 0: -0.5743525624275208
Epoch 1, Loop Adj 0: -0.5760477781295776
Epoch 2: -0.5760477781295776
Mem used: -900MB
best_loss: tensor(-0.5744, device='cuda:1')
final loss: -0.576170802116394
Test:
Test: 0.4546029337379868
0.4546029337379868
