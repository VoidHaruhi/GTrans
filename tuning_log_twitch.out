===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.5937196262431264, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747876614645
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.50it/s]100%|██████████| 1/1 [00:00<00:00,  5.49it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.7652437090873718
Epoch 1: -0.7652437090873718
Mem used: 674MB
best_loss: tensor(-0.8230, device='cuda:1')
best_loss: tensor(-0.8253, device='cuda:1')
final loss: -0.8574569225311279
Test:
Test: 0.5446700002796016
0.5446700002796016
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
=== training GCN model ===
Epoch 0, training loss: 1.0119768381118774
Epoch 10, training loss: 0.6050400733947754
Epoch 20, training loss: 0.5690591931343079
Epoch 30, training loss: 0.5394620895385742
Epoch 40, training loss: 0.5112119317054749
Epoch 50, training loss: 0.48495346307754517
Epoch 60, training loss: 0.4625656306743622
Epoch 70, training loss: 0.44046902656555176
Epoch 80, training loss: 0.4217453598976135
Epoch 90, training loss: 0.40302637219429016
Epoch 100, training loss: 0.3872833847999573
Epoch 110, training loss: 0.36740028858184814
Epoch 120, training loss: 0.35321253538131714
Epoch 130, training loss: 0.34508422017097473
Epoch 140, training loss: 0.3290923237800598
Epoch 150, training loss: 0.31292638182640076
Epoch 160, training loss: 0.3012962341308594
Epoch 170, training loss: 0.29429930448532104
Epoch 180, training loss: 0.276679664850235
Epoch 190, training loss: 0.26776233315467834
=== early stopping at 199, acc_val = 0.6030244705363521 ===
Test accs: [0.6442839156648061, 0.6097034228988698, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987161352803
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.55it/s]100%|██████████| 1/1 [00:00<00:00,  3.55it/s]
Epoch 0, Loop Feat 0: -0.4205028712749481
Epoch 0, Loop Adj 0: -0.632632315158844
Epoch 1: -0.632632315158844
Mem used: 790MB
best_loss: tensor(-0.8530, device='cuda:1')
best_loss: tensor(-0.8545, device='cuda:1')
final loss: -0.8434630632400513
Test:
Test: 0.5845439603525013
0.5845439603525013
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
=== training GCN model ===
Epoch 0, training loss: 0.737730860710144
Epoch 10, training loss: 0.5814486742019653
Epoch 20, training loss: 0.5403404831886292
Epoch 30, training loss: 0.5010312795639038
Epoch 40, training loss: 0.4655964970588684
Epoch 50, training loss: 0.432874858379364
Epoch 60, training loss: 0.40601301193237305
Epoch 70, training loss: 0.38057464361190796
Epoch 80, training loss: 0.35417187213897705
Epoch 90, training loss: 0.33043286204338074
Epoch 100, training loss: 0.31550291180610657
Epoch 110, training loss: 0.300504207611084
Epoch 120, training loss: 0.27651527523994446
Epoch 130, training loss: 0.2593458890914917
Epoch 140, training loss: 0.2647721469402313
Epoch 150, training loss: 0.23828741908073425
Epoch 160, training loss: 0.2199070155620575
Epoch 170, training loss: 0.23061080276966095
Epoch 180, training loss: 0.21475926041603088
Epoch 190, training loss: 0.19767184555530548
=== early stopping at 199, acc_val = 0.6061801949331117 ===
Test accs: [0.6405996180406469, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804498361215
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  8.47it/s]100%|██████████| 1/1 [00:00<00:00,  8.43it/s]
Epoch 0, Loop Feat 0: -0.32333433628082275
Epoch 0, Loop Adj 0: -0.7123326659202576
Epoch 1: -0.7123326659202576
Mem used: 668MB
best_loss: tensor(-0.9136, device='cuda:1')
best_loss: tensor(-0.9141, device='cuda:1')
final loss: -0.8896616697311401
Test:
Test: 0.5989473319658276
0.5989473319658276
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
=== training GCN model ===
Epoch 0, training loss: 0.7484551072120667
Epoch 10, training loss: 0.5552268028259277
Epoch 20, training loss: 0.5130031704902649
Epoch 30, training loss: 0.47667279839515686
Epoch 40, training loss: 0.4437960386276245
Epoch 50, training loss: 0.4128834009170532
Epoch 60, training loss: 0.38436537981033325
Epoch 70, training loss: 0.35684365034103394
Epoch 80, training loss: 0.33763623237609863
Epoch 90, training loss: 0.30879437923431396
Epoch 100, training loss: 0.3062187731266022
Epoch 110, training loss: 0.2859269380569458
Epoch 120, training loss: 0.26168495416641235
Epoch 130, training loss: 0.24636270105838776
Epoch 140, training loss: 0.24993830919265747
Epoch 150, training loss: 0.23771190643310547
Epoch 160, training loss: 0.21710389852523804
Epoch 170, training loss: 0.20350167155265808
Epoch 180, training loss: 0.1914927214384079
Epoch 190, training loss: 0.20062094926834106
=== early stopping at 199, acc_val = 0.6083308629901606 ===
Test accs: [0.6280595883426363, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887516929199
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.68it/s]100%|██████████| 1/1 [00:00<00:00,  3.55it/s]
Epoch 0, Loop Feat 0: -0.40258023142814636
Epoch 0, Loop Adj 0: -0.6950430274009705
Epoch 1: -0.6950430274009705
Mem used: 1058MB
best_loss: tensor(-0.8972, device='cuda:1')
best_loss: tensor(-0.8974, device='cuda:1')
final loss: -0.8742220401763916
Test:
Test: 0.5967196543362386
0.5967196543362386
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
=== training GCN model ===
Epoch 0, training loss: 1.0808868408203125
Epoch 10, training loss: 0.5982497334480286
Epoch 20, training loss: 0.5654531717300415
Epoch 30, training loss: 0.5366921424865723
Epoch 40, training loss: 0.5073695778846741
Epoch 50, training loss: 0.47938063740730286
Epoch 60, training loss: 0.4528122544288635
Epoch 70, training loss: 0.4281795620918274
Epoch 80, training loss: 0.4124639630317688
Epoch 90, training loss: 0.3933424651622772
Epoch 100, training loss: 0.3690299391746521
Epoch 110, training loss: 0.3495018780231476
Epoch 120, training loss: 0.33255213499069214
Epoch 130, training loss: 0.32864150404930115
Epoch 140, training loss: 0.306292861700058
Epoch 150, training loss: 0.2889024317264557
Epoch 160, training loss: 0.27948620915412903
Epoch 170, training loss: 0.269466370344162
Epoch 180, training loss: 0.25098034739494324
Epoch 190, training loss: 0.24985271692276
=== early stopping at 199, acc_val = 0.6051906278833908 ===
Test accs: [0.641035360312008, 0.6205532218848335, 0.576750097652589, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168351136992
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 10.46it/s]
Epoch 0, Loop Feat 0: -0.3591355085372925
Epoch 0, Loop Adj 0: -0.6820432543754578
Epoch 1: -0.6820432543754578
Mem used: 720MB
best_loss: tensor(-0.8641, device='cuda:1')
best_loss: tensor(-0.8654, device='cuda:1')
final loss: -0.8690817952156067
Test:
Test: 0.5869312571012437
0.5869312571012437
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
=== training GCN model ===
Epoch 0, training loss: 0.9562666416168213
Epoch 10, training loss: 0.598611056804657
Epoch 20, training loss: 0.5717058181762695
Epoch 30, training loss: 0.5412198305130005
Epoch 40, training loss: 0.5094974040985107
Epoch 50, training loss: 0.47890475392341614
Epoch 60, training loss: 0.45164063572883606
Epoch 70, training loss: 0.4260926842689514
Epoch 80, training loss: 0.4033707082271576
Epoch 90, training loss: 0.3806859254837036
Epoch 100, training loss: 0.3696633577346802
Epoch 110, training loss: 0.35153236985206604
Epoch 120, training loss: 0.3252147138118744
Epoch 130, training loss: 0.30670180916786194
Epoch 140, training loss: 0.30019503831863403
Epoch 150, training loss: 0.2797749638557434
Epoch 160, training loss: 0.27495813369750977
Epoch 170, training loss: 0.2532792091369629
Epoch 180, training loss: 0.24568824470043182
Epoch 190, training loss: 0.24090726673603058
=== early stopping at 199, acc_val = 0.6073605979787351 ===
Test accs: [0.6404823243165879, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053128002002717
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.62it/s]100%|██████████| 1/1 [00:00<00:00,  6.60it/s]
Epoch 0, Loop Feat 0: -0.424431711435318
Epoch 0, Loop Adj 0: -0.7106456160545349
Epoch 1: -0.7106456160545349
Mem used: 668MB
best_loss: tensor(-0.8868, device='cuda:1')
best_loss: tensor(-0.8868, device='cuda:1')
final loss: -0.8813048005104065
Test:
Test: 0.5909874652722176
0.5909874652722176
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
=== training GCN model ===
Epoch 0, training loss: 0.7495272755622864
Epoch 10, training loss: 0.558996319770813
Epoch 20, training loss: 0.5166807174682617
Epoch 30, training loss: 0.4805479347705841
Epoch 40, training loss: 0.44740864634513855
Epoch 50, training loss: 0.41910165548324585
Epoch 60, training loss: 0.39530712366104126
Epoch 70, training loss: 0.36860978603363037
Epoch 80, training loss: 0.34535452723503113
Epoch 90, training loss: 0.3311731517314911
Epoch 100, training loss: 0.32560479640960693
Epoch 110, training loss: 0.2921140193939209
Epoch 120, training loss: 0.27461159229278564
Epoch 130, training loss: 0.2560756802558899
Epoch 140, training loss: 0.25844383239746094
Epoch 150, training loss: 0.2550612688064575
Epoch 160, training loss: 0.23614151775836945
Epoch 170, training loss: 0.21876247227191925
Epoch 180, training loss: 0.20512542128562927
Epoch 190, training loss: 0.1987949162721634
=== early stopping at 199, acc_val = 0.601258969490388 ===
Test accs: [0.6179835095534565, 0.6310910559022389, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974795940327603
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.40it/s]100%|██████████| 1/1 [00:00<00:00,  3.40it/s]
Epoch 0, Loop Feat 0: -0.26541149616241455
Epoch 0, Loop Adj 0: -0.6688743233680725
Epoch 1: -0.6688743233680725
Mem used: 794MB
best_loss: tensor(-0.8689, device='cuda:1')
best_loss: tensor(-0.8698, device='cuda:1')
final loss: -0.8604233860969543
Test:
Test: 0.6083104489002763
0.6083104489002763
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
=== training GCN model ===
Epoch 0, training loss: 1.086427927017212
Epoch 10, training loss: 0.6045979261398315
Epoch 20, training loss: 0.5787784457206726
Epoch 30, training loss: 0.555431604385376
Epoch 40, training loss: 0.5335279107093811
Epoch 50, training loss: 0.5117900967597961
Epoch 60, training loss: 0.4909440875053406
Epoch 70, training loss: 0.4706663191318512
Epoch 80, training loss: 0.4507414996623993
Epoch 90, training loss: 0.4323575794696808
Epoch 100, training loss: 0.41675031185150146
Epoch 110, training loss: 0.3994176387786865
Epoch 120, training loss: 0.38245126605033875
Epoch 130, training loss: 0.3678276836872101
Epoch 140, training loss: 0.35483965277671814
Epoch 150, training loss: 0.3388577401638031
Epoch 160, training loss: 0.32392871379852295
Epoch 170, training loss: 0.32779526710510254
Epoch 180, training loss: 0.3027236759662628
Epoch 190, training loss: 0.28661879897117615
=== early stopping at 199, acc_val = 0.603834004377035 ===
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483242720478
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.66it/s]100%|██████████| 1/1 [00:00<00:00,  5.64it/s]
Epoch 0, Loop Feat 0: -0.39677003026008606
Epoch 0, Loop Adj 0: -0.6800905466079712
Epoch 1: -0.6800905466079712
Mem used: 670MB
best_loss: tensor(-0.8500, device='cuda:1')
best_loss: tensor(-0.8512, device='cuda:1')
final loss: -0.8709011077880859
Test:
Test: 0.5747634269108859
0.5747634269108859
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
=== training GCN model ===
Epoch 0, training loss: 0.8089263439178467
Epoch 10, training loss: 0.5966920852661133
Epoch 20, training loss: 0.566054105758667
Epoch 30, training loss: 0.5374882221221924
Epoch 40, training loss: 0.5082086324691772
Epoch 50, training loss: 0.48021119832992554
Epoch 60, training loss: 0.4535278379917145
Epoch 70, training loss: 0.42741987109184265
Epoch 80, training loss: 0.40240153670310974
Epoch 90, training loss: 0.3812412619590759
Epoch 100, training loss: 0.36104685068130493
Epoch 110, training loss: 0.34388306736946106
Epoch 120, training loss: 0.32483968138694763
Epoch 130, training loss: 0.30519306659698486
Epoch 140, training loss: 0.2920304834842682
Epoch 150, training loss: 0.314800500869751
Epoch 160, training loss: 0.28865066170692444
Epoch 170, training loss: 0.26290932297706604
Epoch 180, training loss: 0.2446700930595398
Epoch 190, training loss: 0.2313329577445984
=== early stopping at 199, acc_val = 0.6047891772597523 ===
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890690973923
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.39it/s]100%|██████████| 1/1 [00:00<00:00,  4.38it/s]
Epoch 0, Loop Feat 0: -0.40677013993263245
Epoch 0, Loop Adj 0: -0.6982810497283936
Epoch 1: -0.6982810497283936
Mem used: 670MB
best_loss: tensor(-0.8810, device='cuda:1')
best_loss: tensor(-0.8817, device='cuda:1')
final loss: -0.8802503943443298
Test:
Test: 0.5874278278518722
0.5874278278518722
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
=== training GCN model ===
Epoch 0, training loss: 0.8476378917694092
Epoch 10, training loss: 0.593669056892395
Epoch 20, training loss: 0.5711191296577454
Epoch 30, training loss: 0.5443407297134399
Epoch 40, training loss: 0.5170890688896179
Epoch 50, training loss: 0.49174734950065613
Epoch 60, training loss: 0.46861428022384644
Epoch 70, training loss: 0.4438914656639099
Epoch 80, training loss: 0.42149871587753296
Epoch 90, training loss: 0.4064796566963196
Epoch 100, training loss: 0.38270100951194763
Epoch 110, training loss: 0.36393022537231445
Epoch 120, training loss: 0.3488064408302307
Epoch 130, training loss: 0.3583107888698578
Epoch 140, training loss: 0.33002451062202454
Epoch 150, training loss: 0.30775904655456543
Epoch 160, training loss: 0.29152870178222656
Epoch 170, training loss: 0.27890339493751526
Epoch 180, training loss: 0.2729150950908661
Epoch 190, training loss: 0.2647320628166199
=== early stopping at 199, acc_val = 0.6088467754952125 ===
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232557, 0.5836708161590052]
flatten test: 0.6034946216885545
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.43it/s]100%|██████████| 1/1 [00:00<00:00,  7.41it/s]
Epoch 0, Loop Feat 0: -0.4335947036743164
Epoch 0, Loop Adj 0: -0.7085269689559937
Epoch 1: -0.7085269689559937
Mem used: 798MB
best_loss: tensor(-0.8937, device='cuda:1')
best_loss: tensor(-0.8949, device='cuda:1')
final loss: -0.891099750995636
Test:
Test: 0.5918683689952391
0.5918683689952391
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.5937196763338406, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878748042945943
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.99it/s]100%|██████████| 1/1 [00:00<00:00,  4.97it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.7652435898780823
Epoch 1: -0.7652435898780823
Mem used: 728MB
best_loss: tensor(-0.8151, device='cuda:1')
best_loss: tensor(-0.8153, device='cuda:1')
final loss: -0.8488869071006775
Test:
Test: 0.5485362064933645
0.5485362064933645
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344159165859445, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987105909036
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.92it/s]100%|██████████| 1/1 [00:00<00:00,  4.90it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.6332309246063232
Epoch 1: -0.6332309246063232
Mem used: 674MB
best_loss: tensor(-0.8500, device='cuda:1')
best_loss: tensor(-0.8520, device='cuda:1')
final loss: -0.8355407118797302
Test:
Test: 0.5845300994237667
0.5845300994237667
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.556224183928322]
flatten test: 0.6065804276586151
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.84it/s]100%|██████████| 1/1 [00:00<00:00,  4.83it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.7130646705627441
Epoch 1: -0.7130646705627441
Mem used: -595MB
best_loss: tensor(-0.9115, device='cuda:1')
best_loss: tensor(-0.9121, device='cuda:1')
final loss: -0.8862855434417725
Test:
Test: 0.5977271730758966
0.5977271730758966
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163420955350138, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887461485433
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.19it/s]100%|██████████| 1/1 [00:00<00:00,  5.18it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.6978302001953125
Epoch 1: -0.6978302001953125
Mem used: 674MB
best_loss: tensor(-0.8936, device='cuda:1')
best_loss: tensor(-0.8955, device='cuda:1')
final loss: -0.8740726709365845
Test:
Test: 0.5956591542815892
0.5956591542815892
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205531717941192, 0.576750097652589, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168129361927
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.73it/s]100%|██████████| 1/1 [00:00<00:00,  6.70it/s]
Epoch 0, Loop Feat 0: -0.35880887508392334
Epoch 0, Loop Adj 0: -0.6793412566184998
Epoch 1: -0.6793412566184998
Mem used: 674MB
best_loss: tensor(-0.8609, device='cuda:1')
best_loss: tensor(-0.8626, device='cuda:1')
final loss: -0.866545557975769
Test:
Test: 0.5869765732034965
0.5869765732034965
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127835671419
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.77it/s]100%|██████████| 1/1 [00:00<00:00,  5.76it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.7100446224212646
Epoch 1: -0.7100446224212646
Mem used: 674MB
best_loss: tensor(-0.8835, device='cuda:1')
best_loss: tensor(-0.8863, device='cuda:1')
final loss: -0.8802830576896667
Test:
Test: 0.5930839208143014
0.5930839208143014
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310911059929533, 0.6278801467147008, 0.5383905009484999, 0.5426401818150064]
flatten test: 0.597479599577137
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.24it/s]100%|██████████| 1/1 [00:00<00:00,  3.23it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.669219970703125
Epoch 1: -0.669219970703125
Mem used: 802MB
best_loss: tensor(-0.8608, device='cuda:1')
best_loss: tensor(-0.8660, device='cuda:1')
final loss: -0.857987642288208
Test:
Test: 0.609137616701871
0.609137616701871
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483242720477
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.89it/s]100%|██████████| 1/1 [00:00<00:00,  5.61it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.6842021942138672
Epoch 1: -0.6842021942138672
Mem used: 798MB
best_loss: tensor(-0.8442, device='cuda:1')
best_loss: tensor(-0.8459, device='cuda:1')
final loss: -0.865644633769989
Test:
Test: 0.5732751841557431
0.5732751841557431
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890690973923
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.66it/s]100%|██████████| 1/1 [00:00<00:00,  5.35it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.7013939023017883
Epoch 1: -0.7013939023017883
Mem used: 736MB
best_loss: tensor(-0.8742, device='cuda:1')
best_loss: tensor(-0.8783, device='cuda:1')
final loss: -0.8787458539009094
Test:
Test: 0.5870537813566775
0.5870537813566775
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232557, 0.5836708161590052]
flatten test: 0.603494616144178
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.78it/s]100%|██████████| 1/1 [00:00<00:00,  6.76it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.7123950123786926
Epoch 1: -0.7123950123786926
Mem used: 687MB
best_loss: tensor(-0.8881, device='cuda:1')
best_loss: tensor(-0.8900, device='cuda:1')
final loss: -0.888187050819397
Test:
Test: 0.5921350230798363
0.5921350230798363
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.5937196262431264, 0.6002883018849671, 0.5401741024379962, 0.5824575153695682]
flatten test: 0.5878747765727113
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.34it/s]100%|██████████| 1/1 [00:00<00:00,  3.82it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.7652435898780823
Epoch 1: -0.7652435898780823
Mem used: 798MB
best_loss: tensor(-0.8259, device='cuda:1')
best_loss: tensor(-0.8268, device='cuda:1')
final loss: -0.8593544960021973
Test:
Test: 0.5436135909861547
0.5436135909861547
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344159165859445, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987105909036
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.26it/s]100%|██████████| 1/1 [00:00<00:00,  5.81it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.6332309246063232
Epoch 1: -0.6332309246063232
Mem used: 798MB
best_loss: tensor(-0.8558, device='cuda:1')
best_loss: tensor(-0.8567, device='cuda:1')
final loss: -0.8408397436141968
Test:
Test: 0.5858549500275789
0.5858549500275789
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405996180406469, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804332029918
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.41it/s]100%|██████████| 1/1 [00:00<00:00,  3.40it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.7130646705627441
Epoch 1: -0.7130646705627441
Mem used: 674MB
best_loss: tensor(-0.9156, device='cuda:1')
best_loss: tensor(-0.9162, device='cuda:1')
final loss: -0.8920813202857971
Test:
Test: 0.5981687369889964
0.5981687369889964
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280594765278374, 0.6163420955350138, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887461485433
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.70it/s]100%|██████████| 1/1 [00:00<00:00,  4.68it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.6978302001953125
Epoch 1: -0.6978302001953125
Mem used: -595MB
best_loss: tensor(-0.8985, device='cuda:1')
best_loss: tensor(-0.8990, device='cuda:1')
final loss: -0.8751742839813232
Test:
Test: 0.5972981197431733
0.5972981197431733
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205532218848335, 0.576750097652589, 0.5493891660226236, 0.5826381732918821]
flatten test: 0.5907168129361927
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.03it/s]100%|██████████| 1/1 [00:00<00:00,  6.01it/s]
Epoch 0, Loop Feat 0: -0.35880887508392334
Epoch 0, Loop Adj 0: -0.6793412566184998
Epoch 1: -0.6793412566184998
Mem used: 674MB
best_loss: tensor(-0.8630, device='cuda:1')
best_loss: tensor(-0.8632, device='cuda:1')
final loss: -0.8698394298553467
Test:
Test: 0.587716524387609
0.587716524387609
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127724783887
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.53it/s]100%|██████████| 1/1 [00:00<00:00,  6.50it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.7100445628166199
Epoch 1: -0.7100445628166199
Mem used: 674MB
best_loss: tensor(-0.8885, device='cuda:1')
final loss: -0.884240984916687
Test:
Test: 0.5920500702816605
0.5920500702816605
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310910559022389, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974795884883838
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  8.27it/s]100%|██████████| 1/1 [00:00<00:00,  8.25it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.669219970703125
Epoch 1: -0.669219970703125
Mem used: 674MB
best_loss: tensor(-0.8700, device='cuda:1')
final loss: -0.8612125515937805
Test:
Test: 0.6076098961153178
0.6076098961153178
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483242720478
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.80it/s]100%|██████████| 1/1 [00:00<00:00,  3.79it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.6842021942138672
Epoch 1: -0.6842021942138672
Mem used: 746MB
best_loss: tensor(-0.8507, device='cuda:1')
best_loss: tensor(-0.8515, device='cuda:1')
final loss: -0.8725312352180481
Test:
Test: 0.573476703790126
0.573476703790126
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875724, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890801861456
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.85it/s]100%|██████████| 1/1 [00:00<00:00,  3.83it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.7013940215110779
Epoch 1: -0.7013940215110779
Mem used: 778MB
best_loss: tensor(-0.8801, device='cuda:1')
best_loss: tensor(-0.8804, device='cuda:1')
final loss: -0.883304238319397
Test:
Test: 0.5884723223068652
0.5884723223068652
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483719525047425, 0.5836708161590052]
flatten test: 0.6034946050554247
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.82it/s]100%|██████████| 1/1 [00:00<00:00,  3.81it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.7123950123786926
Epoch 1: -0.7123950123786926
Mem used: 762MB
best_loss: tensor(-0.8953, device='cuda:1')
best_loss: tensor(-0.8959, device='cuda:1')
final loss: -0.8962604403495789
Test:
Test: 0.592507044052494
0.592507044052494
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.5937196763338406, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747821170879
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.92it/s]100%|██████████| 2/2 [00:00<00:00,  5.04it/s]100%|██████████| 2/2 [00:00<00:00,  4.83it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.765243649482727
Epoch 1, Loop Feat 0: -0.7576907873153687
Epoch 1, Loop Adj 0: -0.7304244041442871
Epoch 2: -0.7304244041442871
Mem used: 674MB
best_loss: tensor(-0.7589, device='cuda:1')
best_loss: tensor(-0.7593, device='cuda:1')
final loss: -0.7909373044967651
Test:
Test: 0.522120215318606
0.522120215318606
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987216796569
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.59it/s]100%|██████████| 2/2 [00:00<00:00,  4.47it/s]100%|██████████| 2/2 [00:00<00:00,  4.48it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.6332309246063232
Epoch 1, Loop Feat 0: -0.6580675840377808
Epoch 1, Loop Adj 0: -0.7290235161781311
Epoch 2: -0.7290235161781311
Mem used: 674MB
best_loss: tensor(-0.8597, device='cuda:1')
best_loss: tensor(-0.8623, device='cuda:1')
final loss: -0.8565691113471985
Test:
Test: 0.5794223273269838
0.5794223273269838
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804387473683
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.71it/s]100%|██████████| 2/2 [00:00<00:00,  7.29it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.7130646705627441
Epoch 1, Loop Feat 0: -0.7135553359985352
Epoch 1, Loop Adj 0: -0.7816724181175232
Epoch 2: -0.7816724181175232
Mem used: 794MB
best_loss: tensor(-0.9075, device='cuda:1')
best_loss: tensor(-0.9076, device='cuda:1')
final loss: -0.9072628021240234
Test:
Test: 0.5920380760109503
0.5920380760109503
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887461485433
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.79it/s]100%|██████████| 2/2 [00:00<00:00,  7.10it/s]100%|██████████| 2/2 [00:00<00:00,  7.18it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.6978302001953125
Epoch 1, Loop Feat 0: -0.6889728903770447
Epoch 1, Loop Adj 0: -0.7666993141174316
Epoch 2: -0.7666993141174316
Mem used: 784MB
best_loss: tensor(-0.9055, device='cuda:1')
best_loss: tensor(-0.9059, device='cuda:1')
final loss: -0.894012451171875
Test:
Test: 0.5919590806320012
0.5919590806320012
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205531717941191, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168184805693
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.10it/s]100%|██████████| 2/2 [00:00<00:00,  4.49it/s]100%|██████████| 2/2 [00:00<00:00,  4.42it/s]
Epoch 0, Loop Feat 0: -0.35880887508392334
Epoch 0, Loop Adj 0: -0.6793389916419983
Epoch 1, Loop Feat 0: -0.6818594336509705
Epoch 1, Loop Adj 0: -0.7520884275436401
Epoch 2: -0.7520884275436401
Mem used: 774MB
best_loss: tensor(-0.8775, device='cuda:1')
final loss: -0.8837401866912842
Test:
Test: 0.582496514512591
0.582496514512591
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.605312766934012
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.50it/s]100%|██████████| 2/2 [00:00<00:00,  3.40it/s]100%|██████████| 2/2 [00:00<00:00,  3.41it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.7100446224212646
Epoch 1, Loop Feat 0: -0.7065475583076477
Epoch 1, Loop Adj 0: -0.7670301795005798
Epoch 2: -0.7670301795005798
Mem used: 674MB
best_loss: tensor(-0.8802, device='cuda:1')
best_loss: tensor(-0.8815, device='cuda:1')
final loss: -0.8873081207275391
Test:
Test: 0.5815891598482018
0.5815891598482018
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179836213682554, 0.6310910559022389, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.597479599577137
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.57it/s]100%|██████████| 2/2 [00:00<00:00,  3.96it/s]100%|██████████| 2/2 [00:00<00:00,  4.03it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.669219970703125
Epoch 1, Loop Feat 0: -0.6619012951850891
Epoch 1, Loop Adj 0: -0.744821310043335
Epoch 2: -0.744821310043335
Mem used: 674MB
best_loss: tensor(-0.8925, device='cuda:1')
best_loss: tensor(-0.8938, device='cuda:1')
final loss: -0.8940520882606506
Test:
Test: 0.6032686850085278
0.6032686850085278
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483242720477
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 11.95it/s]100%|██████████| 2/2 [00:00<00:00, 11.91it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.6842021942138672
Epoch 1, Loop Feat 0: -0.6807363629341125
Epoch 1, Loop Adj 0: -0.7353226542472839
Epoch 2: -0.7353226542472839
Mem used: 674MB
best_loss: tensor(-0.8579, device='cuda:1')
final loss: -0.8814837336540222
Test:
Test: 0.5665586308547927
0.5665586308547927
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890690973923
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.56it/s]100%|██████████| 2/2 [00:00<00:00,  4.37it/s]100%|██████████| 2/2 [00:00<00:00,  4.17it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.7013940215110779
Epoch 1, Loop Feat 0: -0.6904177069664001
Epoch 1, Loop Adj 0: -0.7858397960662842
Epoch 2: -0.7858397960662842
Mem used: 999MB
best_loss: tensor(-0.8995, device='cuda:1')
final loss: -0.9000895023345947
Test:
Test: 0.5712227340836823
0.5712227340836823
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483719525047425, 0.5836708161590052]
flatten test: 0.6034946216885546
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.80it/s]100%|██████████| 2/2 [00:00<00:00,  5.22it/s]100%|██████████| 2/2 [00:00<00:00,  5.40it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.7123950719833374
Epoch 1, Loop Feat 0: -0.7161945700645447
Epoch 1, Loop Adj 0: -0.7942173480987549
Epoch 2: -0.7942173480987549
Mem used: 862MB
best_loss: tensor(-0.9020, device='cuda:1')
best_loss: tensor(-0.9043, device='cuda:1')
final loss: -0.9135873317718506
Test:
Test: 0.5844380771547747
0.5844380771547747
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.593719576152412, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.587874793205841
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.88it/s]100%|██████████| 2/2 [00:00<00:00,  5.42it/s]100%|██████████| 2/2 [00:00<00:00,  5.47it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.7652435898780823
Epoch 1, Loop Feat 0: -0.7543489336967468
Epoch 1, Loop Adj 0: -0.7341314554214478
Epoch 2: -0.7341314554214478
Mem used: 816MB
best_loss: tensor(-0.7530, device='cuda:1')
best_loss: tensor(-0.7578, device='cuda:1')
final loss: -0.7855923175811768
Test:
Test: 0.5249630163414393
0.5249630163414393
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987216796569
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.71it/s]100%|██████████| 2/2 [00:00<00:00,  5.13it/s]100%|██████████| 2/2 [00:00<00:00,  5.05it/s]
Epoch 0, Loop Feat 0: -0.42172563076019287
Epoch 0, Loop Adj 0: -0.6332308650016785
Epoch 1, Loop Feat 0: -0.6576316952705383
Epoch 1, Loop Adj 0: -0.7287989854812622
Epoch 2: -0.7287989854812622
Mem used: 674MB
best_loss: tensor(-0.8532, device='cuda:1')
best_loss: tensor(-0.8565, device='cuda:1')
final loss: -0.8515167236328125
Test:
Test: 0.5767122178883983
0.5767122178883983
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405996180406469, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.556224183928322]
flatten test: 0.606580416569862
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.31it/s]100%|██████████| 2/2 [00:00<00:00,  3.66it/s]100%|██████████| 2/2 [00:00<00:00,  3.74it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.7130646705627441
Epoch 1, Loop Feat 0: -0.7163513898849487
Epoch 1, Loop Adj 0: -0.7823175191879272
Epoch 2: -0.7823175191879272
Mem used: 674MB
best_loss: tensor(-0.9040, device='cuda:1')
best_loss: tensor(-0.9050, device='cuda:1')
final loss: -0.9044156670570374
Test:
Test: 0.588384629095845
0.588384629095845
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280594765278374, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887461485434
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.23it/s]100%|██████████| 2/2 [00:00<00:00,  2.93it/s]100%|██████████| 2/2 [00:00<00:00,  2.97it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.6978302001953125
Epoch 1, Loop Feat 0: -0.6929330825805664
Epoch 1, Loop Adj 0: -0.7683226466178894
Epoch 2: -0.7683226466178894
Mem used: 1186MB
best_loss: tensor(-0.9022, device='cuda:1')
best_loss: tensor(-0.9049, device='cuda:1')
final loss: -0.8931516408920288
Test:
Test: 0.5924086672029933
0.5924086672029933
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205532218848335, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168184805693
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.08it/s]100%|██████████| 2/2 [00:00<00:00,  4.27it/s]100%|██████████| 2/2 [00:00<00:00,  4.23it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.6793412566184998
Epoch 1, Loop Feat 0: -0.686847448348999
Epoch 1, Loop Adj 0: -0.7516651153564453
Epoch 2: -0.7516651153564453
Mem used: 788MB
best_loss: tensor(-0.8742, device='cuda:1')
best_loss: tensor(-0.8750, device='cuda:1')
final loss: -0.8807734251022339
Test:
Test: 0.5790554694509897
0.5790554694509897
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.605312794655895
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.25it/s]100%|██████████| 2/2 [00:00<00:00,  6.74it/s]100%|██████████| 2/2 [00:00<00:00,  6.45it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.7100445628166199
Epoch 1, Loop Feat 0: -0.7083364725112915
Epoch 1, Loop Adj 0: -0.7699772715568542
Epoch 2: -0.7699772715568542
Mem used: 674MB
best_loss: tensor(-0.8787, device='cuda:1')
best_loss: tensor(-0.8791, device='cuda:1')
final loss: -0.8856674432754517
Test:
Test: 0.58839106310861
0.58839106310861
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179836213682554, 0.6310911059929533, 0.6278801467147008, 0.5383906414670132, 0.5426401818150064]
flatten test: 0.5974796051215135
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  2.91it/s]100%|██████████| 2/2 [00:00<00:00,  4.14it/s]100%|██████████| 2/2 [00:00<00:00,  3.89it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.669219970703125
Epoch 1, Loop Feat 0: -0.6644845604896545
Epoch 1, Loop Adj 0: -0.7477573752403259
Epoch 2: -0.7477573752403259
Mem used: 674MB
best_loss: tensor(-0.8875, device='cuda:1')
best_loss: tensor(-0.8888, device='cuda:1')
final loss: -0.8928601741790771
Test:
Test: 0.6043598459141318
0.6043598459141318
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483298164243
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.76it/s]100%|██████████| 2/2 [00:00<00:00,  5.38it/s]100%|██████████| 2/2 [00:00<00:00,  5.20it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.6842021942138672
Epoch 1, Loop Feat 0: -0.6831567883491516
Epoch 1, Loop Adj 0: -0.7350374460220337
Epoch 2: -0.7350374460220337
Mem used: 1263MB
best_loss: tensor(-0.8520, device='cuda:1')
best_loss: tensor(-0.8571, device='cuda:1')
final loss: -0.8808639049530029
Test:
Test: 0.5672592630720075
0.5672592630720075
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.598189074641769
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.35it/s]100%|██████████| 2/2 [00:00<00:00,  3.97it/s]100%|██████████| 2/2 [00:00<00:00,  3.86it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.7013939023017883
Epoch 1, Loop Feat 0: -0.6943890452384949
Epoch 1, Loop Adj 0: -0.7855396866798401
Epoch 2: -0.7855396866798401
Mem used: 838MB
best_loss: tensor(-0.8961, device='cuda:1')
best_loss: tensor(-0.8985, device='cuda:1')
final loss: -0.8984864354133606
Test:
Test: 0.5719257095524597
0.5719257095524597
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483719525047425, 0.5836708161590052]
flatten test: 0.6034946105998013
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  2.94it/s]100%|██████████| 2/2 [00:00<00:00,  3.86it/s]100%|██████████| 2/2 [00:00<00:00,  3.69it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.7123950719833374
Epoch 1, Loop Feat 0: -0.7214798331260681
Epoch 1, Loop Adj 0: -0.795435905456543
Epoch 2: -0.795435905456543
Mem used: 858MB
best_loss: tensor(-0.8970, device='cuda:1')
best_loss: tensor(-0.9011, device='cuda:1')
final loss: -0.9102908968925476
Test:
Test: 0.5837838730914018
0.5837838730914018
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.593719576152412, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.587874765483958
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.75it/s]100%|██████████| 2/2 [00:00<00:00,  6.48it/s]100%|██████████| 2/2 [00:00<00:00,  6.35it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.7652435898780823
Epoch 1, Loop Feat 0: -0.7575223445892334
Epoch 1, Loop Adj 0: -0.7335649728775024
Epoch 2: -0.7335649728775024
Mem used: 838MB
best_loss: tensor(-0.7572, device='cuda:1')
best_loss: tensor(-0.7622, device='cuda:1')
final loss: -0.7907705903053284
Test:
Test: 0.52103127851618
0.52103127851618
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.644284027479605, 0.6097033728081556, 0.6344159165859445, 0.544936696409752, 0.5785921999441106]
flatten test: 0.604698721679657
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.93it/s]100%|██████████| 2/2 [00:00<00:00,  4.29it/s]100%|██████████| 2/2 [00:00<00:00,  4.06it/s]
Epoch 0, Loop Feat 0: -0.42172563076019287
Epoch 0, Loop Adj 0: -0.6332309246063232
Epoch 1, Loop Feat 0: -0.6583859920501709
Epoch 1, Loop Adj 0: -0.7288687229156494
Epoch 2: -0.7288687229156494
Mem used: 674MB
best_loss: tensor(-0.8617, device='cuda:1')
final loss: -0.8563054203987122
Test:
Test: 0.5791750944290665
0.5791750944290665
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562247297226491]
flatten test: 0.606580427658615
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.72it/s]100%|██████████| 2/2 [00:00<00:00,  4.25it/s]100%|██████████| 2/2 [00:00<00:00,  4.41it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.7130646705627441
Epoch 1, Loop Feat 0: -0.7116483449935913
Epoch 1, Loop Adj 0: -0.7821598649024963
Epoch 2: -0.7821598649024963
Mem used: 674MB
best_loss: tensor(-0.9085, device='cuda:1')
best_loss: tensor(-0.9088, device='cuda:1')
final loss: -0.9079281687736511
Test:
Test: 0.5920048733277922
0.5920048733277922
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163420955350138, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887461485434
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.45it/s]100%|██████████| 2/2 [00:00<00:00,  4.01it/s]100%|██████████| 2/2 [00:00<00:00,  4.30it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.6978302001953125
Epoch 1, Loop Feat 0: -0.6868014931678772
Epoch 1, Loop Adj 0: -0.7666119933128357
Epoch 2: -0.7666119933128357
Mem used: 674MB
best_loss: tensor(-0.9067, device='cuda:1')
best_loss: tensor(-0.9069, device='cuda:1')
final loss: -0.8964241743087769
Test:
Test: 0.5929370505722935
0.5929370505722935
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205531717941192, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168295693227
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.18it/s]100%|██████████| 2/2 [00:00<00:00,  4.65it/s]100%|██████████| 2/2 [00:00<00:00,  4.46it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.6793412566184998
Epoch 1, Loop Feat 0: -0.6793697476387024
Epoch 1, Loop Adj 0: -0.7525430917739868
Epoch 2: -0.7525430917739868
Mem used: 824MB
best_loss: tensor(-0.8788, device='cuda:1')
final loss: -0.8842129111289978
Test:
Test: 0.5816227199765134
0.5816227199765134
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127891115185
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.21it/s]100%|██████████| 2/2 [00:00<00:00,  3.80it/s]100%|██████████| 2/2 [00:00<00:00,  3.69it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.7100446224212646
Epoch 1, Loop Feat 0: -0.7065366506576538
Epoch 1, Loop Adj 0: -0.7634426355361938
Epoch 2: -0.7634426355361938
Mem used: 816MB
best_loss: tensor(-0.8822, device='cuda:1')
final loss: -0.8878676891326904
Test:
Test: 0.5830243021399686
0.5830243021399686
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310911059929533, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.597479599577137
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.89it/s]100%|██████████| 2/2 [00:00<00:00,  5.00it/s]100%|██████████| 2/2 [00:00<00:00,  5.11it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.6692199110984802
Epoch 1, Loop Feat 0: -0.6614292860031128
Epoch 1, Loop Adj 0: -0.7430020570755005
Epoch 2: -0.7430020570755005
Mem used: 674MB
best_loss: tensor(-0.8938, device='cuda:1')
best_loss: tensor(-0.8940, device='cuda:1')
final loss: -0.8955579400062561
Test:
Test: 0.6030938148961534
0.6030938148961534
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483242720478
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.16it/s]100%|██████████| 2/2 [00:00<00:00,  4.94it/s]100%|██████████| 2/2 [00:00<00:00,  5.17it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.6842021942138672
Epoch 1, Loop Feat 0: -0.6805279850959778
Epoch 1, Loop Adj 0: -0.7366795539855957
Epoch 2: -0.7366795539855957
Mem used: 674MB
best_loss: tensor(-0.8614, device='cuda:1')
best_loss: tensor(-0.8620, device='cuda:1')
final loss: -0.8856146931648254
Test:
Test: 0.5679435322444124
0.5679435322444124
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066465368782865, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890857305222
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.90it/s]100%|██████████| 2/2 [00:00<00:00,  3.47it/s]100%|██████████| 2/2 [00:00<00:00,  3.63it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.7013939023017883
Epoch 1, Loop Feat 0: -0.6875528693199158
Epoch 1, Loop Adj 0: -0.7827317118644714
Epoch 2: -0.7827317118644714
Mem used: 1272MB
best_loss: tensor(-0.8992, device='cuda:1')
best_loss: tensor(-0.8996, device='cuda:1')
final loss: -0.9029746651649475
Test:
Test: 0.5719485463261629
0.5719485463261629
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303432937956205, 0.6145207971636634, 0.6325989133050594, 0.5483719525047425, 0.5836708161590052]
flatten test: 0.6034946161441779
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.05it/s]100%|██████████| 2/2 [00:00<00:00,  2.70it/s]100%|██████████| 2/2 [00:00<00:00,  2.72it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.7123950123786926
Epoch 1, Loop Feat 0: -0.7142500281333923
Epoch 1, Loop Adj 0: -0.7937300205230713
Epoch 2: -0.7937300205230713
Mem used: 816MB
best_loss: tensor(-0.9043, device='cuda:1')
best_loss: tensor(-0.9046, device='cuda:1')
final loss: -0.9153492450714111
Test:
Test: 0.5834844134849282
0.5834844134849282
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.593719576152412, 0.6002883018849671, 0.5401741024379962, 0.5824575153695682]
flatten test: 0.587874765483958
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.55it/s]100%|██████████| 1/1 [00:00<00:00,  4.53it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.7652435898780823
Epoch 1: -0.7652435898780823
Mem used: 708MB
best_loss: tensor(-0.8231, device='cuda:1')
best_loss: tensor(-0.8244, device='cuda:1')
final loss: -0.8566563725471497
Test:
Test: 0.5449543280412387
0.5449543280412387
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344159165859445, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987105909036
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  2.96it/s]100%|██████████| 1/1 [00:00<00:00,  2.95it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.6332308650016785
Epoch 1: -0.6332308650016785
Mem used: -595MB
best_loss: tensor(-0.8542, device='cuda:1')
best_loss: tensor(-0.8551, device='cuda:1')
final loss: -0.8408260345458984
Test:
Test: 0.5829779931345112
0.5829779931345112
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804332029917
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.95it/s]100%|██████████| 1/1 [00:00<00:00,  6.92it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.7130646705627441
Epoch 1: -0.7130646705627441
Mem used: 674MB
best_loss: tensor(-0.9146, device='cuda:1')
best_loss: tensor(-0.9147, device='cuda:1')
final loss: -0.8890944123268127
Test:
Test: 0.5981421271831161
0.5981421271831161
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280594765278374, 0.6163420955350138, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887461485434
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.85it/s]100%|██████████| 1/1 [00:00<00:00,  5.84it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.6978302001953125
Epoch 1: -0.6978302001953125
Mem used: 674MB
best_loss: tensor(-0.8977, device='cuda:1')
final loss: -0.8744158148765564
Test:
Test: 0.596345846137813
0.596345846137813
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205532218848335, 0.576750097652589, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168129361927
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.96it/s]100%|██████████| 1/1 [00:00<00:00,  3.95it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.6793412566184998
Epoch 1: -0.6793412566184998
Mem used: 1012MB
best_loss: tensor(-0.8623, device='cuda:1')
best_loss: tensor(-0.8638, device='cuda:1')
final loss: -0.869901180267334
Test:
Test: 0.5878905604612916
0.5878905604612916
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127669340121
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.39it/s]100%|██████████| 1/1 [00:00<00:00,  7.36it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.7100445628166199
Epoch 1: -0.7100445628166199
Mem used: 774MB
best_loss: tensor(-0.8874, device='cuda:1')
best_loss: tensor(-0.8881, device='cuda:1')
final loss: -0.8826403617858887
Test:
Test: 0.5906617533050174
0.5906617533050174
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310911059929533, 0.6278801467147008, 0.5383905009484999, 0.5426401818150064]
flatten test: 0.5974795884883839
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.91it/s]100%|██████████| 1/1 [00:00<00:00,  4.90it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.669219970703125
Epoch 1: -0.669219970703125
Mem used: 886MB
best_loss: tensor(-0.8682, device='cuda:1')
best_loss: tensor(-0.8693, device='cuda:1')
final loss: -0.8603605628013611
Test:
Test: 0.6071717080731133
0.6071717080731133
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.600148335360801
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.66it/s]100%|██████████| 1/1 [00:00<00:00,  3.51it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.6842021942138672
Epoch 1: -0.6842021942138672
Mem used: 674MB
best_loss: tensor(-0.8486, device='cuda:1')
best_loss: tensor(-0.8503, device='cuda:1')
final loss: -0.8693537712097168
Test:
Test: 0.5739883269533346
0.5739883269533346
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875724, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.598189074641769
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.33it/s]100%|██████████| 1/1 [00:00<00:00,  6.30it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.7013939023017883
Epoch 1: -0.7013939023017883
Mem used: 674MB
best_loss: tensor(-0.8794, device='cuda:1')
best_loss: tensor(-0.8796, device='cuda:1')
final loss: -0.8797463774681091
Test:
Test: 0.5874644461220537
0.5874644461220537
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483719525047425, 0.5836708161590052]
flatten test: 0.603494616144178
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.62it/s]100%|██████████| 1/1 [00:00<00:00,  3.58it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.7123950123786926
Epoch 1: -0.7123950123786926
Mem used: 674MB
best_loss: tensor(-0.8938, device='cuda:1')
best_loss: tensor(-0.8949, device='cuda:1')
final loss: -0.891904890537262
Test:
Test: 0.5924231238736506
0.5924231238736506
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.593719576152412, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747710283346
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.82it/s]100%|██████████| 1/1 [00:00<00:00,  3.74it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.765243649482727
Epoch 1: -0.765243649482727
Mem used: 814MB
best_loss: tensor(-0.8151, device='cuda:1')
best_loss: tensor(-0.8159, device='cuda:1')
final loss: -0.848656415939331
Test:
Test: 0.5484889045847027
0.5484889045847027
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442840274796049, 0.6097033728081556, 0.6344159165859445, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987161352803
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.00it/s]100%|██████████| 1/1 [00:00<00:00,  4.46it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.633230984210968
Epoch 1: -0.633230984210968
Mem used: 674MB
best_loss: tensor(-0.8499, device='cuda:1')
best_loss: tensor(-0.8520, device='cuda:1')
final loss: -0.8360506892204285
Test:
Test: 0.5844116262134071
0.5844116262134071
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405996180406469, 0.614043983654398, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804498361216
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.84it/s]100%|██████████| 1/1 [00:00<00:00,  4.83it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.7130646705627441
Epoch 1: -0.7130646705627441
Mem used: -594MB
best_loss: tensor(-0.9115, device='cuda:1')
best_loss: tensor(-0.9120, device='cuda:1')
final loss: -0.8888428807258606
Test:
Test: 0.5980792962683361
0.5980792962683361
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163420955350138, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887461485434
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.31it/s]100%|██████████| 1/1 [00:00<00:00,  5.29it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.6978302001953125
Epoch 1: -0.6978302001953125
Mem used: 674MB
best_loss: tensor(-0.8936, device='cuda:1')
best_loss: tensor(-0.8955, device='cuda:1')
final loss: -0.874713659286499
Test:
Test: 0.59563143242412
0.59563143242412
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205531717941192, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168018474395
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.34it/s]100%|██████████| 1/1 [00:00<00:00,  4.32it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.6793412566184998
Epoch 1: -0.6793412566184998
Mem used: 1425MB
best_loss: tensor(-0.8609, device='cuda:1')
best_loss: tensor(-0.8626, device='cuda:1')
final loss: -0.866047203540802
Test:
Test: 0.5870719713433837
0.5870719713433837
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127891115185
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.53it/s]100%|██████████| 1/1 [00:00<00:00,  3.50it/s]
Epoch 0, Loop Feat 0: -0.4249717593193054
Epoch 0, Loop Adj 0: -0.7100446224212646
Epoch 1: -0.7100446224212646
Mem used: 768MB
best_loss: tensor(-0.8835, device='cuda:1')
best_loss: tensor(-0.8863, device='cuda:1')
final loss: -0.8809335231781006
Test:
Test: 0.5928531701095784
0.5928531701095784
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310910058115247, 0.6278801467147008, 0.5383905009484999, 0.5426401818150064]
flatten test: 0.5974795940327604
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.04it/s]100%|██████████| 1/1 [00:00<00:00,  7.01it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.669219970703125
Epoch 1: -0.669219970703125
Mem used: 772MB
best_loss: tensor(-0.8608, device='cuda:1')
best_loss: tensor(-0.8661, device='cuda:1')
final loss: -0.8582473397254944
Test:
Test: 0.6090089364465694
0.6090089364465694
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483187276712
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.75it/s]100%|██████████| 1/1 [00:00<00:00,  5.59it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.6842021942138672
Epoch 1: -0.6842021942138672
Mem used: 760MB
best_loss: tensor(-0.8442, device='cuda:1')
best_loss: tensor(-0.8460, device='cuda:1')
final loss: -0.8651303052902222
Test:
Test: 0.5731699364160675
0.5731699364160675
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890690973923
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.52it/s]100%|██████████| 1/1 [00:00<00:00,  4.51it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.7013940215110779
Epoch 1: -0.7013940215110779
Mem used: 674MB
best_loss: tensor(-0.8742, device='cuda:1')
best_loss: tensor(-0.8787, device='cuda:1')
final loss: -0.8783876895904541
Test:
Test: 0.5871037442459274
0.5871037442459274
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483719525047425, 0.5836708161590052]
flatten test: 0.6034946161441779
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.52it/s]100%|██████████| 1/1 [00:00<00:00,  5.50it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.7123950123786926
Epoch 1: -0.7123950123786926
Mem used: 674MB
best_loss: tensor(-0.8881, device='cuda:1')
best_loss: tensor(-0.8902, device='cuda:1')
final loss: -0.8875117301940918
Test:
Test: 0.5921297805509167
0.5921297805509167
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.5937195260616978, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.587874765483958
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  2.81it/s]100%|██████████| 1/1 [00:00<00:00,  2.81it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.7652435302734375
Epoch 1: -0.7652435302734375
Mem used: 1078MB
best_loss: tensor(-0.8259, device='cuda:1')
best_loss: tensor(-0.8268, device='cuda:1')
final loss: -0.8596735596656799
Test:
Test: 0.543654141153026
0.543654141153026
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.644284027479605, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987216796569
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.35it/s]100%|██████████| 1/1 [00:00<00:00,  6.33it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.6332309246063232
Epoch 1: -0.6332309246063232
Mem used: 746MB
best_loss: tensor(-0.8558, device='cuda:1')
best_loss: tensor(-0.8567, device='cuda:1')
final loss: -0.8418676257133484
Test:
Test: 0.5858520110340937
0.5858520110340937
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804332029917
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.69it/s]100%|██████████| 1/1 [00:00<00:00,  5.67it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.7130646705627441
Epoch 1: -0.7130646705627441
Mem used: 692MB
best_loss: tensor(-0.9156, device='cuda:1')
best_loss: tensor(-0.9162, device='cuda:1')
final loss: -0.8917816281318665
Test:
Test: 0.598181724162911
0.598181724162911
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280594765278374, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887461485433
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.18it/s]100%|██████████| 1/1 [00:00<00:00,  3.81it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.6978302001953125
Epoch 1: -0.6978302001953125
Mem used: -594MB
best_loss: tensor(-0.8985, device='cuda:1')
best_loss: tensor(-0.8990, device='cuda:1')
final loss: -0.8753259181976318
Test:
Test: 0.5973565421677254
0.5973565421677254
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205531717941192, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168073918162
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.44it/s]100%|██████████| 1/1 [00:00<00:00,  4.43it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.6793412566184998
Epoch 1: -0.6793412566184998
Mem used: 674MB
best_loss: tensor(-0.8631, device='cuda:1')
best_loss: tensor(-0.8632, device='cuda:1')
final loss: -0.8703525066375732
Test:
Test: 0.5876670778080255
0.5876670778080255
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127780227653
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.54it/s]100%|██████████| 1/1 [00:00<00:00,  4.53it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.7100446224212646
Epoch 1: -0.7100446224212646
Mem used: 674MB
best_loss: tensor(-0.8884, device='cuda:1')
final loss: -0.8830121159553528
Test:
Test: 0.5921835164723436
0.5921835164723436
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179836213682554, 0.6310911059929533, 0.6278801467147008, 0.5383905009484999, 0.5426401818150064]
flatten test: 0.5974796106658903
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.71it/s]100%|██████████| 1/1 [00:00<00:00,  4.69it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.669219970703125
Epoch 1: -0.669219970703125
Mem used: 818MB
best_loss: tensor(-0.8700, device='cuda:1')
final loss: -0.8610666990280151
Test:
Test: 0.6076402789533752
0.6076402789533752
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483242720477
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.56it/s]100%|██████████| 1/1 [00:00<00:00,  7.54it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.6842021942138672
Epoch 1: -0.6842021942138672
Mem used: 780MB
best_loss: tensor(-0.8507, device='cuda:1')
best_loss: tensor(-0.8515, device='cuda:1')
final loss: -0.8731964826583862
Test:
Test: 0.5734836541125574
0.5734836541125574
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890801861456
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.06it/s]100%|██████████| 1/1 [00:00<00:00,  5.05it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.7013939023017883
Epoch 1: -0.7013939023017883
Mem used: -594MB
best_loss: tensor(-0.8799, device='cuda:1')
final loss: -0.8817045092582703
Test:
Test: 0.5863563661458453
0.5863563661458453
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232558, 0.5836708161590052]
flatten test: 0.6034946216885546
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.51it/s]100%|██████████| 1/1 [00:00<00:00,  5.50it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.7123937010765076
Epoch 1: -0.7123937010765076
Mem used: 674MB
best_loss: tensor(-0.8952, device='cuda:1')
best_loss: tensor(-0.8959, device='cuda:1')
final loss: -0.893913984298706
Test:
Test: 0.5926029982181755
0.5926029982181755
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.5937196262431264, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747821170878
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.74it/s]100%|██████████| 2/2 [00:00<00:00,  5.04it/s]100%|██████████| 2/2 [00:00<00:00,  4.98it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.765243649482727
Epoch 1, Loop Feat 0: -0.7573859691619873
Epoch 1, Loop Adj 0: -0.7332733869552612
Epoch 2: -0.7332733869552612
Mem used: 824MB
best_loss: tensor(-0.7615, device='cuda:1')
best_loss: tensor(-0.7623, device='cuda:1')
final loss: -0.789483904838562
Test:
Test: 0.5213919009600501
0.5213919009600501
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344159165859445, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987050465271
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.87it/s]100%|██████████| 2/2 [00:00<00:00,  4.88it/s]100%|██████████| 2/2 [00:00<00:00,  4.69it/s]
Epoch 0, Loop Feat 0: -0.42172563076019287
Epoch 0, Loop Adj 0: -0.6332309246063232
Epoch 1, Loop Feat 0: -0.6580984592437744
Epoch 1, Loop Adj 0: -0.7292648553848267
Epoch 2: -0.7292648553848267
Mem used: 802MB
best_loss: tensor(-0.8597, device='cuda:1')
best_loss: tensor(-0.8625, device='cuda:1')
final loss: -0.8569590449333191
Test:
Test: 0.5784558353477354
0.5784558353477354
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804221142385
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.85it/s]100%|██████████| 2/2 [00:00<00:00,  4.08it/s]100%|██████████| 2/2 [00:00<00:00,  4.13it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.7130646705627441
Epoch 1, Loop Feat 0: -0.7134699821472168
Epoch 1, Loop Adj 0: -0.7818268537521362
Epoch 2: -0.7818268537521362
Mem used: -594MB
best_loss: tensor(-0.9076, device='cuda:1')
best_loss: tensor(-0.9076, device='cuda:1')
final loss: -0.9060007333755493
Test:
Test: 0.5920345412755422
0.5920345412755422
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280594765278374, 0.6163420955350138, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887350597901
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.06it/s]100%|██████████| 2/2 [00:00<00:00,  6.80it/s]100%|██████████| 2/2 [00:00<00:00,  6.83it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.6978302001953125
Epoch 1, Loop Feat 0: -0.6888521313667297
Epoch 1, Loop Adj 0: -0.7666606903076172
Epoch 2: -0.7666606903076172
Mem used: 674MB
best_loss: tensor(-0.9057, device='cuda:1')
final loss: -0.8944908976554871
Test:
Test: 0.5906922552914592
0.5906922552914592
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205531717941192, 0.5767507023125826, 0.5493891660226236, 0.5826381732918821]
flatten test: 0.5907168018474395
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.55it/s]100%|██████████| 2/2 [00:00<00:00,  5.86it/s]100%|██████████| 2/2 [00:00<00:00,  5.80it/s]
Epoch 0, Loop Feat 0: -0.35880887508392334
Epoch 0, Loop Adj 0: -0.6793412566184998
Epoch 1, Loop Feat 0: -0.6817376017570496
Epoch 1, Loop Adj 0: -0.7521464228630066
Epoch 2: -0.7521464228630066
Mem used: 674MB
best_loss: tensor(-0.8772, device='cuda:1')
final loss: -0.8832915425300598
Test:
Test: 0.5820649193476641
0.5820649193476641
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127891115184
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.12it/s]100%|██████████| 2/2 [00:00<00:00,  4.99it/s]100%|██████████| 2/2 [00:00<00:00,  4.83it/s]
Epoch 0, Loop Feat 0: -0.4249717891216278
Epoch 0, Loop Adj 0: -0.7100445628166199
Epoch 1, Loop Feat 0: -0.7065502405166626
Epoch 1, Loop Adj 0: -0.7669711709022522
Epoch 2: -0.7669711709022522
Mem used: 1042MB
best_loss: tensor(-0.8806, device='cuda:1')
best_loss: tensor(-0.8814, device='cuda:1')
final loss: -0.8888666033744812
Test:
Test: 0.5807341907568814
0.5807341907568814
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179833977386575, 0.6310911059929533, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974796051215137
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.94it/s]100%|██████████| 2/2 [00:00<00:00,  6.30it/s]100%|██████████| 2/2 [00:00<00:00,  6.04it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.669219970703125
Epoch 1, Loop Feat 0: -0.6618648171424866
Epoch 1, Loop Adj 0: -0.7447064518928528
Epoch 2: -0.7447064518928528
Mem used: 834MB
best_loss: tensor(-0.8925, device='cuda:1')
best_loss: tensor(-0.8939, device='cuda:1')
final loss: -0.89573073387146
Test:
Test: 0.6033418024005064
0.6033418024005064
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483298164244
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.54it/s]100%|██████████| 2/2 [00:00<00:00,  6.04it/s]100%|██████████| 2/2 [00:00<00:00,  5.95it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.6842021942138672
Epoch 1, Loop Feat 0: -0.6807382702827454
Epoch 1, Loop Adj 0: -0.7356358766555786
Epoch 2: -0.7356358766555786
Mem used: 980MB
best_loss: tensor(-0.8580, device='cuda:1')
final loss: -0.8828723430633545
Test:
Test: 0.566204720436585
0.566204720436585
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875724, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890801861456
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.08it/s]100%|██████████| 2/2 [00:00<00:00,  4.12it/s]100%|██████████| 2/2 [00:00<00:00,  4.11it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.7013940215110779
Epoch 1, Loop Feat 0: -0.6902937293052673
Epoch 1, Loop Adj 0: -0.7857016324996948
Epoch 2: -0.7857016324996948
Mem used: 850MB
best_loss: tensor(-0.8990, device='cuda:1')
best_loss: tensor(-0.8992, device='cuda:1')
final loss: -0.8986055850982666
Test:
Test: 0.573251950220758
0.573251950220758
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232557, 0.5836708161590052]
flatten test: 0.6034946161441779
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.54it/s]100%|██████████| 2/2 [00:00<00:00,  5.15it/s]100%|██████████| 2/2 [00:00<00:00,  4.82it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.7123950123786926
Epoch 1, Loop Feat 0: -0.7160903811454773
Epoch 1, Loop Adj 0: -0.7942206859588623
Epoch 2: -0.7942206859588623
Mem used: -594MB
best_loss: tensor(-0.9019, device='cuda:1')
best_loss: tensor(-0.9044, device='cuda:1')
final loss: -0.914951741695404
Test:
Test: 0.5852358153053884
0.5852358153053884
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.5937196262431264, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747765727113
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.73it/s]100%|██████████| 2/2 [00:00<00:00,  6.67it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.7652435302734375
Epoch 1, Loop Feat 0: -0.7549216747283936
Epoch 1, Loop Adj 0: -0.7351241707801819
Epoch 2: -0.7351241707801819
Mem used: 674MB
best_loss: tensor(-0.7558, device='cuda:1')
best_loss: tensor(-0.7578, device='cuda:1')
final loss: -0.7887928485870361
Test:
Test: 0.5261189145359758
0.5261189145359758
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.644284027479605, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987105909036
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.14it/s]100%|██████████| 2/2 [00:00<00:00,  4.28it/s]100%|██████████| 2/2 [00:00<00:00,  4.05it/s]
Epoch 0, Loop Feat 0: -0.42172563076019287
Epoch 0, Loop Adj 0: -0.6332309246063232
Epoch 1, Loop Feat 0: -0.6576277017593384
Epoch 1, Loop Adj 0: -0.7291372418403625
Epoch 2: -0.7291372418403625
Mem used: 686MB
best_loss: tensor(-0.8528, device='cuda:1')
best_loss: tensor(-0.8566, device='cuda:1')
final loss: -0.851318895816803
Test:
Test: 0.5772944960436381
0.5772944960436381
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804332029916
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.54it/s]100%|██████████| 2/2 [00:00<00:00,  3.98it/s]100%|██████████| 2/2 [00:00<00:00,  3.90it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.7130646705627441
Epoch 1, Loop Feat 0: -0.7162514328956604
Epoch 1, Loop Adj 0: -0.782227098941803
Epoch 2: -0.782227098941803
Mem used: 854MB
best_loss: tensor(-0.9040, device='cuda:1')
best_loss: tensor(-0.9050, device='cuda:1')
final loss: -0.9044455289840698
Test:
Test: 0.5882865699753697
0.5882865699753697
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280594765278374, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887350597901
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.85it/s]100%|██████████| 2/2 [00:00<00:00,  5.37it/s]100%|██████████| 2/2 [00:00<00:00,  5.28it/s]
Epoch 0, Loop Feat 0: -0.40305694937705994
Epoch 0, Loop Adj 0: -0.6978302001953125
Epoch 1, Loop Feat 0: -0.6928629875183105
Epoch 1, Loop Adj 0: -0.7681283950805664
Epoch 2: -0.7681283950805664
Mem used: 740MB
best_loss: tensor(-0.9018, device='cuda:1')
best_loss: tensor(-0.9047, device='cuda:1')
final loss: -0.8933124542236328
Test:
Test: 0.5922319304325944
0.5922319304325944
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205531717941192, 0.5767507023125826, 0.5493891660226236, 0.5826381732918821]
flatten test: 0.590716824024946
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.39it/s]100%|██████████| 2/2 [00:00<00:00,  6.46it/s]100%|██████████| 2/2 [00:00<00:00,  6.26it/s]
Epoch 0, Loop Feat 0: -0.35880887508392334
Epoch 0, Loop Adj 0: -0.6793412566184998
Epoch 1, Loop Feat 0: -0.6867499351501465
Epoch 1, Loop Adj 0: -0.751593828201294
Epoch 2: -0.751593828201294
Mem used: -594MB
best_loss: tensor(-0.8742, device='cuda:1')
best_loss: tensor(-0.8762, device='cuda:1')
final loss: -0.88215571641922
Test:
Test: 0.5775654394700789
0.5775654394700789
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127724783887
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.71it/s]100%|██████████| 2/2 [00:00<00:00,  4.32it/s]100%|██████████| 2/2 [00:00<00:00,  4.21it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.7100446224212646
Epoch 1, Loop Feat 0: -0.7082822918891907
Epoch 1, Loop Adj 0: -0.7696213722229004
Epoch 2: -0.7696213722229004
Mem used: 674MB
best_loss: tensor(-0.8789, device='cuda:1')
best_loss: tensor(-0.8793, device='cuda:1')
final loss: -0.8862293362617493
Test:
Test: 0.5864257502217748
0.5864257502217748
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179836213682554, 0.6310911059929533, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974796051215137
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.71it/s]100%|██████████| 2/2 [00:00<00:00,  4.36it/s]100%|██████████| 2/2 [00:00<00:00,  4.17it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.669219970703125
Epoch 1, Loop Feat 0: -0.6644255518913269
Epoch 1, Loop Adj 0: -0.7477290034294128
Epoch 2: -0.7477290034294128
Mem used: 994MB
best_loss: tensor(-0.8871, device='cuda:1')
best_loss: tensor(-0.8889, device='cuda:1')
final loss: -0.8928936719894409
Test:
Test: 0.6045427784005266
0.6045427784005266
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483298164243
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.17it/s]100%|██████████| 2/2 [00:00<00:00,  3.76it/s]100%|██████████| 2/2 [00:00<00:00,  3.65it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.6842021942138672
Epoch 1, Loop Feat 0: -0.6831147074699402
Epoch 1, Loop Adj 0: -0.7348886728286743
Epoch 2: -0.7348886728286743
Mem used: 902MB
best_loss: tensor(-0.8524, device='cuda:1')
best_loss: tensor(-0.8574, device='cuda:1')
final loss: -0.8802430033683777
Test:
Test: 0.5671448806228505
0.5671448806228505
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890801861456
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.07it/s]100%|██████████| 2/2 [00:00<00:00,  7.09it/s]100%|██████████| 2/2 [00:00<00:00,  6.91it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.7013940215110779
Epoch 1, Loop Feat 0: -0.6943761706352234
Epoch 1, Loop Adj 0: -0.7857954502105713
Epoch 2: -0.7857954502105713
Mem used: 674MB
best_loss: tensor(-0.8957, device='cuda:1')
final loss: -0.894346296787262
Test:
Test: 0.5737095594496425
0.5737095594496425
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145208472543777, 0.6325989133050594, 0.5483719525047425, 0.5836708161590052]
flatten test: 0.6034946161441779
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.88it/s]100%|██████████| 2/2 [00:00<00:00,  5.50it/s]100%|██████████| 2/2 [00:00<00:00,  5.55it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.7123950123786926
Epoch 1, Loop Feat 0: -0.7214154601097107
Epoch 1, Loop Adj 0: -0.79598069190979
Epoch 2: -0.79598069190979
Mem used: 674MB
best_loss: tensor(-0.8972, device='cuda:1')
best_loss: tensor(-0.9010, device='cuda:1')
final loss: -0.9112603664398193
Test:
Test: 0.5831426959180717
0.5831426959180717
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.5937196763338406, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.587874793205841
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.32it/s]100%|██████████| 2/2 [00:00<00:00,  4.14it/s]100%|██████████| 2/2 [00:00<00:00,  4.19it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.765243411064148
Epoch 1, Loop Feat 0: -0.757557213306427
Epoch 1, Loop Adj 0: -0.7331420183181763
Epoch 2: -0.7331420183181763
Mem used: 674MB
best_loss: tensor(-0.7565, device='cuda:1')
best_loss: tensor(-0.7618, device='cuda:1')
final loss: -0.7924548387527466
Test:
Test: 0.5205601658037146
0.5205601658037146
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.644284027479605, 0.6097033728081556, 0.6344159165859445, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987105909036
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.43it/s]100%|██████████| 2/2 [00:00<00:00,  3.71it/s]100%|██████████| 2/2 [00:00<00:00,  3.66it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.6332309246063232
Epoch 1, Loop Feat 0: -0.6584001183509827
Epoch 1, Loop Adj 0: -0.728829026222229
Epoch 2: -0.728829026222229
Mem used: 1139MB
best_loss: tensor(-0.8616, device='cuda:1')
best_loss: tensor(-0.8630, device='cuda:1')
final loss: -0.8568234443664551
Test:
Test: 0.5803217784818653
0.5803217784818653
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405996180406469, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.606580444291745
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.51it/s]100%|██████████| 2/2 [00:00<00:00,  4.16it/s]100%|██████████| 2/2 [00:00<00:00,  4.16it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.7130646705627441
Epoch 1, Loop Feat 0: -0.711627185344696
Epoch 1, Loop Adj 0: -0.7821512222290039
Epoch 2: -0.7821512222290039
Mem used: 876MB
best_loss: tensor(-0.9084, device='cuda:1')
best_loss: tensor(-0.9087, device='cuda:1')
final loss: -0.9077335596084595
Test:
Test: 0.5919928393409537
0.5919928393409537
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280594765278374, 0.6163420955350138, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887406041667
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.22it/s]100%|██████████| 2/2 [00:00<00:00,  3.44it/s]100%|██████████| 2/2 [00:00<00:00,  3.62it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.6978302001953125
Epoch 1, Loop Feat 0: -0.6867280006408691
Epoch 1, Loop Adj 0: -0.7666106820106506
Epoch 2: -0.7666106820106506
Mem used: 796MB
best_loss: tensor(-0.9066, device='cuda:1')
best_loss: tensor(-0.9069, device='cuda:1')
final loss: -0.8962026238441467
Test:
Test: 0.5927334656992453
0.5927334656992453
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205531717941192, 0.5767513069725763, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.590716824024946
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.48it/s]100%|██████████| 2/2 [00:00<00:00,  3.47it/s]100%|██████████| 2/2 [00:00<00:00,  3.46it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.6793410778045654
Epoch 1, Loop Feat 0: -0.6792965531349182
Epoch 1, Loop Adj 0: -0.7526069283485413
Epoch 2: -0.7526069283485413
Mem used: 1017MB
best_loss: tensor(-0.8788, device='cuda:1')
best_loss: tensor(-0.8788, device='cuda:1')
final loss: -0.885347843170166
Test:
Test: 0.5810652246852577
0.5810652246852577
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127946558952
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.47it/s]100%|██████████| 2/2 [00:00<00:00,  3.41it/s]100%|██████████| 2/2 [00:00<00:00,  3.41it/s]
Epoch 0, Loop Feat 0: -0.4249718487262726
Epoch 0, Loop Adj 0: -0.7100445628166199
Epoch 1, Loop Feat 0: -0.7065505981445312
Epoch 1, Loop Adj 0: -0.7632101774215698
Epoch 2: -0.7632101774215698
Mem used: -594MB
best_loss: tensor(-0.8822, device='cuda:1')
final loss: -0.8895987868309021
Test:
Test: 0.5837282307958223
0.5837282307958223
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179836213682554, 0.6310910559022389, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.597479599577137
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.10it/s]100%|██████████| 2/2 [00:00<00:00,  6.36it/s]100%|██████████| 2/2 [00:00<00:00,  6.45it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.669219970703125
Epoch 1, Loop Feat 0: -0.6614336967468262
Epoch 1, Loop Adj 0: -0.7429541945457458
Epoch 2: -0.7429541945457458
Mem used: 674MB
best_loss: tensor(-0.8938, device='cuda:1')
best_loss: tensor(-0.8940, device='cuda:1')
final loss: -0.8966624140739441
Test:
Test: 0.603239970247854
0.603239970247854
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483242720478
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.04it/s]100%|██████████| 2/2 [00:00<00:00,  5.82it/s]100%|██████████| 2/2 [00:00<00:00,  5.85it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.6842021942138672
Epoch 1, Loop Feat 0: -0.6805639863014221
Epoch 1, Loop Adj 0: -0.7367590069770813
Epoch 2: -0.7367590069770813
Mem used: 1048MB
best_loss: tensor(-0.8615, device='cuda:1')
best_loss: tensor(-0.8620, device='cuda:1')
final loss: -0.8845558762550354
Test:
Test: 0.5679664881665003
0.5679664881665003
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875724, 0.6335276710552888, 0.5433284620248718, 0.5756913030948722]
flatten test: 0.5981890801861456
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.38it/s]100%|██████████| 2/2 [00:00<00:00,  5.19it/s]100%|██████████| 2/2 [00:00<00:00,  5.04it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.7013940215110779
Epoch 1, Loop Feat 0: -0.6874720454216003
Epoch 1, Loop Adj 0: -0.782806396484375
Epoch 2: -0.782806396484375
Mem used: 852MB
best_loss: tensor(-0.8989, device='cuda:1')
best_loss: tensor(-0.8995, device='cuda:1')
final loss: -0.9036107063293457
Test:
Test: 0.5719020387400646
0.5719020387400646
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232557, 0.5836708161590052]
flatten test: 0.6034946050554247
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.05it/s]100%|██████████| 2/2 [00:00<00:00,  5.50it/s]100%|██████████| 2/2 [00:00<00:00,  5.57it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.7123950123786926
Epoch 1, Loop Feat 0: -0.7142015099525452
Epoch 1, Loop Adj 0: -0.7938910722732544
Epoch 2: -0.7938910722732544
Mem used: 674MB
best_loss: tensor(-0.9045, device='cuda:1')
best_loss: tensor(-0.9046, device='cuda:1')
final loss: -0.9151128530502319
Test:
Test: 0.5835692074185915
0.5835692074185915
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.5937196262431264, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747765727113
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.64it/s]100%|██████████| 1/1 [00:00<00:00,  5.63it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.7652435898780823
Epoch 1: -0.7652435898780823
Mem used: 794MB
best_loss: tensor(-0.8229, device='cuda:1')
best_loss: tensor(-0.8250, device='cuda:1')
final loss: -0.8562672138214111
Test:
Test: 0.5440153990549468
0.5440153990549468
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987105909037
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.00it/s]100%|██████████| 1/1 [00:00<00:00,  4.98it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.6332309246063232
Epoch 1: -0.6332309246063232
Mem used: 674MB
best_loss: tensor(-0.8542, device='cuda:1')
best_loss: tensor(-0.8553, device='cuda:1')
final loss: -0.8399918675422668
Test:
Test: 0.583120415170163
0.583120415170163
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.614043983654398, 0.6456251035480238, 0.5428112133773624, 0.5562247297226491]
flatten test: 0.6065804498361216
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.17it/s]100%|██████████| 1/1 [00:00<00:00,  4.17it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.7130646705627441
Epoch 1: -0.7130646705627441
Mem used: 932MB
best_loss: tensor(-0.9146, device='cuda:1')
best_loss: tensor(-0.9152, device='cuda:1')
final loss: -0.8897262215614319
Test:
Test: 0.5996605939118036
0.5996605939118036
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163420955350138, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887406041668
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.22it/s]100%|██████████| 1/1 [00:00<00:00,  3.21it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.6978302001953125
Epoch 1: -0.6978302001953125
Mem used: 1478MB
best_loss: tensor(-0.8977, device='cuda:1')
best_loss: tensor(-0.8979, device='cuda:1')
final loss: -0.876943051815033
Test:
Test: 0.5971761912296621
0.5971761912296621
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205532218848335, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168295693226
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.20it/s]100%|██████████| 1/1 [00:00<00:00,  4.19it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.6793412566184998
Epoch 1: -0.6793412566184998
Mem used: 692MB
best_loss: tensor(-0.8623, device='cuda:1')
best_loss: tensor(-0.8639, device='cuda:1')
final loss: -0.8709673285484314
Test:
Test: 0.5878641492360523
0.5878641492360523
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127780227654
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.83it/s]100%|██████████| 1/1 [00:00<00:00,  4.70it/s]
Epoch 0, Loop Feat 0: -0.4249717891216278
Epoch 0, Loop Adj 0: -0.7100446224212646
Epoch 1: -0.7100446224212646
Mem used: -594MB
best_loss: tensor(-0.8874, device='cuda:1')
best_loss: tensor(-0.8879, device='cuda:1')
final loss: -0.8834253549575806
Test:
Test: 0.5910091899943317
0.5910091899943317
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310911059929533, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974796051215137
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.04it/s]100%|██████████| 1/1 [00:00<00:00,  5.02it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.669219970703125
Epoch 1: -0.669219970703125
Mem used: -226MB
best_loss: tensor(-0.8682, device='cuda:1')
best_loss: tensor(-0.8689, device='cuda:1')
final loss: -0.8615111708641052
Test:
Test: 0.6082451158694211
0.6082451158694211
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806285182466, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483131832945
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  2.48it/s]100%|██████████| 1/1 [00:00<00:00,  2.47it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.6842021942138672
Epoch 1: -0.6842021942138672
Mem used: 674MB
best_loss: tensor(-0.8487, device='cuda:1')
best_loss: tensor(-0.8509, device='cuda:1')
final loss: -0.8711239099502563
Test:
Test: 0.5737066998884135
0.5737066998884135
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.598189074641769
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.59it/s]100%|██████████| 1/1 [00:00<00:00,  4.58it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.7013940215110779
Epoch 1: -0.7013940215110779
Mem used: 1012MB
best_loss: tensor(-0.8795, device='cuda:1')
best_loss: tensor(-0.8797, device='cuda:1')
final loss: -0.8803537487983704
Test:
Test: 0.587385093297951
0.587385093297951
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232557, 0.5836708161590052]
flatten test: 0.6034946272329312
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.63it/s]100%|██████████| 1/1 [00:00<00:00,  5.47it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.7123950719833374
Epoch 1: -0.7123950719833374
Mem used: 796MB
best_loss: tensor(-0.8939, device='cuda:1')
best_loss: tensor(-0.8951, device='cuda:1')
final loss: -0.8933491110801697
Test:
Test: 0.5926237300370854
0.5926237300370854
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.5937196262431264, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.587874793205841
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.04it/s]100%|██████████| 1/1 [00:00<00:00,  6.02it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.7652435898780823
Epoch 1: -0.7652435898780823
Mem used: 816MB
best_loss: tensor(-0.8151, device='cuda:1')
best_loss: tensor(-0.8250, device='cuda:1')
final loss: -0.8562672138214111
Test:
Test: 0.5440157565001005
0.5440157565001005
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.644284027479605, 0.6097033728081556, 0.6344159165859445, 0.544936696409752, 0.5785921999441106]
flatten test: 0.604698705046527
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.38it/s]100%|██████████| 1/1 [00:00<00:00,  4.37it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.6332309246063232
Epoch 1: -0.6332309246063232
Mem used: 674MB
best_loss: tensor(-0.8500, device='cuda:1')
best_loss: tensor(-0.8549, device='cuda:1')
final loss: -0.8393916487693787
Test:
Test: 0.5827805642613308
0.5827805642613308
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405993944110492, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804221142383
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.85it/s]100%|██████████| 1/1 [00:00<00:00,  7.82it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.7130646705627441
Epoch 1: -0.7130646705627441
Mem used: 674MB
best_loss: tensor(-0.9115, device='cuda:1')
best_loss: tensor(-0.9152, device='cuda:1')
final loss: -0.8897262215614319
Test:
Test: 0.5996605541956754
0.5996605541956754
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280594765278374, 0.6163421456257283, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887461485433
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.60it/s]100%|██████████| 1/1 [00:00<00:00,  4.59it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.6978302001953125
Epoch 1: -0.6978302001953125
Mem used: 674MB
best_loss: tensor(-0.8936, device='cuda:1')
best_loss: tensor(-0.8979, device='cuda:1')
final loss: -0.876943051815033
Test:
Test: 0.5971761912296621
0.5971761912296621
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205531717941192, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168184805694
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.08it/s]100%|██████████| 1/1 [00:00<00:00,  3.99it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.6793412566184998
Epoch 1: -0.6793412566184998
Mem used: 810MB
best_loss: tensor(-0.8609, device='cuda:1')
best_loss: tensor(-0.8626, device='cuda:1')
final loss: -0.8681811094284058
Test:
Test: 0.5873960152332004
0.5873960152332004
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127891115185
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  2.04it/s]100%|██████████| 1/1 [00:00<00:00,  2.03it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.7100446224212646
Epoch 1: -0.7100446224212646
Mem used: -594MB
best_loss: tensor(-0.8835, device='cuda:1')
best_loss: tensor(-0.8879, device='cuda:1')
final loss: -0.8834253549575806
Test:
Test: 0.591009031129819
0.591009031129819
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310911059929533, 0.6278801467147008, 0.5383905009484999, 0.5426401818150064]
flatten test: 0.5974795884883838
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.42it/s]100%|██████████| 1/1 [00:00<00:00,  4.33it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.669219970703125
Epoch 1: -0.669219970703125
Mem used: 674MB
best_loss: tensor(-0.8609, device='cuda:1')
best_loss: tensor(-0.8689, device='cuda:1')
final loss: -0.8615111708641052
Test:
Test: 0.6082451555855493
0.6082451555855493
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483242720478
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  9.83it/s]100%|██████████| 1/1 [00:00<00:00,  9.78it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.6842021942138672
Epoch 1: -0.6842021942138672
Mem used: 674MB
best_loss: tensor(-0.8442, device='cuda:1')
best_loss: tensor(-0.8509, device='cuda:1')
final loss: -0.8711239099502563
Test:
Test: 0.5737068984690545
0.5737068984690545
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890635530158
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.23it/s]100%|██████████| 1/1 [00:00<00:00,  4.22it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.7013940215110779
Epoch 1: -0.7013940215110779
Mem used: 1033MB
best_loss: tensor(-0.8742, device='cuda:1')
best_loss: tensor(-0.8797, device='cuda:1')
final loss: -0.8803537487983704
Test:
Test: 0.587385093297951
0.587385093297951
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483719525047425, 0.5836708161590052]
flatten test: 0.6034946105998014
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.22it/s]100%|██████████| 1/1 [00:00<00:00,  6.06it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.7123950123786926
Epoch 1: -0.7123950123786926
Mem used: 768MB
best_loss: tensor(-0.8881, device='cuda:1')
best_loss: tensor(-0.8951, device='cuda:1')
final loss: -0.8933492302894592
Test:
Test: 0.5926237300370854
0.5926237300370854
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.5937196262431264, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747710283346
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.52it/s]100%|██████████| 1/1 [00:00<00:00,  4.52it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.7652437090873718
Epoch 1: -0.7652437090873718
Mem used: 816MB
best_loss: tensor(-0.8259, device='cuda:1')
final loss: -0.8570111989974976
Test:
Test: 0.5467964812145891
0.5467964812145891
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.604698705046527
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.81it/s]100%|██████████| 1/1 [00:00<00:00,  3.80it/s]
Epoch 0, Loop Feat 0: -0.42172563076019287
Epoch 0, Loop Adj 0: -0.6332309246063232
Epoch 1: -0.6332309246063232
Mem used: 674MB
best_loss: tensor(-0.8558, device='cuda:1')
best_loss: tensor(-0.8567, device='cuda:1')
final loss: -0.8418676257133484
Test:
Test: 0.5858521698986063
0.5858521698986063
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804332029917
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  2.93it/s]100%|██████████| 1/1 [00:00<00:00,  2.93it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.7130646705627441
Epoch 1: -0.7130646705627441
Mem used: 674MB
best_loss: tensor(-0.9156, device='cuda:1')
best_loss: tensor(-0.9162, device='cuda:1')
final loss: -0.8919764161109924
Test:
Test: 0.5981787851694258
0.5981787851694258
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280594765278374, 0.6163420955350138, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887350597901
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.53it/s]100%|██████████| 1/1 [00:00<00:00,  4.25it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.6978302001953125
Epoch 1: -0.6978302001953125
Mem used: 806MB
best_loss: tensor(-0.8984, device='cuda:1')
best_loss: tensor(-0.8990, device='cuda:1')
final loss: -0.8755148649215698
Test:
Test: 0.5973135296009069
0.5973135296009069
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205532218848335, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168184805693
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.90it/s]100%|██████████| 1/1 [00:00<00:00,  5.88it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.6793412566184998
Epoch 1: -0.6793412566184998
Mem used: 776MB
best_loss: tensor(-0.8630, device='cuda:1')
best_loss: tensor(-0.8632, device='cuda:1')
final loss: -0.8708932995796204
Test:
Test: 0.58768618126568
0.58768618126568
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127780227653
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.12it/s]100%|██████████| 1/1 [00:00<00:00,  6.68it/s]
Epoch 0, Loop Feat 0: -0.4249717593193054
Epoch 0, Loop Adj 0: -0.7100446224212646
Epoch 1: -0.7100446224212646
Mem used: -594MB
best_loss: tensor(-0.8883, device='cuda:1')
final loss: -0.8843717575073242
Test:
Test: 0.5920664333264704
0.5920664333264704
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179836213682554, 0.6310911059929533, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974796106658903
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.61it/s]100%|██████████| 1/1 [00:00<00:00,  6.60it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.669219970703125
Epoch 1: -0.669219970703125
Mem used: 790MB
best_loss: tensor(-0.8700, device='cuda:1')
final loss: -0.8615463972091675
Test:
Test: 0.6074392756286586
0.6074392756286586
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483298164244
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.86it/s]100%|██████████| 1/1 [00:00<00:00,  3.83it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.6842021942138672
Epoch 1: -0.6842021942138672
Mem used: 674MB
best_loss: tensor(-0.8507, device='cuda:1')
best_loss: tensor(-0.8515, device='cuda:1')
final loss: -0.8732126355171204
Test:
Test: 0.5734884597640671
0.5734884597640671
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.598189074641769
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.14it/s]100%|██████████| 1/1 [00:00<00:00,  4.13it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.7013940215110779
Epoch 1: -0.7013940215110779
Mem used: 674MB
best_loss: tensor(-0.8800, device='cuda:1')
best_loss: tensor(-0.8802, device='cuda:1')
final loss: -0.882779598236084
Test:
Test: 0.5876277191249997
0.5876277191249997
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232557, 0.5836708161590052]
flatten test: 0.6034946216885546
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.72it/s]100%|██████████| 1/1 [00:00<00:00,  4.70it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.7123950123786926
Epoch 1: -0.7123950123786926
Mem used: 1038MB
best_loss: tensor(-0.8953, device='cuda:1')
best_loss: tensor(-0.8959, device='cuda:1')
final loss: -0.894076406955719
Test:
Test: 0.5925992649021268
0.5925992649021268
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.5937196262431264, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747710283346
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.21it/s]100%|██████████| 2/2 [00:00<00:00,  3.47it/s]100%|██████████| 2/2 [00:00<00:00,  3.56it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.7652435898780823
Epoch 1, Loop Feat 0: -0.7576913833618164
Epoch 1, Loop Adj 0: -0.7328219413757324
Epoch 2: -0.7328219413757324
Mem used: 838MB
best_loss: tensor(-0.7585, device='cuda:1')
best_loss: tensor(-0.7641, device='cuda:1')
final loss: -0.7912524938583374
Test:
Test: 0.5210468075222983
0.5210468075222983
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344159165859445, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987161352804
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.84it/s]100%|██████████| 2/2 [00:00<00:00,  3.87it/s]100%|██████████| 2/2 [00:00<00:00,  3.86it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.6332309246063232
Epoch 1, Loop Feat 0: -0.6581346988677979
Epoch 1, Loop Adj 0: -0.7291544079780579
Epoch 2: -0.7291544079780579
Mem used: 816MB
best_loss: tensor(-0.8604, device='cuda:1')
best_loss: tensor(-0.8628, device='cuda:1')
final loss: -0.8559485673904419
Test:
Test: 0.581392088420175
0.581392088420175
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804276586151
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.93it/s]100%|██████████| 2/2 [00:00<00:00,  5.09it/s]100%|██████████| 2/2 [00:00<00:00,  5.19it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.7130646705627441
Epoch 1, Loop Feat 0: -0.713239312171936
Epoch 1, Loop Adj 0: -0.7819399833679199
Epoch 2: -0.7819399833679199
Mem used: 674MB
best_loss: tensor(-0.9074, device='cuda:1')
best_loss: tensor(-0.9074, device='cuda:1')
final loss: -0.9063432216644287
Test:
Test: 0.5914228334693213
0.5914228334693213
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887516929199
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.76it/s]100%|██████████| 2/2 [00:00<00:00,  4.42it/s]100%|██████████| 2/2 [00:00<00:00,  4.30it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.6978302001953125
Epoch 1, Loop Feat 0: -0.6885762214660645
Epoch 1, Loop Adj 0: -0.7666448950767517
Epoch 2: -0.7666448950767517
Mem used: 674MB
best_loss: tensor(-0.9058, device='cuda:1')
final loss: -0.8942786455154419
Test:
Test: 0.5911556630750577
0.5911556630750577
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205531217034048, 0.576750097652589, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168073918161
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.21it/s]100%|██████████| 2/2 [00:00<00:00,  3.46it/s]100%|██████████| 2/2 [00:00<00:00,  3.41it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.6793412566184998
Epoch 1, Loop Feat 0: -0.681548535823822
Epoch 1, Loop Adj 0: -0.7522132992744446
Epoch 2: -0.7522132992744446
Mem used: 674MB
best_loss: tensor(-0.8772, device='cuda:1')
final loss: -0.8826825618743896
Test:
Test: 0.5821899457191733
0.5821899457191733
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127724783887
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.23it/s]100%|██████████| 2/2 [00:00<00:00,  3.30it/s]100%|██████████| 2/2 [00:00<00:00,  3.40it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.7100446224212646
Epoch 1, Loop Feat 0: -0.7065301537513733
Epoch 1, Loop Adj 0: -0.7669042348861694
Epoch 2: -0.7669042348861694
Mem used: 1197MB
best_loss: tensor(-0.8806, device='cuda:1')
best_loss: tensor(-0.8817, device='cuda:1')
final loss: -0.8870409727096558
Test:
Test: 0.5808496455414992
0.5808496455414992
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179836213682554, 0.6310911560836675, 0.6278801467147008, 0.5383905009484999, 0.5426401818150064]
flatten test: 0.5974796051215137
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.72it/s]100%|██████████| 2/2 [00:00<00:00,  4.60it/s]100%|██████████| 2/2 [00:00<00:00,  4.74it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.6692199110984802
Epoch 1, Loop Feat 0: -0.6617691516876221
Epoch 1, Loop Adj 0: -0.744401752948761
Epoch 2: -0.744401752948761
Mem used: 854MB
best_loss: tensor(-0.8922, device='cuda:1')
best_loss: tensor(-0.8940, device='cuda:1')
final loss: -0.8955386281013489
Test:
Test: 0.6028104800377208
0.6028104800377208
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483298164245
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.71it/s]100%|██████████| 2/2 [00:00<00:00,  8.50it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.6842021942138672
Epoch 1, Loop Feat 0: -0.6806269884109497
Epoch 1, Loop Adj 0: -0.7357063889503479
Epoch 2: -0.7357063889503479
Mem used: 848MB
best_loss: tensor(-0.8579, device='cuda:1')
final loss: -0.8837998509407043
Test:
Test: 0.5654021766344617
0.5654021766344617
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875724, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890580086391
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.77it/s]100%|██████████| 2/2 [00:00<00:00,  6.55it/s]100%|██████████| 2/2 [00:00<00:00,  6.57it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.7013940215110779
Epoch 1, Loop Feat 0: -0.6899392008781433
Epoch 1, Loop Adj 0: -0.7847253084182739
Epoch 2: -0.7847253084182739
Mem used: 674MB
best_loss: tensor(-0.8984, device='cuda:1')
best_loss: tensor(-0.8990, device='cuda:1')
final loss: -0.8996185660362244
Test:
Test: 0.5733392462704967
0.5733392462704967
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483719525047425, 0.5836708161590052]
flatten test: 0.6034946105998013
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.58it/s]100%|██████████| 2/2 [00:00<00:00,  5.31it/s]100%|██████████| 2/2 [00:00<00:00,  5.46it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.7123937606811523
Epoch 1, Loop Feat 0: -0.7158887386322021
Epoch 1, Loop Adj 0: -0.7943779230117798
Epoch 2: -0.7943779230117798
Mem used: 674MB
best_loss: tensor(-0.9019, device='cuda:1')
best_loss: tensor(-0.9044, device='cuda:1')
final loss: -0.9143087863922119
Test:
Test: 0.5849600265113098
0.5849600265113098
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.5937196262431264, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747765727113
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.03it/s]100%|██████████| 2/2 [00:00<00:00,  6.31it/s]100%|██████████| 2/2 [00:00<00:00,  6.07it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.7652435898780823
Epoch 1, Loop Feat 0: -0.7576915621757507
Epoch 1, Loop Adj 0: -0.7325337529182434
Epoch 2: -0.7325337529182434
Mem used: 674MB
best_loss: tensor(-0.7469, device='cuda:1')
best_loss: tensor(-0.7626, device='cuda:1')
final loss: -0.7901273369789124
Test:
Test: 0.5208246752173903
0.5208246752173903
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987161352804
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.74it/s]100%|██████████| 2/2 [00:00<00:00,  3.94it/s]100%|██████████| 2/2 [00:00<00:00,  4.04it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.6332309246063232
Epoch 1, Loop Feat 0: -0.6581346988677979
Epoch 1, Loop Adj 0: -0.7291544079780579
Epoch 2: -0.7291544079780579
Mem used: 956MB
best_loss: tensor(-0.8543, device='cuda:1')
best_loss: tensor(-0.8629, device='cuda:1')
final loss: -0.8563545346260071
Test:
Test: 0.5784918181598661
0.5784918181598661
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804221142385
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.67it/s]100%|██████████| 2/2 [00:00<00:00,  4.55it/s]100%|██████████| 2/2 [00:00<00:00,  4.51it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.7130646705627441
Epoch 1, Loop Feat 0: -0.713239312171936
Epoch 1, Loop Adj 0: -0.7819399833679199
Epoch 2: -0.7819399833679199
Mem used: 674MB
best_loss: tensor(-0.9030, device='cuda:1')
best_loss: tensor(-0.9074, device='cuda:1')
final loss: -0.9068571925163269
Test:
Test: 0.5913335118970456
0.5913335118970456
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280594765278374, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887516929199
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.78it/s]100%|██████████| 2/2 [00:00<00:00,  4.38it/s]100%|██████████| 2/2 [00:00<00:00,  4.38it/s]
Epoch 0, Loop Feat 0: -0.40305694937705994
Epoch 0, Loop Adj 0: -0.6978302001953125
Epoch 1, Loop Feat 0: -0.6885762214660645
Epoch 1, Loop Adj 0: -0.7666448950767517
Epoch 2: -0.7666448950767517
Mem used: 674MB
best_loss: tensor(-0.9023, device='cuda:1')
best_loss: tensor(-0.9066, device='cuda:1')
final loss: -0.8959588408470154
Test:
Test: 0.5939353551702138
0.5939353551702138
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205531717941192, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168295693226
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.96it/s]100%|██████████| 2/2 [00:00<00:00,  6.14it/s]100%|██████████| 2/2 [00:00<00:00,  6.10it/s]
Epoch 0, Loop Feat 0: -0.35880887508392334
Epoch 0, Loop Adj 0: -0.6793412566184998
Epoch 1, Loop Feat 0: -0.681548535823822
Epoch 1, Loop Adj 0: -0.7522132992744446
Epoch 2: -0.7522132992744446
Mem used: 822MB
best_loss: tensor(-0.8747, device='cuda:1')
best_loss: tensor(-0.8767, device='cuda:1')
final loss: -0.8828432559967041
Test:
Test: 0.578901768034935
0.578901768034935
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127724783887
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  2.83it/s]100%|██████████| 2/2 [00:00<00:00,  3.22it/s]100%|██████████| 2/2 [00:00<00:00,  3.13it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.7100446224212646
Epoch 1, Loop Feat 0: -0.7065301537513733
Epoch 1, Loop Adj 0: -0.7669042348861694
Epoch 2: -0.7669042348861694
Mem used: 922MB
best_loss: tensor(-0.8790, device='cuda:1')
best_loss: tensor(-0.8814, device='cuda:1')
final loss: -0.8881572484970093
Test:
Test: 0.5808434895416313
0.5808434895416313
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179836213682554, 0.6310910559022389, 0.6278801467147008, 0.5383906414670132, 0.5426401818150064]
flatten test: 0.5974795995771369
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.64it/s]100%|██████████| 2/2 [00:00<00:00,  4.60it/s]100%|██████████| 2/2 [00:00<00:00,  4.60it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.6692199110984802
Epoch 1, Loop Feat 0: -0.6617691516876221
Epoch 1, Loop Adj 0: -0.7444016933441162
Epoch 2: -0.7444016933441162
Mem used: -594MB
best_loss: tensor(-0.8870, device='cuda:1')
best_loss: tensor(-0.8916, device='cuda:1')
final loss: -0.8954123854637146
Test:
Test: 0.6044298654481124
0.6044298654481124
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483242720478
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.94it/s]100%|██████████| 2/2 [00:00<00:00,  4.61it/s]100%|██████████| 2/2 [00:00<00:00,  4.49it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.6842021942138672
Epoch 1, Loop Feat 0: -0.6806270480155945
Epoch 1, Loop Adj 0: -0.7357063293457031
Epoch 2: -0.7357063293457031
Mem used: 1410MB
best_loss: tensor(-0.8526, device='cuda:1')
best_loss: tensor(-0.8599, device='cuda:1')
final loss: -0.8865043520927429
Test:
Test: 0.5675223029889405
0.5675223029889405
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890746417688
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.00it/s]100%|██████████| 2/2 [00:00<00:00,  4.49it/s]100%|██████████| 2/2 [00:00<00:00,  4.56it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.7013940215110779
Epoch 1, Loop Feat 0: -0.6899392008781433
Epoch 1, Loop Adj 0: -0.7847253084182739
Epoch 2: -0.7847253084182739
Mem used: 994MB
best_loss: tensor(-0.8956, device='cuda:1')
best_loss: tensor(-0.8988, device='cuda:1')
final loss: -0.9003967046737671
Test:
Test: 0.5731501975003621
0.5731501975003621
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483719525047425, 0.5836708161590052]
flatten test: 0.6034946105998013
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.61it/s]100%|██████████| 2/2 [00:00<00:00,  6.85it/s]100%|██████████| 2/2 [00:00<00:00,  6.69it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.7123950719833374
Epoch 1, Loop Feat 0: -0.7158836126327515
Epoch 1, Loop Adj 0: -0.7943513989448547
Epoch 2: -0.7943513989448547
Mem used: 758MB
best_loss: tensor(-0.8970, device='cuda:1')
best_loss: tensor(-0.9043, device='cuda:1')
final loss: -0.9150585532188416
Test:
Test: 0.5857752397583227
0.5857752397583227
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.5937196262431264, 0.6002883018849671, 0.5401741024379962, 0.5824575153695682]
flatten test: 0.587874765483958
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.13it/s]100%|██████████| 2/2 [00:00<00:00,  7.72it/s]100%|██████████| 2/2 [00:00<00:00,  7.07it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.765243649482727
Epoch 1, Loop Feat 0: -0.7576658725738525
Epoch 1, Loop Adj 0: -0.7329513430595398
Epoch 2: -0.7329513430595398
Mem used: -893MB
best_loss: tensor(-0.7580, device='cuda:1')
best_loss: tensor(-0.7623, device='cuda:1')
final loss: -0.7890793681144714
Test:
Test: 0.5194970444846054
0.5194970444846054
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097034228988698, 0.6344165212459382, 0.5449365558912387, 0.5785921999441106]
flatten test: 0.6046987105909036
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.32it/s]100%|██████████| 2/2 [00:00<00:00,  8.54it/s]100%|██████████| 2/2 [00:00<00:00,  8.32it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.6332309246063232
Epoch 1, Loop Feat 0: -0.6584063768386841
Epoch 1, Loop Adj 0: -0.7288381457328796
Epoch 2: -0.7288381457328796
Mem used: 674MB
best_loss: tensor(-0.8616, device='cuda:1')
best_loss: tensor(-0.8631, device='cuda:1')
final loss: -0.8569844365119934
Test:
Test: 0.5800955951318829
0.5800955951318829
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804387473683
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  2.87it/s]100%|██████████| 2/2 [00:00<00:00,  4.00it/s]100%|██████████| 2/2 [00:00<00:00,  3.77it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.7130646705627441
Epoch 1, Loop Feat 0: -0.7116100788116455
Epoch 1, Loop Adj 0: -0.7821462750434875
Epoch 2: -0.7821462750434875
Mem used: 674MB
best_loss: tensor(-0.9084, device='cuda:1')
final loss: -0.9067498445510864
Test:
Test: 0.5918868767109708
0.5918868767109708
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280594765278374, 0.6163420454442996, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887350597901
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.31it/s]100%|██████████| 2/2 [00:00<00:00,  4.92it/s]100%|██████████| 2/2 [00:00<00:00,  5.10it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.6978302001953125
Epoch 1, Loop Feat 0: -0.6866936087608337
Epoch 1, Loop Adj 0: -0.7665714621543884
Epoch 2: -0.7665714621543884
Mem used: 1016MB
best_loss: tensor(-0.9066, device='cuda:1')
best_loss: tensor(-0.9068, device='cuda:1')
final loss: -0.8956278562545776
Test:
Test: 0.5927819988078807
0.5927819988078807
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205532218848335, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168295693226
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.98it/s]100%|██████████| 2/2 [00:00<00:00,  3.56it/s]100%|██████████| 2/2 [00:00<00:00,  3.16it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.6793412566184998
Epoch 1, Loop Feat 0: -0.679261326789856
Epoch 1, Loop Adj 0: -0.7526415586471558
Epoch 2: -0.7526415586471558
Mem used: 1012MB
best_loss: tensor(-0.8788, device='cuda:1')
best_loss: tensor(-0.8788, device='cuda:1')
final loss: -0.8853476643562317
Test:
Test: 0.5810535481435729
0.5810535481435729
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127891115185
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  8.29it/s]100%|██████████| 2/2 [00:00<00:00,  7.83it/s]100%|██████████| 2/2 [00:00<00:00,  7.87it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.7100446224212646
Epoch 1, Loop Feat 0: -0.7065195441246033
Epoch 1, Loop Adj 0: -0.763104259967804
Epoch 2: -0.763104259967804
Mem used: 778MB
best_loss: tensor(-0.8820, device='cuda:1')
final loss: -0.8887639045715332
Test:
Test: 0.5834847709300819
0.5834847709300819
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310910559022389, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974795884883838
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.08it/s]100%|██████████| 2/2 [00:00<00:00,  6.57it/s]100%|██████████| 2/2 [00:00<00:00,  6.29it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.669219970703125
Epoch 1, Loop Feat 0: -0.6614341735839844
Epoch 1, Loop Adj 0: -0.7429019808769226
Epoch 2: -0.7429019808769226
Mem used: 674MB
best_loss: tensor(-0.8938, device='cuda:1')
best_loss: tensor(-0.8940, device='cuda:1')
final loss: -0.8966148495674133
Test:
Test: 0.6032632041828392
0.6032632041828392
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483298164243
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.08it/s]100%|██████████| 2/2 [00:00<00:00,  6.08it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.6842021942138672
Epoch 1, Loop Feat 0: -0.6805775165557861
Epoch 1, Loop Adj 0: -0.7368014454841614
Epoch 2: -0.7368014454841614
Mem used: 685MB
best_loss: tensor(-0.8615, device='cuda:1')
best_loss: tensor(-0.8620, device='cuda:1')
final loss: -0.8852220177650452
Test:
Test: 0.5679903972756642
0.5679903972756642
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875724, 0.6335276710552888, 0.5433284620248718, 0.5756913030948722]
flatten test: 0.5981890635530157
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.01it/s]100%|██████████| 2/2 [00:00<00:00,  5.45it/s]100%|██████████| 2/2 [00:00<00:00,  5.63it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.7013940215110779
Epoch 1, Loop Feat 0: -0.6874312162399292
Epoch 1, Loop Adj 0: -0.7828161120414734
Epoch 2: -0.7828161120414734
Mem used: 1174MB
best_loss: tensor(-0.8990, device='cuda:1')
best_loss: tensor(-0.8995, device='cuda:1')
final loss: -0.9003834128379822
Test:
Test: 0.5711663371816673
0.5711663371816673
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.005, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232557, 0.5836708161590052]
flatten test: 0.6034946105998014
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.98it/s]100%|██████████| 2/2 [00:00<00:00,  5.01it/s]100%|██████████| 2/2 [00:00<00:00,  5.00it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.7123950123786926
Epoch 1, Loop Feat 0: -0.7141732573509216
Epoch 1, Loop Adj 0: -0.7939214110374451
Epoch 2: -0.7939214110374451
Mem used: 736MB
best_loss: tensor(-0.9046, device='cuda:1')
best_loss: tensor(-0.9046, device='cuda:1')
final loss: -0.9151710271835327
Test:
Test: 0.5836815643452113
0.5836815643452113
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.5937196262431264, 0.6002883018849671, 0.5401741024379962, 0.5824575153695682]
flatten test: 0.5878747710283345
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.71it/s]100%|██████████| 1/1 [00:00<00:00,  4.70it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.686050534248352
Epoch 1: -0.686050534248352
Mem used: 674MB
best_loss: tensor(-0.8064, device='cuda:1')
best_loss: tensor(-0.8096, device='cuda:1')
final loss: -0.7747521996498108
Test:
Test: 0.5956999030291014
0.5956999030291014
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.644284027479605, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987105909036
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.23it/s]100%|██████████| 1/1 [00:00<00:00,  5.21it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.5354421734809875
Epoch 1: -0.5354421734809875
Mem used: -529MB
best_loss: tensor(-0.7132, device='cuda:1')
best_loss: tensor(-0.7158, device='cuda:1')
final loss: -0.6623319387435913
Test:
Test: 0.5985931435347227
0.5985931435347227
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405996180406469, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.606580444291745
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.25it/s]100%|██████████| 1/1 [00:00<00:00,  4.24it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.49716970324516296
Epoch 1: -0.49716970324516296
Mem used: 674MB
best_loss: tensor(-0.6330, device='cuda:1')
final loss: -0.5834753513336182
Test:
Test: 0.6083419437899227
0.6083419437899227
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280594765278374, 0.616342095535014, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887461485434
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.20it/s]100%|██████████| 1/1 [00:00<00:00,  6.19it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.5564684867858887
Epoch 1: -0.5564684867858887
Mem used: 674MB
best_loss: tensor(-0.7005, device='cuda:1')
best_loss: tensor(-0.7006, device='cuda:1')
final loss: -0.6514332294464111
Test:
Test: 0.612458679340242
0.612458679340242
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205531217034048, 0.576750097652589, 0.5493891660226236, 0.5826381732918821]
flatten test: 0.5907168018474395
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.28it/s]100%|██████████| 1/1 [00:00<00:00,  4.28it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.528098464012146
Epoch 1: -0.528098464012146
Mem used: 788MB
best_loss: tensor(-0.6780, device='cuda:1')
final loss: -0.6360345482826233
Test:
Test: 0.6014702990084313
0.6014702990084313
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127946558952
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.35it/s]100%|██████████| 1/1 [00:00<00:00,  5.33it/s]
Epoch 0, Loop Feat 0: -0.4249717593193054
Epoch 0, Loop Adj 0: -0.5801600217819214
Epoch 1: -0.5801600217819214
Mem used: 686MB
best_loss: tensor(-0.7304, device='cuda:1')
best_loss: tensor(-0.7354, device='cuda:1')
final loss: -0.696571946144104
Test:
Test: 0.6054056510013548
0.6054056510013548
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310910559022389, 0.6278801467147008, 0.5383905009484999, 0.5426401818150064]
flatten test: 0.5974795884883838
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  8.97it/s]100%|██████████| 1/1 [00:00<00:00,  8.92it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.45483046770095825
Epoch 1: -0.45483046770095825
Mem used: 732MB
best_loss: tensor(-0.5648, device='cuda:1')
final loss: -0.5248779058456421
Test:
Test: 0.6118684182432381
0.6118684182432381
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483298164243
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  2.72it/s]100%|██████████| 1/1 [00:00<00:00,  2.71it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.5451187491416931
Epoch 1: -0.5451187491416931
Mem used: 1072MB
best_loss: tensor(-0.6606, device='cuda:1')
best_loss: tensor(-0.6662, device='cuda:1')
final loss: -0.6370120644569397
Test:
Test: 0.59819832550449
0.59819832550449
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890746417691
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.78it/s]100%|██████████| 1/1 [00:00<00:00,  4.66it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.5750350952148438
Epoch 1: -0.5750350952148438
Mem used: 788MB
best_loss: tensor(-0.6974, device='cuda:1')
best_loss: tensor(-0.7025, device='cuda:1')
final loss: -0.679090678691864
Test:
Test: 0.6039245968654124
0.6039245968654124
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232557, 0.5836708161590052]
flatten test: 0.6034946105998013
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.67it/s]100%|██████████| 1/1 [00:00<00:00,  3.51it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.5563409924507141
Epoch 1: -0.5563409924507141
Mem used: 674MB
best_loss: tensor(-0.7230, device='cuda:1')
best_loss: tensor(-0.7277, device='cuda:1')
final loss: -0.6745167970657349
Test:
Test: 0.6084297958654556
0.6084297958654556
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.593719576152412, 0.6002883018849671, 0.5401741024379962, 0.5824575153695682]
flatten test: 0.5878747710283345
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.19it/s]100%|██████████| 1/1 [00:00<00:00,  3.19it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.686050534248352
Epoch 1: -0.686050534248352
Mem used: 141MB
best_loss: tensor(-0.8018, device='cuda:1')
best_loss: tensor(-0.8089, device='cuda:1')
final loss: -0.7790924906730652
Test:
Test: 0.5945209694802207
0.5945209694802207
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.644284027479605, 0.6097034228988698, 0.6344159165859445, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987105909037
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.13it/s]100%|██████████| 1/1 [00:00<00:00,  3.12it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.5354421734809875
Epoch 1: -0.5354421734809875
Mem used: 674MB
best_loss: tensor(-0.7112, device='cuda:1')
best_loss: tensor(-0.7175, device='cuda:1')
final loss: -0.6686740517616272
Test:
Test: 0.59846644908583
0.59846644908583
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804387473683
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.59it/s]100%|██████████| 1/1 [00:00<00:00,  3.58it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.49716970324516296
Epoch 1: -0.49716970324516296
Mem used: 830MB
best_loss: tensor(-0.6327, device='cuda:1')
best_loss: tensor(-0.6332, device='cuda:1')
final loss: -0.5863572955131531
Test:
Test: 0.6100265430827849
0.6100265430827849
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280594765278374, 0.6163421456257283, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887516929199
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.06it/s]100%|██████████| 1/1 [00:00<00:00,  4.05it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.5564684867858887
Epoch 1: -0.5564684867858887
Mem used: -106MB
best_loss: tensor(-0.7014, device='cuda:1')
best_loss: tensor(-0.7078, device='cuda:1')
final loss: -0.6596541404724121
Test:
Test: 0.6100321430568583
0.6100321430568583
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205531717941192, 0.5767507023125826, 0.5493891660226236, 0.5826381732918821]
flatten test: 0.5907168073918162
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.67it/s]100%|██████████| 1/1 [00:00<00:00,  4.66it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.528098464012146
Epoch 1: -0.528098464012146
Mem used: 834MB
best_loss: tensor(-0.6795, device='cuda:1')
best_loss: tensor(-0.6887, device='cuda:1')
final loss: -0.6510166525840759
Test:
Test: 0.6026753260535259
0.6026753260535259
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127724783887
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  2.26it/s]100%|██████████| 1/1 [00:00<00:00,  2.26it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.5801600217819214
Epoch 1: -0.5801600217819214
Mem used: -594MB
best_loss: tensor(-0.7388, device='cuda:1')
best_loss: tensor(-0.7456, device='cuda:1')
final loss: -0.7037687301635742
Test:
Test: 0.6085784533332317
0.6085784533332317
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179836213682554, 0.6310910058115247, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.597479599577137
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.74it/s]100%|██████████| 1/1 [00:00<00:00,  4.41it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.45483046770095825
Epoch 1: -0.45483046770095825
Mem used: 674MB
best_loss: tensor(-0.5629, device='cuda:1')
best_loss: tensor(-0.5662, device='cuda:1')
final loss: -0.5294688940048218
Test:
Test: 0.6113368575836835
0.6113368575836835
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483353608009
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.42it/s]100%|██████████| 1/1 [00:00<00:00,  5.41it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.5451187491416931
Epoch 1: -0.5451187491416931
Mem used: 674MB
best_loss: tensor(-0.6623, device='cuda:1')
best_loss: tensor(-0.6728, device='cuda:1')
final loss: -0.6436518430709839
Test:
Test: 0.5960082590482872
0.5960082590482872
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890857305222
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.01it/s]100%|██████████| 1/1 [00:00<00:00,  4.00it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.5750350952148438
Epoch 1: -0.5750350952148438
Mem used: 778MB
best_loss: tensor(-0.6982, device='cuda:1')
best_loss: tensor(-0.7106, device='cuda:1')
final loss: -0.6850813031196594
Test:
Test: 0.6042482435939474
0.6042482435939474
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303430701660226, 0.6145207971636634, 0.6325989133050594, 0.5483719525047425, 0.5836708161590052]
flatten test: 0.6034945995110481
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.51it/s]100%|██████████| 1/1 [00:00<00:00,  6.49it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.5563409924507141
Epoch 1: -0.5563409924507141
Mem used: 674MB
best_loss: tensor(-0.7215, device='cuda:1')
best_loss: tensor(-0.7290, device='cuda:1')
final loss: -0.6801378130912781
Test:
Test: 0.6084137902657993
0.6084137902657993
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.593719576152412, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.587874765483958
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.85it/s]100%|██████████| 1/1 [00:00<00:00,  3.84it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.686050534248352
Epoch 1: -0.686050534248352
Mem used: 674MB
best_loss: tensor(-0.8093, device='cuda:1')
final loss: -0.7710564732551575
Test:
Test: 0.593803974218196
0.593803974218196
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987105909037
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.29it/s]100%|██████████| 1/1 [00:00<00:00,  5.27it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.5354421734809875
Epoch 1: -0.5354421734809875
Mem used: 674MB
best_loss: tensor(-0.7149, device='cuda:1')
final loss: -0.6641701459884644
Test:
Test: 0.598379510481245
0.598379510481245
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.614043983654398, 0.6456251035480238, 0.5428112133773624, 0.5562247297226491]
flatten test: 0.606580444291745
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.18it/s]100%|██████████| 1/1 [00:00<00:00,  5.16it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.49716970324516296
Epoch 1: -0.49716970324516296
Mem used: 838MB
best_loss: tensor(-0.6246, device='cuda:1')
final loss: -0.5764954686164856
Test:
Test: 0.6085782150364625
0.6085782150364625
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280594765278374, 0.6163420955350138, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887461485433
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.92it/s]100%|██████████| 1/1 [00:00<00:00,  4.91it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.5564684867858887
Epoch 1: -0.5564684867858887
Mem used: 674MB
best_loss: tensor(-0.7006, device='cuda:1')
final loss: -0.6532577276229858
Test:
Test: 0.6113723240861478
0.6113723240861478
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205530716126906, 0.576750097652589, 0.5493891660226234, 0.5826381732918821]
flatten test: 0.5907167907586862
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.56it/s]100%|██████████| 1/1 [00:00<00:00,  5.55it/s]
Epoch 0, Loop Feat 0: -0.35880887508392334
Epoch 0, Loop Adj 0: -0.528098464012146
Epoch 1: -0.528098464012146
Mem used: 674MB
best_loss: tensor(-0.6776, device='cuda:1')
final loss: -0.6358343958854675
Test:
Test: 0.6016895717521104
0.6016895717521104
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127835671419
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  2.97it/s]100%|██████████| 1/1 [00:00<00:00,  2.96it/s]
Epoch 0, Loop Feat 0: -0.4249717891216278
Epoch 0, Loop Adj 0: -0.5801600217819214
Epoch 1: -0.5801600217819214
Mem used: 674MB
best_loss: tensor(-0.7325, device='cuda:1')
final loss: -0.694154679775238
Test:
Test: 0.6054896903285827
0.6054896903285827
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310911059929533, 0.6278801467147008, 0.5383906414670132, 0.5426401818150064]
flatten test: 0.5974796106658903
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.30it/s]100%|██████████| 1/1 [00:00<00:00,  5.29it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.45483046770095825
Epoch 1: -0.45483046770095825
Mem used: 1050MB
best_loss: tensor(-0.5607, device='cuda:1')
final loss: -0.5222133994102478
Test:
Test: 0.6114477450135607
0.6114477450135607
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483242720478
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.54it/s]100%|██████████| 1/1 [00:00<00:00,  3.53it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.5451187491416931
Epoch 1: -0.5451187491416931
Mem used: 1030MB
best_loss: tensor(-0.6626, device='cuda:1')
final loss: -0.6328694820404053
Test:
Test: 0.5961755036640511
0.5961755036640511
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890690973923
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.95it/s]100%|██████████| 1/1 [00:00<00:00,  7.92it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.5750350952148438
Epoch 1: -0.5750350952148438
Mem used: 674MB
best_loss: tensor(-0.6962, device='cuda:1')
best_loss: tensor(-0.6965, device='cuda:1')
final loss: -0.6740047335624695
Test:
Test: 0.604396186171416
0.604396186171416
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483719525047425, 0.5836708161590052]
flatten test: 0.6034946050554246
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.67it/s]100%|██████████| 1/1 [00:00<00:00,  3.60it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.5563409924507141
Epoch 1: -0.5563409924507141
Mem used: 674MB
best_loss: tensor(-0.7257, device='cuda:1')
best_loss: tensor(-0.7266, device='cuda:1')
final loss: -0.6736124753952026
Test:
Test: 0.6068108870486024
0.6068108870486024
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.593719576152412, 0.6002883018849671, 0.5401741024379962, 0.5824575153695682]
flatten test: 0.5878747765727113
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.23it/s]100%|██████████| 2/2 [00:00<00:00,  4.55it/s]100%|██████████| 2/2 [00:00<00:00,  4.28it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.6860505938529968
Epoch 1, Loop Feat 0: -0.6964092254638672
Epoch 1, Loop Adj 0: -0.7448997497558594
Epoch 2: -0.7448997497558594
Mem used: -413MB
best_loss: tensor(-0.8362, device='cuda:1')
best_loss: tensor(-0.8377, device='cuda:1')
final loss: -0.8262713551521301
Test:
Test: 0.586644387507403
0.586644387507403
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987105909037
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.32it/s]100%|██████████| 2/2 [00:00<00:00,  7.09it/s]100%|██████████| 2/2 [00:00<00:00,  7.10it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.5354421734809875
Epoch 1, Loop Feat 0: -0.5595853328704834
Epoch 1, Loop Adj 0: -0.6284939646720886
Epoch 2: -0.6284939646720886
Mem used: 674MB
best_loss: tensor(-0.7799, device='cuda:1')
best_loss: tensor(-0.7821, device='cuda:1')
final loss: -0.7437562942504883
Test:
Test: 0.6001221747535058
0.6001221747535058
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405996180406469, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804498361215
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.56it/s]100%|██████████| 2/2 [00:00<00:00,  6.19it/s]100%|██████████| 2/2 [00:00<00:00,  5.87it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.49716970324516296
Epoch 1, Loop Feat 0: -0.49217480421066284
Epoch 1, Loop Adj 0: -0.6042203903198242
Epoch 2: -0.6042203903198242
Mem used: 674MB
best_loss: tensor(-0.7571, device='cuda:1')
final loss: -0.7140790224075317
Test:
Test: 0.6075278425944989
0.6075278425944989
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887572372965
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.42it/s]100%|██████████| 2/2 [00:00<00:00,  7.52it/s]100%|██████████| 2/2 [00:00<00:00,  7.24it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.5564684867858887
Epoch 1, Loop Feat 0: -0.5511734485626221
Epoch 1, Loop Adj 0: -0.628646731376648
Epoch 2: -0.628646731376648
Mem used: 1526MB
best_loss: tensor(-0.7852, device='cuda:1')
final loss: -0.7509424090385437
Test:
Test: 0.6115412764954233
0.6115412764954233
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205531717941192, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.590716824024946
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.15it/s]100%|██████████| 2/2 [00:00<00:00,  4.65it/s]100%|██████████| 2/2 [00:00<00:00,  4.78it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.528098464012146
Epoch 1, Loop Feat 0: -0.5394728779792786
Epoch 1, Loop Adj 0: -0.6134523749351501
Epoch 2: -0.6134523749351501
Mem used: 824MB
best_loss: tensor(-0.7618, device='cuda:1')
final loss: -0.7382686734199524
Test:
Test: 0.5990838760145089
0.5990838760145089
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127835671419
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.92it/s]100%|██████████| 2/2 [00:00<00:00,  5.65it/s]100%|██████████| 2/2 [00:00<00:00,  5.52it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.5801600217819214
Epoch 1, Loop Feat 0: -0.5945892930030823
Epoch 1, Loop Adj 0: -0.6657118201255798
Epoch 2: -0.6657118201255798
Mem used: -594MB
best_loss: tensor(-0.8162, device='cuda:1')
final loss: -0.7894020080566406
Test:
Test: 0.6043912216553936
0.6043912216553936
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179836213682554, 0.6310911059929533, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974796106658903
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.81it/s]100%|██████████| 2/2 [00:00<00:00,  3.79it/s]100%|██████████| 2/2 [00:00<00:00,  3.61it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.45483046770095825
Epoch 1, Loop Feat 0: -0.45529818534851074
Epoch 1, Loop Adj 0: -0.5528035759925842
Epoch 2: -0.5528035759925842
Mem used: 674MB
best_loss: tensor(-0.6845, device='cuda:1')
final loss: -0.6539887189865112
Test:
Test: 0.6113967892211063
0.6113967892211063
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483242720478
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.71it/s]100%|██████████| 2/2 [00:00<00:00,  6.72it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.5451187491416931
Epoch 1, Loop Feat 0: -0.5467809438705444
Epoch 1, Loop Adj 0: -0.6125560402870178
Epoch 2: -0.6125560402870178
Mem used: 674MB
best_loss: tensor(-0.7399, device='cuda:1')
final loss: -0.7196645736694336
Test:
Test: 0.5940439787807847
0.5940439787807847
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248718, 0.5756913030948722]
flatten test: 0.5981890801861456
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.26it/s]100%|██████████| 2/2 [00:00<00:00,  4.44it/s]100%|██████████| 2/2 [00:00<00:00,  4.41it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.5750350952148438
Epoch 1, Loop Feat 0: -0.5707768797874451
Epoch 1, Loop Adj 0: -0.6461136341094971
Epoch 2: -0.6461136341094971
Mem used: 818MB
best_loss: tensor(-0.7654, device='cuda:1')
best_loss: tensor(-0.7668, device='cuda:1')
final loss: -0.7616191506385803
Test:
Test: 0.6010358442822755
0.6010358442822755
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483719525047425, 0.5836708161590052]
flatten test: 0.6034945939666715
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.47it/s]100%|██████████| 2/2 [00:00<00:00,  4.22it/s]100%|██████████| 2/2 [00:00<00:00,  4.25it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.5563409924507141
Epoch 1, Loop Feat 0: -0.5692532658576965
Epoch 1, Loop Adj 0: -0.6455729007720947
Epoch 2: -0.6455729007720947
Mem used: -849MB
best_loss: tensor(-0.7953, device='cuda:1')
best_loss: tensor(-0.7993, device='cuda:1')
final loss: -0.768415093421936
Test:
Test: 0.6077388543835167
0.6077388543835167
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.5937196262431264, 0.6002883018849671, 0.5401741024379962, 0.5824575153695682]
flatten test: 0.587874793205841
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  8.16it/s]100%|██████████| 2/2 [00:00<00:00,  9.10it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.686050534248352
Epoch 1, Loop Feat 0: -0.7124640345573425
Epoch 1, Loop Adj 0: -0.7528998851776123
Epoch 2: -0.7528998851776123
Mem used: 674MB
best_loss: tensor(-0.8335, device='cuda:1')
best_loss: tensor(-0.8405, device='cuda:1')
final loss: -0.8251644968986511
Test:
Test: 0.587395498923534
0.587395498923534
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987105909036
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.91it/s]100%|██████████| 2/2 [00:00<00:00,  8.43it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.5354421734809875
Epoch 1, Loop Feat 0: -0.5688880681991577
Epoch 1, Loop Adj 0: -0.6350508332252502
Epoch 2: -0.6350508332252502
Mem used: 674MB
best_loss: tensor(-0.7819, device='cuda:1')
best_loss: tensor(-0.7846, device='cuda:1')
final loss: -0.7484357953071594
Test:
Test: 0.6002473202733994
0.6002473202733994
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804221142385
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.80it/s]100%|██████████| 2/2 [00:00<00:00,  3.46it/s]100%|██████████| 2/2 [00:00<00:00,  3.60it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.49716970324516296
Epoch 1, Loop Feat 0: -0.5008334517478943
Epoch 1, Loop Adj 0: -0.6110386252403259
Epoch 2: -0.6110386252403259
Mem used: 898MB
best_loss: tensor(-0.7563, device='cuda:1')
best_loss: tensor(-0.7578, device='cuda:1')
final loss: -0.7175399661064148
Test:
Test: 0.6069608948647364
0.6069608948647364
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163420955350138, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887516929199
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.44it/s]100%|██████████| 2/2 [00:00<00:00,  4.22it/s]100%|██████████| 2/2 [00:00<00:00,  4.07it/s]
Epoch 0, Loop Feat 0: -0.40305694937705994
Epoch 0, Loop Adj 0: -0.5564684867858887
Epoch 1, Loop Feat 0: -0.5590135455131531
Epoch 1, Loop Adj 0: -0.6370231509208679
Epoch 2: -0.6370231509208679
Mem used: 788MB
best_loss: tensor(-0.7817, device='cuda:1')
best_loss: tensor(-0.7879, device='cuda:1')
final loss: -0.7558726072311401
Test:
Test: 0.6124669800110316
0.6124669800110316
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205531217034048, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168073918162
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.06it/s]100%|██████████| 2/2 [00:00<00:00,  6.16it/s]100%|██████████| 2/2 [00:00<00:00,  5.71it/s]
Epoch 0, Loop Feat 0: -0.35880887508392334
Epoch 0, Loop Adj 0: -0.528098464012146
Epoch 1, Loop Feat 0: -0.5593225359916687
Epoch 1, Loop Adj 0: -0.624099850654602
Epoch 2: -0.624099850654602
Mem used: 674MB
best_loss: tensor(-0.7647, device='cuda:1')
best_loss: tensor(-0.7683, device='cuda:1')
final loss: -0.7400447130203247
Test:
Test: 0.5991071099494938
0.5991071099494938
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127724783887
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.86it/s]100%|██████████| 2/2 [00:00<00:00,  5.67it/s]100%|██████████| 2/2 [00:00<00:00,  5.69it/s]
Epoch 0, Loop Feat 0: -0.4249717593193054
Epoch 0, Loop Adj 0: -0.5801600217819214
Epoch 1, Loop Feat 0: -0.6071678996086121
Epoch 1, Loop Adj 0: -0.6778581142425537
Epoch 2: -0.6778581142425537
Mem used: 674MB
best_loss: tensor(-0.8148, device='cuda:1')
best_loss: tensor(-0.8201, device='cuda:1')
final loss: -0.7917101979255676
Test:
Test: 0.6058331554050791
0.6058331554050791
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179836213682554, 0.6310910559022389, 0.6278801467147008, 0.5383905009484999, 0.5426401818150064]
flatten test: 0.5974795884883838
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.21it/s]100%|██████████| 2/2 [00:00<00:00,  3.74it/s]100%|██████████| 2/2 [00:00<00:00,  3.65it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.45483046770095825
Epoch 1, Loop Feat 0: -0.4630446135997772
Epoch 1, Loop Adj 0: -0.561670184135437
Epoch 2: -0.561670184135437
Mem used: 902MB
best_loss: tensor(-0.6844, device='cuda:1')
best_loss: tensor(-0.6879, device='cuda:1')
final loss: -0.6579884886741638
Test:
Test: 0.6119320037644536
0.6119320037644536
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.600148318727671
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  2.56it/s]100%|██████████| 2/2 [00:00<00:00,  3.45it/s]100%|██████████| 2/2 [00:00<00:00,  3.28it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.5451187491416931
Epoch 1, Loop Feat 0: -0.5628519058227539
Epoch 1, Loop Adj 0: -0.6283114552497864
Epoch 2: -0.6283114552497864
Mem used: 816MB
best_loss: tensor(-0.7429, device='cuda:1')
best_loss: tensor(-0.7475, device='cuda:1')
final loss: -0.7311087250709534
Test:
Test: 0.5952236669361008
0.5952236669361008
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890801861455
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.88it/s]100%|██████████| 2/2 [00:00<00:00,  6.78it/s]100%|██████████| 2/2 [00:00<00:00,  6.62it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.5750350952148438
Epoch 1, Loop Feat 0: -0.5875573754310608
Epoch 1, Loop Adj 0: -0.6594626903533936
Epoch 2: -0.6594626903533936
Mem used: -594MB
best_loss: tensor(-0.7677, device='cuda:1')
best_loss: tensor(-0.7739, device='cuda:1')
final loss: -0.7652688026428223
Test:
Test: 0.6014383275252467
0.6014383275252467
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232557, 0.5836708161590052]
flatten test: 0.6034946105998014
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.33it/s]100%|██████████| 2/2 [00:00<00:00,  3.20it/s]100%|██████████| 2/2 [00:00<00:00,  3.33it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.5563409924507141
Epoch 1, Loop Feat 0: -0.58024001121521
Epoch 1, Loop Adj 0: -0.6550161242485046
Epoch 2: -0.6550161242485046
Mem used: 674MB
best_loss: tensor(-0.7938, device='cuda:1')
best_loss: tensor(-0.8003, device='cuda:1')
final loss: -0.7729185819625854
Test:
Test: 0.6101342532224078
0.6101342532224078
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.5937196262431264, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.587874782117088
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.37it/s]100%|██████████| 2/2 [00:00<00:00,  4.28it/s]100%|██████████| 2/2 [00:00<00:00,  4.29it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.6860488057136536
Epoch 1, Loop Feat 0: -0.6873889565467834
Epoch 1, Loop Adj 0: -0.7414032220840454
Epoch 2: -0.7414032220840454
Mem used: 1143MB
best_loss: tensor(-0.8390, device='cuda:1')
best_loss: tensor(-0.8391, device='cuda:1')
final loss: -0.8215414881706238
Test:
Test: 0.5857201534885376
0.5857201534885376
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.644284027479605, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987105909036
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.58it/s]100%|██████████| 2/2 [00:00<00:00,  4.82it/s]100%|██████████| 2/2 [00:00<00:00,  4.77it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.5354421734809875
Epoch 1, Loop Feat 0: -0.5543598532676697
Epoch 1, Loop Adj 0: -0.6250876188278198
Epoch 2: -0.6250876188278198
Mem used: 856MB
best_loss: tensor(-0.7807, device='cuda:1')
best_loss: tensor(-0.7819, device='cuda:1')
final loss: -0.741710364818573
Test:
Test: 0.6008059276162443
0.6008059276162443
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804276586151
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.73it/s]100%|██████████| 2/2 [00:00<00:00,  3.76it/s]100%|██████████| 2/2 [00:00<00:00,  3.75it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.49716970324516296
Epoch 1, Loop Feat 0: -0.4884408116340637
Epoch 1, Loop Adj 0: -0.6017580628395081
Epoch 2: -0.6017580628395081
Mem used: 870MB
best_loss: tensor(-0.7535, device='cuda:1')
final loss: -0.7114465236663818
Test:
Test: 0.6080149211904925
0.6080149211904925
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163421456257281, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887461485434
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.78it/s]100%|██████████| 2/2 [00:00<00:00,  3.77it/s]100%|██████████| 2/2 [00:00<00:00,  3.76it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.5564684867858887
Epoch 1, Loop Feat 0: -0.547982394695282
Epoch 1, Loop Adj 0: -0.6241351962089539
Epoch 2: -0.6241351962089539
Mem used: 790MB
best_loss: tensor(-0.7834, device='cuda:1')
final loss: -0.7495684027671814
Test:
Test: 0.6111561094843385
0.6111561094843385
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205532218848335, 0.576750097652589, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.590716824024946
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.66it/s]100%|██████████| 2/2 [00:00<00:00,  6.77it/s]100%|██████████| 2/2 [00:00<00:00,  6.57it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.528098464012146
Epoch 1, Loop Feat 0: -0.530495822429657
Epoch 1, Loop Adj 0: -0.6093640923500061
Epoch 2: -0.6093640923500061
Mem used: 674MB
best_loss: tensor(-0.7617, device='cuda:1')
final loss: -0.7308093905448914
Test:
Test: 0.599009368558044
0.599009368558044
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053128002002717
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.23it/s]100%|██████████| 2/2 [00:00<00:00,  5.77it/s]100%|██████████| 2/2 [00:00<00:00,  5.68it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.5801600217819214
Epoch 1, Loop Feat 0: -0.5878954529762268
Epoch 1, Loop Adj 0: -0.6573300957679749
Epoch 2: -0.6573300957679749
Mem used: 674MB
best_loss: tensor(-0.8094, device='cuda:1')
final loss: -0.7874707579612732
Test:
Test: 0.6047780170277339
0.6047780170277339
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310910559022389, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974795884883838
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.51it/s]100%|██████████| 2/2 [00:00<00:00,  4.17it/s]100%|██████████| 2/2 [00:00<00:00,  4.21it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.45483046770095825
Epoch 1, Loop Feat 0: -0.45192331075668335
Epoch 1, Loop Adj 0: -0.5487015843391418
Epoch 2: -0.5487015843391418
Mem used: 794MB
best_loss: tensor(-0.6824, device='cuda:1')
final loss: -0.6521055102348328
Test:
Test: 0.6110030038102064
0.6110030038102064
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483242720478
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.06it/s]100%|██████████| 2/2 [00:00<00:00,  4.70it/s]100%|██████████| 2/2 [00:00<00:00,  4.57it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.5451187491416931
Epoch 1, Loop Feat 0: -0.5397828817367554
Epoch 1, Loop Adj 0: -0.605924129486084
Epoch 2: -0.605924129486084
Mem used: 812MB
best_loss: tensor(-0.7381, device='cuda:1')
final loss: -0.7226455211639404
Test:
Test: 0.5939031453902601
0.5939031453902601
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890801861456
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.29it/s]100%|██████████| 2/2 [00:00<00:00,  3.53it/s]100%|██████████| 2/2 [00:00<00:00,  3.71it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.5750350952148438
Epoch 1, Loop Feat 0: -0.5619704127311707
Epoch 1, Loop Adj 0: -0.6382367610931396
Epoch 2: -0.6382367610931396
Mem used: -594MB
best_loss: tensor(-0.7641, device='cuda:1')
best_loss: tensor(-0.7642, device='cuda:1')
final loss: -0.7596129179000854
Test:
Test: 0.6017306779447762
0.6017306779447762
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483719525047425, 0.5836708161590052]
flatten test: 0.6034946050554247
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.79it/s]100%|██████████| 2/2 [00:00<00:00,  3.39it/s]100%|██████████| 2/2 [00:00<00:00,  3.44it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.5563409924507141
Epoch 1, Loop Feat 0: -0.5640146732330322
Epoch 1, Loop Adj 0: -0.6409950852394104
Epoch 2: -0.6409950852394104
Mem used: 842MB
best_loss: tensor(-0.7972, device='cuda:1')
best_loss: tensor(-0.7988, device='cuda:1')
final loss: -0.7687683701515198
Test:
Test: 0.6064893055587328
0.6064893055587328
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.593719576152412, 0.6002883018849671, 0.5401741024379962, 0.5824575153695682]
flatten test: 0.5878747654839579
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.54it/s]100%|██████████| 1/1 [00:00<00:00,  3.54it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.686050534248352
Epoch 1: -0.686050534248352
Mem used: 674MB
best_loss: tensor(-0.8064, device='cuda:1')
best_loss: tensor(-0.8100, device='cuda:1')
final loss: -0.7757471799850464
Test:
Test: 0.5952408640196026
0.5952408640196026
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.644284027479605, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987216796569
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.50it/s]100%|██████████| 1/1 [00:00<00:00,  3.49it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.5354421734809875
Epoch 1: -0.5354421734809875
Mem used: 766MB
best_loss: tensor(-0.7132, device='cuda:1')
best_loss: tensor(-0.7159, device='cuda:1')
final loss: -0.6629786491394043
Test:
Test: 0.598252061425917
0.598252061425917
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405996180406469, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804332029918
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.97it/s]100%|██████████| 1/1 [00:00<00:00,  3.96it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.49716970324516296
Epoch 1: -0.49716970324516296
Mem used: 1496MB
best_loss: tensor(-0.6330, device='cuda:1')
final loss: -0.5837647318840027
Test:
Test: 0.608324309829011
0.608324309829011
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280594765278374, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887406041667
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.38it/s]100%|██████████| 1/1 [00:00<00:00,  6.36it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.5564684867858887
Epoch 1: -0.5564684867858887
Mem used: 674MB
best_loss: tensor(-0.7005, device='cuda:1')
final loss: -0.6539758443832397
Test:
Test: 0.6110006605586439
0.6110006605586439
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205531717941192, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168184805693
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.39it/s]100%|██████████| 1/1 [00:00<00:00,  4.38it/s]
Epoch 0, Loop Feat 0: -0.35880887508392334
Epoch 0, Loop Adj 0: -0.528098464012146
Epoch 1: -0.528098464012146
Mem used: 674MB
best_loss: tensor(-0.6780, device='cuda:1')
final loss: -0.6360536217689514
Test:
Test: 0.6016081934054704
0.6016081934054704
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127558452589
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.53it/s]100%|██████████| 1/1 [00:00<00:00,  3.46it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.5801600217819214
Epoch 1: -0.5801600217819214
Mem used: 1016MB
best_loss: tensor(-0.7303, device='cuda:1')
best_loss: tensor(-0.7355, device='cuda:1')
final loss: -0.6963080763816833
Test:
Test: 0.6052413850952043
0.6052413850952043
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179836213682554, 0.6310911059929533, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974796106658902
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.20it/s]100%|██████████| 1/1 [00:00<00:00,  4.19it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.45483046770095825
Epoch 1: -0.45483046770095825
Mem used: 816MB
best_loss: tensor(-0.5648, device='cuda:1')
final loss: -0.5256093144416809
Test:
Test: 0.6118670281787518
0.6118670281787518
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483242720477
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.16it/s]100%|██████████| 1/1 [00:00<00:00,  7.13it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.5451187491416931
Epoch 1: -0.5451187491416931
Mem used: 674MB
best_loss: tensor(-0.6607, device='cuda:1')
best_loss: tensor(-0.6662, device='cuda:1')
final loss: -0.6349533796310425
Test:
Test: 0.5981800163693995
0.5981800163693995
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.598189074641769
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.04it/s]100%|██████████| 1/1 [00:00<00:00,  4.03it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.5750350952148438
Epoch 1: -0.5750350952148438
Mem used: 674MB
best_loss: tensor(-0.6974, device='cuda:1')
best_loss: tensor(-0.7020, device='cuda:1')
final loss: -0.6796324253082275
Test:
Test: 0.6038488582089743
0.6038488582089743
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483719525047425, 0.5836708161590052]
flatten test: 0.603494616144178
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.39it/s]100%|██████████| 1/1 [00:00<00:00,  4.38it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.5563409924507141
Epoch 1: -0.5563409924507141
Mem used: 800MB
best_loss: tensor(-0.7231, device='cuda:1')
best_loss: tensor(-0.7274, device='cuda:1')
final loss: -0.6740476489067078
Test:
Test: 0.608626311267688
0.608626311267688
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.5937196262431264, 0.6002883018849671, 0.5401741024379962, 0.5824575153695682]
flatten test: 0.5878747765727113
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.12it/s]100%|██████████| 1/1 [00:00<00:00,  6.10it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.686050534248352
Epoch 1: -0.686050534248352
Mem used: 838MB
best_loss: tensor(-0.8017, device='cuda:1')
best_loss: tensor(-0.8091, device='cuda:1')
final loss: -0.7798296809196472
Test:
Test: 0.5945990911043498
0.5945990911043498
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.644284027479605, 0.6097033728081556, 0.6344159165859445, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987105909036
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.29it/s]100%|██████████| 1/1 [00:00<00:00,  5.27it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.5354421734809875
Epoch 1: -0.5354421734809875
Mem used: 674MB
best_loss: tensor(-0.7112, device='cuda:1')
best_loss: tensor(-0.7166, device='cuda:1')
final loss: -0.6687633395195007
Test:
Test: 0.5979244828006924
0.5979244828006924
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.614043983654398, 0.6456251035480238, 0.5428112133773624, 0.5562247297226491]
flatten test: 0.6065804387473683
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.99it/s]100%|██████████| 1/1 [00:00<00:00,  3.71it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.49716970324516296
Epoch 1: -0.49716970324516296
Mem used: -594MB
best_loss: tensor(-0.6327, device='cuda:1')
best_loss: tensor(-0.6332, device='cuda:1')
final loss: -0.5861653089523315
Test:
Test: 0.6101348092482023
0.6101348092482023
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887516929199
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.04it/s]100%|██████████| 1/1 [00:00<00:00,  3.88it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.5564684867858887
Epoch 1: -0.5564684867858887
Mem used: 784MB
best_loss: tensor(-0.7013, device='cuda:1')
best_loss: tensor(-0.7077, device='cuda:1')
final loss: -0.6606483459472656
Test:
Test: 0.6101008122424806
0.6101008122424806
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205531717941192, 0.576750097652589, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168129361927
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.61it/s]100%|██████████| 1/1 [00:00<00:00,  5.57it/s]
Epoch 0, Loop Feat 0: -0.35880887508392334
Epoch 0, Loop Adj 0: -0.528098464012146
Epoch 1: -0.528098464012146
Mem used: 742MB
best_loss: tensor(-0.6795, device='cuda:1')
best_loss: tensor(-0.6886, device='cuda:1')
final loss: -0.6496526598930359
Test:
Test: 0.6028998810422529
0.6028998810422529
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.605312766934012
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.48it/s]100%|██████████| 1/1 [00:00<00:00,  6.46it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.5801600217819214
Epoch 1: -0.5801600217819214
Mem used: 830MB
best_loss: tensor(-0.7389, device='cuda:1')
best_loss: tensor(-0.7455, device='cuda:1')
final loss: -0.7042228579521179
Test:
Test: 0.6083403948609236
0.6083403948609236
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310910559022389, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974795940327604
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.77it/s]100%|██████████| 1/1 [00:00<00:00,  3.76it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.45483046770095825
Epoch 1: -0.45483046770095825
Mem used: 1022MB
best_loss: tensor(-0.5629, device='cuda:1')
best_loss: tensor(-0.5664, device='cuda:1')
final loss: -0.5287636518478394
Test:
Test: 0.6111399450201694
0.6111399450201694
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483242720477
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.42it/s]100%|██████████| 1/1 [00:00<00:00,  6.39it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.5451187491416931
Epoch 1: -0.5451187491416931
Mem used: -594MB
best_loss: tensor(-0.6623, device='cuda:1')
best_loss: tensor(-0.6728, device='cuda:1')
final loss: -0.6430956125259399
Test:
Test: 0.5957807650660749
0.5957807650660749
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875724, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890746417688
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.58it/s]100%|██████████| 1/1 [00:00<00:00,  3.58it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.5750350952148438
Epoch 1: -0.5750350952148438
Mem used: 674MB
best_loss: tensor(-0.6982, device='cuda:1')
best_loss: tensor(-0.7100, device='cuda:1')
final loss: -0.6856259703636169
Test:
Test: 0.603996602205802
0.603996602205802
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232557, 0.5836708161590052]
flatten test: 0.603494616144178
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.00it/s]100%|██████████| 1/1 [00:00<00:00,  3.92it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.5563409924507141
Epoch 1: -0.5563409924507141
Mem used: 914MB
best_loss: tensor(-0.7215, device='cuda:1')
best_loss: tensor(-0.7290, device='cuda:1')
final loss: -0.6795833110809326
Test:
Test: 0.6084138299819276
0.6084138299819276
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.5937196763338406, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747987502176
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.87it/s]100%|██████████| 1/1 [00:00<00:00,  4.86it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.6860505938529968
Epoch 1: -0.6860505938529968
Mem used: 756MB
best_loss: tensor(-0.8093, device='cuda:1')
final loss: -0.7710564732551575
Test:
Test: 0.593803974218196
0.593803974218196
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987105909036
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.35it/s]100%|██████████| 1/1 [00:00<00:00,  4.34it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.5354421734809875
Epoch 1: -0.5354421734809875
Mem used: 674MB
best_loss: tensor(-0.7149, device='cuda:1')
final loss: -0.6646474003791809
Test:
Test: 0.5981782688597594
0.5981782688597594
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804276586151
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  2.44it/s]100%|██████████| 1/1 [00:00<00:00,  2.43it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.49716970324516296
Epoch 1: -0.49716970324516296
Mem used: 1117MB
best_loss: tensor(-0.6246, device='cuda:1')
final loss: -0.5764954686164856
Test:
Test: 0.6085782150364625
0.6085782150364625
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.60168875169292
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.12it/s]100%|██████████| 1/1 [00:00<00:00,  4.11it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.5564684867858887
Epoch 1: -0.5564684867858887
Mem used: 840MB
best_loss: tensor(-0.7006, device='cuda:1')
final loss: -0.6528106331825256
Test:
Test: 0.6112667189013183
0.6112667189013183
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205531217034048, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.590716796303063
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.39it/s]100%|██████████| 1/1 [00:00<00:00,  5.38it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.528098464012146
Epoch 1: -0.528098464012146
Mem used: 674MB
best_loss: tensor(-0.6776, device='cuda:1')
final loss: -0.6356596946716309
Test:
Test: 0.6017343715446969
0.6017343715446969
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127780227653
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.72it/s]100%|██████████| 1/1 [00:00<00:00,  4.70it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.5801600217819214
Epoch 1: -0.5801600217819214
Mem used: 1148MB
best_loss: tensor(-0.7324, device='cuda:1')
final loss: -0.6944180130958557
Test:
Test: 0.6054529926261448
0.6054529926261448
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179836213682554, 0.6310910559022389, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974795995771371
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.94it/s]100%|██████████| 1/1 [00:00<00:00,  4.93it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.45483046770095825
Epoch 1: -0.45483046770095825
Mem used: 674MB
best_loss: tensor(-0.5607, device='cuda:1')
final loss: -0.5221341848373413
Test:
Test: 0.6114848001611521
0.6114848001611521
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483464495542
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.24it/s]100%|██████████| 1/1 [00:00<00:00,  4.23it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.5451187491416931
Epoch 1: -0.5451187491416931
Mem used: 820MB
best_loss: tensor(-0.6626, device='cuda:1')
final loss: -0.6323856115341187
Test:
Test: 0.5959182623018324
0.5959182623018324
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890635530157
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.65it/s]100%|██████████| 1/1 [00:00<00:00,  4.64it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.5750350952148438
Epoch 1: -0.5750350952148438
Mem used: -128MB
best_loss: tensor(-0.6962, device='cuda:1')
best_loss: tensor(-0.6965, device='cuda:1')
final loss: -0.6743878722190857
Test:
Test: 0.6043681068687932
0.6043681068687932
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232557, 0.5836708161590052]
flatten test: 0.6034946272329312
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.81it/s]100%|██████████| 1/1 [00:00<00:00,  4.80it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.5563409924507141
Epoch 1: -0.5563409924507141
Mem used: 772MB
best_loss: tensor(-0.7257, device='cuda:1')
best_loss: tensor(-0.7266, device='cuda:1')
final loss: -0.6735805869102478
Test:
Test: 0.6068064785583744
0.6068064785583744
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.5937196763338406, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747876614644
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.54it/s]100%|██████████| 2/2 [00:00<00:00,  4.66it/s]100%|██████████| 2/2 [00:00<00:00,  4.64it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.6860505938529968
Epoch 1, Loop Feat 0: -0.6957825422286987
Epoch 1, Loop Adj 0: -0.7446808815002441
Epoch 2: -0.7446808815002441
Mem used: 782MB
best_loss: tensor(-0.8361, device='cuda:1')
best_loss: tensor(-0.8377, device='cuda:1')
final loss: -0.8249886631965637
Test:
Test: 0.5866965347837028
0.5866965347837028
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344159165859445, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987216796569
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.98it/s]100%|██████████| 2/2 [00:00<00:00,  4.41it/s]100%|██████████| 2/2 [00:00<00:00,  4.49it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.5354421734809875
Epoch 1, Loop Feat 0: -0.5592967867851257
Epoch 1, Loop Adj 0: -0.6282554268836975
Epoch 2: -0.6282554268836975
Mem used: -594MB
best_loss: tensor(-0.7801, device='cuda:1')
best_loss: tensor(-0.7822, device='cuda:1')
final loss: -0.7433033585548401
Test:
Test: 0.6005293047834741
0.6005293047834741
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405996180406469, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804498361216
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.19it/s]100%|██████████| 2/2 [00:00<00:00,  5.26it/s]100%|██████████| 2/2 [00:00<00:00,  5.24it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.49716970324516296
Epoch 1, Loop Feat 0: -0.4918729066848755
Epoch 1, Loop Adj 0: -0.6040619611740112
Epoch 2: -0.6040619611740112
Mem used: 674MB
best_loss: tensor(-0.7572, device='cuda:1')
final loss: -0.7138507962226868
Test:
Test: 0.6077029112875143
0.6077029112875143
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887516929199
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.05it/s]100%|██████████| 2/2 [00:00<00:00,  3.98it/s]100%|██████████| 2/2 [00:00<00:00,  3.81it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.5564684867858887
Epoch 1, Loop Feat 0: -0.5509547591209412
Epoch 1, Loop Adj 0: -0.6283407211303711
Epoch 2: -0.6283407211303711
Mem used: 1159MB
best_loss: tensor(-0.7852, device='cuda:1')
final loss: -0.7507712244987488
Test:
Test: 0.611534087876223
0.611534087876223
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205532218848335, 0.576750097652589, 0.5493891660226236, 0.5826381732918821]
flatten test: 0.5907168184805693
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.97it/s]100%|██████████| 2/2 [00:00<00:00,  8.88it/s]
Epoch 0, Loop Feat 0: -0.35880887508392334
Epoch 0, Loop Adj 0: -0.528098464012146
Epoch 1, Loop Feat 0: -0.5388807058334351
Epoch 1, Loop Adj 0: -0.6132206320762634
Epoch 2: -0.6132206320762634
Mem used: 782MB
best_loss: tensor(-0.7616, device='cuda:1')
final loss: -0.7371889352798462
Test:
Test: 0.5987825894661389
0.5987825894661389
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127780227653
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.05it/s]100%|██████████| 2/2 [00:00<00:00,  5.19it/s]100%|██████████| 2/2 [00:00<00:00,  5.16it/s]
Epoch 0, Loop Feat 0: -0.4249717593193054
Epoch 0, Loop Adj 0: -0.5801600217819214
Epoch 1, Loop Feat 0: -0.594219446182251
Epoch 1, Loop Adj 0: -0.6652761101722717
Epoch 2: -0.6652761101722717
Mem used: 852MB
best_loss: tensor(-0.8162, device='cuda:1')
final loss: -0.7894144058227539
Test:
Test: 0.6043594884689782
0.6043594884689782
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179836213682554, 0.6310911059929533, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974796051215138
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.73it/s]100%|██████████| 2/2 [00:00<00:00,  4.30it/s]100%|██████████| 2/2 [00:00<00:00,  4.20it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.45483046770095825
Epoch 1, Loop Feat 0: -0.4550151228904724
Epoch 1, Loop Adj 0: -0.5524086356163025
Epoch 2: -0.5524086356163025
Mem used: 686MB
best_loss: tensor(-0.6843, device='cuda:1')
final loss: -0.6532251834869385
Test:
Test: 0.611607125835945
0.611607125835945
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483242720477
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.24it/s]100%|██████████| 2/2 [00:00<00:00,  6.07it/s]100%|██████████| 2/2 [00:00<00:00,  5.92it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.5451187491416931
Epoch 1, Loop Feat 0: -0.5463197827339172
Epoch 1, Loop Adj 0: -0.6120650768280029
Epoch 2: -0.6120650768280029
Mem used: 674MB
best_loss: tensor(-0.7399, device='cuda:1')
best_loss: tensor(-0.7407, device='cuda:1')
final loss: -0.726534903049469
Test:
Test: 0.5963624871955203
0.5963624871955203
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890580086391
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.16it/s]100%|██████████| 2/2 [00:00<00:00,  3.80it/s]100%|██████████| 2/2 [00:00<00:00,  3.96it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.5750350952148438
Epoch 1, Loop Feat 0: -0.5702198147773743
Epoch 1, Loop Adj 0: -0.6456179618835449
Epoch 2: -0.6456179618835449
Mem used: 842MB
best_loss: tensor(-0.7653, device='cuda:1')
best_loss: tensor(-0.7663, device='cuda:1')
final loss: -0.7599202990531921
Test:
Test: 0.6015255044266008
0.6015255044266008
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232558, 0.5836708161590052]
flatten test: 0.6034946161441781
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.20it/s]100%|██████████| 2/2 [00:00<00:00,  3.73it/s]100%|██████████| 2/2 [00:00<00:00,  3.79it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.5563409924507141
Epoch 1, Loop Feat 0: -0.5689558386802673
Epoch 1, Loop Adj 0: -0.6453217267990112
Epoch 2: -0.6453217267990112
Mem used: 948MB
best_loss: tensor(-0.7953, device='cuda:1')
best_loss: tensor(-0.7995, device='cuda:1')
final loss: -0.7694376111030579
Test:
Test: 0.6065180203194066
0.6065180203194066
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.5937196262431264, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747876614644
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.35it/s]100%|██████████| 2/2 [00:00<00:00,  5.77it/s]100%|██████████| 2/2 [00:00<00:00,  5.49it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.6860505938529968
Epoch 1, Loop Feat 0: -0.712171196937561
Epoch 1, Loop Adj 0: -0.7532882690429688
Epoch 2: -0.7532882690429688
Mem used: 674MB
best_loss: tensor(-0.8340, device='cuda:1')
best_loss: tensor(-0.8404, device='cuda:1')
final loss: -0.8278130292892456
Test:
Test: 0.5867628210016345
0.5867628210016345
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344159165859445, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046986995021504
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.04it/s]100%|██████████| 2/2 [00:00<00:00,  4.76it/s]100%|██████████| 2/2 [00:00<00:00,  4.63it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.5354421734809875
Epoch 1, Loop Feat 0: -0.5687227249145508
Epoch 1, Loop Adj 0: -0.6349074244499207
Epoch 2: -0.6349074244499207
Mem used: 674MB
best_loss: tensor(-0.7819, device='cuda:1')
best_loss: tensor(-0.7850, device='cuda:1')
final loss: -0.7475990056991577
Test:
Test: 0.600461827081697
0.600461827081697
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405996180406469, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804498361216
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.79it/s]100%|██████████| 2/2 [00:00<00:00,  5.98it/s]100%|██████████| 2/2 [00:00<00:00,  5.95it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.49716970324516296
Epoch 1, Loop Feat 0: -0.5006288886070251
Epoch 1, Loop Adj 0: -0.6108648777008057
Epoch 2: -0.6108648777008057
Mem used: 790MB
best_loss: tensor(-0.7564, device='cuda:1')
best_loss: tensor(-0.7578, device='cuda:1')
final loss: -0.7172390222549438
Test:
Test: 0.6066438012973512
0.6066438012973512
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887516929199
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.66it/s]100%|██████████| 2/2 [00:00<00:00,  3.71it/s]100%|██████████| 2/2 [00:00<00:00,  3.82it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.5564685463905334
Epoch 1, Loop Feat 0: -0.5588317513465881
Epoch 1, Loop Adj 0: -0.6368458867073059
Epoch 2: -0.6368458867073059
Mem used: 838MB
best_loss: tensor(-0.7818, device='cuda:1')
final loss: -0.7533026337623596
Test:
Test: 0.6109884677072928
0.6109884677072928
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205532218848335, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168129361928
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.09it/s]100%|██████████| 2/2 [00:00<00:00,  5.03it/s]100%|██████████| 2/2 [00:00<00:00,  5.03it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.528098464012146
Epoch 1, Loop Feat 0: -0.5589362978935242
Epoch 1, Loop Adj 0: -0.6239264011383057
Epoch 2: -0.6239264011383057
Mem used: 854MB
best_loss: tensor(-0.7650, device='cuda:1')
best_loss: tensor(-0.7680, device='cuda:1')
final loss: -0.7385929226875305
Test:
Test: 0.5991134248138743
0.5991134248138743
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127891115186
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.77it/s]100%|██████████| 2/2 [00:00<00:00,  4.31it/s]100%|██████████| 2/2 [00:00<00:00,  4.37it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.5801600217819214
Epoch 1, Loop Feat 0: -0.6069286465644836
Epoch 1, Loop Adj 0: -0.6776171326637268
Epoch 2: -0.6776171326637268
Mem used: 674MB
best_loss: tensor(-0.8147, device='cuda:1')
best_loss: tensor(-0.8202, device='cuda:1')
final loss: -0.7903220653533936
Test:
Test: 0.6061288022632474
0.6061288022632474
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310910559022389, 0.6278801467147008, 0.5383905009484999, 0.5426401818150064]
flatten test: 0.5974795884883838
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.79it/s]100%|██████████| 2/2 [00:00<00:00,  6.48it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.45483046770095825
Epoch 1, Loop Feat 0: -0.4628254175186157
Epoch 1, Loop Adj 0: -0.5613975524902344
Epoch 2: -0.5613975524902344
Mem used: 674MB
best_loss: tensor(-0.6847, device='cuda:1')
best_loss: tensor(-0.6873, device='cuda:1')
final loss: -0.6582087874412537
Test:
Test: 0.612176813978552
0.612176813978552
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483298164244
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.75it/s]100%|██████████| 2/2 [00:00<00:00,  4.79it/s]100%|██████████| 2/2 [00:00<00:00,  4.78it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.5451187491416931
Epoch 1, Loop Feat 0: -0.562527060508728
Epoch 1, Loop Adj 0: -0.6280248165130615
Epoch 2: -0.6280248165130615
Mem used: 992MB
best_loss: tensor(-0.7436, device='cuda:1')
best_loss: tensor(-0.7479, device='cuda:1')
final loss: -0.7316901087760925
Test:
Test: 0.5955285279360067
0.5955285279360067
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890690973923
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.58it/s]100%|██████████| 2/2 [00:00<00:00,  4.52it/s]100%|██████████| 2/2 [00:00<00:00,  4.39it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.5750350952148438
Epoch 1, Loop Feat 0: -0.5872377157211304
Epoch 1, Loop Adj 0: -0.6591724157333374
Epoch 2: -0.6591724157333374
Mem used: 816MB
best_loss: tensor(-0.7678, device='cuda:1')
best_loss: tensor(-0.7734, device='cuda:1')
final loss: -0.765310525894165
Test:
Test: 0.6014461118863699
0.6014461118863699
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483719525047425, 0.5836708161590052]
flatten test: 0.6034946161441779
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.60it/s]100%|██████████| 2/2 [00:00<00:00,  4.00it/s]100%|██████████| 2/2 [00:00<00:00,  3.99it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.5563409924507141
Epoch 1, Loop Feat 0: -0.580025315284729
Epoch 1, Loop Adj 0: -0.6548181772232056
Epoch 2: -0.6548181772232056
Mem used: -594MB
best_loss: tensor(-0.7942, device='cuda:1')
best_loss: tensor(-0.8005, device='cuda:1')
final loss: -0.7735632658004761
Test:
Test: 0.6096814496450332
0.6096814496450332
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.5937196262431264, 0.6002883018849671, 0.5401741024379962, 0.5824575153695682]
flatten test: 0.587874765483958
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.65it/s]100%|██████████| 2/2 [00:00<00:00,  4.25it/s]100%|██████████| 2/2 [00:00<00:00,  4.26it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.6860488653182983
Epoch 1, Loop Feat 0: -0.6871955990791321
Epoch 1, Loop Adj 0: -0.7415067553520203
Epoch 2: -0.7415067553520203
Mem used: 838MB
best_loss: tensor(-0.8391, device='cuda:1')
best_loss: tensor(-0.8392, device='cuda:1')
final loss: -0.8207266926765442
Test:
Test: 0.5856836543667407
0.5856836543667407
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987105909036
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.07it/s]100%|██████████| 2/2 [00:00<00:00,  5.25it/s]100%|██████████| 2/2 [00:00<00:00,  5.03it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.5354421734809875
Epoch 1, Loop Feat 0: -0.5542113184928894
Epoch 1, Loop Adj 0: -0.6249324083328247
Epoch 2: -0.6249324083328247
Mem used: 674MB
best_loss: tensor(-0.7807, device='cuda:1')
best_loss: tensor(-0.7820, device='cuda:1')
final loss: -0.7427242398262024
Test:
Test: 0.6009540290582258
0.6009540290582258
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.614043983654398, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804221142385
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.40it/s]100%|██████████| 2/2 [00:00<00:00,  8.01it/s]100%|██████████| 2/2 [00:00<00:00,  7.70it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.49716970324516296
Epoch 1, Loop Feat 0: -0.4883252680301666
Epoch 1, Loop Adj 0: -0.601706326007843
Epoch 2: -0.601706326007843
Mem used: 674MB
best_loss: tensor(-0.7535, device='cuda:1')
final loss: -0.7114353775978088
Test:
Test: 0.608010592132521
0.608010592132521
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280594765278374, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887516929199
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  2.83it/s]100%|██████████| 2/2 [00:00<00:00,  2.91it/s]100%|██████████| 2/2 [00:00<00:00,  2.89it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.5564684867858887
Epoch 1, Loop Feat 0: -0.5479023456573486
Epoch 1, Loop Adj 0: -0.6240021586418152
Epoch 2: -0.6240021586418152
Mem used: 1173MB
best_loss: tensor(-0.7834, device='cuda:1')
final loss: -0.7495636343955994
Test:
Test: 0.611143360607193
0.611143360607193
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205532218848335, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168295693226
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.04it/s]100%|██████████| 2/2 [00:00<00:00,  4.82it/s]100%|██████████| 2/2 [00:00<00:00,  4.68it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.528098464012146
Epoch 1, Loop Feat 0: -0.5302494764328003
Epoch 1, Loop Adj 0: -0.6092736721038818
Epoch 2: -0.6092736721038818
Mem used: 806MB
best_loss: tensor(-0.7617, device='cuda:1')
final loss: -0.7303951978683472
Test:
Test: 0.5990107189064021
0.5990107189064021
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127780227653
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.61it/s]100%|██████████| 2/2 [00:00<00:00,  4.14it/s]100%|██████████| 2/2 [00:00<00:00,  4.15it/s]
Epoch 0, Loop Feat 0: -0.4249717593193054
Epoch 0, Loop Adj 0: -0.5801600217819214
Epoch 1, Loop Feat 0: -0.5877124071121216
Epoch 1, Loop Adj 0: -0.657018780708313
Epoch 2: -0.657018780708313
Mem used: 812MB
best_loss: tensor(-0.8095, device='cuda:1')
final loss: -0.7870997190475464
Test:
Test: 0.6048854094383314
0.6048854094383314
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179836213682554, 0.6310910559022389, 0.6278801467147008, 0.5383907819855266, 0.5426401818150064]
flatten test: 0.5974796051215137
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.16it/s]100%|██████████| 2/2 [00:00<00:00,  5.84it/s]100%|██████████| 2/2 [00:00<00:00,  5.50it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.45483046770095825
Epoch 1, Loop Feat 0: -0.451808899641037
Epoch 1, Loop Adj 0: -0.5485676527023315
Epoch 2: -0.5485676527023315
Mem used: 694MB
best_loss: tensor(-0.6824, device='cuda:1')
final loss: -0.6520962119102478
Test:
Test: 0.6110084052036389
0.6110084052036389
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483242720478
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.14it/s]100%|██████████| 2/2 [00:00<00:00,  4.69it/s]100%|██████████| 2/2 [00:00<00:00,  4.59it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.5451187491416931
Epoch 1, Loop Feat 0: -0.5396389365196228
Epoch 1, Loop Adj 0: -0.6057539582252502
Epoch 2: -0.6057539582252502
Mem used: 674MB
best_loss: tensor(-0.7381, device='cuda:1')
best_loss: tensor(-0.7386, device='cuda:1')
final loss: -0.7234945893287659
Test:
Test: 0.5971068468698608
0.5971068468698608
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890801861456
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.55it/s]100%|██████████| 2/2 [00:00<00:00,  6.45it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.5750350952148438
Epoch 1, Loop Feat 0: -0.5617361068725586
Epoch 1, Loop Adj 0: -0.6379595994949341
Epoch 2: -0.6379595994949341
Mem used: 674MB
best_loss: tensor(-0.7640, device='cuda:1')
final loss: -0.7599054574966431
Test:
Test: 0.6004034443732731
0.6004034443732731
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483719525047425, 0.5836708161590052]
flatten test: 0.6034946050554247
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.75it/s]100%|██████████| 2/2 [00:00<00:00,  4.42it/s]100%|██████████| 2/2 [00:00<00:00,  4.46it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.5563409924507141
Epoch 1, Loop Feat 0: -0.5638718605041504
Epoch 1, Loop Adj 0: -0.6408731341362
Epoch 2: -0.6408731341362
Mem used: 858MB
best_loss: tensor(-0.7972, device='cuda:1')
best_loss: tensor(-0.7987, device='cuda:1')
final loss: -0.7689052820205688
Test:
Test: 0.6064794162428162
0.6064794162428162
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.5937196262431264, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747765727113
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.13it/s]100%|██████████| 1/1 [00:00<00:00,  3.13it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.686050534248352
Epoch 1: -0.686050534248352
Mem used: 674MB
best_loss: tensor(-0.8064, device='cuda:1')
best_loss: tensor(-0.8098, device='cuda:1')
final loss: -0.7760041952133179
Test:
Test: 0.5942664288147183
0.5942664288147183
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987272240335
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.01it/s]100%|██████████| 1/1 [00:00<00:00,  2.92it/s]
Epoch 0, Loop Feat 0: -0.42172563076019287
Epoch 0, Loop Adj 0: -0.5354421734809875
Epoch 1: -0.5354421734809875
Mem used: 824MB
best_loss: tensor(-0.7132, device='cuda:1')
best_loss: tensor(-0.7159, device='cuda:1')
final loss: -0.6624070405960083
Test:
Test: 0.5981499512603674
0.5981499512603674
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405996180406469, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804442917448
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.04it/s]100%|██████████| 1/1 [00:00<00:00,  3.96it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.49716970324516296
Epoch 1: -0.49716970324516296
Mem used: 904MB
best_loss: tensor(-0.6330, device='cuda:1')
final loss: -0.5836054682731628
Test:
Test: 0.608315929725965
0.608315929725965
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887516929199
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.18it/s]100%|██████████| 1/1 [00:00<00:00,  4.91it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.5564684867858887
Epoch 1: -0.5564684867858887
Mem used: 674MB
best_loss: tensor(-0.7008, device='cuda:1')
final loss: -0.6550396680831909
Test:
Test: 0.6112588948240671
0.6112588948240671
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205531217034048, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168073918162
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.83it/s]100%|██████████| 1/1 [00:00<00:00,  7.80it/s]
Epoch 0, Loop Feat 0: -0.35880887508392334
Epoch 0, Loop Adj 0: -0.528098464012146
Epoch 1: -0.528098464012146
Mem used: 674MB
best_loss: tensor(-0.6781, device='cuda:1')
final loss: -0.6361533403396606
Test:
Test: 0.6016201082439244
0.6016201082439244
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.605312794655895
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.24it/s]100%|██████████| 1/1 [00:00<00:00,  3.23it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.5801600217819214
Epoch 1: -0.5801600217819214
Mem used: 820MB
best_loss: tensor(-0.7306, device='cuda:1')
best_loss: tensor(-0.7355, device='cuda:1')
final loss: -0.6960563659667969
Test:
Test: 0.605287535236149
0.605287535236149
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310910058115247, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974795829440072
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  2.72it/s]100%|██████████| 1/1 [00:00<00:00,  2.72it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.45483046770095825
Epoch 1: -0.45483046770095825
Mem used: 848MB
best_loss: tensor(-0.5648, device='cuda:1')
final loss: -0.5258162021636963
Test:
Test: 0.6120316515300559
0.6120316515300559
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483242720478
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.88it/s]100%|██████████| 1/1 [00:00<00:00,  4.86it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.5451187491416931
Epoch 1: -0.5451187491416931
Mem used: 816MB
best_loss: tensor(-0.6606, device='cuda:1')
best_loss: tensor(-0.6660, device='cuda:1')
final loss: -0.6353790163993835
Test:
Test: 0.5982037666140507
0.5982037666140507
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875724, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890635530157
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.41it/s]100%|██████████| 1/1 [00:00<00:00,  4.25it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.5750350952148438
Epoch 1: -0.5750350952148438
Mem used: 674MB
best_loss: tensor(-0.6972, device='cuda:1')
best_loss: tensor(-0.7019, device='cuda:1')
final loss: -0.6791397929191589
Test:
Test: 0.6039247557299252
0.6039247557299252
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145208472543777, 0.6325989133050594, 0.5483720930232557, 0.5836708161590052]
flatten test: 0.6034946272329311
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.64it/s]100%|██████████| 1/1 [00:00<00:00,  5.63it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.5563409924507141
Epoch 1: -0.5563409924507141
Mem used: 674MB
best_loss: tensor(-0.7230, device='cuda:1')
best_loss: tensor(-0.7274, device='cuda:1')
final loss: -0.6734732985496521
Test:
Test: 0.6086323084030432
0.6086323084030432
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.5937196262431264, 0.6002883018849671, 0.5401741024379962, 0.5824575153695682]
flatten test: 0.5878747765727113
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.75it/s]100%|██████████| 1/1 [00:00<00:00,  6.73it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.6860488057136536
Epoch 1: -0.6860488057136536
Mem used: 764MB
best_loss: tensor(-0.8017, device='cuda:1')
best_loss: tensor(-0.8098, device='cuda:1')
final loss: -0.7760042548179626
Test:
Test: 0.594264840169591
0.594264840169591
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344159165859445, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987050465271
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.00it/s]100%|██████████| 1/1 [00:00<00:00,  6.97it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.5354421734809875
Epoch 1: -0.5354421734809875
Mem used: 674MB
best_loss: tensor(-0.7113, device='cuda:1')
best_loss: tensor(-0.7161, device='cuda:1')
final loss: -0.662358820438385
Test:
Test: 0.5977809884295798
0.5977809884295798
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804276586151
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.64it/s]100%|██████████| 1/1 [00:00<00:00,  3.57it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.49716970324516296
Epoch 1: -0.49716970324516296
Mem used: 674MB
best_loss: tensor(-0.6327, device='cuda:1')
final loss: -0.5865304470062256
Test:
Test: 0.6084742382128886
0.6084742382128886
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887572372966
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.30it/s]100%|██████████| 1/1 [00:00<00:00,  6.28it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.5564684867858887
Epoch 1: -0.5564684867858887
Mem used: 674MB
best_loss: tensor(-0.7013, device='cuda:1')
best_loss: tensor(-0.7030, device='cuda:1')
final loss: -0.6556580662727356
Test:
Test: 0.611721031691564
0.611721031691564
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205531717941192, 0.576750097652589, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168018474395
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.10it/s]100%|██████████| 1/1 [00:00<00:00,  5.09it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.528098464012146
Epoch 1: -0.528098464012146
Mem used: 792MB
best_loss: tensor(-0.6795, device='cuda:1')
best_loss: tensor(-0.6811, device='cuda:1')
final loss: -0.6413094997406006
Test:
Test: 0.6016727718298904
0.6016727718298904
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127780227653
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.69it/s]100%|██████████| 1/1 [00:00<00:00,  6.66it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.5801600217819214
Epoch 1: -0.5801600217819214
Mem used: 820MB
best_loss: tensor(-0.7388, device='cuda:1')
final loss: -0.6980243921279907
Test:
Test: 0.6074651705442318
0.6074651705442318
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179836213682554, 0.6310911059929533, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974796051215135
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.61it/s]100%|██████████| 1/1 [00:00<00:00,  5.60it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.45483046770095825
Epoch 1: -0.45483046770095825
Mem used: 764MB
best_loss: tensor(-0.5629, device='cuda:1')
final loss: -0.5268694162368774
Test:
Test: 0.6138620884455934
0.6138620884455934
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483298164244
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.37it/s]100%|██████████| 1/1 [00:00<00:00,  5.35it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.5451187491416931
Epoch 1: -0.5451187491416931
Mem used: 674MB
best_loss: tensor(-0.6623, device='cuda:1')
best_loss: tensor(-0.6661, device='cuda:1')
final loss: -0.6363379955291748
Test:
Test: 0.598223743826525
0.598223743826525
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890857305221
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.57it/s]100%|██████████| 1/1 [00:00<00:00,  5.55it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.5750350952148438
Epoch 1: -0.5750350952148438
Mem used: 770MB
best_loss: tensor(-0.6982, device='cuda:1')
best_loss: tensor(-0.7020, device='cuda:1')
final loss: -0.6790894269943237
Test:
Test: 0.6037894825973458
0.6037894825973458
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303432937956205, 0.6145207971636634, 0.6325989133050594, 0.5483719525047425, 0.5836708161590052]
flatten test: 0.6034946216885545
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.20it/s]100%|██████████| 1/1 [00:00<00:00,  5.19it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.5563409924507141
Epoch 1: -0.5563409924507141
Mem used: 878MB
best_loss: tensor(-0.7215, device='cuda:1')
best_loss: tensor(-0.7275, device='cuda:1')
final loss: -0.6755241751670837
Test:
Test: 0.6065799377632385
0.6065799377632385
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.5937196262431264, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747821170878
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.19it/s]100%|██████████| 1/1 [00:00<00:00,  6.17it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.6860488653182983
Epoch 1: -0.6860488653182983
Mem used: 674MB
best_loss: tensor(-0.8093, device='cuda:1')
final loss: -0.7704538702964783
Test:
Test: 0.593802623869838
0.593802623869838
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987105909036
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.01it/s]100%|██████████| 1/1 [00:00<00:00,  5.97it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.5354421734809875
Epoch 1: -0.5354421734809875
Mem used: 674MB
best_loss: tensor(-0.7149, device='cuda:1')
final loss: -0.6646474003791809
Test:
Test: 0.5981782688597594
0.5981782688597594
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405996180406469, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.556224183928322]
flatten test: 0.6065804332029917
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.85it/s]100%|██████████| 1/1 [00:00<00:00,  4.85it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.49716970324516296
Epoch 1: -0.49716970324516296
Mem used: 888MB
best_loss: tensor(-0.6246, device='cuda:1')
final loss: -0.5764954686164856
Test:
Test: 0.6085782547525906
0.6085782547525906
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280594765278374, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887516929199
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.48it/s]100%|██████████| 1/1 [00:00<00:00,  6.08it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.5564684867858887
Epoch 1: -0.5564684867858887
Mem used: 674MB
best_loss: tensor(-0.7006, device='cuda:1')
final loss: -0.653325080871582
Test:
Test: 0.6113807439053218
0.6113807439053218
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205532218848334, 0.576750097652589, 0.5493891660226236, 0.5826381732918821]
flatten test: 0.5907168184805693
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.17it/s]100%|██████████| 1/1 [00:00<00:00,  4.16it/s]
Epoch 0, Loop Feat 0: -0.35880887508392334
Epoch 0, Loop Adj 0: -0.528098464012146
Epoch 1: -0.528098464012146
Mem used: 836MB
best_loss: tensor(-0.6776, device='cuda:1')
final loss: -0.6353991627693176
Test:
Test: 0.6016900880617766
0.6016900880617766
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.605312766934012
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.13it/s]100%|██████████| 1/1 [00:00<00:00,  4.12it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.5801599621772766
Epoch 1: -0.5801599621772766
Mem used: -813MB
best_loss: tensor(-0.7325, device='cuda:1')
final loss: -0.6947252750396729
Test:
Test: 0.6052357454050028
0.6052357454050028
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179836213682554, 0.6310911059929533, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.597479599577137
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.32it/s]100%|██████████| 1/1 [00:00<00:00,  6.31it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.45483046770095825
Epoch 1: -0.45483046770095825
Mem used: 674MB
best_loss: tensor(-0.5607, device='cuda:1')
final loss: -0.5221341848373413
Test:
Test: 0.611484760445024
0.611484760445024
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483242720478
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.41it/s]100%|██████████| 1/1 [00:00<00:00,  5.39it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.5451187491416931
Epoch 1: -0.5451187491416931
Mem used: 674MB
best_loss: tensor(-0.6627, device='cuda:1')
final loss: -0.6330512762069702
Test:
Test: 0.5961525080258352
0.5961525080258352
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.598189074641769
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.87it/s]100%|██████████| 1/1 [00:00<00:00,  4.85it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.5750350952148438
Epoch 1: -0.5750350952148438
Mem used: 674MB
best_loss: tensor(-0.6963, device='cuda:1')
final loss: -0.6766383647918701
Test:
Test: 0.60265233041531
0.60265233041531
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232558, 0.5836708161590052]
flatten test: 0.6034946216885545
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.68it/s]100%|██████████| 1/1 [00:00<00:00,  5.66it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.5563409924507141
Epoch 1: -0.5563409924507141
Mem used: 784MB
best_loss: tensor(-0.7257, device='cuda:1')
best_loss: tensor(-0.7266, device='cuda:1')
final loss: -0.6737866997718811
Test:
Test: 0.6068052473584009
0.6068052473584009
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.5937196262431264, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.587874793205841
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.26it/s]100%|██████████| 2/2 [00:00<00:00,  2.82it/s]100%|██████████| 2/2 [00:00<00:00,  2.84it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.6860488057136536
Epoch 1, Loop Feat 0: -0.6953644752502441
Epoch 1, Loop Adj 0: -0.7442482113838196
Epoch 2: -0.7442482113838196
Mem used: 940MB
best_loss: tensor(-0.8362, device='cuda:1')
best_loss: tensor(-0.8379, device='cuda:1')
final loss: -0.8240513801574707
Test:
Test: 0.5865666233284277
0.5865666233284277
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344159165859445, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987050465271
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.46it/s]100%|██████████| 2/2 [00:00<00:00,  5.48it/s]100%|██████████| 2/2 [00:00<00:00,  5.47it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.5354421734809875
Epoch 1, Loop Feat 0: -0.5591918230056763
Epoch 1, Loop Adj 0: -0.628167450428009
Epoch 2: -0.628167450428009
Mem used: 674MB
best_loss: tensor(-0.7801, device='cuda:1')
best_loss: tensor(-0.7819, device='cuda:1')
final loss: -0.7423720359802246
Test:
Test: 0.6001075195022076
0.6001075195022076
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405996180406469, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804387473683
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.87it/s]100%|██████████| 2/2 [00:00<00:00,  6.45it/s]100%|██████████| 2/2 [00:00<00:00,  6.50it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.49716970324516296
Epoch 1, Loop Feat 0: -0.49176228046417236
Epoch 1, Loop Adj 0: -0.6039867997169495
Epoch 2: -0.6039867997169495
Mem used: 674MB
best_loss: tensor(-0.7573, device='cuda:1')
final loss: -0.7139798998832703
Test:
Test: 0.607676301481634
0.607676301481634
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887461485433
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.02it/s]100%|██████████| 2/2 [00:00<00:00,  4.04it/s]100%|██████████| 2/2 [00:00<00:00,  4.04it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.5564684867858887
Epoch 1, Loop Feat 0: -0.5508725643157959
Epoch 1, Loop Adj 0: -0.628229558467865
Epoch 2: -0.628229558467865
Mem used: 674MB
best_loss: tensor(-0.7852, device='cuda:1')
final loss: -0.7505797743797302
Test:
Test: 0.6115525955919546
0.6115525955919546
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205531717941192, 0.576750097652589, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168184805693
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.16it/s]100%|██████████| 2/2 [00:00<00:00,  3.37it/s]100%|██████████| 2/2 [00:00<00:00,  3.33it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.528098464012146
Epoch 1, Loop Feat 0: -0.5386577248573303
Epoch 1, Loop Adj 0: -0.6131088137626648
Epoch 2: -0.6131088137626648
Mem used: 818MB
best_loss: tensor(-0.7615, device='cuda:1')
final loss: -0.7372334599494934
Test:
Test: 0.5987550264731825
0.5987550264731825
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404819888721912, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127558452588
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.04it/s]100%|██████████| 2/2 [00:00<00:00,  5.24it/s]100%|██████████| 2/2 [00:00<00:00,  5.01it/s]
Epoch 0, Loop Feat 0: -0.4249717593193054
Epoch 0, Loop Adj 0: -0.5801600217819214
Epoch 1, Loop Feat 0: -0.5940923094749451
Epoch 1, Loop Adj 0: -0.6651296615600586
Epoch 2: -0.6651296615600586
Mem used: 804MB
best_loss: tensor(-0.8162, device='cuda:1')
final loss: -0.7893017530441284
Test:
Test: 0.6044856268920764
0.6044856268920764
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310910559022389, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.597479599577137
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.41it/s]100%|██████████| 2/2 [00:00<00:00,  6.33it/s]100%|██████████| 2/2 [00:00<00:00,  6.34it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.45483046770095825
Epoch 1, Loop Feat 0: -0.4549054205417633
Epoch 1, Loop Adj 0: -0.5522749423980713
Epoch 2: -0.5522749423980713
Mem used: 674MB
best_loss: tensor(-0.6843, device='cuda:1')
final loss: -0.6537416577339172
Test:
Test: 0.6116517270478906
0.6116517270478906
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483298164243
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.08it/s]100%|██████████| 2/2 [00:00<00:00,  6.54it/s]100%|██████████| 2/2 [00:00<00:00,  6.26it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.5451187491416931
Epoch 1, Loop Feat 0: -0.5461369156837463
Epoch 1, Loop Adj 0: -0.6118417382240295
Epoch 2: -0.6118417382240295
Mem used: 674MB
best_loss: tensor(-0.7399, device='cuda:1')
final loss: -0.7194167375564575
Test:
Test: 0.5941158252566615
0.5941158252566615
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.598189074641769
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.27it/s]100%|██████████| 2/2 [00:00<00:00,  3.67it/s]100%|██████████| 2/2 [00:00<00:00,  3.65it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.5750350952148438
Epoch 1, Loop Feat 0: -0.5700013637542725
Epoch 1, Loop Adj 0: -0.6454135179519653
Epoch 2: -0.6454135179519653
Mem used: 674MB
best_loss: tensor(-0.7653, device='cuda:1')
best_loss: tensor(-0.7663, device='cuda:1')
final loss: -0.7604041695594788
Test:
Test: 0.60136691792678
0.60136691792678
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232558, 0.5836708161590052]
flatten test: 0.6034946050554246
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.56it/s]100%|██████████| 2/2 [00:00<00:00,  3.66it/s]100%|██████████| 2/2 [00:00<00:00,  3.65it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.5563409924507141
Epoch 1, Loop Feat 0: -0.5688389539718628
Epoch 1, Loop Adj 0: -0.6452334523200989
Epoch 2: -0.6452334523200989
Mem used: 1070MB
best_loss: tensor(-0.7955, device='cuda:1')
best_loss: tensor(-0.7995, device='cuda:1')
final loss: -0.7693928480148315
Test:
Test: 0.6067098492185137
0.6067098492185137
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.5937196262431264, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747821170879
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.29it/s]100%|██████████| 2/2 [00:00<00:00,  4.00it/s]100%|██████████| 2/2 [00:00<00:00,  3.87it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.686050534248352
Epoch 1, Loop Feat 0: -0.6953650712966919
Epoch 1, Loop Adj 0: -0.743992030620575
Epoch 2: -0.743992030620575
Mem used: 674MB
best_loss: tensor(-0.8333, device='cuda:1')
best_loss: tensor(-0.8376, device='cuda:1')
final loss: -0.8249917030334473
Test:
Test: 0.5863656597198392
0.5863656597198392
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033227174413, 0.6344159165859445, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046986995021504
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.56it/s]100%|██████████| 2/2 [00:00<00:00,  5.05it/s]100%|██████████| 2/2 [00:00<00:00,  5.23it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.5354421734809875
Epoch 1, Loop Feat 0: -0.5593252778053284
Epoch 1, Loop Adj 0: -0.6282562613487244
Epoch 2: -0.6282562613487244
Mem used: 674MB
best_loss: tensor(-0.7814, device='cuda:1')
best_loss: tensor(-0.7827, device='cuda:1')
final loss: -0.7438904047012329
Test:
Test: 0.5991378502327047
0.5991378502327047
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562247297226491]
flatten test: 0.6065804442917448
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.14it/s]100%|██████████| 2/2 [00:00<00:00,  3.60it/s]100%|██████████| 2/2 [00:00<00:00,  3.52it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.49716970324516296
Epoch 1, Loop Feat 0: -0.49195560812950134
Epoch 1, Loop Adj 0: -0.6041264533996582
Epoch 2: -0.6041264533996582
Mem used: 828MB
best_loss: tensor(-0.7561, device='cuda:1')
final loss: -0.7128883004188538
Test:
Test: 0.6073582150110441
0.6073582150110441
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887516929199
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.61it/s]100%|██████████| 2/2 [00:00<00:00,  7.85it/s]100%|██████████| 2/2 [00:00<00:00,  7.79it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.5564684867858887
Epoch 1, Loop Feat 0: -0.5510899424552917
Epoch 1, Loop Adj 0: -0.6285090446472168
Epoch 2: -0.6285090446472168
Mem used: 848MB
best_loss: tensor(-0.7817, device='cuda:1')
best_loss: tensor(-0.7858, device='cuda:1')
final loss: -0.7519353628158569
Test:
Test: 0.6130058881542995
0.6130058881542995
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205531717941192, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168184805694
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.28it/s]100%|██████████| 2/2 [00:00<00:00,  5.33it/s]100%|██████████| 2/2 [00:00<00:00,  5.44it/s]
Epoch 0, Loop Feat 0: -0.35880887508392334
Epoch 0, Loop Adj 0: -0.528098464012146
Epoch 1, Loop Feat 0: -0.5395639538764954
Epoch 1, Loop Adj 0: -0.6135253310203552
Epoch 2: -0.6135253310203552
Mem used: 830MB
best_loss: tensor(-0.7612, device='cuda:1')
best_loss: tensor(-0.7652, device='cuda:1')
final loss: -0.7364374995231628
Test:
Test: 0.5994592728580616
0.5994592728580616
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127724783887
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.00it/s]100%|██████████| 2/2 [00:00<00:00,  5.60it/s]100%|██████████| 2/2 [00:00<00:00,  5.65it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.5801600217819214
Epoch 1, Loop Feat 0: -0.5941920280456543
Epoch 1, Loop Adj 0: -0.665239691734314
Epoch 2: -0.665239691734314
Mem used: 776MB
best_loss: tensor(-0.8133, device='cuda:1')
best_loss: tensor(-0.8174, device='cuda:1')
final loss: -0.7894014120101929
Test:
Test: 0.604032227572779
0.604032227572779
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179836213682554, 0.631091055902239, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974795940327604
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.21it/s]100%|██████████| 2/2 [00:00<00:00,  5.23it/s]100%|██████████| 2/2 [00:00<00:00,  5.22it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.45483046770095825
Epoch 1, Loop Feat 0: -0.45516160130500793
Epoch 1, Loop Adj 0: -0.5525919795036316
Epoch 2: -0.5525919795036316
Mem used: 674MB
best_loss: tensor(-0.6830, device='cuda:1')
best_loss: tensor(-0.6851, device='cuda:1')
final loss: -0.6543302536010742
Test:
Test: 0.6122697894346203
0.6122697894346203
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483298164244
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.53it/s]100%|██████████| 2/2 [00:00<00:00,  6.96it/s]100%|██████████| 2/2 [00:00<00:00,  6.69it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.5451187491416931
Epoch 1, Loop Feat 0: -0.5465937256813049
Epoch 1, Loop Adj 0: -0.6123703718185425
Epoch 2: -0.6123703718185425
Mem used: 674MB
best_loss: tensor(-0.7377, device='cuda:1')
best_loss: tensor(-0.7434, device='cuda:1')
final loss: -0.7258943915367126
Test:
Test: 0.5967598073418281
0.5967598073418281
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875724, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.598189074641769
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  2.88it/s]100%|██████████| 2/2 [00:00<00:00,  3.21it/s]100%|██████████| 2/2 [00:00<00:00,  3.15it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.5750350952148438
Epoch 1, Loop Feat 0: -0.5703049898147583
Epoch 1, Loop Adj 0: -0.6456820964813232
Epoch 2: -0.6456820964813232
Mem used: -96MB
best_loss: tensor(-0.7672, device='cuda:1')
best_loss: tensor(-0.7680, device='cuda:1')
final loss: -0.7627649903297424
Test:
Test: 0.6013067082764598
0.6013067082764598
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483719525047425, 0.5836708161590052]
flatten test: 0.6034946105998014
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.65it/s]100%|██████████| 2/2 [00:00<00:00,  8.78it/s]100%|██████████| 2/2 [00:00<00:00,  8.57it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.5563409924507141
Epoch 1, Loop Feat 0: -0.5690284967422485
Epoch 1, Loop Adj 0: -0.6453998684883118
Epoch 2: -0.6453998684883118
Mem used: 780MB
best_loss: tensor(-0.7922, device='cuda:1')
best_loss: tensor(-0.7995, device='cuda:1')
final loss: -0.7685865759849548
Test:
Test: 0.6083445253382543
0.6083445253382543
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.5937196262431264, 0.6002883018849671, 0.5401741024379962, 0.5824575153695682]
flatten test: 0.5878747876614645
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.03it/s]100%|██████████| 2/2 [00:00<00:00,  5.61it/s]100%|██████████| 2/2 [00:00<00:00,  5.66it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.6860488057136536
Epoch 1, Loop Feat 0: -0.687077522277832
Epoch 1, Loop Adj 0: -0.740671694278717
Epoch 2: -0.740671694278717
Mem used: 674MB
best_loss: tensor(-0.8387, device='cuda:1')
best_loss: tensor(-0.8388, device='cuda:1')
final loss: -0.8207730650901794
Test:
Test: 0.5857372314236549
0.5857372314236549
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344159165859445, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987161352804
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.76it/s]100%|██████████| 2/2 [00:00<00:00,  4.14it/s]100%|██████████| 2/2 [00:00<00:00,  4.07it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.5354421734809875
Epoch 1, Loop Feat 0: -0.5541298985481262
Epoch 1, Loop Adj 0: -0.6249120235443115
Epoch 2: -0.6249120235443115
Mem used: -226MB
best_loss: tensor(-0.7807, device='cuda:1')
best_loss: tensor(-0.7819, device='cuda:1')
final loss: -0.7432513236999512
Test:
Test: 0.600936355381186
0.600936355381186
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562247297226491]
flatten test: 0.6065804387473683
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.42it/s]100%|██████████| 2/2 [00:00<00:00,  4.12it/s]100%|██████████| 2/2 [00:00<00:00,  4.16it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.49716970324516296
Epoch 1, Loop Feat 0: -0.4882644712924957
Epoch 1, Loop Adj 0: -0.6016725897789001
Epoch 2: -0.6016725897789001
Mem used: 674MB
best_loss: tensor(-0.7535, device='cuda:1')
final loss: -0.7114296555519104
Test:
Test: 0.6080088843390092
0.6080088843390092
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163420955350138, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887461485433
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.85it/s]100%|██████████| 2/2 [00:00<00:00,  4.56it/s]100%|██████████| 2/2 [00:00<00:00,  4.59it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.5564684867858887
Epoch 1, Loop Feat 0: -0.5478558540344238
Epoch 1, Loop Adj 0: -0.6239176392555237
Epoch 2: -0.6239176392555237
Mem used: 1062MB
best_loss: tensor(-0.7834, device='cuda:1')
final loss: -0.7495551109313965
Test:
Test: 0.6111420499749629
0.6111420499749629
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035360312008, 0.6205532218848335, 0.576750097652589, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168184805694
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.00it/s]100%|██████████| 2/2 [00:00<00:00,  5.14it/s]100%|██████████| 2/2 [00:00<00:00,  5.11it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.528098464012146
Epoch 1, Loop Feat 0: -0.5301361680030823
Epoch 1, Loop Adj 0: -0.6092279553413391
Epoch 2: -0.6092279553413391
Mem used: 1544MB
best_loss: tensor(-0.7617, device='cuda:1')
final loss: -0.7303900718688965
Test:
Test: 0.5990105600418894
0.5990105600418894
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.605312766934012
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.35it/s]100%|██████████| 2/2 [00:00<00:00,  5.29it/s]100%|██████████| 2/2 [00:00<00:00,  5.11it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.5801600217819214
Epoch 1, Loop Feat 0: -0.5876073837280273
Epoch 1, Loop Adj 0: -0.6568365097045898
Epoch 2: -0.6568365097045898
Mem used: 838MB
best_loss: tensor(-0.8094, device='cuda:1')
final loss: -0.7868611216545105
Test:
Test: 0.6049557467013373
0.6049557467013373
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310910559022389, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.597479599577137
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.88it/s]100%|██████████| 2/2 [00:00<00:00,  5.10it/s]100%|██████████| 2/2 [00:00<00:00,  5.38it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.45483046770095825
Epoch 1, Loop Feat 0: -0.45174840092658997
Epoch 1, Loop Adj 0: -0.548485517501831
Epoch 2: -0.548485517501831
Mem used: 674MB
best_loss: tensor(-0.6824, device='cuda:1')
final loss: -0.6520954370498657
Test:
Test: 0.6110094775390997
0.6110094775390997
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483298164244
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.49it/s]100%|██████████| 2/2 [00:00<00:00,  3.61it/s]100%|██████████| 2/2 [00:00<00:00,  3.58it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.5451187491416931
Epoch 1, Loop Feat 0: -0.5395508408546448
Epoch 1, Loop Adj 0: -0.605709433555603
Epoch 2: -0.605709433555603
Mem used: 1385MB
best_loss: tensor(-0.7380, device='cuda:1')
final loss: -0.7229430079460144
Test:
Test: 0.5941294478886271
0.5941294478886271
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.598189074641769
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.45it/s]100%|██████████| 2/2 [00:00<00:00,  6.63it/s]100%|██████████| 2/2 [00:00<00:00,  6.59it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.5750350952148438
Epoch 1, Loop Feat 0: -0.5616262555122375
Epoch 1, Loop Adj 0: -0.6378675103187561
Epoch 2: -0.6378675103187561
Mem used: 800MB
best_loss: tensor(-0.7641, device='cuda:1')
final loss: -0.7595453262329102
Test:
Test: 0.6002813967113775
0.6002813967113775
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232558, 0.5836708161590052]
flatten test: 0.6034946216885545
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.32it/s]100%|██████████| 2/2 [00:00<00:00,  3.45it/s]100%|██████████| 2/2 [00:00<00:00,  3.43it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.5563409924507141
Epoch 1, Loop Feat 0: -0.5638072490692139
Epoch 1, Loop Adj 0: -0.6408170461654663
Epoch 2: -0.6408170461654663
Mem used: 860MB
best_loss: tensor(-0.7972, device='cuda:1')
best_loss: tensor(-0.7984, device='cuda:1')
final loss: -0.7699554562568665
Test:
Test: 0.6063734138967051
0.6063734138967051
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.5937196262431264, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.587874793205841
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.14it/s]100%|██████████| 1/1 [00:00<00:00,  4.13it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5961663722991943
Epoch 1: -0.5961663722991943
Mem used: 1410MB
best_loss: tensor(-0.6429, device='cuda:1')
best_loss: tensor(-0.6456, device='cuda:1')
final loss: -0.6281796097755432
Test:
Test: 0.6031066829216836
0.6031066829216836
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097034228988698, 0.6344159165859445, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987161352803
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.80it/s]100%|██████████| 1/1 [00:00<00:00,  6.79it/s]
Epoch 0, Loop Feat 0: -0.42172563076019287
Epoch 0, Loop Adj 0: -0.4318486154079437
Epoch 1: -0.4318486154079437
Mem used: 674MB
best_loss: tensor(-0.4652, device='cuda:1')
best_loss: tensor(-0.4704, device='cuda:1')
final loss: -0.45496758818626404
Test:
Test: 0.6059328826029378
0.6059328826029378
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804332029917
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.13it/s]100%|██████████| 1/1 [00:00<00:00,  6.11it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.34195631742477417
Epoch 1: -0.34195631742477417
Mem used: 674MB
best_loss: tensor(-0.3662, device='cuda:1')
final loss: -0.3558909296989441
Test:
Test: 0.6066628253227492
0.6066628253227492
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887461485434
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.59it/s]100%|██████████| 1/1 [00:00<00:00,  5.57it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.43079623579978943
Epoch 1: -0.43079623579978943
Mem used: 674MB
best_loss: tensor(-0.4497, device='cuda:1')
final loss: -0.44062426686286926
Test:
Test: 0.6093538313036804
0.6093538313036804
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205531217034048, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907167963030628
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.81it/s]100%|██████████| 1/1 [00:00<00:00,  4.80it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3838514983654022
Epoch 1: -0.3838514983654022
Mem used: 674MB
best_loss: tensor(-0.4114, device='cuda:1')
final loss: -0.40167805552482605
Test:
Test: 0.6064470475983499
0.6064470475983499
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127891115185
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.24it/s]100%|██████████| 1/1 [00:00<00:00,  6.22it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.45348650217056274
Epoch 1: -0.45348650217056274
Mem used: 798MB
best_loss: tensor(-0.4696, device='cuda:1')
best_loss: tensor(-0.4732, device='cuda:1')
final loss: -0.46986061334609985
Test:
Test: 0.6077524770154823
0.6077524770154823
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310911059929533, 0.6278801467147008, 0.5383906414670132, 0.5426401818150064]
flatten test: 0.597479599577137
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.36it/s]100%|██████████| 1/1 [00:00<00:00,  3.36it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.28516924381256104
Epoch 1: -0.28516924381256104
Mem used: 902MB
best_loss: tensor(-0.3041, device='cuda:1')
final loss: -0.29736194014549255
Test:
Test: 0.6049331482244031
0.6049331482244031
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483131832945
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.41it/s]100%|██████████| 1/1 [00:00<00:00,  3.30it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.4213796555995941
Epoch 1: -0.4213796555995941
Mem used: 674MB
best_loss: tensor(-0.4349, device='cuda:1')
final loss: -0.4313628673553467
Test:
Test: 0.6042108707173304
0.6042108707173304
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890635530158
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.49it/s]100%|██████████| 1/1 [00:00<00:00,  5.48it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.44288572669029236
Epoch 1: -0.44288572669029236
Mem used: 674MB
best_loss: tensor(-0.4525, device='cuda:1')
best_loss: tensor(-0.4570, device='cuda:1')
final loss: -0.4581202566623688
Test:
Test: 0.6053491349509554
0.6053491349509554
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232558, 0.5836708161590052]
flatten test: 0.603494616144178
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.75it/s]100%|██████████| 1/1 [00:00<00:00,  3.75it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.4372488260269165
Epoch 1: -0.4372488260269165
Mem used: 798MB
best_loss: tensor(-0.4761, device='cuda:1')
best_loss: tensor(-0.4807, device='cuda:1')
final loss: -0.4604512155056
Test:
Test: 0.6090411462265231
0.6090411462265231
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.593719576152412, 0.6002883018849671, 0.5401741024379962, 0.5824575153695682]
flatten test: 0.5878747821170878
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.25it/s]100%|██████████| 1/1 [00:00<00:00,  3.25it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5961663722991943
Epoch 1: -0.5961663722991943
Mem used: 694MB
best_loss: tensor(-0.6404, device='cuda:1')
best_loss: tensor(-0.6511, device='cuda:1')
final loss: -0.6332541704177856
Test:
Test: 0.600774432726598
0.600774432726598
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.644284027479605, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987272240334
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.53it/s]100%|██████████| 1/1 [00:00<00:00,  3.53it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.4318486154079437
Epoch 1: -0.4318486154079437
Mem used: 798MB
best_loss: tensor(-0.4687, device='cuda:1')
best_loss: tensor(-0.4790, device='cuda:1')
final loss: -0.4684700071811676
Test:
Test: 0.6063262311364278
0.6063262311364278
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405997298554459, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804498361216
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.89it/s]100%|██████████| 1/1 [00:00<00:00,  3.88it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.34195631742477417
Epoch 1: -0.34195631742477417
Mem used: 1442MB
best_loss: tensor(-0.3695, device='cuda:1')
final loss: -0.35873278975486755
Test:
Test: 0.6078745246773779
0.6078745246773779
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887516929199
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.60it/s]100%|██████████| 1/1 [00:00<00:00,  3.59it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.43079623579978943
Epoch 1: -0.43079623579978943
Mem used: 674MB
best_loss: tensor(-0.4513, device='cuda:1')
best_loss: tensor(-0.4574, device='cuda:1')
final loss: -0.45032331347465515
Test:
Test: 0.6096242981365828
0.6096242981365828
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205532218848335, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.590716824024946
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.40it/s]100%|██████████| 1/1 [00:00<00:00,  7.38it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3838514983654022
Epoch 1: -0.3838514983654022
Mem used: 674MB
best_loss: tensor(-0.4156, device='cuda:1')
final loss: -0.41011708974838257
Test:
Test: 0.6113870190535742
0.6113870190535742
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127780227653
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.41it/s]100%|██████████| 1/1 [00:00<00:00,  6.39it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.45348650217056274
Epoch 1: -0.45348650217056274
Mem used: 764MB
best_loss: tensor(-0.4820, device='cuda:1')
best_loss: tensor(-0.4897, device='cuda:1')
final loss: -0.4851028323173523
Test:
Test: 0.6099255052526963
0.6099255052526963
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310910559022389, 0.6278801467147008, 0.5383905009484999, 0.5426401818150064]
flatten test: 0.5974795829440073
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.92it/s]100%|██████████| 1/1 [00:00<00:00,  3.91it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.2851692736148834
Epoch 1: -0.2851692736148834
Mem used: 768MB
best_loss: tensor(-0.3057, device='cuda:1')
best_loss: tensor(-0.3062, device='cuda:1')
final loss: -0.30233079195022583
Test:
Test: 0.6052023044250757
0.6052023044250757
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483242720478
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.72it/s]100%|██████████| 1/1 [00:00<00:00,  3.71it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.4213796555995941
Epoch 1: -0.4213796555995941
Mem used: 674MB
best_loss: tensor(-0.4386, device='cuda:1')
best_loss: tensor(-0.4499, device='cuda:1')
final loss: -0.4471629858016968
Test:
Test: 0.6068472670220147
0.6068472670220147
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.598189074641769
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.34it/s]100%|██████████| 1/1 [00:00<00:00,  5.33it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.44288572669029236
Epoch 1: -0.44288572669029236
Mem used: 674MB
best_loss: tensor(-0.4604, device='cuda:1')
best_loss: tensor(-0.4679, device='cuda:1')
final loss: -0.46884462237358093
Test:
Test: 0.606361221045354
0.606361221045354
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232558, 0.5836708161590052]
flatten test: 0.6034946161441779
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.77it/s]100%|██████████| 1/1 [00:00<00:00,  5.75it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.4372488260269165
Epoch 1: -0.4372488260269165
Mem used: 674MB
best_loss: tensor(-0.4795, device='cuda:1')
final loss: -0.46573489904403687
Test:
Test: 0.6090011520854463
0.6090011520854463
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.5937196262431264, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747876614644
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.22it/s]100%|██████████| 1/1 [00:00<00:00,  4.22it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5961663722991943
Epoch 1: -0.5961663722991943
Mem used: 798MB
best_loss: tensor(-0.6457, device='cuda:1')
final loss: -0.6178764700889587
Test:
Test: 0.6002279388028479
0.6002279388028479
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344159165859445, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987105909037
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.34it/s]100%|██████████| 1/1 [00:00<00:00,  4.33it/s]
Epoch 0, Loop Feat 0: -0.42172563076019287
Epoch 0, Loop Adj 0: -0.4318486154079437
Epoch 1: -0.4318486154079437
Mem used: 788MB
best_loss: tensor(-0.4676, device='cuda:1')
final loss: -0.4525858461856842
Test:
Test: 0.6018128108978513
0.6018128108978513
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405996180406469, 0.614043983654398, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804332029917
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.87it/s]100%|██████████| 1/1 [00:00<00:00,  3.87it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.34195631742477417
Epoch 1: -0.34195631742477417
Mem used: 816MB
best_loss: tensor(-0.3609, device='cuda:1')
final loss: -0.35208195447921753
Test:
Test: 0.606510791984078
0.606510791984078
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163420955350138, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887572372966
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.33it/s]100%|██████████| 1/1 [00:00<00:00,  5.31it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.43079623579978943
Epoch 1: -0.43079623579978943
Mem used: 674MB
best_loss: tensor(-0.4459, device='cuda:1')
final loss: -0.43874412775039673
Test:
Test: 0.6100917569652556
0.6100917569652556
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205532218848335, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168184805694
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.74it/s]100%|██████████| 1/1 [00:00<00:00,  6.72it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3838514983654022
Epoch 1: -0.3838514983654022
Mem used: 674MB
best_loss: tensor(-0.4076, device='cuda:1')
final loss: -0.4010887145996094
Test:
Test: 0.606253510905731
0.606253510905731
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127891115185
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.45it/s]100%|██████████| 1/1 [00:00<00:00,  4.44it/s]
Epoch 0, Loop Feat 0: -0.4249717593193054
Epoch 0, Loop Adj 0: -0.45348650217056274
Epoch 1: -0.45348650217056274
Mem used: 674MB
best_loss: tensor(-0.4702, device='cuda:1')
final loss: -0.4688570499420166
Test:
Test: 0.6082599697013601
0.6082599697013601
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179836213682554, 0.6310910559022389, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974795940327604
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.32it/s]100%|██████████| 1/1 [00:00<00:00,  4.32it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.2851692736148834
Epoch 1: -0.2851692736148834
Mem used: 780MB
best_loss: tensor(-0.2997, device='cuda:1')
final loss: -0.29463475942611694
Test:
Test: 0.604675152255749
0.604675152255749
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483242720478
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.03it/s]100%|██████████| 1/1 [00:00<00:00,  3.02it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.4213796555995941
Epoch 1: -0.4213796555995941
Mem used: 958MB
best_loss: tensor(-0.4356, device='cuda:1')
final loss: -0.4288501441478729
Test:
Test: 0.602957668008754
0.602957668008754
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890690973923
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.97it/s]100%|██████████| 1/1 [00:00<00:00,  3.96it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.44288572669029236
Epoch 1: -0.44288572669029236
Mem used: 674MB
best_loss: tensor(-0.4505, device='cuda:1')
final loss: -0.45298874378204346
Test:
Test: 0.6040195184117616
0.6040195184117616
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483719525047425, 0.5836708161590052]
flatten test: 0.6034946105998013
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.21it/s]100%|██████████| 1/1 [00:00<00:00,  7.18it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.4372488260269165
Epoch 1: -0.4372488260269165
Mem used: 674MB
best_loss: tensor(-0.4783, device='cuda:1')
best_loss: tensor(-0.4785, device='cuda:1')
final loss: -0.4568331241607666
Test:
Test: 0.6090471830780063
0.6090471830780063
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.5937196262431264, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747876614645
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.44it/s]100%|██████████| 2/2 [00:00<00:00,  4.40it/s]100%|██████████| 2/2 [00:00<00:00,  4.40it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5961663722991943
Epoch 1, Loop Feat 0: -0.6149173378944397
Epoch 1, Loop Adj 0: -0.6219687461853027
Epoch 2: -0.6219687461853027
Mem used: 892MB
best_loss: tensor(-0.6608, device='cuda:1')
best_loss: tensor(-0.6623, device='cuda:1')
final loss: -0.6468228101730347
Test:
Test: 0.6018361242650927
0.6018361242650927
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987216796569
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.61it/s]100%|██████████| 2/2 [00:00<00:00,  5.93it/s]100%|██████████| 2/2 [00:00<00:00,  5.87it/s]
Epoch 0, Loop Feat 0: -0.42172563076019287
Epoch 0, Loop Adj 0: -0.4318486154079437
Epoch 1, Loop Feat 0: -0.447739839553833
Epoch 1, Loop Adj 0: -0.46691659092903137
Epoch 2: -0.46691659092903137
Mem used: 674MB
best_loss: tensor(-0.4909, device='cuda:1')
best_loss: tensor(-0.4956, device='cuda:1')
final loss: -0.4797821044921875
Test:
Test: 0.6050261633965995
0.6050261633965995
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405996180406469, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804387473683
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.96it/s]100%|██████████| 2/2 [00:00<00:00,  4.56it/s]100%|██████████| 2/2 [00:00<00:00,  4.40it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.3419562876224518
Epoch 1, Loop Feat 0: -0.33856847882270813
Epoch 1, Loop Adj 0: -0.3589516282081604
Epoch 2: -0.3589516282081604
Mem used: 674MB
best_loss: tensor(-0.3895, device='cuda:1')
final loss: -0.3790365159511566
Test:
Test: 0.6068544953573435
0.6068544953573435
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887516929199
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.69it/s]100%|██████████| 2/2 [00:00<00:00,  4.90it/s]100%|██████████| 2/2 [00:00<00:00,  4.86it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.43079623579978943
Epoch 1, Loop Feat 0: -0.43235352635383606
Epoch 1, Loop Adj 0: -0.4408210217952728
Epoch 2: -0.4408210217952728
Mem used: 674MB
best_loss: tensor(-0.4741, device='cuda:1')
final loss: -0.4644123315811157
Test:
Test: 0.6104069441584883
0.6104069441584883
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205532218848335, 0.5767507023125826, 0.5493891660226236, 0.5826381732918821]
flatten test: 0.5907168129361927
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.86it/s]100%|██████████| 2/2 [00:00<00:00,  3.81it/s]100%|██████████| 2/2 [00:00<00:00,  3.62it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3838514983654022
Epoch 1, Loop Feat 0: -0.39997607469558716
Epoch 1, Loop Adj 0: -0.41899123787879944
Epoch 2: -0.41899123787879944
Mem used: 892MB
best_loss: tensor(-0.4406, device='cuda:1')
final loss: -0.4323712885379791
Test:
Test: 0.6068446060414268
0.6068446060414268
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127891115184
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.77it/s]100%|██████████| 2/2 [00:00<00:00,  4.17it/s]100%|██████████| 2/2 [00:00<00:00,  4.10it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.45348653197288513
Epoch 1, Loop Feat 0: -0.46744465827941895
Epoch 1, Loop Adj 0: -0.4828242063522339
Epoch 2: -0.4828242063522339
Mem used: 804MB
best_loss: tensor(-0.5023, device='cuda:1')
final loss: -0.5008134245872498
Test:
Test: 0.6088193713667686
0.6088193713667686
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179836213682554, 0.6310911059929533, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974796106658903
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.84it/s]100%|██████████| 2/2 [00:00<00:00,  5.87it/s]100%|██████████| 2/2 [00:00<00:00,  5.68it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.2851692736148834
Epoch 1, Loop Feat 0: -0.28881773352622986
Epoch 1, Loop Adj 0: -0.30457523465156555
Epoch 2: -0.30457523465156555
Mem used: 856MB
best_loss: tensor(-0.3278, device='cuda:1')
final loss: -0.3217662572860718
Test:
Test: 0.6069509658326915
0.6069509658326915
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483242720478
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.92it/s]100%|██████████| 2/2 [00:00<00:00,  4.52it/s]100%|██████████| 2/2 [00:00<00:00,  4.41it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.4213796555995941
Epoch 1, Loop Feat 0: -0.4246031939983368
Epoch 1, Loop Adj 0: -0.4373428523540497
Epoch 2: -0.4373428523540497
Mem used: 674MB
best_loss: tensor(-0.4579, device='cuda:1')
best_loss: tensor(-0.4618, device='cuda:1')
final loss: -0.4577583968639374
Test:
Test: 0.6043917776811881
0.6043917776811881
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875724, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890635530156
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.81it/s]100%|██████████| 2/2 [00:00<00:00,  4.45it/s]100%|██████████| 2/2 [00:00<00:00,  4.69it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.44288572669029236
Epoch 1, Loop Feat 0: -0.4381231367588043
Epoch 1, Loop Adj 0: -0.46650612354278564
Epoch 2: -0.46650612354278564
Mem used: 674MB
best_loss: tensor(-0.4793, device='cuda:1')
best_loss: tensor(-0.4841, device='cuda:1')
final loss: -0.4867902100086212
Test:
Test: 0.6057093999496718
0.6057093999496718
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483719525047425, 0.5836708161590052]
flatten test: 0.6034946050554247
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.82it/s]100%|██████████| 2/2 [00:00<00:00,  4.06it/s]100%|██████████| 2/2 [00:00<00:00,  4.00it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.4372488260269165
Epoch 1, Loop Feat 0: -0.45220836997032166
Epoch 1, Loop Adj 0: -0.46137043833732605
Epoch 2: -0.46137043833732605
Mem used: 674MB
best_loss: tensor(-0.5043, device='cuda:1')
best_loss: tensor(-0.5051, device='cuda:1')
final loss: -0.48523199558258057
Test:
Test: 0.6108633619035273
0.6108633619035273
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.5937196763338406, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747876614645
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.24it/s]100%|██████████| 2/2 [00:00<00:00,  4.37it/s]100%|██████████| 2/2 [00:00<00:00,  4.35it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5961663722991943
Epoch 1, Loop Feat 0: -0.6299731135368347
Epoch 1, Loop Adj 0: -0.6330777406692505
Epoch 2: -0.6330777406692505
Mem used: 884MB
best_loss: tensor(-0.6692, device='cuda:1')
final loss: -0.6518484354019165
Test:
Test: 0.5993495769120297
0.5993495769120297
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.644284027479605, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987161352803
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.40it/s]100%|██████████| 2/2 [00:00<00:00,  7.56it/s]100%|██████████| 2/2 [00:00<00:00,  7.52it/s]
Epoch 0, Loop Feat 0: -0.42172563076019287
Epoch 0, Loop Adj 0: -0.4318486154079437
Epoch 1, Loop Feat 0: -0.4635968506336212
Epoch 1, Loop Adj 0: -0.4825446903705597
Epoch 2: -0.4825446903705597
Mem used: 816MB
best_loss: tensor(-0.5010, device='cuda:1')
best_loss: tensor(-0.5039, device='cuda:1')
final loss: -0.4888875484466553
Test:
Test: 0.6105492867618838
0.6105492867618838
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405996180406469, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562247297226491]
flatten test: 0.606580444291745
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.53it/s]100%|██████████| 2/2 [00:00<00:00,  8.17it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.34195631742477417
Epoch 1, Loop Feat 0: -0.3468582034111023
Epoch 1, Loop Adj 0: -0.3663933277130127
Epoch 2: -0.3663933277130127
Mem used: 674MB
best_loss: tensor(-0.3942, device='cuda:1')
final loss: -0.3846885561943054
Test:
Test: 0.6103377586631996
0.6103377586631996
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163420955350138, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887461485434
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.96it/s]100%|██████████| 2/2 [00:00<00:00,  5.69it/s]100%|██████████| 2/2 [00:00<00:00,  5.56it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.43079623579978943
Epoch 1, Loop Feat 0: -0.4432550072669983
Epoch 1, Loop Adj 0: -0.45445385575294495
Epoch 2: -0.45445385575294495
Mem used: 674MB
best_loss: tensor(-0.4765, device='cuda:1')
best_loss: tensor(-0.4846, device='cuda:1')
final loss: -0.4800110161304474
Test:
Test: 0.6139266668700132
0.6139266668700132
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205531217034048, 0.576750097652589, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168018474395
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.35it/s]100%|██████████| 2/2 [00:00<00:00,  5.23it/s]100%|██████████| 2/2 [00:00<00:00,  5.36it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3838514983654022
Epoch 1, Loop Feat 0: -0.4176245331764221
Epoch 1, Loop Adj 0: -0.43683379888534546
Epoch 2: -0.43683379888534546
Mem used: 998MB
best_loss: tensor(-0.4526, device='cuda:1')
best_loss: tensor(-0.4595, device='cuda:1')
final loss: -0.4533945322036743
Test:
Test: 0.6072951457994952
0.6072951457994952
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127891115185
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.06it/s]100%|██████████| 2/2 [00:00<00:00,  6.30it/s]100%|██████████| 2/2 [00:00<00:00,  6.39it/s]
Epoch 0, Loop Feat 0: -0.4249717891216278
Epoch 0, Loop Adj 0: -0.45348653197288513
Epoch 1, Loop Feat 0: -0.4848185181617737
Epoch 1, Loop Adj 0: -0.5014687776565552
Epoch 2: -0.5014687776565552
Mem used: 812MB
best_loss: tensor(-0.5146, device='cuda:1')
best_loss: tensor(-0.5156, device='cuda:1')
final loss: -0.5126175880432129
Test:
Test: 0.6110408135642333
0.6110408135642333
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310910058115247, 0.6278801467147008, 0.5383905009484999, 0.5426401818150064]
flatten test: 0.5974795884883838
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.21it/s]100%|██████████| 2/2 [00:00<00:00,  5.01it/s]100%|██████████| 2/2 [00:00<00:00,  4.87it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.28516924381256104
Epoch 1, Loop Feat 0: -0.2956063151359558
Epoch 1, Loop Adj 0: -0.3125401437282562
Epoch 2: -0.3125401437282562
Mem used: 674MB
best_loss: tensor(-0.3316, device='cuda:1')
best_loss: tensor(-0.3327, device='cuda:1')
final loss: -0.32846686244010925
Test:
Test: 0.6076741568107124
0.6076741568107124
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483353608009
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.80it/s]100%|██████████| 2/2 [00:00<00:00,  3.94it/s]100%|██████████| 2/2 [00:00<00:00,  4.05it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.4213796555995941
Epoch 1, Loop Feat 0: -0.4443027377128601
Epoch 1, Loop Adj 0: -0.4585835039615631
Epoch 2: -0.4585835039615631
Mem used: 890MB
best_loss: tensor(-0.4700, device='cuda:1')
best_loss: tensor(-0.4765, device='cuda:1')
final loss: -0.473478764295578
Test:
Test: 0.608596921332835
0.608596921332835
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875724, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890857305222
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.14it/s]100%|██████████| 2/2 [00:00<00:00,  3.85it/s]100%|██████████| 2/2 [00:00<00:00,  3.99it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.44288572669029236
Epoch 1, Loop Feat 0: -0.4544866383075714
Epoch 1, Loop Adj 0: -0.4843246638774872
Epoch 2: -0.4843246638774872
Mem used: 906MB
best_loss: tensor(-0.4881, device='cuda:1')
best_loss: tensor(-0.4955, device='cuda:1')
final loss: -0.49797433614730835
Test:
Test: 0.6062902880404253
0.6062902880404253
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483719525047425, 0.5836708161590052]
flatten test: 0.6034946161441779
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.00it/s]100%|██████████| 2/2 [00:00<00:00,  3.64it/s]100%|██████████| 2/2 [00:00<00:00,  3.68it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.4372488260269165
Epoch 1, Loop Feat 0: -0.464885950088501
Epoch 1, Loop Adj 0: -0.47263237833976746
Epoch 2: -0.47263237833976746
Mem used: 794MB
best_loss: tensor(-0.5092, device='cuda:1')
best_loss: tensor(-0.5132, device='cuda:1')
final loss: -0.49522581696510315
Test:
Test: 0.6144079866274208
0.6144079866274208
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.5937196262431264, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747876614644
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.77it/s]100%|██████████| 2/2 [00:00<00:00,  6.14it/s]100%|██████████| 2/2 [00:00<00:00,  5.88it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5961663722991943
Epoch 1, Loop Feat 0: -0.6065686941146851
Epoch 1, Loop Adj 0: -0.6174347996711731
Epoch 2: -0.6174347996711731
Mem used: 1544MB
best_loss: tensor(-0.6594, device='cuda:1')
best_loss: tensor(-0.6605, device='cuda:1')
final loss: -0.6385716199874878
Test:
Test: 0.6007005607281841
0.6007005607281841
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344159165859445, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987161352804
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.76it/s]100%|██████████| 2/2 [00:00<00:00,  5.08it/s]100%|██████████| 2/2 [00:00<00:00,  5.03it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.4318486154079437
Epoch 1, Loop Feat 0: -0.44098228216171265
Epoch 1, Loop Adj 0: -0.46010804176330566
Epoch 2: -0.46010804176330566
Mem used: 692MB
best_loss: tensor(-0.4909, device='cuda:1')
best_loss: tensor(-0.4911, device='cuda:1')
final loss: -0.4728664457798004
Test:
Test: 0.604339511256504
0.604339511256504
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405996180406469, 0.614043983654398, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804498361215
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  9.54it/s]100%|██████████| 2/2 [00:00<00:00,  8.85it/s]100%|██████████| 2/2 [00:00<00:00,  8.71it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.34195631742477417
Epoch 1, Loop Feat 0: -0.3354460597038269
Epoch 1, Loop Adj 0: -0.3561908006668091
Epoch 2: -0.3561908006668091
Mem used: -594MB
best_loss: tensor(-0.3840, device='cuda:1')
final loss: -0.3760771155357361
Test:
Test: 0.6069282482073728
0.6069282482073728
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887516929199
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.73it/s]100%|██████████| 2/2 [00:00<00:00,  4.23it/s]100%|██████████| 2/2 [00:00<00:00,  4.21it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.43079623579978943
Epoch 1, Loop Feat 0: -0.4280817210674286
Epoch 1, Loop Adj 0: -0.43490660190582275
Epoch 2: -0.43490660190582275
Mem used: 886MB
best_loss: tensor(-0.4701, device='cuda:1')
final loss: -0.4636794924736023
Test:
Test: 0.6110487965059974
0.6110487965059974
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205531717941192, 0.5767507023125826, 0.5493891660226236, 0.5826381732918821]
flatten test: 0.5907168018474395
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.14it/s]100%|██████████| 2/2 [00:00<00:00,  3.23it/s]100%|██████████| 2/2 [00:00<00:00,  3.34it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3838514983654022
Epoch 1, Loop Feat 0: -0.3929321765899658
Epoch 1, Loop Adj 0: -0.4123283624649048
Epoch 2: -0.4123283624649048
Mem used: 674MB
best_loss: tensor(-0.4357, device='cuda:1')
final loss: -0.43088507652282715
Test:
Test: 0.6068331677965111
0.6068331677965111
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127780227653
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.11it/s]100%|██████████| 2/2 [00:00<00:00,  5.49it/s]100%|██████████| 2/2 [00:00<00:00,  5.57it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.45348653197288513
Epoch 1, Loop Feat 0: -0.4595825970172882
Epoch 1, Loop Adj 0: -0.474230021238327
Epoch 2: -0.474230021238327
Mem used: 818MB
best_loss: tensor(-0.4959, device='cuda:1')
final loss: -0.496069997549057
Test:
Test: 0.6090213675946896
0.6090213675946896
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310910559022389, 0.6278801467147008, 0.5383905009484999, 0.5426401818150064]
flatten test: 0.5974795829440072
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  2.79it/s]100%|██████████| 2/2 [00:00<00:00,  3.18it/s]100%|██████████| 2/2 [00:00<00:00,  3.09it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.2851692736148834
Epoch 1, Loop Feat 0: -0.2860543131828308
Epoch 1, Loop Adj 0: -0.3014105558395386
Epoch 2: -0.3014105558395386
Mem used: 2056MB
best_loss: tensor(-0.3233, device='cuda:1')
final loss: -0.3181881308555603
Test:
Test: 0.6064456178177353
0.6064456178177353
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483187276712
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.08it/s]100%|██████████| 2/2 [00:00<00:00,  4.99it/s]100%|██████████| 2/2 [00:00<00:00,  4.82it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.4213796555995941
Epoch 1, Loop Feat 0: -0.4176514148712158
Epoch 1, Loop Adj 0: -0.4287126064300537
Epoch 2: -0.4287126064300537
Mem used: 674MB
best_loss: tensor(-0.4578, device='cuda:1')
final loss: -0.4523178040981293
Test:
Test: 0.6025019651540223
0.6025019651540223
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875724, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890801861456
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.20it/s]100%|██████████| 2/2 [00:00<00:00,  5.94it/s]100%|██████████| 2/2 [00:00<00:00,  6.09it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.44288572669029236
Epoch 1, Loop Feat 0: -0.43091505765914917
Epoch 1, Loop Adj 0: -0.4581461250782013
Epoch 2: -0.4581461250782013
Mem used: 674MB
best_loss: tensor(-0.4771, device='cuda:1')
best_loss: tensor(-0.4771, device='cuda:1')
final loss: -0.47925519943237305
Test:
Test: 0.6055772643912185
0.6055772643912185
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483719525047425, 0.5836708161590052]
flatten test: 0.6034946161441779
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.07it/s]100%|██████████| 2/2 [00:00<00:00,  5.31it/s]100%|██████████| 2/2 [00:00<00:00,  5.07it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.4372488260269165
Epoch 1, Loop Feat 0: -0.44673073291778564
Epoch 1, Loop Adj 0: -0.4552032947540283
Epoch 2: -0.4552032947540283
Mem used: 818MB
best_loss: tensor(-0.5037, device='cuda:1')
final loss: -0.48296332359313965
Test:
Test: 0.6093808382708423
0.6093808382708423
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.5937196262431264, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747765727111
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.30it/s]100%|██████████| 1/1 [00:00<00:00,  4.20it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5961663722991943
Epoch 1: -0.5961663722991943
Mem used: 844MB
best_loss: tensor(-0.6430, device='cuda:1')
best_loss: tensor(-0.6458, device='cuda:1')
final loss: -0.6269594430923462
Test:
Test: 0.6024109357882348
0.6024109357882348
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987161352803
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.59it/s]100%|██████████| 1/1 [00:00<00:00,  4.58it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.4318486154079437
Epoch 1: -0.4318486154079437
Mem used: -594MB
best_loss: tensor(-0.4653, device='cuda:1')
best_loss: tensor(-0.4701, device='cuda:1')
final loss: -0.454089492559433
Test:
Test: 0.6060687117613117
0.6060687117613117
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804332029917
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.58it/s]100%|██████████| 1/1 [00:00<00:00,  4.57it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.3419562876224518
Epoch 1: -0.3419562876224518
Mem used: 674MB
best_loss: tensor(-0.3662, device='cuda:1')
final loss: -0.35581740736961365
Test:
Test: 0.6066799032578664
0.6066799032578664
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280594765278374, 0.6163420955350138, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.60168873505979
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.77it/s]100%|██████████| 1/1 [00:00<00:00,  4.76it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.43079623579978943
Epoch 1: -0.43079623579978943
Mem used: 782MB
best_loss: tensor(-0.4497, device='cuda:1')
final loss: -0.4403359889984131
Test:
Test: 0.6093437434071227
0.6093437434071227
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035360312008, 0.6205531717941192, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168184805693
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.76it/s]100%|██████████| 1/1 [00:00<00:00,  5.75it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3838514983654022
Epoch 1: -0.3838514983654022
Mem used: 806MB
best_loss: tensor(-0.4113, device='cuda:1')
final loss: -0.4026869237422943
Test:
Test: 0.6064516149530905
0.6064516149530905
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127724783887
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.28it/s]100%|██████████| 1/1 [00:00<00:00,  5.14it/s]
Epoch 0, Loop Feat 0: -0.4249717593193054
Epoch 0, Loop Adj 0: -0.45348653197288513
Epoch 1: -0.45348653197288513
Mem used: 674MB
best_loss: tensor(-0.4697, device='cuda:1')
best_loss: tensor(-0.4731, device='cuda:1')
final loss: -0.47153761982917786
Test:
Test: 0.6079179741216063
0.6079179741216063
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179836213682554, 0.6310910559022389, 0.6278801467147008, 0.5383906414670132, 0.5426401818150064]
flatten test: 0.5974796051215137
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  2.74it/s]100%|██████████| 1/1 [00:00<00:00,  2.74it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.28516924381256104
Epoch 1: -0.28516924381256104
Mem used: -594MB
best_loss: tensor(-0.3041, device='cuda:1')
final loss: -0.29752352833747864
Test:
Test: 0.6049112646377762
0.6049112646377762
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483242720478
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.80it/s]100%|██████████| 1/1 [00:00<00:00,  4.79it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.4213796555995941
Epoch 1: -0.4213796555995941
Mem used: 674MB
best_loss: tensor(-0.4349, device='cuda:1')
final loss: -0.43109366297721863
Test:
Test: 0.6041483575315759
0.6041483575315759
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890801861456
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.35it/s]100%|██████████| 1/1 [00:00<00:00,  3.34it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.44288572669029236
Epoch 1: -0.44288572669029236
Mem used: 674MB
best_loss: tensor(-0.4526, device='cuda:1')
best_loss: tensor(-0.4569, device='cuda:1')
final loss: -0.4570639431476593
Test:
Test: 0.6054409983554345
0.6054409983554345
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232557, 0.5836708161590052]
flatten test: 0.6034946216885546
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.29it/s]100%|██████████| 1/1 [00:00<00:00,  3.27it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.4372488260269165
Epoch 1: -0.4372488260269165
Mem used: 674MB
best_loss: tensor(-0.4762, device='cuda:1')
best_loss: tensor(-0.4808, device='cuda:1')
final loss: -0.45939627289772034
Test:
Test: 0.6091857923653528
0.6091857923653528
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.5937196763338406, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747876614644
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.61it/s]100%|██████████| 1/1 [00:00<00:00,  4.60it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5961663722991943
Epoch 1: -0.5961663722991943
Mem used: 1142MB
best_loss: tensor(-0.6405, device='cuda:1')
best_loss: tensor(-0.6515, device='cuda:1')
final loss: -0.6332325339317322
Test:
Test: 0.6000044958657099
0.6000044958657099
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.644284027479605, 0.6097033728081556, 0.6344159165859445, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987216796568
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.76it/s]100%|██████████| 1/1 [00:00<00:00,  5.74it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.4318486154079437
Epoch 1: -0.4318486154079437
Mem used: 740MB
best_loss: tensor(-0.4688, device='cuda:1')
best_loss: tensor(-0.4785, device='cuda:1')
final loss: -0.4674451947212219
Test:
Test: 0.6067090151798219
0.6067090151798219
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405996180406469, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562250026198128]
flatten test: 0.6065804498361215
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.53it/s]100%|██████████| 1/1 [00:00<00:00,  5.33it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.3419562876224518
Epoch 1: -0.3419562876224518
Mem used: 816MB
best_loss: tensor(-0.3695, device='cuda:1')
final loss: -0.35873278975486755
Test:
Test: 0.6078745246773779
0.6078745246773779
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280594765278374, 0.6163420955350138, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887461485433
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.46it/s]100%|██████████| 1/1 [00:00<00:00,  5.44it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.43079623579978943
Epoch 1: -0.43079623579978943
Mem used: 760MB
best_loss: tensor(-0.4513, device='cuda:1')
best_loss: tensor(-0.4573, device='cuda:1')
final loss: -0.45047256350517273
Test:
Test: 0.6092118064293104
0.6092118064293104
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205532218848334, 0.5767507023125826, 0.5493891660226236, 0.5826381732918821]
flatten test: 0.5907168184805693
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.46it/s]100%|██████████| 1/1 [00:00<00:00,  5.44it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3838514983654022
Epoch 1: -0.3838514983654022
Mem used: 674MB
best_loss: tensor(-0.4156, device='cuda:1')
final loss: -0.41011708974838257
Test:
Test: 0.6113870587697023
0.6113870587697023
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127891115185
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  8.85it/s]100%|██████████| 1/1 [00:00<00:00,  8.80it/s]
Epoch 0, Loop Feat 0: -0.4249717593193054
Epoch 0, Loop Adj 0: -0.45348653197288513
Epoch 1: -0.45348653197288513
Mem used: 674MB
best_loss: tensor(-0.4821, device='cuda:1')
best_loss: tensor(-0.4891, device='cuda:1')
final loss: -0.4848245084285736
Test:
Test: 0.609991831186756
0.609991831186756
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179833977386575, 0.6310911059929533, 0.6278801467147008, 0.5383905009484999, 0.5426401818150064]
flatten test: 0.5974796051215138
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.67it/s]100%|██████████| 1/1 [00:00<00:00,  5.66it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.28516924381256104
Epoch 1: -0.28516924381256104
Mem used: 808MB
best_loss: tensor(-0.3057, device='cuda:1')
best_loss: tensor(-0.3060, device='cuda:1')
final loss: -0.30217310786247253
Test:
Test: 0.6050190542096554
0.6050190542096554
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483298164244
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.15it/s]100%|██████████| 1/1 [00:00<00:00,  5.14it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.4213796555995941
Epoch 1: -0.4213796555995941
Mem used: 792MB
best_loss: tensor(-0.4387, device='cuda:1')
best_loss: tensor(-0.4496, device='cuda:1')
final loss: -0.44620805978775024
Test:
Test: 0.6065175040097404
0.6065175040097404
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890635530157
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.37it/s]100%|██████████| 1/1 [00:00<00:00,  4.36it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.44288572669029236
Epoch 1: -0.44288572669029236
Mem used: 674MB
best_loss: tensor(-0.4604, device='cuda:1')
best_loss: tensor(-0.4677, device='cuda:1')
final loss: -0.46725350618362427
Test:
Test: 0.606214549383987
0.606214549383987
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232558, 0.5836708161590052]
flatten test: 0.6034946105998013
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.96it/s]100%|██████████| 1/1 [00:00<00:00,  6.49it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.4372488260269165
Epoch 1: -0.4372488260269165
Mem used: 674MB
best_loss: tensor(-0.4795, device='cuda:1')
best_loss: tensor(-0.4873, device='cuda:1')
final loss: -0.4698680341243744
Test:
Test: 0.6114749108452354
0.6114749108452354
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.593719576152412, 0.6002883018849671, 0.5401741024379962, 0.5824575153695682]
flatten test: 0.587874765483958
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.21it/s]100%|██████████| 1/1 [00:00<00:00,  4.20it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5961663722991943
Epoch 1: -0.5961663722991943
Mem used: 674MB
best_loss: tensor(-0.6456, device='cuda:1')
final loss: -0.6206684112548828
Test:
Test: 0.6000969550121118
0.6000969550121118
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987161352803
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.56it/s]100%|██████████| 1/1 [00:00<00:00,  5.55it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.4318486154079437
Epoch 1: -0.4318486154079437
Mem used: 834MB
best_loss: tensor(-0.4674, device='cuda:1')
final loss: -0.45301586389541626
Test:
Test: 0.601718048216015
0.601718048216015
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405996180406469, 0.6140439335636838, 0.6456251035480238, 0.5428112133773625, 0.5562244568254855]
flatten test: 0.6065804332029917
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.78it/s]100%|██████████| 1/1 [00:00<00:00,  6.75it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.34195631742477417
Epoch 1: -0.34195631742477417
Mem used: 748MB
best_loss: tensor(-0.3609, device='cuda:1')
final loss: -0.35208195447921753
Test:
Test: 0.606510791984078
0.606510791984078
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280594765278374, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887516929199
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.49it/s]100%|██████████| 1/1 [00:00<00:00,  3.48it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.43079623579978943
Epoch 1: -0.43079623579978943
Mem used: 674MB
best_loss: tensor(-0.4459, device='cuda:1')
final loss: -0.43874406814575195
Test:
Test: 0.6100917569652556
0.6100917569652556
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205531217034048, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168129361927
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.41it/s]100%|██████████| 1/1 [00:00<00:00,  5.18it/s]
Epoch 0, Loop Feat 0: -0.35880887508392334
Epoch 0, Loop Adj 0: -0.3838514983654022
Epoch 1: -0.3838514983654022
Mem used: 674MB
best_loss: tensor(-0.4076, device='cuda:1')
final loss: -0.40120866894721985
Test:
Test: 0.606358560064766
0.606358560064766
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127724783887
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.79it/s]100%|██████████| 1/1 [00:00<00:00,  5.78it/s]
Epoch 0, Loop Feat 0: -0.4249717593193054
Epoch 0, Loop Adj 0: -0.45348653197288513
Epoch 1: -0.45348653197288513
Mem used: 674MB
best_loss: tensor(-0.4702, device='cuda:1')
final loss: -0.46888434886932373
Test:
Test: 0.6082737909139666
0.6082737909139666
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179836213682554, 0.6310910058115247, 0.6278801467147008, 0.5383905009484999, 0.5426401818150064]
flatten test: 0.5974795829440072
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.54it/s]100%|██████████| 1/1 [00:00<00:00,  3.53it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.2851692736148834
Epoch 1: -0.2851692736148834
Mem used: 842MB
best_loss: tensor(-0.2997, device='cuda:1')
final loss: -0.29463475942611694
Test:
Test: 0.604675152255749
0.604675152255749
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483242720478
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.25it/s]100%|██████████| 1/1 [00:00<00:00,  3.24it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.4213796555995941
Epoch 1: -0.4213796555995941
Mem used: 816MB
best_loss: tensor(-0.4357, device='cuda:1')
final loss: -0.42906421422958374
Test:
Test: 0.6030126351301546
0.6030126351301546
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890801861455
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.84it/s]100%|██████████| 1/1 [00:00<00:00,  7.54it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.44288572669029236
Epoch 1: -0.44288572669029236
Mem used: 674MB
best_loss: tensor(-0.4505, device='cuda:1')
final loss: -0.45298874378204346
Test:
Test: 0.6040195581278898
0.6040195581278898
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483719525047425, 0.5836708161590052]
flatten test: 0.6034946105998013
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.82it/s]100%|██████████| 1/1 [00:00<00:00,  4.59it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.4372488260269165
Epoch 1: -0.4372488260269165
Mem used: 674MB
best_loss: tensor(-0.4783, device='cuda:1')
best_loss: tensor(-0.4785, device='cuda:1')
final loss: -0.4568331241607666
Test:
Test: 0.6090472227941345
0.6090472227941345
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.593719576152412, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747821170878
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.84it/s]100%|██████████| 2/2 [00:00<00:00,  4.84it/s]100%|██████████| 2/2 [00:00<00:00,  4.83it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5961663722991943
Epoch 1, Loop Feat 0: -0.6142982840538025
Epoch 1, Loop Adj 0: -0.6215090155601501
Epoch 2: -0.6215090155601501
Mem used: 674MB
best_loss: tensor(-0.6618, device='cuda:1')
final loss: -0.6408308148384094
Test:
Test: 0.6008340863511236
0.6008340863511236
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987050465271
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.06it/s]100%|██████████| 2/2 [00:00<00:00,  3.20it/s]100%|██████████| 2/2 [00:00<00:00,  3.39it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.4318486154079437
Epoch 1, Loop Feat 0: -0.44727545976638794
Epoch 1, Loop Adj 0: -0.46644294261932373
Epoch 2: -0.46644294261932373
Mem used: 1181MB
best_loss: tensor(-0.4911, device='cuda:1')
best_loss: tensor(-0.4954, device='cuda:1')
final loss: -0.4797617793083191
Test:
Test: 0.6052106448119934
0.6052106448119934
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405993944110492, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804387473683
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.17it/s]100%|██████████| 2/2 [00:00<00:00,  3.94it/s]100%|██████████| 2/2 [00:00<00:00,  4.08it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.34195631742477417
Epoch 1, Loop Feat 0: -0.3382504880428314
Epoch 1, Loop Adj 0: -0.3586941063404083
Epoch 2: -0.3586941063404083
Mem used: 826MB
best_loss: tensor(-0.3895, device='cuda:1')
final loss: -0.3789314925670624
Test:
Test: 0.6068649406990547
0.6068649406990547
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280594765278374, 0.6163420955350138, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887461485434
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.06it/s]100%|██████████| 2/2 [00:00<00:00,  4.46it/s]100%|██████████| 2/2 [00:00<00:00,  4.54it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.43079623579978943
Epoch 1, Loop Feat 0: -0.4319988191127777
Epoch 1, Loop Adj 0: -0.4403209090232849
Epoch 2: -0.4403209090232849
Mem used: 674MB
best_loss: tensor(-0.4740, device='cuda:1')
final loss: -0.4653288424015045
Test:
Test: 0.610461950996017
0.610461950996017
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205532218848335, 0.576750097652589, 0.5493891660226236, 0.5826381732918821]
flatten test: 0.5907168073918161
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.62it/s]100%|██████████| 2/2 [00:00<00:00,  4.59it/s]100%|██████████| 2/2 [00:00<00:00,  4.59it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.38385146856307983
Epoch 1, Loop Feat 0: -0.3993770480155945
Epoch 1, Loop Adj 0: -0.418432354927063
Epoch 2: -0.418432354927063
Mem used: 674MB
best_loss: tensor(-0.4405, device='cuda:1')
final loss: -0.433040976524353
Test:
Test: 0.6068483790736039
0.6068483790736039
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.605312766934012
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.64it/s]100%|██████████| 2/2 [00:00<00:00,  4.87it/s]100%|██████████| 2/2 [00:00<00:00,  4.63it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.45348653197288513
Epoch 1, Loop Feat 0: -0.46687600016593933
Epoch 1, Loop Adj 0: -0.48223260045051575
Epoch 2: -0.48223260045051575
Mem used: 674MB
best_loss: tensor(-0.5023, device='cuda:1')
final loss: -0.5000612735748291
Test:
Test: 0.608813691960439
0.608813691960439
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310911059929533, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974796051215135
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.54it/s]100%|██████████| 2/2 [00:00<00:00,  3.37it/s]100%|██████████| 2/2 [00:00<00:00,  3.39it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.2851692736148834
Epoch 1, Loop Feat 0: -0.28849220275878906
Epoch 1, Loop Adj 0: -0.30419227480888367
Epoch 2: -0.30419227480888367
Mem used: 952MB
best_loss: tensor(-0.3278, device='cuda:1')
final loss: -0.3218522369861603
Test:
Test: 0.6069392495748787
0.6069392495748787
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483298164245
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.80it/s]100%|██████████| 2/2 [00:00<00:00,  4.96it/s]100%|██████████| 2/2 [00:00<00:00,  4.93it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.4213796555995941
Epoch 1, Loop Feat 0: -0.4240187108516693
Epoch 1, Loop Adj 0: -0.436652272939682
Epoch 2: -0.436652272939682
Mem used: 870MB
best_loss: tensor(-0.4574, device='cuda:1')
best_loss: tensor(-0.4607, device='cuda:1')
final loss: -0.4576015770435333
Test:
Test: 0.6045282820137412
0.6045282820137412
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890635530158
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.11it/s]100%|██████████| 2/2 [00:00<00:00,  4.40it/s]100%|██████████| 2/2 [00:00<00:00,  4.30it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.44288572669029236
Epoch 1, Loop Feat 0: -0.4375769793987274
Epoch 1, Loop Adj 0: -0.4658524990081787
Epoch 2: -0.4658524990081787
Mem used: -594MB
best_loss: tensor(-0.4793, device='cuda:1')
best_loss: tensor(-0.4840, device='cuda:1')
final loss: -0.48658287525177
Test:
Test: 0.6059915036081308
0.6059915036081308
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232558, 0.5836708161590052]
flatten test: 0.6034946161441779
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.35it/s]100%|██████████| 2/2 [00:00<00:00,  4.05it/s]100%|██████████| 2/2 [00:00<00:00,  4.17it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.4372488260269165
Epoch 1, Loop Feat 0: -0.4518125355243683
Epoch 1, Loop Adj 0: -0.46095767617225647
Epoch 2: -0.46095767617225647
Mem used: 674MB
best_loss: tensor(-0.5042, device='cuda:1')
best_loss: tensor(-0.5050, device='cuda:1')
final loss: -0.4851357340812683
Test:
Test: 0.6091156536829878
0.6091156536829878
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.5937196262431264, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747876614644
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.54it/s]100%|██████████| 2/2 [00:00<00:00,  4.80it/s]100%|██████████| 2/2 [00:00<00:00,  4.76it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5961663722991943
Epoch 1, Loop Feat 0: -0.6295655369758606
Epoch 1, Loop Adj 0: -0.6326860189437866
Epoch 2: -0.6326860189437866
Mem used: 674MB
best_loss: tensor(-0.6682, device='cuda:1')
final loss: -0.6523744463920593
Test:
Test: 0.5997384375230354
0.5997384375230354
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344159165859445, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987161352803
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.34it/s]100%|██████████| 2/2 [00:00<00:00,  5.95it/s]100%|██████████| 2/2 [00:00<00:00,  5.72it/s]
Epoch 0, Loop Feat 0: -0.42172563076019287
Epoch 0, Loop Adj 0: -0.4318486154079437
Epoch 1, Loop Feat 0: -0.46317601203918457
Epoch 1, Loop Adj 0: -0.48215267062187195
Epoch 2: -0.48215267062187195
Mem used: 996MB
best_loss: tensor(-0.5008, device='cuda:1')
best_loss: tensor(-0.5033, device='cuda:1')
final loss: -0.4878816306591034
Test:
Test: 0.6100083928122069
0.6100083928122069
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405996180406469, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562247297226491]
flatten test: 0.6065804387473683
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.49it/s]100%|██████████| 2/2 [00:00<00:00,  6.30it/s]100%|██████████| 2/2 [00:00<00:00,  6.21it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.34195631742477417
Epoch 1, Loop Feat 0: -0.3465598523616791
Epoch 1, Loop Adj 0: -0.3661424517631531
Epoch 2: -0.3661424517631531
Mem used: 828MB
best_loss: tensor(-0.3942, device='cuda:1')
final loss: -0.38402727246284485
Test:
Test: 0.6103804535009926
0.6103804535009926
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280594765278374, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887516929199
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.17it/s]100%|██████████| 2/2 [00:00<00:00,  4.89it/s]100%|██████████| 2/2 [00:00<00:00,  5.13it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.43079623579978943
Epoch 1, Loop Feat 0: -0.44291952252388
Epoch 1, Loop Adj 0: -0.4540286362171173
Epoch 2: -0.4540286362171173
Mem used: 1022MB
best_loss: tensor(-0.4760, device='cuda:1')
best_loss: tensor(-0.4845, device='cuda:1')
final loss: -0.47902464866638184
Test:
Test: 0.6143917824471236
0.6143917824471236
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205531217034048, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168184805693
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.59it/s]100%|██████████| 2/2 [00:00<00:00,  6.28it/s]100%|██████████| 2/2 [00:00<00:00,  5.94it/s]
Epoch 0, Loop Feat 0: -0.35880887508392334
Epoch 0, Loop Adj 0: -0.3838514983654022
Epoch 1, Loop Feat 0: -0.41705378890037537
Epoch 1, Loop Adj 0: -0.43625760078430176
Epoch 2: -0.43625760078430176
Mem used: 674MB
best_loss: tensor(-0.4526, device='cuda:1')
best_loss: tensor(-0.4588, device='cuda:1')
final loss: -0.45306235551834106
Test:
Test: 0.6074843137180143
0.6074843137180143
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127558452589
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.55it/s]100%|██████████| 2/2 [00:00<00:00,  3.21it/s]100%|██████████| 2/2 [00:00<00:00,  3.25it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.45348650217056274
Epoch 1, Loop Feat 0: -0.4844103753566742
Epoch 1, Loop Adj 0: -0.5009595155715942
Epoch 2: -0.5009595155715942
Mem used: 674MB
best_loss: tensor(-0.5146, device='cuda:1')
best_loss: tensor(-0.5151, device='cuda:1')
final loss: -0.5115472674369812
Test:
Test: 0.6110283029838568
0.6110283029838568
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179836213682554, 0.6310911059929533, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974796051215135
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.53it/s]100%|██████████| 2/2 [00:00<00:00,  4.37it/s]100%|██████████| 2/2 [00:00<00:00,  4.59it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.28516924381256104
Epoch 1, Loop Feat 0: -0.29530102014541626
Epoch 1, Loop Adj 0: -0.31217098236083984
Epoch 2: -0.31217098236083984
Mem used: 674MB
best_loss: tensor(-0.3314, device='cuda:1')
best_loss: tensor(-0.3323, device='cuda:1')
final loss: -0.3281802833080292
Test:
Test: 0.6076311045277657
0.6076311045277657
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.600148318727671
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.54it/s]100%|██████████| 2/2 [00:00<00:00,  3.61it/s]100%|██████████| 2/2 [00:00<00:00,  3.72it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.4213796555995941
Epoch 1, Loop Feat 0: -0.4437474310398102
Epoch 1, Loop Adj 0: -0.45798665285110474
Epoch 2: -0.45798665285110474
Mem used: 874MB
best_loss: tensor(-0.4703, device='cuda:1')
best_loss: tensor(-0.4756, device='cuda:1')
final loss: -0.47344398498535156
Test:
Test: 0.6087811644514599
0.6087811644514599
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890690973923
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.16it/s]100%|██████████| 2/2 [00:00<00:00,  4.35it/s]100%|██████████| 2/2 [00:00<00:00,  4.45it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.44288572669029236
Epoch 1, Loop Feat 0: -0.4540225863456726
Epoch 1, Loop Adj 0: -0.4838244616985321
Epoch 2: -0.4838244616985321
Mem used: 792MB
best_loss: tensor(-0.4880, device='cuda:1')
best_loss: tensor(-0.4943, device='cuda:1')
final loss: -0.4976600408554077
Test:
Test: 0.6063070482465169
0.6063070482465169
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232557, 0.5836710890561687]
flatten test: 0.6034946272329311
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.97it/s]100%|██████████| 2/2 [00:00<00:00,  6.05it/s]100%|██████████| 2/2 [00:00<00:00,  5.82it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.4372488260269165
Epoch 1, Loop Feat 0: -0.4645979106426239
Epoch 1, Loop Adj 0: -0.472370445728302
Epoch 2: -0.472370445728302
Mem used: 674MB
best_loss: tensor(-0.5085, device='cuda:1')
best_loss: tensor(-0.5131, device='cuda:1')
final loss: -0.49468374252319336
Test:
Test: 0.6137330110290098
0.6137330110290098
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.5937196262431264, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747821170878
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.58it/s]100%|██████████| 2/2 [00:00<00:00,  5.28it/s]100%|██████████| 2/2 [00:00<00:00,  4.92it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5961663722991943
Epoch 1, Loop Feat 0: -0.6063768863677979
Epoch 1, Loop Adj 0: -0.6173189282417297
Epoch 2: -0.6173189282417297
Mem used: 674MB
best_loss: tensor(-0.6594, device='cuda:1')
best_loss: tensor(-0.6602, device='cuda:1')
final loss: -0.6378799676895142
Test:
Test: 0.5997449509680568
0.5997449509680568
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.604698705046527
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.97it/s]100%|██████████| 2/2 [00:00<00:00,  7.06it/s]100%|██████████| 2/2 [00:00<00:00,  6.65it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.4318486154079437
Epoch 1, Loop Feat 0: -0.44082164764404297
Epoch 1, Loop Adj 0: -0.45994362235069275
Epoch 2: -0.45994362235069275
Mem used: 674MB
best_loss: tensor(-0.4900, device='cuda:1')
best_loss: tensor(-0.4910, device='cuda:1')
final loss: -0.47227734327316284
Test:
Test: 0.6043496388691897
0.6043496388691897
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804332029917
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.40it/s]100%|██████████| 2/2 [00:00<00:00,  5.14it/s]100%|██████████| 2/2 [00:00<00:00,  5.00it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.34195631742477417
Epoch 1, Loop Feat 0: -0.33535251021385193
Epoch 1, Loop Adj 0: -0.3561159074306488
Epoch 2: -0.3561159074306488
Mem used: 1084MB
best_loss: tensor(-0.3840, device='cuda:1')
final loss: -0.37607496976852417
Test:
Test: 0.6069272553041682
0.6069272553041682
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280594765278374, 0.6163421456257283, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887461485434
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.64it/s]100%|██████████| 2/2 [00:00<00:00,  5.60it/s]100%|██████████| 2/2 [00:00<00:00,  5.73it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.43079623579978943
Epoch 1, Loop Feat 0: -0.4279816150665283
Epoch 1, Loop Adj 0: -0.4347383975982666
Epoch 2: -0.4347383975982666
Mem used: 812MB
best_loss: tensor(-0.4701, device='cuda:1')
final loss: -0.4641006886959076
Test:
Test: 0.610859310858453
0.610859310858453
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205531717941192, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168184805693
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.89it/s]100%|██████████| 2/2 [00:00<00:00,  4.53it/s]100%|██████████| 2/2 [00:00<00:00,  4.41it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3838514983654022
Epoch 1, Loop Feat 0: -0.39277467131614685
Epoch 1, Loop Adj 0: -0.4121744632720947
Epoch 2: -0.4121744632720947
Mem used: 816MB
best_loss: tensor(-0.4357, device='cuda:1')
final loss: -0.4308832585811615
Test:
Test: 0.6068312217062303
0.6068312217062303
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127780227653
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.88it/s]100%|██████████| 2/2 [00:00<00:00,  4.47it/s]100%|██████████| 2/2 [00:00<00:00,  4.35it/s]
Epoch 0, Loop Feat 0: -0.4249717593193054
Epoch 0, Loop Adj 0: -0.45348650217056274
Epoch 1, Loop Feat 0: -0.4593732953071594
Epoch 1, Loop Adj 0: -0.4739728569984436
Epoch 2: -0.4739728569984436
Mem used: 674MB
best_loss: tensor(-0.4959, device='cuda:1')
final loss: -0.4963327646255493
Test:
Test: 0.6089270020741351
0.6089270020741351
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310911059929533, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974795940327604
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.79it/s]100%|██████████| 2/2 [00:00<00:00,  4.75it/s]100%|██████████| 2/2 [00:00<00:00,  4.75it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.2851692736148834
Epoch 1, Loop Feat 0: -0.28596043586730957
Epoch 1, Loop Adj 0: -0.3013043701648712
Epoch 2: -0.3013043701648712
Mem used: 674MB
best_loss: tensor(-0.3233, device='cuda:1')
final loss: -0.31818604469299316
Test:
Test: 0.606444227753249
0.606444227753249
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483131832945
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.13it/s]100%|██████████| 2/2 [00:00<00:00,  5.53it/s]100%|██████████| 2/2 [00:00<00:00,  5.26it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.4213796555995941
Epoch 1, Loop Feat 0: -0.4175336956977844
Epoch 1, Loop Adj 0: -0.42853471636772156
Epoch 2: -0.42853471636772156
Mem used: 1510MB
best_loss: tensor(-0.4578, device='cuda:1')
final loss: -0.4521033465862274
Test:
Test: 0.6023673671956219
0.6023673671956219
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890801861456
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.67it/s]100%|██████████| 2/2 [00:00<00:00,  5.77it/s]100%|██████████| 2/2 [00:00<00:00,  5.57it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.44288572669029236
Epoch 1, Loop Feat 0: -0.4307369887828827
Epoch 1, Loop Adj 0: -0.4579218626022339
Epoch 2: -0.4579218626022339
Mem used: 674MB
best_loss: tensor(-0.4771, device='cuda:1')
final loss: -0.48142603039741516
Test:
Test: 0.6044188243644784
0.6044188243644784
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232558, 0.5836708161590052]
flatten test: 0.6034946216885545
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.73it/s]100%|██████████| 2/2 [00:00<00:00,  4.68it/s]100%|██████████| 2/2 [00:00<00:00,  4.68it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.4372488260269165
Epoch 1, Loop Feat 0: -0.44658225774765015
Epoch 1, Loop Adj 0: -0.4550188183784485
Epoch 2: -0.4550188183784485
Mem used: 674MB
best_loss: tensor(-0.5037, device='cuda:1')
final loss: -0.48339608311653137
Test:
Test: 0.6093284526977736
0.6093284526977736
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.5937196763338406, 0.6002883018849671, 0.5401741024379962, 0.5824575153695682]
flatten test: 0.5878747876614644
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.29it/s]100%|██████████| 1/1 [00:00<00:00,  5.28it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5961663722991943
Epoch 1: -0.5961663722991943
Mem used: -234MB
best_loss: tensor(-0.6430, device='cuda:1')
best_loss: tensor(-0.6462, device='cuda:1')
final loss: -0.6257025599479675
Test:
Test: 0.6026454595251349
0.6026454595251349
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987216796569
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.94it/s]100%|██████████| 1/1 [00:00<00:00,  5.62it/s]
Epoch 0, Loop Feat 0: -0.42172563076019287
Epoch 0, Loop Adj 0: -0.4318486154079437
Epoch 1: -0.4318486154079437
Mem used: 674MB
best_loss: tensor(-0.4653, device='cuda:1')
best_loss: tensor(-0.4702, device='cuda:1')
final loss: -0.45440372824668884
Test:
Test: 0.6060155715818076
0.6060155715818076
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804332029917
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.92it/s]100%|██████████| 1/1 [00:00<00:00,  4.90it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.3419562876224518
Epoch 1: -0.3419562876224518
Mem used: 1088MB
best_loss: tensor(-0.3662, device='cuda:1')
final loss: -0.35546261072158813
Test:
Test: 0.6066715628709487
0.6066715628709487
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163420955350138, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887516929199
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.78it/s]100%|██████████| 1/1 [00:00<00:00,  4.66it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.43079623579978943
Epoch 1: -0.43079623579978943
Mem used: 798MB
best_loss: tensor(-0.4498, device='cuda:1')
final loss: -0.4399685263633728
Test:
Test: 0.609342035613611
0.609342035613611
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205532218848335, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.590716824024946
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.63it/s]100%|██████████| 1/1 [00:00<00:00,  4.42it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3838514983654022
Epoch 1: -0.3838514983654022
Mem used: 674MB
best_loss: tensor(-0.4110, device='cuda:1')
final loss: -0.40187403559684753
Test:
Test: 0.6064701226688222
0.6064701226688222
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127780227653
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.41it/s]100%|██████████| 1/1 [00:00<00:00,  5.40it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.45348650217056274
Epoch 1: -0.45348650217056274
Mem used: 674MB
best_loss: tensor(-0.4696, device='cuda:1')
best_loss: tensor(-0.4731, device='cuda:1')
final loss: -0.4708157479763031
Test:
Test: 0.6079120961346357
0.6079120961346357
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310911059929533, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974795995771369
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.63it/s]100%|██████████| 1/1 [00:00<00:00,  5.61it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.2851692736148834
Epoch 1: -0.2851692736148834
Mem used: 690MB
best_loss: tensor(-0.3041, device='cuda:1')
final loss: -0.29731786251068115
Test:
Test: 0.6049363652307856
0.6049363652307856
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483298164243
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.36it/s]100%|██████████| 1/1 [00:00<00:00,  4.35it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.4213796555995941
Epoch 1: -0.4213796555995941
Mem used: 674MB
best_loss: tensor(-0.4349, device='cuda:1')
best_loss: tensor(-0.4372, device='cuda:1')
final loss: -0.43233269453048706
Test:
Test: 0.6042003459433629
0.6042003459433629
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875724, 0.6335276710552888, 0.5433284620248718, 0.5756913030948722]
flatten test: 0.598189074641769
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.50it/s]100%|██████████| 1/1 [00:00<00:00,  4.49it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.44288572669029236
Epoch 1: -0.44288572669029236
Mem used: 1058MB
best_loss: tensor(-0.4525, device='cuda:1')
best_loss: tensor(-0.4568, device='cuda:1')
final loss: -0.45688050985336304
Test:
Test: 0.6054838520577402
0.6054838520577402
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232558, 0.5836708161590052]
flatten test: 0.603494616144178
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.01it/s]100%|██████████| 1/1 [00:00<00:00,  2.96it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.4372488260269165
Epoch 1: -0.4372488260269165
Mem used: 802MB
best_loss: tensor(-0.4762, device='cuda:1')
best_loss: tensor(-0.4808, device='cuda:1')
final loss: -0.45789992809295654
Test:
Test: 0.6109626919401043
0.6109626919401043
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.5937196262431264, 0.6002883018849671, 0.5401741024379962, 0.5824575153695682]
flatten test: 0.5878747821170879
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.79it/s]100%|██████████| 1/1 [00:00<00:00,  4.78it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5961663722991943
Epoch 1: -0.5961663722991943
Mem used: 798MB
best_loss: tensor(-0.6404, device='cuda:1')
best_loss: tensor(-0.6462, device='cuda:1')
final loss: -0.6257025599479675
Test:
Test: 0.6026454992412631
0.6026454992412631
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987105909037
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.67it/s]100%|██████████| 1/1 [00:00<00:00,  4.47it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.4318486154079437
Epoch 1: -0.4318486154079437
Mem used: -594MB
best_loss: tensor(-0.4687, device='cuda:1')
best_loss: tensor(-0.4706, device='cuda:1')
final loss: -0.4559967815876007
Test:
Test: 0.6027812092512524
0.6027812092512524
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405996180406469, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.606580444291745
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  2.93it/s]100%|██████████| 1/1 [00:00<00:00,  2.82it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.34195631742477417
Epoch 1: -0.34195631742477417
Mem used: 790MB
best_loss: tensor(-0.3695, device='cuda:1')
final loss: -0.35873278975486755
Test:
Test: 0.6078745246773779
0.6078745246773779
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.616342095535014, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887406041667
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.44it/s]100%|██████████| 1/1 [00:00<00:00,  7.40it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.43079623579978943
Epoch 1: -0.43079623579978943
Mem used: 686MB
best_loss: tensor(-0.4513, device='cuda:1')
final loss: -0.4447494447231293
Test:
Test: 0.6104045214746694
0.6104045214746694
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205532218848335, 0.576750097652589, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168184805694
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.95it/s]100%|██████████| 1/1 [00:00<00:00,  6.93it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3838514983654022
Epoch 1: -0.3838514983654022
Mem used: 864MB
best_loss: tensor(-0.4156, device='cuda:1')
final loss: -0.41047289967536926
Test:
Test: 0.6113870190535742
0.6113870190535742
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127780227654
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.75it/s]100%|██████████| 1/1 [00:00<00:00,  4.74it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.45348650217056274
Epoch 1: -0.45348650217056274
Mem used: 674MB
best_loss: tensor(-0.4821, device='cuda:1')
final loss: -0.47653961181640625
Test:
Test: 0.6119062677133932
0.6119062677133932
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310911560836675, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974795995771369
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.78it/s]100%|██████████| 1/1 [00:00<00:00,  6.76it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.2851692736148834
Epoch 1: -0.2851692736148834
Mem used: 718MB
best_loss: tensor(-0.3057, device='cuda:1')
final loss: -0.30111297965049744
Test:
Test: 0.604511204078624
0.604511204078624
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483298164245
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.08it/s]100%|██████████| 1/1 [00:00<00:00,  6.06it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.4213796555995941
Epoch 1: -0.4213796555995941
Mem used: 792MB
best_loss: tensor(-0.4388, device='cuda:1')
final loss: -0.4316560924053192
Test:
Test: 0.6056753632278219
0.6056753632278219
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875724, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890690973923
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.43it/s]100%|██████████| 1/1 [00:00<00:00,  4.42it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.44288569688796997
Epoch 1: -0.44288569688796997
Mem used: 674MB
best_loss: tensor(-0.4604, device='cuda:1')
final loss: -0.46018150448799133
Test:
Test: 0.6078911657350852
0.6078911657350852
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483719525047425, 0.5836708161590052]
flatten test: 0.6034946105998013
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.82it/s]100%|██████████| 1/1 [00:00<00:00,  4.81it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.4372488260269165
Epoch 1: -0.4372488260269165
Mem used: 674MB
best_loss: tensor(-0.4795, device='cuda:1')
best_loss: tensor(-0.4806, device='cuda:1')
final loss: -0.459848552942276
Test:
Test: 0.6090733560064766
0.6090733560064766
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.593719576152412, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747710283346
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.61it/s]100%|██████████| 1/1 [00:00<00:00,  5.60it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5961663722991943
Epoch 1: -0.5961663722991943
Mem used: 832MB
best_loss: tensor(-0.6457, device='cuda:1')
final loss: -0.6179152131080627
Test:
Test: 0.6000549353484979
0.6000549353484979
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.644284027479605, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987272240335
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.78it/s]100%|██████████| 1/1 [00:00<00:00,  4.76it/s]
Epoch 0, Loop Feat 0: -0.42172563076019287
Epoch 0, Loop Adj 0: -0.4318486154079437
Epoch 1: -0.4318486154079437
Mem used: 674MB
best_loss: tensor(-0.4674, device='cuda:1')
final loss: -0.45301586389541626
Test:
Test: 0.601718048216015
0.601718048216015
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804221142383
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.09it/s]100%|██████████| 1/1 [00:00<00:00,  4.03it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.34195631742477417
Epoch 1: -0.34195631742477417
Mem used: 1016MB
best_loss: tensor(-0.3609, device='cuda:1')
final loss: -0.35208195447921753
Test:
Test: 0.606510791984078
0.606510791984078
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887572372965
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.86it/s]100%|██████████| 1/1 [00:00<00:00,  6.83it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.43079623579978943
Epoch 1: -0.43079623579978943
Mem used: 758MB
best_loss: tensor(-0.4459, device='cuda:1')
final loss: -0.43874412775039673
Test:
Test: 0.6100917569652556
0.6100917569652556
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205531717941192, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168184805693
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.03it/s]100%|██████████| 1/1 [00:00<00:00,  5.02it/s]
Epoch 0, Loop Feat 0: -0.35880887508392334
Epoch 0, Loop Adj 0: -0.3838514983654022
Epoch 1: -0.3838514983654022
Mem used: 674MB
best_loss: tensor(-0.4077, device='cuda:1')
final loss: -0.4014374315738678
Test:
Test: 0.6062347251771022
0.6062347251771022
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127946558952
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.82it/s]100%|██████████| 1/1 [00:00<00:00,  7.79it/s]
Epoch 0, Loop Feat 0: -0.4249717593193054
Epoch 0, Loop Adj 0: -0.45348653197288513
Epoch 1: -0.45348653197288513
Mem used: 674MB
best_loss: tensor(-0.4704, device='cuda:1')
final loss: -0.46900123357772827
Test:
Test: 0.6082414222695003
0.6082414222695003
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310910058115247, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974795884883838
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.74it/s]100%|██████████| 1/1 [00:00<00:00,  4.73it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.2851692736148834
Epoch 1: -0.2851692736148834
Mem used: 1058MB
best_loss: tensor(-0.2997, device='cuda:1')
final loss: -0.29463475942611694
Test:
Test: 0.604675152255749
0.604675152255749
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483409051777
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.62it/s]100%|██████████| 1/1 [00:00<00:00,  5.60it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.4213796555995941
Epoch 1: -0.4213796555995941
Mem used: 796MB
best_loss: tensor(-0.4355, device='cuda:1')
final loss: -0.42975521087646484
Test:
Test: 0.6031817464039428
0.6031817464039428
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.598189074641769
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.86it/s]100%|██████████| 1/1 [00:00<00:00,  5.58it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.44288572669029236
Epoch 1: -0.44288572669029236
Mem used: 814MB
best_loss: tensor(-0.4505, device='cuda:1')
final loss: -0.45265936851501465
Test:
Test: 0.6039195529171337
0.6039195529171337
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232557, 0.5836710890561687]
flatten test: 0.6034946216885545
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.21it/s]100%|██████████| 1/1 [00:00<00:00,  5.19it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.4372488260269165
Epoch 1: -0.4372488260269165
Mem used: 822MB
best_loss: tensor(-0.4783, device='cuda:1')
best_loss: tensor(-0.4785, device='cuda:1')
final loss: -0.4570463299751282
Test:
Test: 0.6090451575554692
0.6090451575554692
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.5937196262431264, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747821170878
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.57it/s]100%|██████████| 2/2 [00:00<00:00,  4.48it/s]100%|██████████| 2/2 [00:00<00:00,  4.49it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5961663722991943
Epoch 1, Loop Feat 0: -0.6140773892402649
Epoch 1, Loop Adj 0: -0.6213611960411072
Epoch 2: -0.6213611960411072
Mem used: 674MB
best_loss: tensor(-0.6606, device='cuda:1')
best_loss: tensor(-0.6617, device='cuda:1')
final loss: -0.6450427174568176
Test:
Test: 0.6022262955083283
0.6022262955083283
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.644284027479605, 0.6097033728081556, 0.6344159165859445, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987216796569
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.52it/s]100%|██████████| 2/2 [00:00<00:00,  5.33it/s]100%|██████████| 2/2 [00:00<00:00,  5.21it/s]
Epoch 0, Loop Feat 0: -0.42172563076019287
Epoch 0, Loop Adj 0: -0.4318486154079437
Epoch 1, Loop Feat 0: -0.44709548354148865
Epoch 1, Loop Adj 0: -0.46625977754592896
Epoch 2: -0.46625977754592896
Mem used: 674MB
best_loss: tensor(-0.4912, device='cuda:1')
best_loss: tensor(-0.4953, device='cuda:1')
final loss: -0.4778638482093811
Test:
Test: 0.6061577553206903
0.6061577553206903
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804165698618
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.34it/s]100%|██████████| 2/2 [00:00<00:00,  5.34it/s]100%|██████████| 2/2 [00:00<00:00,  5.33it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.34195631742477417
Epoch 1, Loop Feat 0: -0.33812910318374634
Epoch 1, Loop Adj 0: -0.3585944175720215
Epoch 2: -0.3585944175720215
Mem used: 904MB
best_loss: tensor(-0.3895, device='cuda:1')
final loss: -0.37913015484809875
Test:
Test: 0.6068744725698179
0.6068744725698179
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163420955350138, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887461485434
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.48it/s]100%|██████████| 2/2 [00:00<00:00,  4.43it/s]100%|██████████| 2/2 [00:00<00:00,  4.43it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.43079623579978943
Epoch 1, Loop Feat 0: -0.43186211585998535
Epoch 1, Loop Adj 0: -0.44012606143951416
Epoch 2: -0.44012606143951416
Mem used: 674MB
best_loss: tensor(-0.4740, device='cuda:1')
final loss: -0.46559497714042664
Test:
Test: 0.6104577808025582
0.6104577808025582
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205532218848335, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168129361928
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.82it/s]100%|██████████| 2/2 [00:00<00:00,  4.90it/s]100%|██████████| 2/2 [00:00<00:00,  4.88it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3838514983654022
Epoch 1, Loop Feat 0: -0.3991301655769348
Epoch 1, Loop Adj 0: -0.41820940375328064
Epoch 2: -0.41820940375328064
Mem used: 674MB
best_loss: tensor(-0.4402, device='cuda:1')
final loss: -0.43269050121307373
Test:
Test: 0.6069917542963319
0.6069917542963319
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127780227653
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.43it/s]100%|██████████| 2/2 [00:00<00:00,  5.02it/s]100%|██████████| 2/2 [00:00<00:00,  4.97it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.45348650217056274
Epoch 1, Loop Feat 0: -0.46666640043258667
Epoch 1, Loop Adj 0: -0.4820138216018677
Epoch 2: -0.4820138216018677
Mem used: 824MB
best_loss: tensor(-0.5023, device='cuda:1')
final loss: -0.5008054971694946
Test:
Test: 0.6089696571957999
0.6089696571957999
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179836213682554, 0.6310910559022389, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974795940327604
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  8.08it/s]100%|██████████| 2/2 [00:00<00:00,  6.63it/s]100%|██████████| 2/2 [00:00<00:00,  6.80it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.28516924381256104
Epoch 1, Loop Feat 0: -0.28835850954055786
Epoch 1, Loop Adj 0: -0.30403590202331543
Epoch 2: -0.30403590202331543
Mem used: 674MB
best_loss: tensor(-0.3278, device='cuda:1')
final loss: -0.32178911566734314
Test:
Test: 0.6069433800522093
0.6069433800522093
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483242720478
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.11it/s]100%|██████████| 2/2 [00:00<00:00,  3.45it/s]100%|██████████| 2/2 [00:00<00:00,  3.39it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.4213796555995941
Epoch 1, Loop Feat 0: -0.4237948954105377
Epoch 1, Loop Adj 0: -0.43638062477111816
Epoch 2: -0.43638062477111816
Mem used: 832MB
best_loss: tensor(-0.4574, device='cuda:1')
final loss: -0.45352885127067566
Test:
Test: 0.6045565598970049
0.6045565598970049
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066465368782865, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890857305222
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.82it/s]100%|██████████| 2/2 [00:00<00:00,  4.48it/s]100%|██████████| 2/2 [00:00<00:00,  4.36it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.44288572669029236
Epoch 1, Loop Feat 0: -0.4373524785041809
Epoch 1, Loop Adj 0: -0.4655885696411133
Epoch 2: -0.4655885696411133
Mem used: -54MB
best_loss: tensor(-0.4793, device='cuda:1')
best_loss: tensor(-0.4840, device='cuda:1')
final loss: -0.48668456077575684
Test:
Test: 0.6060314183169513
0.6060314183169513
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232558, 0.5836710890561687]
flatten test: 0.6034946272329311
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.38it/s]100%|██████████| 2/2 [00:00<00:00,  5.52it/s]100%|██████████| 2/2 [00:00<00:00,  5.30it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.4372488260269165
Epoch 1, Loop Feat 0: -0.45167019963264465
Epoch 1, Loop Adj 0: -0.4608110189437866
Epoch 2: -0.4608110189437866
Mem used: -594MB
best_loss: tensor(-0.5042, device='cuda:1')
best_loss: tensor(-0.5050, device='cuda:1')
final loss: -0.4851088225841522
Test:
Test: 0.6090177931431535
0.6090177931431535
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.5937196262431264, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747765727113
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.50it/s]100%|██████████| 2/2 [00:00<00:00,  3.66it/s]100%|██████████| 2/2 [00:00<00:00,  3.85it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5961663722991943
Epoch 1, Loop Feat 0: -0.6140773892402649
Epoch 1, Loop Adj 0: -0.6213611960411072
Epoch 2: -0.6213611960411072
Mem used: 674MB
best_loss: tensor(-0.6626, device='cuda:1')
best_loss: tensor(-0.6630, device='cuda:1')
final loss: -0.6482121348381042
Test:
Test: 0.601695449739081
0.601695449739081
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987161352804
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.89it/s]100%|██████████| 2/2 [00:00<00:00,  4.72it/s]100%|██████████| 2/2 [00:00<00:00,  4.86it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.4318486154079437
Epoch 1, Loop Feat 0: -0.44794678688049316
Epoch 1, Loop Adj 0: -0.46711981296539307
Epoch 2: -0.46711981296539307
Mem used: -811MB
best_loss: tensor(-0.4929, device='cuda:1')
best_loss: tensor(-0.4990, device='cuda:1')
final loss: -0.4857148230075836
Test:
Test: 0.6038529489701767
0.6038529489701767
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405996180406469, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562247297226491]
flatten test: 0.6065804332029917
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.01it/s]100%|██████████| 2/2 [00:00<00:00,  5.09it/s]100%|██████████| 2/2 [00:00<00:00,  5.05it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.3419562876224518
Epoch 1, Loop Feat 0: -0.3383951485157013
Epoch 1, Loop Adj 0: -0.358829140663147
Epoch 2: -0.358829140663147
Mem used: -594MB
best_loss: tensor(-0.3917, device='cuda:1')
final loss: -0.3834458291530609
Test:
Test: 0.6077801988729516
0.6077801988729516
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163420454442996, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887406041668
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.17it/s]100%|██████████| 2/2 [00:00<00:00,  4.66it/s]100%|██████████| 2/2 [00:00<00:00,  4.72it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.43079623579978943
Epoch 1, Loop Feat 0: -0.4325465261936188
Epoch 1, Loop Adj 0: -0.4410353899002075
Epoch 2: -0.4410353899002075
Mem used: 674MB
best_loss: tensor(-0.4736, device='cuda:1')
best_loss: tensor(-0.4766, device='cuda:1')
final loss: -0.47084614634513855
Test:
Test: 0.6125006195715996
0.6125006195715996
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205532218848335, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168184805693
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.58it/s]100%|██████████| 2/2 [00:00<00:00,  5.52it/s]100%|██████████| 2/2 [00:00<00:00,  5.52it/s]
Epoch 0, Loop Feat 0: -0.35880887508392334
Epoch 0, Loop Adj 0: -0.3838514983654022
Epoch 1, Loop Feat 0: -0.4003073573112488
Epoch 1, Loop Adj 0: -0.4193246066570282
Epoch 2: -0.4193246066570282
Mem used: 674MB
best_loss: tensor(-0.4481, device='cuda:1')
final loss: -0.4406763017177582
Test:
Test: 0.6094116182701815
0.6094116182701815
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127835671419
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.02it/s]100%|██████████| 2/2 [00:00<00:00,  7.57it/s]100%|██████████| 2/2 [00:00<00:00,  7.27it/s]
Epoch 0, Loop Feat 0: -0.4249717593193054
Epoch 0, Loop Adj 0: -0.45348650217056274
Epoch 1, Loop Feat 0: -0.4674210846424103
Epoch 1, Loop Adj 0: -0.4828108251094818
Epoch 2: -0.4828108251094818
Mem used: 694MB
best_loss: tensor(-0.5074, device='cuda:1')
final loss: -0.5028385519981384
Test:
Test: 0.611556011178978
0.611556011178978
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179836213682554, 0.6310910559022389, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974795940327604
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.79it/s]100%|██████████| 2/2 [00:00<00:00,  3.62it/s]100%|██████████| 2/2 [00:00<00:00,  3.64it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.2851692736148834
Epoch 1, Loop Feat 0: -0.28866812586784363
Epoch 1, Loop Adj 0: -0.30439266562461853
Epoch 2: -0.30439266562461853
Mem used: 830MB
best_loss: tensor(-0.3306, device='cuda:1')
final loss: -0.3257816731929779
Test:
Test: 0.6070628461657732
0.6070628461657732
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483242720477
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.58it/s]100%|██████████| 2/2 [00:00<00:00,  3.85it/s]100%|██████████| 2/2 [00:00<00:00,  4.03it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.4213796555995941
Epoch 1, Loop Feat 0: -0.4246799945831299
Epoch 1, Loop Adj 0: -0.43741196393966675
Epoch 2: -0.43741196393966675
Mem used: 816MB
best_loss: tensor(-0.4624, device='cuda:1')
best_loss: tensor(-0.4640, device='cuda:1')
final loss: -0.4614194929599762
Test:
Test: 0.6060682351677735
0.6060682351677735
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890690973923
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.46it/s]100%|██████████| 2/2 [00:00<00:00,  5.07it/s]100%|██████████| 2/2 [00:00<00:00,  4.96it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.44288572669029236
Epoch 1, Loop Feat 0: -0.43816354870796204
Epoch 1, Loop Adj 0: -0.4665147662162781
Epoch 2: -0.4665147662162781
Mem used: 674MB
best_loss: tensor(-0.4915, device='cuda:1')
final loss: -0.4898771345615387
Test:
Test: 0.6054762265611298
0.6054762265611298
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232558, 0.5836708161590052]
flatten test: 0.6034946050554246
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.19it/s]100%|██████████| 2/2 [00:00<00:00,  5.25it/s]100%|██████████| 2/2 [00:00<00:00,  4.98it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.4372488260269165
Epoch 1, Loop Feat 0: -0.45205941796302795
Epoch 1, Loop Adj 0: -0.4612060487270355
Epoch 2: -0.4612060487270355
Mem used: 674MB
best_loss: tensor(-0.5039, device='cuda:1')
best_loss: tensor(-0.5061, device='cuda:1')
final loss: -0.48484674096107483
Test:
Test: 0.6116227342743197
0.6116227342743197
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.5937196763338406, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.587874793205841
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.01it/s]100%|██████████| 2/2 [00:00<00:00,  3.10it/s]100%|██████████| 2/2 [00:00<00:00,  3.04it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5961663722991943
Epoch 1, Loop Feat 0: -0.6062703728675842
Epoch 1, Loop Adj 0: -0.6172824501991272
Epoch 2: -0.6172824501991272
Mem used: -990MB
best_loss: tensor(-0.6594, device='cuda:1')
best_loss: tensor(-0.6604, device='cuda:1')
final loss: -0.6372078061103821
Test:
Test: 0.5997460630196458
0.5997460630196458
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987216796569
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.80it/s]100%|██████████| 2/2 [00:00<00:00,  3.95it/s]100%|██████████| 2/2 [00:00<00:00,  4.05it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.4318486154079437
Epoch 1, Loop Feat 0: -0.44072189927101135
Epoch 1, Loop Adj 0: -0.45984092354774475
Epoch 2: -0.45984092354774475
Mem used: 822MB
best_loss: tensor(-0.4900, device='cuda:1')
best_loss: tensor(-0.4910, device='cuda:1')
final loss: -0.4724372923374176
Test:
Test: 0.6043619111527971
0.6043619111527971
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405996180406469, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804387473682
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.72it/s]100%|██████████| 2/2 [00:00<00:00,  4.74it/s]100%|██████████| 2/2 [00:00<00:00,  4.55it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.34195631742477417
Epoch 1, Loop Feat 0: -0.3353000581264496
Epoch 1, Loop Adj 0: -0.3560730218887329
Epoch 2: -0.3560730218887329
Mem used: 906MB
best_loss: tensor(-0.3840, device='cuda:1')
final loss: -0.37615689635276794
Test:
Test: 0.6068941717693948
0.6068941717693948
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163420454442996, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887461485433
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  9.35it/s]100%|██████████| 2/2 [00:00<00:00,  5.15it/s]100%|██████████| 2/2 [00:00<00:00,  5.52it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.43079623579978943
Epoch 1, Loop Feat 0: -0.42791470885276794
Epoch 1, Loop Adj 0: -0.43463319540023804
Epoch 2: -0.43463319540023804
Mem used: 674MB
best_loss: tensor(-0.4701, device='cuda:1')
final loss: -0.4641002416610718
Test:
Test: 0.6108558952714296
0.6108558952714296
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205532218848335, 0.576750097652589, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168184805693
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.70it/s]100%|██████████| 2/2 [00:00<00:00,  7.31it/s]100%|██████████| 2/2 [00:00<00:00,  6.88it/s]
Epoch 0, Loop Feat 0: -0.35880887508392334
Epoch 0, Loop Adj 0: -0.3838514983654022
Epoch 1, Loop Feat 0: -0.3926664888858795
Epoch 1, Loop Adj 0: -0.41207078099250793
Epoch 2: -0.41207078099250793
Mem used: 674MB
best_loss: tensor(-0.4357, device='cuda:1')
final loss: -0.4305243194103241
Test:
Test: 0.60678955948777
0.60678955948777
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127780227653
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.56it/s]100%|██████████| 2/2 [00:00<00:00,  4.66it/s]100%|██████████| 2/2 [00:00<00:00,  4.45it/s]
Epoch 0, Loop Feat 0: -0.4249717593193054
Epoch 0, Loop Adj 0: -0.45348650217056274
Epoch 1, Loop Feat 0: -0.4592631459236145
Epoch 1, Loop Adj 0: -0.4738369286060333
Epoch 2: -0.4738369286060333
Mem used: 1138MB
best_loss: tensor(-0.4959, device='cuda:1')
final loss: -0.4954155683517456
Test:
Test: 0.6089210446549082
0.6089210446549082
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179836213682554, 0.6310910559022389, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.597479599577137
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.02it/s]100%|██████████| 2/2 [00:00<00:00,  2.94it/s]100%|██████████| 2/2 [00:00<00:00,  2.93it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.28516924381256104
Epoch 1, Loop Feat 0: -0.2859046459197998
Epoch 1, Loop Adj 0: -0.3012408912181854
Epoch 2: -0.3012408912181854
Mem used: 966MB
best_loss: tensor(-0.3233, device='cuda:1')
final loss: -0.3180408775806427
Test:
Test: 0.6064346561663578
0.6064346561663578
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483187276712
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.48it/s]100%|██████████| 2/2 [00:00<00:00,  3.45it/s]100%|██████████| 2/2 [00:00<00:00,  3.57it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.4213796555995941
Epoch 1, Loop Feat 0: -0.41744011640548706
Epoch 1, Loop Adj 0: -0.428404301404953
Epoch 2: -0.428404301404953
Mem used: 674MB
best_loss: tensor(-0.4579, device='cuda:1')
final loss: -0.4509359896183014
Test:
Test: 0.6025439053853798
0.6025439053853798
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875724, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890580086391
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.01it/s]100%|██████████| 2/2 [00:00<00:00,  7.25it/s]100%|██████████| 2/2 [00:00<00:00,  7.02it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.44288572669029236
Epoch 1, Loop Feat 0: -0.4306389093399048
Epoch 1, Loop Adj 0: -0.4578022360801697
Epoch 2: -0.4578022360801697
Mem used: 674MB
best_loss: tensor(-0.4771, device='cuda:1')
final loss: -0.4802878201007843
Test:
Test: 0.6044741092149043
0.6044741092149043
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=0.0001, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232558, 0.5836708161590052]
flatten test: 0.6034946383216844
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.69it/s]100%|██████████| 2/2 [00:00<00:00,  3.63it/s]100%|██████████| 2/2 [00:00<00:00,  3.64it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.4372488260269165
Epoch 1, Loop Feat 0: -0.4465075731277466
Epoch 1, Loop Adj 0: -0.4549225866794586
Epoch 2: -0.4549225866794586
Mem used: 778MB
best_loss: tensor(-0.5037, device='cuda:1')
final loss: -0.4835050702095032
Test:
Test: 0.6092950911501027
0.6092950911501027
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.5937196262431264, 0.6002883018849671, 0.5401741024379962, 0.5824575153695682]
flatten test: 0.5878747876614644
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.53it/s]100%|██████████| 1/1 [00:00<00:00,  5.36it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5831117630004883
Epoch 1: -0.5831117630004883
Mem used: 800MB
best_loss: tensor(-0.6065, device='cuda:1')
best_loss: tensor(-0.6095, device='cuda:1')
final loss: -0.6011855602264404
Test:
Test: 0.6035193334934688
0.6035193334934688
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344159165859445, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987105909037
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.89it/s]100%|██████████| 1/1 [00:00<00:00,  5.87it/s]
Epoch 0, Loop Feat 0: -0.42172563076019287
Epoch 0, Loop Adj 0: -0.4137086868286133
Epoch 1: -0.4137086868286133
Mem used: 674MB
best_loss: tensor(-0.4252, device='cuda:1')
best_loss: tensor(-0.4300, device='cuda:1')
final loss: -0.4241614043712616
Test:
Test: 0.6057498309681586
0.6057498309681586
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804387473683
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.63it/s]100%|██████████| 1/1 [00:00<00:00,  5.62it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.32399165630340576
Epoch 1: -0.32399165630340576
Mem used: 674MB
best_loss: tensor(-0.3346, device='cuda:1')
final loss: -0.3299402594566345
Test:
Test: 0.6062434230091734
0.6062434230091734
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887572372966
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.55it/s]100%|██████████| 1/1 [00:00<00:00,  5.33it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.41172561049461365
Epoch 1: -0.41172561049461365
Mem used: 674MB
best_loss: tensor(-0.4126, device='cuda:1')
final loss: -0.41051623225212097
Test:
Test: 0.6073795425718767
0.6073795425718767
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205531217034048, 0.5767507023125826, 0.5493891660226236, 0.5826381732918821]
flatten test: 0.5907168129361927
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.84it/s]100%|██████████| 1/1 [00:00<00:00,  4.83it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3609839379787445
Epoch 1: -0.3609839379787445
Mem used: 674MB
best_loss: tensor(-0.3718, device='cuda:1')
final loss: -0.3690580129623413
Test:
Test: 0.6056852922598668
0.6056852922598668
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127835671419
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.84it/s]100%|██████████| 1/1 [00:00<00:00,  5.83it/s]
Epoch 0, Loop Feat 0: -0.4249717593193054
Epoch 0, Loop Adj 0: -0.43351078033447266
Epoch 1: -0.43351078033447266
Mem used: 674MB
best_loss: tensor(-0.4303, device='cuda:1')
best_loss: tensor(-0.4338, device='cuda:1')
final loss: -0.4405313730239868
Test:
Test: 0.6074426514995539
0.6074426514995539
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179836213682554, 0.6310911059929533, 0.6278801467147008, 0.5383905009484999, 0.5426401818150064]
flatten test: 0.5974796051215137
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.99it/s]100%|██████████| 1/1 [00:00<00:00,  4.98it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.26614269614219666
Epoch 1: -0.26614269614219666
Mem used: 758MB
best_loss: tensor(-0.2745, device='cuda:1')
final loss: -0.2729758024215698
Test:
Test: 0.6021634645935483
0.6021634645935483
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483187276712
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.04it/s]100%|██████████| 1/1 [00:00<00:00,  2.81it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.40417084097862244
Epoch 1: -0.40417084097862244
Mem used: 1028MB
best_loss: tensor(-0.4013, device='cuda:1')
best_loss: tensor(-0.4040, device='cuda:1')
final loss: -0.4069554805755615
Test:
Test: 0.60385898582166
0.60385898582166
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875724, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890746417691
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.10it/s]100%|██████████| 1/1 [00:00<00:00,  5.07it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.4198577404022217
Epoch 1: -0.4198577404022217
Mem used: 674MB
best_loss: tensor(-0.4133, device='cuda:1')
best_loss: tensor(-0.4174, device='cuda:1')
final loss: -0.42434775829315186
Test:
Test: 0.6046322191211869
0.6046322191211869
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303432937956205, 0.6145207971636634, 0.6325989133050594, 0.5483719525047425, 0.5836708161590052]
flatten test: 0.6034946216885546
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.67it/s]100%|██████████| 1/1 [00:00<00:00,  4.66it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.4205489754676819
Epoch 1: -0.4205489754676819
Mem used: 674MB
best_loss: tensor(-0.4371, device='cuda:1')
best_loss: tensor(-0.4413, device='cuda:1')
final loss: -0.43053677678108215
Test:
Test: 0.60907502408386
0.60907502408386
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.5937196763338406, 0.6002883018849671, 0.5401741024379962, 0.5824575153695682]
flatten test: 0.5878747876614645
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.38it/s]100%|██████████| 1/1 [00:00<00:00,  3.37it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5831117630004883
Epoch 1: -0.5831117630004883
Mem used: 958MB
best_loss: tensor(-0.6103, device='cuda:1')
best_loss: tensor(-0.6162, device='cuda:1')
final loss: -0.6081100702285767
Test:
Test: 0.6004984453518785
0.6004984453518785
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.604698705046527
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.71it/s]100%|██████████| 1/1 [00:00<00:00,  4.69it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.4137086868286133
Epoch 1: -0.4137086868286133
Mem used: 798MB
best_loss: tensor(-0.4295, device='cuda:1')
best_loss: tensor(-0.4398, device='cuda:1')
final loss: -0.43819689750671387
Test:
Test: 0.6058514248240416
0.6058514248240416
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405996180406469, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.606580444291745
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.46it/s]100%|██████████| 1/1 [00:00<00:00,  6.44it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.32399165630340576
Epoch 1: -0.32399165630340576
Mem used: 674MB
best_loss: tensor(-0.3379, device='cuda:1')
final loss: -0.33362650871276855
Test:
Test: 0.6067544107143311
0.6067544107143311
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280594765278374, 0.6163420955350138, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887572372966
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.97it/s]100%|██████████| 1/1 [00:00<00:00,  3.84it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.41172561049461365
Epoch 1: -0.41172561049461365
Mem used: 674MB
best_loss: tensor(-0.4145, device='cuda:1')
best_loss: tensor(-0.4206, device='cuda:1')
final loss: -0.42140939831733704
Test:
Test: 0.6075998082187601
0.6075998082187601
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205531717941192, 0.576750097652589, 0.5493891660226236, 0.5826381732918821]
flatten test: 0.5907168073918161
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.09it/s]100%|██████████| 1/1 [00:00<00:00,  5.07it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3609839379787445
Epoch 1: -0.3609839379787445
Mem used: 686MB
best_loss: tensor(-0.3752, device='cuda:1')
final loss: -0.3762214779853821
Test:
Test: 0.6092301949966574
0.6092301949966574
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127613896354
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.27it/s]100%|██████████| 1/1 [00:00<00:00,  6.26it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.43351078033447266
Epoch 1: -0.43351078033447266
Mem used: 816MB
best_loss: tensor(-0.4411, device='cuda:1')
best_loss: tensor(-0.4508, device='cuda:1')
final loss: -0.4539179801940918
Test:
Test: 0.6094211898570727
0.6094211898570727
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310911059929533, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974795995771371
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.53it/s]100%|██████████| 1/1 [00:00<00:00,  3.53it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.26614269614219666
Epoch 1: -0.26614269614219666
Mem used: -242MB
best_loss: tensor(-0.2769, device='cuda:1')
final loss: -0.2760950028896332
Test:
Test: 0.6014938109563136
0.6014938109563136
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.600148335360801
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.01it/s]100%|██████████| 1/1 [00:00<00:00,  5.00it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.40417084097862244
Epoch 1: -0.40417084097862244
Mem used: 674MB
best_loss: tensor(-0.4066, device='cuda:1')
best_loss: tensor(-0.4163, device='cuda:1')
final loss: -0.420167475938797
Test:
Test: 0.6062894937178617
0.6062894937178617
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875724, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.598189074641769
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.24it/s]100%|██████████| 1/1 [00:00<00:00,  4.24it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.4198577404022217
Epoch 1: -0.4198577404022217
Mem used: 674MB
best_loss: tensor(-0.4203, device='cuda:1')
best_loss: tensor(-0.4283, device='cuda:1')
final loss: -0.4347728192806244
Test:
Test: 0.605572736752606
0.605572736752606
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232558, 0.5836708161590052]
flatten test: 0.6034946216885546
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.58it/s]100%|██████████| 1/1 [00:00<00:00,  3.58it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.4205489754676819
Epoch 1: -0.4205489754676819
Mem used: 890MB
best_loss: tensor(-0.4414, device='cuda:1')
best_loss: tensor(-0.4501, device='cuda:1')
final loss: -0.4408658444881439
Test:
Test: 0.6128817355376102
0.6128817355376102
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.5937196262431264, 0.6002883018849671, 0.5401741024379962, 0.5824575153695682]
flatten test: 0.5878747821170879
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.49it/s]100%|██████████| 1/1 [00:00<00:00,  3.37it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5831117630004883
Epoch 1: -0.5831117630004883
Mem used: -594MB
best_loss: tensor(-0.6090, device='cuda:1')
final loss: -0.590933084487915
Test:
Test: 0.6001577604043546
0.6001577604043546
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987161352803
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.73it/s]100%|██████████| 1/1 [00:00<00:00,  6.72it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.4137086868286133
Epoch 1: -0.4137086868286133
Mem used: 674MB
best_loss: tensor(-0.4272, device='cuda:1')
final loss: -0.42069384455680847
Test:
Test: 0.6015134704397623
0.6015134704397623
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405996180406469, 0.614043983654398, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.606580444291745
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.99it/s]100%|██████████| 1/1 [00:00<00:00,  7.97it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.32399165630340576
Epoch 1: -0.32399165630340576
Mem used: 674MB
best_loss: tensor(-0.3294, device='cuda:1')
final loss: -0.32641875743865967
Test:
Test: 0.6060370580071527
0.6060370580071527
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163420955350138, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887516929199
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.47it/s]100%|██████████| 1/1 [00:00<00:00,  4.10it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.41172561049461365
Epoch 1: -0.41172561049461365
Mem used: 674MB
best_loss: tensor(-0.4086, device='cuda:1')
final loss: -0.4087843596935272
Test:
Test: 0.608089786092111
0.608089786092111
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205532218848335, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168184805693
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.79it/s]100%|██████████| 1/1 [00:00<00:00,  4.79it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3609839379787445
Epoch 1: -0.3609839379787445
Mem used: 868MB
best_loss: tensor(-0.3679, device='cuda:1')
final loss: -0.3682725131511688
Test:
Test: 0.6052343156243883
0.6052343156243883
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.605312766934012
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.71it/s]100%|██████████| 1/1 [00:00<00:00,  3.70it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.43351078033447266
Epoch 1: -0.43351078033447266
Mem used: 816MB
best_loss: tensor(-0.4306, device='cuda:1')
final loss: -0.4371282756328583
Test:
Test: 0.6075392014071583
0.6075392014071583
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179836213682554, 0.6310911059929533, 0.6278801467147008, 0.5383906414670132, 0.5426401818150064]
flatten test: 0.597479599577137
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.60it/s]100%|██████████| 1/1 [00:00<00:00,  5.59it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.26614269614219666
Epoch 1: -0.26614269614219666
Mem used: -594MB
best_loss: tensor(-0.2704, device='cuda:1')
final loss: -0.2694048285484314
Test:
Test: 0.6018391029747062
0.6018391029747062
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483298164244
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.68it/s]100%|██████████| 1/1 [00:00<00:00,  5.67it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.40417084097862244
Epoch 1: -0.40417084097862244
Mem used: 674MB
best_loss: tensor(-0.4015, device='cuda:1')
final loss: -0.4009440839290619
Test:
Test: 0.6029536963959361
0.6029536963959361
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875724, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890746417691
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.45it/s]100%|██████████| 1/1 [00:00<00:00,  5.10it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.4198577404022217
Epoch 1: -0.4198577404022217
Mem used: 686MB
best_loss: tensor(-0.4111, device='cuda:1')
final loss: -0.4194999635219574
Test:
Test: 0.6034191297020719
0.6034191297020719
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232558, 0.5836708161590052]
flatten test: 0.6034946216885545
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.75it/s]100%|██████████| 1/1 [00:00<00:00,  5.74it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.4205489754676819
Epoch 1: -0.4205489754676819
Mem used: 780MB
best_loss: tensor(-0.4392, device='cuda:1')
final loss: -0.428933322429657
Test:
Test: 0.6077366302803386
0.6077366302803386
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.593719576152412, 0.6002883018849671, 0.5401741024379962, 0.5824575153695682]
flatten test: 0.587874765483958
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.95it/s]100%|██████████| 2/2 [00:00<00:00,  5.39it/s]100%|██████████| 2/2 [00:00<00:00,  5.31it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5831117630004883
Epoch 1, Loop Feat 0: -0.603249728679657
Epoch 1, Loop Adj 0: -0.5986042618751526
Epoch 2: -0.5986042618751526
Mem used: 810MB
best_loss: tensor(-0.6115, device='cuda:1')
best_loss: tensor(-0.6130, device='cuda:1')
final loss: -0.6035670042037964
Test:
Test: 0.603314755717216
0.603314755717216
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987050465271
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.67it/s]100%|██████████| 2/2 [00:00<00:00,  3.94it/s]100%|██████████| 2/2 [00:00<00:00,  4.13it/s]
Epoch 0, Loop Feat 0: -0.42172563076019287
Epoch 0, Loop Adj 0: -0.4137086868286133
Epoch 1, Loop Feat 0: -0.4290233552455902
Epoch 1, Loop Adj 0: -0.4314075708389282
Epoch 2: -0.4314075708389282
Mem used: 844MB
best_loss: tensor(-0.4291, device='cuda:1')
best_loss: tensor(-0.4332, device='cuda:1')
final loss: -0.4272772967815399
Test:
Test: 0.6043874883393447
0.6043874883393447
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405997298554459, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804609248748
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.28it/s]100%|██████████| 2/2 [00:00<00:00,  7.70it/s]100%|██████████| 2/2 [00:00<00:00,  7.63it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.32399165630340576
Epoch 1, Loop Feat 0: -0.3207694888114929
Epoch 1, Loop Adj 0: -0.32443907856941223
Epoch 2: -0.32443907856941223
Mem used: 674MB
best_loss: tensor(-0.3370, device='cuda:1')
final loss: -0.3319724500179291
Test:
Test: 0.6059582612088446
0.6059582612088446
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887516929199
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.45it/s]100%|██████████| 2/2 [00:00<00:00,  4.69it/s]100%|██████████| 2/2 [00:00<00:00,  4.45it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.41172561049461365
Epoch 1, Loop Feat 0: -0.41374126076698303
Epoch 1, Loop Adj 0: -0.4050842523574829
Epoch 2: -0.4050842523574829
Mem used: 1092MB
best_loss: tensor(-0.4152, device='cuda:1')
final loss: -0.41228026151657104
Test:
Test: 0.6075729601161108
0.6075729601161108
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035360312008, 0.6205531717941192, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.590716824024946
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.38it/s]100%|██████████| 2/2 [00:00<00:00,  6.65it/s]100%|██████████| 2/2 [00:00<00:00,  6.42it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3609839379787445
Epoch 1, Loop Feat 0: -0.37669429183006287
Epoch 1, Loop Adj 0: -0.3749717175960541
Epoch 2: -0.3749717175960541
Mem used: 822MB
best_loss: tensor(-0.3744, device='cuda:1')
final loss: -0.37193232774734497
Test:
Test: 0.6056232556676504
0.6056232556676504
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127724783887
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.75it/s]100%|██████████| 2/2 [00:00<00:00,  5.48it/s]100%|██████████| 2/2 [00:00<00:00,  5.35it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.43351078033447266
Epoch 1, Loop Feat 0: -0.44670313596725464
Epoch 1, Loop Adj 0: -0.44384896755218506
Epoch 2: -0.44384896755218506
Mem used: 804MB
best_loss: tensor(-0.4398, device='cuda:1')
final loss: -0.4458540081977844
Test:
Test: 0.6076279669536395
0.6076279669536395
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310910559022389, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974795940327604
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.35it/s]100%|██████████| 2/2 [00:00<00:00,  3.74it/s]100%|██████████| 2/2 [00:00<00:00,  3.67it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.26614269614219666
Epoch 1, Loop Feat 0: -0.2699112594127655
Epoch 1, Loop Adj 0: -0.2675600051879883
Epoch 2: -0.2675600051879883
Mem used: -1495MB
best_loss: tensor(-0.2770, device='cuda:1')
final loss: -0.2750469148159027
Test:
Test: 0.6023887741887106
0.6023887741887106
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.600148335360801
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.85it/s]100%|██████████| 2/2 [00:00<00:00,  5.61it/s]100%|██████████| 2/2 [00:00<00:00,  5.48it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.40417084097862244
Epoch 1, Loop Feat 0: -0.40745407342910767
Epoch 1, Loop Adj 0: -0.4039035439491272
Epoch 2: -0.4039035439491272
Mem used: 674MB
best_loss: tensor(-0.4040, device='cuda:1')
best_loss: tensor(-0.4080, device='cuda:1')
final loss: -0.4107065200805664
Test:
Test: 0.6041806467437858
0.6041806467437858
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890635530157
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.43it/s]100%|██████████| 2/2 [00:00<00:00,  6.00it/s]100%|██████████| 2/2 [00:00<00:00,  5.90it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.4198577404022217
Epoch 1, Loop Feat 0: -0.4153608977794647
Epoch 1, Loop Adj 0: -0.42358747124671936
Epoch 2: -0.42358747124671936
Mem used: 674MB
best_loss: tensor(-0.4162, device='cuda:1')
best_loss: tensor(-0.4203, device='cuda:1')
final loss: -0.4286510944366455
Test:
Test: 0.6041562213249554
0.6041562213249554
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483719525047425, 0.5836708161590052]
flatten test: 0.603494616144178
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.53it/s]100%|██████████| 2/2 [00:00<00:00,  4.11it/s]100%|██████████| 2/2 [00:00<00:00,  4.16it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.4205489754676819
Epoch 1, Loop Feat 0: -0.43549737334251404
Epoch 1, Loop Adj 0: -0.4293164610862732
Epoch 2: -0.4293164610862732
Mem used: 874MB
best_loss: tensor(-0.4450, device='cuda:1')
final loss: -0.43489977717399597
Test:
Test: 0.6091176394893967
0.6091176394893967
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.5937196763338406, 0.6002883018849671, 0.5401741024379962, 0.5824575153695682]
flatten test: 0.5878747710283345
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.66it/s]100%|██████████| 2/2 [00:00<00:00,  6.15it/s]100%|██████████| 2/2 [00:00<00:00,  6.07it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5831117630004883
Epoch 1, Loop Feat 0: -0.617814838886261
Epoch 1, Loop Adj 0: -0.6095531582832336
Epoch 2: -0.6095531582832336
Mem used: 788MB
best_loss: tensor(-0.6223, device='cuda:1')
final loss: -0.6099131107330322
Test:
Test: 0.6000774543931757
0.6000774543931757
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987105909037
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.60it/s]100%|██████████| 2/2 [00:00<00:00,  4.34it/s]100%|██████████| 2/2 [00:00<00:00,  4.37it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.4137086868286133
Epoch 1, Loop Feat 0: -0.4448694586753845
Epoch 1, Loop Adj 0: -0.44734856486320496
Epoch 2: -0.44734856486320496
Mem used: 993MB
best_loss: tensor(-0.4403, device='cuda:1')
best_loss: tensor(-0.4426, device='cuda:1')
final loss: -0.4362384080886841
Test:
Test: 0.6110717921442135
0.6110717921442135
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405997298554459, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804553804982
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.95it/s]100%|██████████| 2/2 [00:00<00:00,  5.16it/s]100%|██████████| 2/2 [00:00<00:00,  5.26it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.32399165630340576
Epoch 1, Loop Feat 0: -0.3288801312446594
Epoch 1, Loop Adj 0: -0.3314417600631714
Epoch 2: -0.3314417600631714
Mem used: 674MB
best_loss: tensor(-0.3433, device='cuda:1')
final loss: -0.33952978253364563
Test:
Test: 0.6102212315431209
0.6102212315431209
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887516929199
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.21it/s]100%|██████████| 2/2 [00:00<00:00,  7.94it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.41172561049461365
Epoch 1, Loop Feat 0: -0.4244484007358551
Epoch 1, Loop Adj 0: -0.41805076599121094
Epoch 2: -0.41805076599121094
Mem used: 674MB
best_loss: tensor(-0.4187, device='cuda:1')
final loss: -0.42112597823143005
Test:
Test: 0.6090644198776363
0.6090644198776363
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205532218848335, 0.5767507023125826, 0.5493891660226234, 0.5826381732918821]
flatten test: 0.5907168018474396
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.56it/s]100%|██████████| 2/2 [00:00<00:00,  4.55it/s]100%|██████████| 2/2 [00:00<00:00,  4.55it/s]
Epoch 0, Loop Feat 0: -0.35880887508392334
Epoch 0, Loop Adj 0: -0.3609839379787445
Epoch 1, Loop Feat 0: -0.3938083052635193
Epoch 1, Loop Adj 0: -0.39244410395622253
Epoch 2: -0.39244410395622253
Mem used: 864MB
best_loss: tensor(-0.3906, device='cuda:1')
best_loss: tensor(-0.3946, device='cuda:1')
final loss: -0.39447179436683655
Test:
Test: 0.6065347408093702
0.6065347408093702
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127835671419
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.41it/s]100%|██████████| 2/2 [00:00<00:00,  5.18it/s]100%|██████████| 2/2 [00:00<00:00,  5.21it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.43351078033447266
Epoch 1, Loop Feat 0: -0.46398288011550903
Epoch 1, Loop Adj 0: -0.4620743989944458
Epoch 2: -0.4620743989944458
Mem used: 1042MB
best_loss: tensor(-0.4528, device='cuda:1')
best_loss: tensor(-0.4537, device='cuda:1')
final loss: -0.45935219526290894
Test:
Test: 0.6096570639423309
0.6096570639423309
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179836213682554, 0.6310911059929533, 0.6278801467147008, 0.5383905009484999, 0.5426401818150064]
flatten test: 0.597479599577137
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.40it/s]100%|██████████| 2/2 [00:00<00:00,  5.76it/s]100%|██████████| 2/2 [00:00<00:00,  5.70it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.26614269614219666
Epoch 1, Loop Feat 0: -0.27634331583976746
Epoch 1, Loop Adj 0: -0.27443891763687134
Epoch 2: -0.27443891763687134
Mem used: 890MB
best_loss: tensor(-0.2814, device='cuda:1')
final loss: -0.2810141444206238
Test:
Test: 0.6030704220966556
0.6030704220966556
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483242720478
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.01it/s]100%|██████████| 2/2 [00:00<00:00,  4.53it/s]100%|██████████| 2/2 [00:00<00:00,  4.44it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.40417084097862244
Epoch 1, Loop Feat 0: -0.4272705912590027
Epoch 1, Loop Adj 0: -0.4252098500728607
Epoch 2: -0.4252098500728607
Mem used: 840MB
best_loss: tensor(-0.4193, device='cuda:1')
best_loss: tensor(-0.4229, device='cuda:1')
final loss: -0.4257643222808838
Test:
Test: 0.6037488529982182
0.6037488529982182
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875724, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.598189074641769
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.70it/s]100%|██████████| 2/2 [00:00<00:00,  5.22it/s]100%|██████████| 2/2 [00:00<00:00,  5.28it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.4198577404022217
Epoch 1, Loop Feat 0: -0.43073952198028564
Epoch 1, Loop Adj 0: -0.4395250678062439
Epoch 2: -0.4395250678062439
Mem used: 674MB
best_loss: tensor(-0.4257, device='cuda:1')
best_loss: tensor(-0.4312, device='cuda:1')
final loss: -0.4389606714248657
Test:
Test: 0.6044626709699885
0.6044626709699885
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483719525047425, 0.5836708161590052]
flatten test: 0.6034946161441779
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.64it/s]100%|██████████| 2/2 [00:00<00:00,  4.90it/s]100%|██████████| 2/2 [00:00<00:00,  4.86it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.4205489754676819
Epoch 1, Loop Feat 0: -0.44795674085617065
Epoch 1, Loop Adj 0: -0.4402853548526764
Epoch 2: -0.4402853548526764
Mem used: 674MB
best_loss: tensor(-0.4506, device='cuda:1')
best_loss: tensor(-0.4548, device='cuda:1')
final loss: -0.4425617754459381
Test:
Test: 0.6127303773731181
0.6127303773731181
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.5937196262431264, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747821170878
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.65it/s]100%|██████████| 2/2 [00:00<00:00,  4.90it/s]100%|██████████| 2/2 [00:00<00:00,  4.66it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5831117630004883
Epoch 1, Loop Feat 0: -0.5946860909461975
Epoch 1, Loop Adj 0: -0.5943599939346313
Epoch 2: -0.5943599939346313
Mem used: 798MB
best_loss: tensor(-0.6095, device='cuda:1')
best_loss: tensor(-0.6108, device='cuda:1')
final loss: -0.5955896973609924
Test:
Test: 0.6012038037883467
0.6012038037883467
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987216796569
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.39it/s]100%|██████████| 2/2 [00:00<00:00,  4.34it/s]100%|██████████| 2/2 [00:00<00:00,  4.35it/s]
Epoch 0, Loop Feat 0: -0.42172563076019287
Epoch 0, Loop Adj 0: -0.4137086868286133
Epoch 1, Loop Feat 0: -0.42248082160949707
Epoch 1, Loop Adj 0: -0.42461976408958435
Epoch 2: -0.42461976408958435
Mem used: 816MB
best_loss: tensor(-0.4281, device='cuda:1')
best_loss: tensor(-0.4284, device='cuda:1')
final loss: -0.41910842061042786
Test:
Test: 0.6033006167755841
0.6033006167755841
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.614043983654398, 0.6456251035480238, 0.5428112133773624, 0.5562247297226491]
flatten test: 0.6065804332029916
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.63it/s]100%|██████████| 2/2 [00:00<00:00,  4.52it/s]100%|██████████| 2/2 [00:00<00:00,  4.66it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.32399165630340576
Epoch 1, Loop Feat 0: -0.31773003935813904
Epoch 1, Loop Adj 0: -0.3218705952167511
Epoch 2: -0.3218705952167511
Mem used: -594MB
best_loss: tensor(-0.3318, device='cuda:1')
final loss: -0.3291729986667633
Test:
Test: 0.6060544536712953
0.6060544536712953
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163420955350138, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887406041668
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.82it/s]100%|██████████| 2/2 [00:00<00:00,  5.20it/s]100%|██████████| 2/2 [00:00<00:00,  5.14it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.41172561049461365
Epoch 1, Loop Feat 0: -0.4096381664276123
Epoch 1, Loop Adj 0: -0.39949581027030945
Epoch 2: -0.39949581027030945
Mem used: -990MB
best_loss: tensor(-0.4112, device='cuda:1')
final loss: -0.4121383726596832
Test:
Test: 0.6081202880785528
0.6081202880785528
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205532218848335, 0.576750097652589, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168240249461
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.20it/s]100%|██████████| 2/2 [00:00<00:00,  4.23it/s]100%|██████████| 2/2 [00:00<00:00,  4.35it/s]
Epoch 0, Loop Feat 0: -0.35880887508392334
Epoch 0, Loop Adj 0: -0.3609839379787445
Epoch 1, Loop Feat 0: -0.3699599802494049
Epoch 1, Loop Adj 0: -0.36853161454200745
Epoch 2: -0.36853161454200745
Mem used: 860MB
best_loss: tensor(-0.3709, device='cuda:1')
final loss: -0.37231969833374023
Test:
Test: 0.6052620771979859
0.6052620771979859
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127780227652
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.98it/s]100%|██████████| 2/2 [00:00<00:00,  6.85it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.43351078033447266
Epoch 1, Loop Feat 0: -0.4390609860420227
Epoch 1, Loop Adj 0: -0.4357861578464508
Epoch 2: -0.4357861578464508
Mem used: 850MB
best_loss: tensor(-0.4334, device='cuda:1')
final loss: -0.4399396777153015
Test:
Test: 0.6077843690664104
0.6077843690664104
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310911059929533, 0.6278801467147008, 0.5383905009484999, 0.5426401818150064]
flatten test: 0.5974795940327604
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.29it/s]100%|██████████| 2/2 [00:00<00:00,  8.17it/s]100%|██████████| 2/2 [00:00<00:00,  8.01it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.26614269614219666
Epoch 1, Loop Feat 0: -0.2673081159591675
Epoch 1, Loop Adj 0: -0.2648443281650543
Epoch 2: -0.2648443281650543
Mem used: 674MB
best_loss: tensor(-0.2727, device='cuda:1')
final loss: -0.27187612652778625
Test:
Test: 0.6018638064064339
0.6018638064064339
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483187276712
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.22it/s]100%|██████████| 2/2 [00:00<00:00,  4.25it/s]100%|██████████| 2/2 [00:00<00:00,  4.37it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.40417084097862244
Epoch 1, Loop Feat 0: -0.4005622863769531
Epoch 1, Loop Adj 0: -0.39556580781936646
Epoch 2: -0.39556580781936646
Mem used: 674MB
best_loss: tensor(-0.4040, device='cuda:1')
final loss: -0.40411069989204407
Test:
Test: 0.6022220855987412
0.6022220855987412
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875724, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890690973924
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.90it/s]100%|██████████| 2/2 [00:00<00:00,  3.05it/s]100%|██████████| 2/2 [00:00<00:00,  3.16it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.4198577404022217
Epoch 1, Loop Feat 0: -0.4085712134838104
Epoch 1, Loop Adj 0: -0.41599592566490173
Epoch 2: -0.41599592566490173
Mem used: 1084MB
best_loss: tensor(-0.4139, device='cuda:1')
final loss: -0.4221491515636444
Test:
Test: 0.6032814736018017
0.6032814736018017
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232557, 0.5836708161590052]
flatten test: 0.6034946327773077
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.70it/s]100%|██████████| 2/2 [00:00<00:00,  7.22it/s]100%|██████████| 2/2 [00:00<00:00,  6.93it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.4205489754676819
Epoch 1, Loop Feat 0: -0.43007877469062805
Epoch 1, Loop Adj 0: -0.42330819368362427
Epoch 2: -0.42330819368362427
Mem used: 874MB
best_loss: tensor(-0.4437, device='cuda:1')
final loss: -0.4311772286891937
Test:
Test: 0.6089571863315515
0.6089571863315515
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.593719576152412, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747765727113
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.34it/s]100%|██████████| 1/1 [00:00<00:00,  4.33it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5831117630004883
Epoch 1: -0.5831117630004883
Mem used: 780MB
best_loss: tensor(-0.6065, device='cuda:1')
best_loss: tensor(-0.6097, device='cuda:1')
final loss: -0.5990026593208313
Test:
Test: 0.6029579857377795
0.6029579857377795
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987272240335
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.43it/s]100%|██████████| 1/1 [00:00<00:00,  3.37it/s]
Epoch 0, Loop Feat 0: -0.42172563076019287
Epoch 0, Loop Adj 0: -0.4137086868286133
Epoch 1: -0.4137086868286133
Mem used: 107MB
best_loss: tensor(-0.4252, device='cuda:1')
best_loss: tensor(-0.4298, device='cuda:1')
final loss: -0.42361658811569214
Test:
Test: 0.605820088798908
0.605820088798908
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405996180406469, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804221142385
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.87it/s]100%|██████████| 1/1 [00:00<00:00,  4.86it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.32399165630340576
Epoch 1: -0.32399165630340576
Mem used: 674MB
best_loss: tensor(-0.3346, device='cuda:1')
final loss: -0.3299402594566345
Test:
Test: 0.6062434230091734
0.6062434230091734
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163420955350138, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887461485434
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.62it/s]100%|██████████| 1/1 [00:00<00:00,  4.61it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.41172561049461365
Epoch 1: -0.41172561049461365
Mem used: 792MB
best_loss: tensor(-0.4126, device='cuda:1')
final loss: -0.41051623225212097
Test:
Test: 0.6073795425718767
0.6073795425718767
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205532218848335, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168184805693
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.93it/s]100%|██████████| 1/1 [00:00<00:00,  5.92it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3609839379787445
Epoch 1: -0.3609839379787445
Mem used: 1138MB
best_loss: tensor(-0.3718, device='cuda:1')
final loss: -0.3690580427646637
Test:
Test: 0.6056852922598668
0.6056852922598668
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127835671419
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.23it/s]100%|██████████| 1/1 [00:00<00:00,  4.22it/s]
Epoch 0, Loop Feat 0: -0.4249717593193054
Epoch 0, Loop Adj 0: -0.43351078033447266
Epoch 1: -0.43351078033447266
Mem used: 816MB
best_loss: tensor(-0.4303, device='cuda:1')
best_loss: tensor(-0.4337, device='cuda:1')
final loss: -0.43900197744369507
Test:
Test: 0.607637141379249
0.607637141379249
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310910559022389, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974795995771371
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.62it/s]100%|██████████| 1/1 [00:00<00:00,  4.61it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.26614269614219666
Epoch 1: -0.26614269614219666
Mem used: 674MB
best_loss: tensor(-0.2745, device='cuda:1')
final loss: -0.2728453576564789
Test:
Test: 0.6021630674322666
0.6021630674322666
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483187276712
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.90it/s]100%|██████████| 1/1 [00:00<00:00,  3.89it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.40417084097862244
Epoch 1: -0.40417084097862244
Mem used: 960MB
best_loss: tensor(-0.4012, device='cuda:1')
best_loss: tensor(-0.4038, device='cuda:1')
final loss: -0.40631213784217834
Test:
Test: 0.6043650884430516
0.6043650884430516
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875724, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890690973923
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.98it/s]100%|██████████| 1/1 [00:00<00:00,  4.97it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.4198577404022217
Epoch 1: -0.4198577404022217
Mem used: 748MB
best_loss: tensor(-0.4133, device='cuda:1')
best_loss: tensor(-0.4173, device='cuda:1')
final loss: -0.4248157739639282
Test:
Test: 0.6046474303982796
0.6046474303982796
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145208472543777, 0.6325989133050594, 0.5483719525047425, 0.5836708161590052]
flatten test: 0.6034946272329311
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.00it/s]100%|██████████| 1/1 [00:00<00:00,  6.98it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.4205489754676819
Epoch 1: -0.4205489754676819
Mem used: 766MB
best_loss: tensor(-0.4371, device='cuda:1')
best_loss: tensor(-0.4413, device='cuda:1')
final loss: -0.43043768405914307
Test:
Test: 0.6092276928805822
0.6092276928805822
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.5937196262431264, 0.6002883018849671, 0.5401741024379962, 0.5824575153695682]
flatten test: 0.5878747765727111
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  8.43it/s]100%|██████████| 1/1 [00:00<00:00,  8.40it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5831117630004883
Epoch 1: -0.5831117630004883
Mem used: 674MB
best_loss: tensor(-0.6103, device='cuda:1')
best_loss: tensor(-0.6164, device='cuda:1')
final loss: -0.6065523624420166
Test:
Test: 0.6001044216442095
0.6001044216442095
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.604698721679657
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.16it/s]100%|██████████| 1/1 [00:00<00:00,  6.15it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.4137086868286133
Epoch 1: -0.4137086868286133
Mem used: 674MB
best_loss: tensor(-0.4295, device='cuda:1')
best_loss: tensor(-0.4393, device='cuda:1')
final loss: -0.4377420246601105
Test:
Test: 0.6058257284891095
0.6058257284891095
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804110254853
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.63it/s]100%|██████████| 1/1 [00:00<00:00,  3.63it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.32399165630340576
Epoch 1: -0.32399165630340576
Mem used: 792MB
best_loss: tensor(-0.3379, device='cuda:1')
final loss: -0.33362650871276855
Test:
Test: 0.6067544107143311
0.6067544107143311
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163421456257283, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887516929199
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.97it/s]100%|██████████| 1/1 [00:00<00:00,  4.96it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.41172561049461365
Epoch 1: -0.41172561049461365
Mem used: 740MB
best_loss: tensor(-0.4146, device='cuda:1')
best_loss: tensor(-0.4205, device='cuda:1')
final loss: -0.4204125702381134
Test:
Test: 0.6071120147324595
0.6071120147324595
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035360312008, 0.6205532218848335, 0.5767507023125826, 0.5493891660226236, 0.5826381732918821]
flatten test: 0.590716824024946
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.01it/s]100%|██████████| 1/1 [00:00<00:00,  5.00it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3609839379787445
Epoch 1: -0.3609839379787445
Mem used: 674MB
best_loss: tensor(-0.3752, device='cuda:1')
final loss: -0.3762214779853821
Test:
Test: 0.6092301949966574
0.6092301949966574
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127613896354
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.20it/s]100%|██████████| 1/1 [00:00<00:00,  6.19it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.43351078033447266
Epoch 1: -0.43351078033447266
Mem used: 674MB
best_loss: tensor(-0.4411, device='cuda:1')
best_loss: tensor(-0.4500, device='cuda:1')
final loss: -0.4537816643714905
Test:
Test: 0.6090673985872497
0.6090673985872497
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179833977386575, 0.6310910559022389, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974795829440072
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  9.50it/s]100%|██████████| 1/1 [00:00<00:00,  9.47it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.26614269614219666
Epoch 1: -0.26614269614219666
Mem used: 674MB
best_loss: tensor(-0.2769, device='cuda:1')
final loss: -0.2760950028896332
Test:
Test: 0.6014938109563136
0.6014938109563136
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483242720478
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.90it/s]100%|██████████| 1/1 [00:00<00:00,  4.89it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.40417084097862244
Epoch 1: -0.40417084097862244
Mem used: 674MB
best_loss: tensor(-0.4066, device='cuda:1')
best_loss: tensor(-0.4170, device='cuda:1')
final loss: -0.4208342730998993
Test:
Test: 0.6022730016750674
0.6022730016750674
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890690973923
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.97it/s]100%|██████████| 1/1 [00:00<00:00,  5.96it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.4198577404022217
Epoch 1: -0.4198577404022217
Mem used: 674MB
best_loss: tensor(-0.4203, device='cuda:1')
best_loss: tensor(-0.4279, device='cuda:1')
final loss: -0.4347417950630188
Test:
Test: 0.6055233298891507
0.6055233298891507
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232557, 0.5836708161590052]
flatten test: 0.603494616144178
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.23it/s]100%|██████████| 1/1 [00:00<00:00,  4.23it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.4205489754676819
Epoch 1: -0.4205489754676819
Mem used: 674MB
best_loss: tensor(-0.4414, device='cuda:1')
final loss: -0.43652379512786865
Test:
Test: 0.6091983823779856
0.6091983823779856
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.593719576152412, 0.6002883018849671, 0.5401741024379962, 0.5824575153695682]
flatten test: 0.587874765483958
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.77it/s]100%|██████████| 1/1 [00:00<00:00,  4.76it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5831117630004883
Epoch 1: -0.5831117630004883
Mem used: 806MB
best_loss: tensor(-0.6090, device='cuda:1')
final loss: -0.5933783650398254
Test:
Test: 0.6001578001204829
0.6001578001204829
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.644284027479605, 0.6097033728081556, 0.6344159165859445, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987105909037
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.17it/s]100%|██████████| 1/1 [00:00<00:00,  7.16it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.4137086868286133
Epoch 1: -0.4137086868286133
Mem used: 784MB
best_loss: tensor(-0.4272, device='cuda:1')
final loss: -0.42069384455680847
Test:
Test: 0.6015134704397623
0.6015134704397623
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804332029917
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.66it/s]100%|██████████| 1/1 [00:00<00:00,  4.66it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.32399165630340576
Epoch 1: -0.32399165630340576
Mem used: 762MB
best_loss: tensor(-0.3294, device='cuda:1')
final loss: -0.32641875743865967
Test:
Test: 0.6060370580071527
0.6060370580071527
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163420955350138, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887516929199
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.56it/s]100%|██████████| 1/1 [00:00<00:00,  3.55it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.41172561049461365
Epoch 1: -0.41172561049461365
Mem used: -282MB
best_loss: tensor(-0.4086, device='cuda:1')
final loss: -0.4087843596935272
Test:
Test: 0.608089786092111
0.608089786092111
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205531717941192, 0.576750097652589, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168073918162
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.58it/s]100%|██████████| 1/1 [00:00<00:00,  4.57it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3609839379787445
Epoch 1: -0.3609839379787445
Mem used: 674MB
best_loss: tensor(-0.3679, device='cuda:1')
final loss: -0.3682725131511688
Test:
Test: 0.6052343156243883
0.6052343156243883
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127835671419
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.99it/s]100%|██████████| 1/1 [00:00<00:00,  3.98it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.43351078033447266
Epoch 1: -0.43351078033447266
Mem used: 780MB
best_loss: tensor(-0.4306, device='cuda:1')
final loss: -0.4371282756328583
Test:
Test: 0.6075392014071583
0.6075392014071583
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179836213682554, 0.6310910559022389, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.597479599577137
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.78it/s]100%|██████████| 1/1 [00:00<00:00,  3.78it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.26614269614219666
Epoch 1: -0.26614269614219666
Mem used: 2122MB
best_loss: tensor(-0.2704, device='cuda:1')
final loss: -0.2694048285484314
Test:
Test: 0.6018391029747062
0.6018391029747062
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483298164243
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.91it/s]100%|██████████| 1/1 [00:00<00:00,  4.90it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.40417084097862244
Epoch 1: -0.40417084097862244
Mem used: 674MB
best_loss: tensor(-0.4015, device='cuda:1')
final loss: -0.4009440541267395
Test:
Test: 0.6029536963959361
0.6029536963959361
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890690973923
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.53it/s]100%|██████████| 1/1 [00:00<00:00,  5.52it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.4198577404022217
Epoch 1: -0.4198577404022217
Mem used: 674MB
best_loss: tensor(-0.4111, device='cuda:1')
final loss: -0.4194999635219574
Test:
Test: 0.6034191297020719
0.6034191297020719
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303432937956205, 0.6145207971636634, 0.6325989133050594, 0.5483720930232557, 0.5836708161590052]
flatten test: 0.6034946216885546
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.32it/s]100%|██████████| 1/1 [00:00<00:00,  6.31it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.4205489754676819
Epoch 1: -0.4205489754676819
Mem used: 856MB
best_loss: tensor(-0.4392, device='cuda:1')
final loss: -0.428933322429657
Test:
Test: 0.6077366302803386
0.6077366302803386
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.593719576152412, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747765727111
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.94it/s]100%|██████████| 2/2 [00:00<00:00,  5.77it/s]100%|██████████| 2/2 [00:00<00:00,  5.91it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5831117630004883
Epoch 1, Loop Feat 0: -0.6026473045349121
Epoch 1, Loop Adj 0: -0.59825599193573
Epoch 2: -0.59825599193573
Mem used: 1064MB
best_loss: tensor(-0.6113, device='cuda:1')
best_loss: tensor(-0.6125, device='cuda:1')
final loss: -0.6035565137863159
Test:
Test: 0.6032683672795024
0.6032683672795024
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097034228988698, 0.6344159165859445, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987105909036
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.73it/s]100%|██████████| 2/2 [00:00<00:00,  6.55it/s]100%|██████████| 2/2 [00:00<00:00,  6.18it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.4137086868286133
Epoch 1, Loop Feat 0: -0.42854025959968567
Epoch 1, Loop Adj 0: -0.43090465664863586
Epoch 2: -0.43090465664863586
Mem used: 826MB
best_loss: tensor(-0.4284, device='cuda:1')
best_loss: tensor(-0.4329, device='cuda:1')
final loss: -0.42722591757774353
Test:
Test: 0.6044981374724528
0.6044981374724528
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562247297226491]
flatten test: 0.6065804276586151
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.35it/s]100%|██████████| 2/2 [00:00<00:00,  4.45it/s]100%|██████████| 2/2 [00:00<00:00,  4.43it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.32399165630340576
Epoch 1, Loop Feat 0: -0.3204447329044342
Epoch 1, Loop Adj 0: -0.32418563961982727
Epoch 2: -0.32418563961982727
Mem used: 816MB
best_loss: tensor(-0.3370, device='cuda:1')
final loss: -0.33214253187179565
Test:
Test: 0.6059621533894062
0.6059621533894062
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280594765278374, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887461485434
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.24it/s]100%|██████████| 2/2 [00:00<00:00,  5.23it/s]100%|██████████| 2/2 [00:00<00:00,  5.36it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.41172561049461365
Epoch 1, Loop Feat 0: -0.4133794903755188
Epoch 1, Loop Adj 0: -0.40458595752716064
Epoch 2: -0.40458595752716064
Mem used: 674MB
best_loss: tensor(-0.4152, device='cuda:1')
final loss: -0.4129655063152313
Test:
Test: 0.6075290340783444
0.6075290340783444
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205531717941192, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.590716824024946
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.69it/s]100%|██████████| 2/2 [00:00<00:00,  5.36it/s]100%|██████████| 2/2 [00:00<00:00,  5.40it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3609839379787445
Epoch 1, Loop Feat 0: -0.37611159682273865
Epoch 1, Loop Adj 0: -0.3744197487831116
Epoch 2: -0.3744197487831116
Mem used: 674MB
best_loss: tensor(-0.3743, device='cuda:1')
final loss: -0.3721018433570862
Test:
Test: 0.6056338598738744
0.6056338598738744
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.605312766934012
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.88it/s]100%|██████████| 2/2 [00:00<00:00,  3.82it/s]100%|██████████| 2/2 [00:00<00:00,  4.03it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.43351078033447266
Epoch 1, Loop Feat 0: -0.44612550735473633
Epoch 1, Loop Adj 0: -0.4432545602321625
Epoch 2: -0.4432545602321625
Mem used: 862MB
best_loss: tensor(-0.4393, device='cuda:1')
final loss: -0.4446346163749695
Test:
Test: 0.60779179598238
0.60779179598238
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310911059929533, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974796051215137
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.32it/s]100%|██████████| 2/2 [00:00<00:00,  5.01it/s]100%|██████████| 2/2 [00:00<00:00,  4.89it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.26614269614219666
Epoch 1, Loop Feat 0: -0.26959335803985596
Epoch 1, Loop Adj 0: -0.2672173082828522
Epoch 2: -0.2672173082828522
Mem used: 746MB
best_loss: tensor(-0.2769, device='cuda:1')
final loss: -0.2747510075569153
Test:
Test: 0.6026451815122377
0.6026451815122377
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483298164243
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.86it/s]100%|██████████| 2/2 [00:00<00:00,  4.61it/s]100%|██████████| 2/2 [00:00<00:00,  4.64it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.40417084097862244
Epoch 1, Loop Feat 0: -0.4068847894668579
Epoch 1, Loop Adj 0: -0.40323778986930847
Epoch 2: -0.40323778986930847
Mem used: -578MB
best_loss: tensor(-0.4040, device='cuda:1')
best_loss: tensor(-0.4069, device='cuda:1')
final loss: -0.4093157947063446
Test:
Test: 0.6042105927044332
0.6042105927044332
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890746417688
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.84it/s]100%|██████████| 2/2 [00:00<00:00,  6.06it/s]100%|██████████| 2/2 [00:00<00:00,  5.84it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.4198577404022217
Epoch 1, Loop Feat 0: -0.414806991815567
Epoch 1, Loop Adj 0: -0.4229603111743927
Epoch 2: -0.4229603111743927
Mem used: 674MB
best_loss: tensor(-0.4162, device='cuda:1')
best_loss: tensor(-0.4201, device='cuda:1')
final loss: -0.42772626876831055
Test:
Test: 0.6043845890619877
0.6043845890619877
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232557, 0.5836708161590052]
flatten test: 0.6034946327773077
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.05it/s]100%|██████████| 2/2 [00:00<00:00,  5.78it/s]100%|██████████| 2/2 [00:00<00:00,  5.81it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.4205489754676819
Epoch 1, Loop Feat 0: -0.4350935220718384
Epoch 1, Loop Adj 0: -0.42891204357147217
Epoch 2: -0.42891204357147217
Mem used: 674MB
best_loss: tensor(-0.4450, device='cuda:1')
best_loss: tensor(-0.4451, device='cuda:1')
final loss: -0.4336538314819336
Test:
Test: 0.6086000191908332
0.6086000191908332
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.5937196763338406, 0.6002883018849671, 0.5401741024379962, 0.5824575153695682]
flatten test: 0.5878747821170879
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.20it/s]100%|██████████| 2/2 [00:00<00:00,  5.21it/s]100%|██████████| 2/2 [00:00<00:00,  5.33it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5831117630004883
Epoch 1, Loop Feat 0: -0.6175664663314819
Epoch 1, Loop Adj 0: -0.6094393730163574
Epoch 2: -0.6094393730163574
Mem used: 842MB
best_loss: tensor(-0.6222, device='cuda:1')
final loss: -0.6106860041618347
Test:
Test: 0.5999558038925619
0.5999558038925619
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987105909037
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.74it/s]100%|██████████| 2/2 [00:00<00:00,  7.30it/s]100%|██████████| 2/2 [00:00<00:00,  7.20it/s]
Epoch 0, Loop Feat 0: -0.42172563076019287
Epoch 0, Loop Adj 0: -0.4137086868286133
Epoch 1, Loop Feat 0: -0.4444068670272827
Epoch 1, Loop Adj 0: -0.44688913226127625
Epoch 2: -0.44688913226127625
Mem used: 802MB
best_loss: tensor(-0.4403, device='cuda:1')
best_loss: tensor(-0.4422, device='cuda:1')
final loss: -0.4358314573764801
Test:
Test: 0.6110264363258324
0.6110264363258324
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405996180406469, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804387473683
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.14it/s]100%|██████████| 2/2 [00:00<00:00,  8.02it/s]100%|██████████| 2/2 [00:00<00:00,  7.86it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.32399165630340576
Epoch 1, Loop Feat 0: -0.3285720646381378
Epoch 1, Loop Adj 0: -0.33118176460266113
Epoch 2: -0.33118176460266113
Mem used: 726MB
best_loss: tensor(-0.3430, device='cuda:1')
final loss: -0.33938753604888916
Test:
Test: 0.6099176811754449
0.6099176811754449
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887461485433
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.16it/s]100%|██████████| 2/2 [00:00<00:00,  5.72it/s]100%|██████████| 2/2 [00:00<00:00,  5.77it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.41172561049461365
Epoch 1, Loop Feat 0: -0.424089252948761
Epoch 1, Loop Adj 0: -0.417643666267395
Epoch 2: -0.417643666267395
Mem used: 1004MB
best_loss: tensor(-0.4186, device='cuda:1')
final loss: -0.42081016302108765
Test:
Test: 0.6088438762178554
0.6088438762178554
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205531217034048, 0.576750097652589, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.590716796303063
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.42it/s]100%|██████████| 2/2 [00:00<00:00,  4.04it/s]100%|██████████| 2/2 [00:00<00:00,  3.93it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3609839379787445
Epoch 1, Loop Feat 0: -0.3932376503944397
Epoch 1, Loop Adj 0: -0.3918383717536926
Epoch 2: -0.3918383717536926
Mem used: 764MB
best_loss: tensor(-0.3902, device='cuda:1')
final loss: -0.3923387825489044
Test:
Test: 0.6086443423898814
0.6086443423898814
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.605312766934012
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.53it/s]100%|██████████| 2/2 [00:00<00:00,  6.51it/s]100%|██████████| 2/2 [00:00<00:00,  6.51it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.43351078033447266
Epoch 1, Loop Feat 0: -0.4635556936264038
Epoch 1, Loop Adj 0: -0.46162381768226624
Epoch 2: -0.46162381768226624
Mem used: 674MB
best_loss: tensor(-0.4529, device='cuda:1')
best_loss: tensor(-0.4530, device='cuda:1')
final loss: -0.45631369948387146
Test:
Test: 0.60975242236609
0.60975242236609
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179836213682554, 0.6310911059929533, 0.6278801467147008, 0.5383905009484999, 0.5426401818150064]
flatten test: 0.5974795940327605
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.09it/s]100%|██████████| 2/2 [00:00<00:00,  2.93it/s]100%|██████████| 2/2 [00:00<00:00,  2.95it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.26614269614219666
Epoch 1, Loop Feat 0: -0.27604159712791443
Epoch 1, Loop Adj 0: -0.27409520745277405
Epoch 2: -0.27409520745277405
Mem used: 1136MB
best_loss: tensor(-0.2815, device='cuda:1')
final loss: -0.2807057797908783
Test:
Test: 0.6031402033338671
0.6031402033338671
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483298164243
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.89it/s]100%|██████████| 2/2 [00:00<00:00,  4.51it/s]100%|██████████| 2/2 [00:00<00:00,  4.67it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.40417084097862244
Epoch 1, Loop Feat 0: -0.4266990125179291
Epoch 1, Loop Adj 0: -0.42460769414901733
Epoch 2: -0.42460769414901733
Mem used: 784MB
best_loss: tensor(-0.4190, device='cuda:1')
best_loss: tensor(-0.4222, device='cuda:1')
final loss: -0.4250761568546295
Test:
Test: 0.6048161842269144
0.6048161842269144
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.598189074641769
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.16it/s]100%|██████████| 2/2 [00:00<00:00,  5.69it/s]100%|██████████| 2/2 [00:00<00:00,  5.39it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.4198577404022217
Epoch 1, Loop Feat 0: -0.43025144934654236
Epoch 1, Loop Adj 0: -0.4390586316585541
Epoch 2: -0.4390586316585541
Mem used: -594MB
best_loss: tensor(-0.4254, device='cuda:1')
best_loss: tensor(-0.4300, device='cuda:1')
final loss: -0.43776771426200867
Test:
Test: 0.6042283458137294
0.6042283458137294
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232557, 0.5836708161590052]
flatten test: 0.6034946161441779
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.32it/s]100%|██████████| 2/2 [00:00<00:00,  4.40it/s]100%|██████████| 2/2 [00:00<00:00,  4.52it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.4205489754676819
Epoch 1, Loop Feat 0: -0.4476433992385864
Epoch 1, Loop Adj 0: -0.44000643491744995
Epoch 2: -0.44000643491744995
Mem used: 674MB
best_loss: tensor(-0.4501, device='cuda:1')
best_loss: tensor(-0.4543, device='cuda:1')
final loss: -0.4430529475212097
Test:
Test: 0.6124833827719698
0.6124833827719698
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.5937196262431264, 0.6002883018849671, 0.5401741024379962, 0.5824575153695682]
flatten test: 0.5878747710283345
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.80it/s]100%|██████████| 2/2 [00:00<00:00,  4.85it/s]100%|██████████| 2/2 [00:00<00:00,  4.84it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5831117630004883
Epoch 1, Loop Feat 0: -0.5945156216621399
Epoch 1, Loop Adj 0: -0.5942988991737366
Epoch 2: -0.5942988991737366
Mem used: 674MB
best_loss: tensor(-0.6095, device='cuda:1')
best_loss: tensor(-0.6108, device='cuda:1')
final loss: -0.5961467623710632
Test:
Test: 0.6012304930264833
0.6012304930264833
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033227174413, 0.6344159165859445, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987105909036
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.49it/s]100%|██████████| 2/2 [00:00<00:00,  7.16it/s]100%|██████████| 2/2 [00:00<00:00,  7.20it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.4137086868286133
Epoch 1, Loop Feat 0: -0.4223300516605377
Epoch 1, Loop Adj 0: -0.4244590699672699
Epoch 2: -0.4244590699672699
Mem used: 994MB
best_loss: tensor(-0.4288, device='cuda:1')
final loss: -0.4211893379688263
Test:
Test: 0.602669606931068
0.602669606931068
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.606580444291745
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.68it/s]100%|██████████| 2/2 [00:00<00:00,  6.70it/s]100%|██████████| 2/2 [00:00<00:00,  6.51it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.32399165630340576
Epoch 1, Loop Feat 0: -0.3176364600658417
Epoch 1, Loop Adj 0: -0.32179906964302063
Epoch 2: -0.32179906964302063
Mem used: 850MB
best_loss: tensor(-0.3317, device='cuda:1')
final loss: -0.3292529582977295
Test:
Test: 0.6060390040974335
0.6060390040974335
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280594765278374, 0.6163420955350138, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887516929199
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.59it/s]100%|██████████| 2/2 [00:00<00:00,  5.45it/s]100%|██████████| 2/2 [00:00<00:00,  5.29it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.41172561049461365
Epoch 1, Loop Feat 0: -0.40953877568244934
Epoch 1, Loop Adj 0: -0.39932981133461
Epoch 2: -0.39932981133461
Mem used: 816MB
best_loss: tensor(-0.4112, device='cuda:1')
final loss: -0.4121383726596832
Test:
Test: 0.6081208838204755
0.6081208838204755
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205531717941192, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168073918161
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.82it/s]100%|██████████| 2/2 [00:00<00:00,  5.27it/s]100%|██████████| 2/2 [00:00<00:00,  5.19it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3609839379787445
Epoch 1, Loop Feat 0: -0.36980125308036804
Epoch 1, Loop Adj 0: -0.36837661266326904
Epoch 2: -0.36837661266326904
Mem used: 674MB
best_loss: tensor(-0.3708, device='cuda:1')
final loss: -0.3722281754016876
Test:
Test: 0.6053101734292112
0.6053101734292112
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404823243165879, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053128002002718
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.78it/s]100%|██████████| 2/2 [00:00<00:00,  5.34it/s]100%|██████████| 2/2 [00:00<00:00,  5.25it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.43351078033447266
Epoch 1, Loop Feat 0: -0.43886661529541016
Epoch 1, Loop Adj 0: -0.4355473816394806
Epoch 2: -0.4355473816394806
Mem used: 674MB
best_loss: tensor(-0.4333, device='cuda:1')
final loss: -0.43982407450675964
Test:
Test: 0.6079208336828352
0.6079208336828352
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179836213682554, 0.6310910559022389, 0.6278801467147008, 0.5383906414670132, 0.5426401818150064]
flatten test: 0.597479599577137
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.39it/s]100%|██████████| 2/2 [00:00<00:00,  7.17it/s]100%|██████████| 2/2 [00:00<00:00,  7.19it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.26614269614219666
Epoch 1, Loop Feat 0: -0.26722073554992676
Epoch 1, Loop Adj 0: -0.26475560665130615
Epoch 2: -0.26475560665130615
Mem used: 976MB
best_loss: tensor(-0.2727, device='cuda:1')
final loss: -0.27187591791152954
Test:
Test: 0.6018641638515876
0.6018641638515876
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483242720478
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.39it/s]100%|██████████| 2/2 [00:00<00:00,  3.95it/s]100%|██████████| 2/2 [00:00<00:00,  3.85it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.40417084097862244
Epoch 1, Loop Feat 0: -0.40044790506362915
Epoch 1, Loop Adj 0: -0.39539000391960144
Epoch 2: -0.39539000391960144
Mem used: 1023MB
best_loss: tensor(-0.4040, device='cuda:1')
final loss: -0.40416258573532104
Test:
Test: 0.6021553625033997
0.6021553625033997
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875724, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890801861456
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.85it/s]100%|██████████| 2/2 [00:00<00:00,  5.73it/s]100%|██████████| 2/2 [00:00<00:00,  5.74it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.4198577404022217
Epoch 1, Loop Feat 0: -0.40839824080467224
Epoch 1, Loop Adj 0: -0.41578251123428345
Epoch 2: -0.41578251123428345
Mem used: 750MB
best_loss: tensor(-0.4139, device='cuda:1')
final loss: -0.4218280017375946
Test:
Test: 0.6034621422688902
0.6034621422688902
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303432937956205, 0.6145207971636634, 0.6325989133050594, 0.5483720930232557, 0.5836708161590052]
flatten test: 0.6034946272329312
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.50it/s]100%|██████████| 2/2 [00:00<00:00,  5.65it/s]100%|██████████| 2/2 [00:00<00:00,  5.62it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.4205489754676819
Epoch 1, Loop Feat 0: -0.4299439787864685
Epoch 1, Loop Adj 0: -0.42313888669013977
Epoch 2: -0.42313888669013977
Mem used: -594MB
best_loss: tensor(-0.4437, device='cuda:1')
final loss: -0.43117693066596985
Test:
Test: 0.608956630305757
0.608956630305757
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.593719576152412, 0.6002883018849671, 0.5401741024379962, 0.5824575153695682]
flatten test: 0.5878747710283346
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.28it/s]100%|██████████| 1/1 [00:00<00:00,  5.28it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5831117630004883
Epoch 1: -0.5831117630004883
Mem used: -226MB
best_loss: tensor(-0.6065, device='cuda:1')
best_loss: tensor(-0.6101, device='cuda:1')
final loss: -0.5986692905426025
Test:
Test: 0.6029625530925201
0.6029625530925201
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.644284027479605, 0.6097033227174413, 0.6344159165859445, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987105909036
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.65it/s]100%|██████████| 1/1 [00:00<00:00,  6.64it/s]
Epoch 0, Loop Feat 0: -0.42172563076019287
Epoch 0, Loop Adj 0: -0.4137086868286133
Epoch 1: -0.4137086868286133
Mem used: 674MB
best_loss: tensor(-0.4252, device='cuda:1')
best_loss: tensor(-0.4298, device='cuda:1')
final loss: -0.4232114553451538
Test:
Test: 0.6058148859861165
0.6058148859861165
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405996180406469, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804387473683
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.10it/s]100%|██████████| 1/1 [00:00<00:00,  7.08it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.32399165630340576
Epoch 1: -0.32399165630340576
Mem used: 892MB
best_loss: tensor(-0.3346, device='cuda:1')
final loss: -0.3299402594566345
Test:
Test: 0.6062434230091734
0.6062434230091734
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163420955350138, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887461485433
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.72it/s]100%|██████████| 1/1 [00:00<00:00,  5.71it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.41172561049461365
Epoch 1: -0.41172561049461365
Mem used: 674MB
best_loss: tensor(-0.4125, device='cuda:1')
final loss: -0.41050323843955994
Test:
Test: 0.6073155598893796
0.6073155598893796
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205531717941192, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168018474395
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.08it/s]100%|██████████| 1/1 [00:00<00:00,  6.07it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3609839379787445
Epoch 1: -0.3609839379787445
Mem used: 674MB
best_loss: tensor(-0.3718, device='cuda:1')
final loss: -0.3690580129623413
Test:
Test: 0.6056852922598668
0.6056852922598668
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127891115185
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.42it/s]100%|██████████| 1/1 [00:00<00:00,  7.41it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.43351078033447266
Epoch 1: -0.43351078033447266
Mem used: 674MB
best_loss: tensor(-0.4303, device='cuda:1')
best_loss: tensor(-0.4337, device='cuda:1')
final loss: -0.43938496708869934
Test:
Test: 0.6075448410973597
0.6075448410973597
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310911059929533, 0.6278801467147008, 0.5383906414670132, 0.5426401818150064]
flatten test: 0.5974795940327604
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.22it/s]100%|██████████| 1/1 [00:00<00:00,  4.22it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.26614269614219666
Epoch 1: -0.26614269614219666
Mem used: 674MB
best_loss: tensor(-0.2745, device='cuda:1')
final loss: -0.2731528580188751
Test:
Test: 0.6022309025791971
0.6022309025791971
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483298164243
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.69it/s]100%|██████████| 1/1 [00:00<00:00,  5.67it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.40417084097862244
Epoch 1: -0.40417084097862244
Mem used: 674MB
best_loss: tensor(-0.4013, device='cuda:1')
best_loss: tensor(-0.4031, device='cuda:1')
final loss: -0.4060099720954895
Test:
Test: 0.6039699923999218
0.6039699923999218
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.598189074641769
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.54it/s]100%|██████████| 1/1 [00:00<00:00,  6.32it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.4198577404022217
Epoch 1: -0.4198577404022217
Mem used: 1009MB
best_loss: tensor(-0.4133, device='cuda:1')
best_loss: tensor(-0.4171, device='cuda:1')
final loss: -0.42406463623046875
Test:
Test: 0.6046357935727231
0.6046357935727231
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483719525047425, 0.5836708161590052]
flatten test: 0.6034946272329312
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.38it/s]100%|██████████| 1/1 [00:00<00:00,  4.37it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.4205489754676819
Epoch 1: -0.4205489754676819
Mem used: 1120MB
best_loss: tensor(-0.4370, device='cuda:1')
best_loss: tensor(-0.4416, device='cuda:1')
final loss: -0.4284380078315735
Test:
Test: 0.6107822218536566
0.6107822218536566
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.5937196262431264, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747821170878
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.76it/s]100%|██████████| 1/1 [00:00<00:00,  7.73it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5831117630004883
Epoch 1: -0.5831117630004883
Mem used: 774MB
best_loss: tensor(-0.6103, device='cuda:1')
final loss: -0.5966867804527283
Test:
Test: 0.6008254679513086
0.6008254679513086
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.644284027479605, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987216796569
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.68it/s]100%|██████████| 1/1 [00:00<00:00,  4.67it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.4137086868286133
Epoch 1: -0.4137086868286133
Mem used: 818MB
best_loss: tensor(-0.4295, device='cuda:1')
best_loss: tensor(-0.4303, device='cuda:1')
final loss: -0.4252748191356659
Test:
Test: 0.6025588386495754
0.6025588386495754
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405993944110492, 0.614043983654398, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804498361215
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.14it/s]100%|██████████| 1/1 [00:00<00:00,  4.13it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.32399165630340576
Epoch 1: -0.32399165630340576
Mem used: 692MB
best_loss: tensor(-0.3379, device='cuda:1')
final loss: -0.33362650871276855
Test:
Test: 0.6067544107143311
0.6067544107143311
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163420955350138, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887516929199
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  9.14it/s]100%|██████████| 1/1 [00:00<00:00,  9.11it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.41172561049461365
Epoch 1: -0.41172561049461365
Mem used: 674MB
best_loss: tensor(-0.4145, device='cuda:1')
final loss: -0.4154692590236664
Test:
Test: 0.6079346548954417
0.6079346548954417
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205531217034048, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168073918162
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.77it/s]100%|██████████| 1/1 [00:00<00:00,  6.75it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3609839379787445
Epoch 1: -0.3609839379787445
Mem used: 674MB
best_loss: tensor(-0.3752, device='cuda:1')
final loss: -0.37656956911087036
Test:
Test: 0.6092301949966574
0.6092301949966574
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127835671419
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.17it/s]100%|██████████| 1/1 [00:00<00:00,  5.16it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.43351078033447266
Epoch 1: -0.43351078033447266
Mem used: -990MB
best_loss: tensor(-0.4411, device='cuda:1')
final loss: -0.4455203115940094
Test:
Test: 0.6105455137297067
0.6105455137297067
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179836213682554, 0.6310911059929533, 0.6278801467147008, 0.5383907819855266, 0.5426401818150064]
flatten test: 0.5974796217546435
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.16it/s]100%|██████████| 1/1 [00:00<00:00,  5.16it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.26614269614219666
Epoch 1: -0.26614269614219666
Mem used: 674MB
best_loss: tensor(-0.2769, device='cuda:1')
final loss: -0.2760950028896332
Test:
Test: 0.6014938109563136
0.6014938109563136
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483409051775
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.14it/s]100%|██████████| 1/1 [00:00<00:00,  7.12it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.40417084097862244
Epoch 1: -0.40417084097862244
Mem used: 674MB
best_loss: tensor(-0.4066, device='cuda:1')
final loss: -0.4050496518611908
Test:
Test: 0.606163236146379
0.606163236146379
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890690973923
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.19it/s]100%|██████████| 1/1 [00:00<00:00,  5.19it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.4198577404022217
Epoch 1: -0.4198577404022217
Mem used: 674MB
best_loss: tensor(-0.4203, device='cuda:1')
final loss: -0.4262967109680176
Test:
Test: 0.6067007145090324
0.6067007145090324
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145208472543777, 0.6325989133050594, 0.5483720930232558, 0.5836708161590052]
flatten test: 0.6034946216885545
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.44it/s]100%|██████████| 1/1 [00:00<00:00,  6.43it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.4205489754676819
Epoch 1: -0.4205489754676819
Mem used: 1056MB
best_loss: tensor(-0.4414, device='cuda:1')
final loss: -0.43625426292419434
Test:
Test: 0.6091983823779856
0.6091983823779856
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.5937196763338406, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747821170879
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.63it/s]100%|██████████| 1/1 [00:00<00:00,  3.63it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5831117630004883
Epoch 1: -0.5831117630004883
Mem used: 816MB
best_loss: tensor(-0.6091, device='cuda:1')
best_loss: tensor(-0.6102, device='cuda:1')
final loss: -0.5929436087608337
Test:
Test: 0.5995178938632545
0.5995178938632545
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987161352804
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.25it/s]100%|██████████| 1/1 [00:00<00:00,  4.24it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.4137086868286133
Epoch 1: -0.4137086868286133
Mem used: 674MB
best_loss: tensor(-0.4271, device='cuda:1')
final loss: -0.4218120872974396
Test:
Test: 0.6013544470625316
0.6013544470625316
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.606580427658615
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.54it/s]100%|██████████| 1/1 [00:00<00:00,  4.54it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.32399165630340576
Epoch 1: -0.32399165630340576
Mem used: 674MB
best_loss: tensor(-0.3294, device='cuda:1')
final loss: -0.32641875743865967
Test:
Test: 0.6060370580071527
0.6060370580071527
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163420955350138, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887572372966
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.02it/s]100%|██████████| 1/1 [00:00<00:00,  4.02it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.41172561049461365
Epoch 1: -0.41172561049461365
Mem used: 1048MB
best_loss: tensor(-0.4086, device='cuda:1')
final loss: -0.4090663194656372
Test:
Test: 0.6081278341429068
0.6081278341429068
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205531217034048, 0.576750097652589, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907167907586863
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.15it/s]100%|██████████| 1/1 [00:00<00:00,  4.15it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3609839379787445
Epoch 1: -0.3609839379787445
Mem used: 808MB
best_loss: tensor(-0.3679, device='cuda:1')
final loss: -0.3682725131511688
Test:
Test: 0.6052343156243883
0.6052343156243883
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053128057446484
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.79it/s]100%|██████████| 1/1 [00:00<00:00,  6.78it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.43351078033447266
Epoch 1: -0.43351078033447266
Mem used: 880MB
best_loss: tensor(-0.4306, device='cuda:1')
final loss: -0.4371282756328583
Test:
Test: 0.6075392014071583
0.6075392014071583
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179836213682554, 0.6310910559022389, 0.6278801467147008, 0.5383905009484999, 0.5426401818150064]
flatten test: 0.597479599577137
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.72it/s]100%|██████████| 1/1 [00:00<00:00,  5.71it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.26614269614219666
Epoch 1: -0.26614269614219666
Mem used: 834MB
best_loss: tensor(-0.2704, device='cuda:1')
final loss: -0.2694048285484314
Test:
Test: 0.6018391029747062
0.6018391029747062
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483242720478
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.36it/s]100%|██████████| 1/1 [00:00<00:00,  5.35it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.40417084097862244
Epoch 1: -0.40417084097862244
Mem used: 674MB
best_loss: tensor(-0.4015, device='cuda:1')
final loss: -0.4016260504722595
Test:
Test: 0.6029536963959361
0.6029536963959361
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890690973923
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.89it/s]100%|██████████| 1/1 [00:00<00:00,  7.87it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.4198577404022217
Epoch 1: -0.4198577404022217
Mem used: 674MB
best_loss: tensor(-0.4111, device='cuda:1')
final loss: -0.41908586025238037
Test:
Test: 0.6033183698848804
0.6033183698848804
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232557, 0.5836708161590052]
flatten test: 0.6034946272329311
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.77it/s]100%|██████████| 1/1 [00:00<00:00,  5.76it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.4205489754676819
Epoch 1: -0.4205489754676819
Mem used: 1824MB
best_loss: tensor(-0.4392, device='cuda:1')
final loss: -0.428933322429657
Test:
Test: 0.6077366302803386
0.6077366302803386
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.593719576152412, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747765727113
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.33it/s]100%|██████████| 2/2 [00:00<00:00,  4.58it/s]100%|██████████| 2/2 [00:00<00:00,  4.64it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5831117630004883
Epoch 1, Loop Feat 0: -0.6022651791572571
Epoch 1, Loop Adj 0: -0.5979876518249512
Epoch 2: -0.5979876518249512
Mem used: 806MB
best_loss: tensor(-0.6115, device='cuda:1')
best_loss: tensor(-0.6127, device='cuda:1')
final loss: -0.6034330725669861
Test:
Test: 0.6033935127993961
0.6033935127993961
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987161352804
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.55it/s]100%|██████████| 2/2 [00:00<00:00,  3.96it/s]100%|██████████| 2/2 [00:00<00:00,  3.89it/s]
Epoch 0, Loop Feat 0: -0.42172563076019287
Epoch 0, Loop Adj 0: -0.4137086868286133
Epoch 1, Loop Feat 0: -0.42833828926086426
Epoch 1, Loop Adj 0: -0.43069732189178467
Epoch 2: -0.43069732189178467
Mem used: 852MB
best_loss: tensor(-0.4284, device='cuda:1')
best_loss: tensor(-0.4324, device='cuda:1')
final loss: -0.4278508424758911
Test:
Test: 0.6044670000279602
0.6044670000279602
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405997298554459, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804387473682
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.29it/s]100%|██████████| 2/2 [00:00<00:00,  9.12it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.32399165630340576
Epoch 1, Loop Feat 0: -0.3203222453594208
Epoch 1, Loop Adj 0: -0.3240884840488434
Epoch 2: -0.3240884840488434
Mem used: 674MB
best_loss: tensor(-0.3370, device='cuda:1')
final loss: -0.3323356509208679
Test:
Test: 0.606014975839885
0.606014975839885
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163420955350138, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887516929199
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.76it/s]100%|██████████| 2/2 [00:00<00:00,  5.46it/s]100%|██████████| 2/2 [00:00<00:00,  5.71it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.41172561049461365
Epoch 1, Loop Feat 0: -0.41323888301849365
Epoch 1, Loop Adj 0: -0.40439727902412415
Epoch 2: -0.40439727902412415
Mem used: 674MB
best_loss: tensor(-0.4152, device='cuda:1')
final loss: -0.41296544671058655
Test:
Test: 0.6075287163493188
0.6075287163493188
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035360312008, 0.6205532218848335, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168351136992
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.01it/s]100%|██████████| 2/2 [00:00<00:00,  7.01it/s]100%|██████████| 2/2 [00:00<00:00,  6.84it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3609839379787445
Epoch 1, Loop Feat 0: -0.375881552696228
Epoch 1, Loop Adj 0: -0.3742021918296814
Epoch 2: -0.3742021918296814
Mem used: 674MB
best_loss: tensor(-0.3743, device='cuda:1')
final loss: -0.3725779354572296
Test:
Test: 0.6056319932158499
0.6056319932158499
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.605312766934012
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.83it/s]100%|██████████| 2/2 [00:00<00:00,  3.95it/s]100%|██████████| 2/2 [00:00<00:00,  4.06it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.43351078033447266
Epoch 1, Loop Feat 0: -0.44591179490089417
Epoch 1, Loop Adj 0: -0.4430393576622009
Epoch 2: -0.4430393576622009
Mem used: 882MB
best_loss: tensor(-0.4392, device='cuda:1')
final loss: -0.4455297887325287
Test:
Test: 0.6078561361100308
0.6078561361100308
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310910559022389, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974795995771371
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.92it/s]100%|██████████| 2/2 [00:00<00:00,  3.47it/s]100%|██████████| 2/2 [00:00<00:00,  3.53it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.26614269614219666
Epoch 1, Loop Feat 0: -0.26945945620536804
Epoch 1, Loop Adj 0: -0.2670729160308838
Epoch 2: -0.2670729160308838
Mem used: 692MB
best_loss: tensor(-0.2769, device='cuda:1')
final loss: -0.2746730148792267
Test:
Test: 0.6026419247897269
0.6026419247897269
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483242720478
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.89it/s]100%|██████████| 2/2 [00:00<00:00,  4.96it/s]100%|██████████| 2/2 [00:00<00:00,  4.76it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.40417084097862244
Epoch 1, Loop Feat 0: -0.4066489636898041
Epoch 1, Loop Adj 0: -0.40296825766563416
Epoch 2: -0.40296825766563416
Mem used: 810MB
best_loss: tensor(-0.4040, device='cuda:1')
best_loss: tensor(-0.4067, device='cuda:1')
final loss: -0.4080367386341095
Test:
Test: 0.6040264290180648
0.6040264290180648
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890690973923
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.52it/s]100%|██████████| 2/2 [00:00<00:00,  6.45it/s]100%|██████████| 2/2 [00:00<00:00,  6.28it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.4198577404022217
Epoch 1, Loop Feat 0: -0.41458117961883545
Epoch 1, Loop Adj 0: -0.4227074682712555
Epoch 2: -0.4227074682712555
Mem used: 986MB
best_loss: tensor(-0.4162, device='cuda:1')
best_loss: tensor(-0.4200, device='cuda:1')
final loss: -0.42867833375930786
Test:
Test: 0.6043445154886545
0.6043445154886545
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232558, 0.5836708161590052]
flatten test: 0.6034946105998013
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.56it/s]100%|██████████| 2/2 [00:00<00:00,  7.17it/s]100%|██████████| 2/2 [00:00<00:00,  6.87it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.4205489754676819
Epoch 1, Loop Feat 0: -0.43494316935539246
Epoch 1, Loop Adj 0: -0.4287583529949188
Epoch 2: -0.4287583529949188
Mem used: 782MB
best_loss: tensor(-0.4450, device='cuda:1')
best_loss: tensor(-0.4450, device='cuda:1')
final loss: -0.4335305988788605
Test:
Test: 0.6085176082248607
0.6085176082248607
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.5937196763338406, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747876614644
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.24it/s]100%|██████████| 2/2 [00:00<00:00,  6.13it/s]100%|██████████| 2/2 [00:00<00:00,  6.14it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5831117630004883
Epoch 1, Loop Feat 0: -0.6022651791572571
Epoch 1, Loop Adj 0: -0.5979876518249512
Epoch 2: -0.5979876518249512
Mem used: 816MB
best_loss: tensor(-0.6142, device='cuda:1')
final loss: -0.6036648750305176
Test:
Test: 0.5962028680763668
0.5962028680763668
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344159165859445, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987105909037
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.46it/s]100%|██████████| 2/2 [00:00<00:00,  4.98it/s]100%|██████████| 2/2 [00:00<00:00,  4.89it/s]
Epoch 0, Loop Feat 0: -0.42172563076019287
Epoch 0, Loop Adj 0: -0.4137086868286133
Epoch 1, Loop Feat 0: -0.42922243475914
Epoch 1, Loop Adj 0: -0.43161195516586304
Epoch 2: -0.43161195516586304
Mem used: 674MB
best_loss: tensor(-0.4315, device='cuda:1')
best_loss: tensor(-0.4375, device='cuda:1')
final loss: -0.43361932039260864
Test:
Test: 0.6030464335552352
0.6030464335552352
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405996180406469, 0.614043983654398, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804442917448
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  9.88it/s]100%|██████████| 2/2 [00:00<00:00,  7.14it/s]100%|██████████| 2/2 [00:00<00:00,  7.44it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.32399165630340576
Epoch 1, Loop Feat 0: -0.3205872178077698
Epoch 1, Loop Adj 0: -0.32431119680404663
Epoch 2: -0.32431119680404663
Mem used: 674MB
best_loss: tensor(-0.3403, device='cuda:1')
final loss: -0.33639979362487793
Test:
Test: 0.6086949407371822
0.6086949407371822
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887516929199
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.95it/s]100%|██████████| 2/2 [00:00<00:00,  5.96it/s]100%|██████████| 2/2 [00:00<00:00,  5.78it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.41172561049461365
Epoch 1, Loop Feat 0: -0.4139252007007599
Epoch 1, Loop Adj 0: -0.40529611706733704
Epoch 2: -0.40529611706733704
Mem used: 770MB
best_loss: tensor(-0.4157, device='cuda:1')
best_loss: tensor(-0.4175, device='cuda:1')
final loss: -0.4189111590385437
Test:
Test: 0.6095403382416112
0.6095403382416112
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205532218848335, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168184805693
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.29it/s]100%|██████████| 2/2 [00:00<00:00,  6.85it/s]100%|██████████| 2/2 [00:00<00:00,  6.75it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3609839379787445
Epoch 1, Loop Feat 0: -0.3769918382167816
Epoch 1, Loop Adj 0: -0.3752647042274475
Epoch 2: -0.3752647042274475
Mem used: 826MB
best_loss: tensor(-0.3816, device='cuda:1')
final loss: -0.38171085715293884
Test:
Test: 0.6087049492014834
0.6087049492014834
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127558452588
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.52it/s]100%|██████████| 2/2 [00:00<00:00,  4.34it/s]100%|██████████| 2/2 [00:00<00:00,  4.48it/s]
Epoch 0, Loop Feat 0: -0.4249717891216278
Epoch 0, Loop Adj 0: -0.43351078033447266
Epoch 1, Loop Feat 0: -0.4467099606990814
Epoch 1, Loop Adj 0: -0.4438626170158386
Epoch 2: -0.4438626170158386
Mem used: 814MB
best_loss: tensor(-0.4458, device='cuda:1')
final loss: -0.4494048058986664
Test:
Test: 0.6097951569200111
0.6097951569200111
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179836213682554, 0.6310911059929533, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974796051215137
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.72it/s]100%|██████████| 2/2 [00:00<00:00,  5.35it/s]100%|██████████| 2/2 [00:00<00:00,  5.24it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.26614269614219666
Epoch 1, Loop Feat 0: -0.269746333360672
Epoch 1, Loop Adj 0: -0.2673744559288025
Epoch 2: -0.2673744559288025
Mem used: -991MB
best_loss: tensor(-0.2800, device='cuda:1')
final loss: -0.27894726395606995
Test:
Test: 0.6022824541135742
0.6022824541135742
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483353608009
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.21it/s]100%|██████████| 2/2 [00:00<00:00,  3.56it/s]100%|██████████| 2/2 [00:00<00:00,  3.85it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.40417084097862244
Epoch 1, Loop Feat 0: -0.40755704045295715
Epoch 1, Loop Adj 0: -0.4040035009384155
Epoch 2: -0.4040035009384155
Mem used: -594MB
best_loss: tensor(-0.4098, device='cuda:1')
best_loss: tensor(-0.4102, device='cuda:1')
final loss: -0.41449904441833496
Test:
Test: 0.6052542928368627
0.6052542928368627
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875724, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.598189074641769
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.86it/s]100%|██████████| 2/2 [00:00<00:00,  4.18it/s]100%|██████████| 2/2 [00:00<00:00,  4.18it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.4198577404022217
Epoch 1, Loop Feat 0: -0.4154125452041626
Epoch 1, Loop Adj 0: -0.4236222803592682
Epoch 2: -0.4236222803592682
Mem used: 674MB
best_loss: tensor(-0.4252, device='cuda:1')
final loss: -0.43030330538749695
Test:
Test: 0.6040801252233634
0.6040801252233634
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303432937956205, 0.6145207971636634, 0.6325989133050594, 0.5483720930232557, 0.5836708161590052]
flatten test: 0.6034946327773077
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.40it/s]100%|██████████| 2/2 [00:00<00:00,  7.45it/s]100%|██████████| 2/2 [00:00<00:00,  7.44it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.4205489754676819
Epoch 1, Loop Feat 0: -0.43532490730285645
Epoch 1, Loop Adj 0: -0.4291457235813141
Epoch 2: -0.4291457235813141
Mem used: 686MB
best_loss: tensor(-0.4460, device='cuda:1')
best_loss: tensor(-0.4461, device='cuda:1')
final loss: -0.4342329800128937
Test:
Test: 0.6114875008578684
0.6114875008578684
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.5937196262431264, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747821170878
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.41it/s]100%|██████████| 2/2 [00:00<00:00,  4.97it/s]100%|██████████| 2/2 [00:00<00:00,  5.03it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5831117630004883
Epoch 1, Loop Feat 0: -0.5944169759750366
Epoch 1, Loop Adj 0: -0.5942555665969849
Epoch 2: -0.5942555665969849
Mem used: 856MB
best_loss: tensor(-0.6095, device='cuda:1')
best_loss: tensor(-0.6108, device='cuda:1')
final loss: -0.5948098301887512
Test:
Test: 0.6003754047867784
0.6003754047867784
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344159165859445, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046986995021505
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.50it/s]100%|██████████| 2/2 [00:00<00:00,  4.95it/s]100%|██████████| 2/2 [00:00<00:00,  5.02it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.4137086868286133
Epoch 1, Loop Feat 0: -0.42223504185676575
Epoch 1, Loop Adj 0: -0.42435941100120544
Epoch 2: -0.42435941100120544
Mem used: 674MB
best_loss: tensor(-0.4289, device='cuda:1')
final loss: -0.4217976927757263
Test:
Test: 0.6024394519682678
0.6024394519682678
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405996180406469, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.556224183928322]
flatten test: 0.6065804276586151
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.75it/s]100%|██████████| 2/2 [00:00<00:00,  5.88it/s]100%|██████████| 2/2 [00:00<00:00,  5.99it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.32399165630340576
Epoch 1, Loop Feat 0: -0.31758609414100647
Epoch 1, Loop Adj 0: -0.321759432554245
Epoch 2: -0.321759432554245
Mem used: 674MB
best_loss: tensor(-0.3317, device='cuda:1')
final loss: -0.32925286889076233
Test:
Test: 0.6060387260845362
0.6060387260845362
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163420955350138, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887350597901
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.27it/s]100%|██████████| 2/2 [00:00<00:00,  5.52it/s]100%|██████████| 2/2 [00:00<00:00,  5.72it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.41172561049461365
Epoch 1, Loop Feat 0: -0.4094744324684143
Epoch 1, Loop Adj 0: -0.3992321193218231
Epoch 2: -0.3992321193218231
Mem used: 674MB
best_loss: tensor(-0.4112, device='cuda:1')
final loss: -0.41213834285736084
Test:
Test: 0.6081210824011164
0.6081210824011164
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205532218848335, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168184805693
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  8.12it/s]100%|██████████| 2/2 [00:00<00:00,  8.69it/s]100%|██████████| 2/2 [00:00<00:00,  8.59it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3609839379787445
Epoch 1, Loop Feat 0: -0.3696989417076111
Epoch 1, Loop Adj 0: -0.36827540397644043
Epoch 2: -0.36827540397644043
Mem used: 674MB
best_loss: tensor(-0.3708, device='cuda:1')
final loss: -0.37222790718078613
Test:
Test: 0.6053104514421086
0.6053104514421086
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127780227653
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.68it/s]100%|██████████| 2/2 [00:00<00:00,  4.44it/s]100%|██████████| 2/2 [00:00<00:00,  4.47it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.43351078033447266
Epoch 1, Loop Feat 0: -0.4387626647949219
Epoch 1, Loop Adj 0: -0.43542054295539856
Epoch 2: -0.43542054295539856
Mem used: 898MB
best_loss: tensor(-0.4334, device='cuda:1')
final loss: -0.4411036968231201
Test:
Test: 0.60785462689716
0.60785462689716
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310910559022389, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.597479599577137
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.81it/s]100%|██████████| 2/2 [00:00<00:00,  4.66it/s]100%|██████████| 2/2 [00:00<00:00,  4.51it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.26614269614219666
Epoch 1, Loop Feat 0: -0.26716506481170654
Epoch 1, Loop Adj 0: -0.2646979093551636
Epoch 2: -0.2646979093551636
Mem used: 840MB
best_loss: tensor(-0.2727, device='cuda:1')
final loss: -0.27187591791152954
Test:
Test: 0.6018644815806129
0.6018644815806129
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483187276712
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.29it/s]100%|██████████| 2/2 [00:00<00:00,  4.17it/s]100%|██████████| 2/2 [00:00<00:00,  4.46it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.40417084097862244
Epoch 1, Loop Feat 0: -0.4003560543060303
Epoch 1, Loop Adj 0: -0.39526045322418213
Epoch 2: -0.39526045322418213
Mem used: -455MB
best_loss: tensor(-0.4040, device='cuda:1')
final loss: -0.4030856192111969
Test:
Test: 0.6022467493143409
0.6022467493143409
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066465368782865, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890690973923
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.21it/s]100%|██████████| 2/2 [00:00<00:00,  6.37it/s]100%|██████████| 2/2 [00:00<00:00,  6.34it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.4198577404022217
Epoch 1, Loop Feat 0: -0.40829306840896606
Epoch 1, Loop Adj 0: -0.4156584143638611
Epoch 2: -0.4156584143638611
Mem used: 674MB
best_loss: tensor(-0.4139, device='cuda:1')
final loss: -0.42182788252830505
Test:
Test: 0.6034624202817875
0.6034624202817875
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-05, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232557, 0.5836708161590052]
flatten test: 0.6034946105998014
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  8.97it/s]100%|██████████| 2/2 [00:00<00:00,  9.99it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.4205489754676819
Epoch 1, Loop Feat 0: -0.4298579692840576
Epoch 1, Loop Adj 0: -0.4230342507362366
Epoch 2: -0.4230342507362366
Mem used: 674MB
best_loss: tensor(-0.4437, device='cuda:1')
final loss: -0.43147730827331543
Test:
Test: 0.6089660430281355
0.6089660430281355
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.5937196763338406, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747876614644
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.28it/s]100%|██████████| 1/1 [00:00<00:00,  6.26it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5818973779678345
Epoch 1: -0.5818973779678345
Mem used: 674MB
best_loss: tensor(-0.6024, device='cuda:1')
best_loss: tensor(-0.6056, device='cuda:1')
final loss: -0.594386637210846
Test:
Test: 0.6033462903229906
0.6033462903229906
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344159165859445, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987216796569
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.32it/s]100%|██████████| 1/1 [00:00<00:00,  7.30it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.41181913018226624
Epoch 1: -0.41181913018226624
Mem used: 830MB
best_loss: tensor(-0.4210, device='cuda:1')
best_loss: tensor(-0.4259, device='cuda:1')
final loss: -0.4210207164287567
Test:
Test: 0.6057234991751755
0.6057234991751755
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562247297226491]
flatten test: 0.6065804387473683
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.57it/s]100%|██████████| 1/1 [00:00<00:00,  5.57it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.3221884071826935
Epoch 1: -0.3221884071826935
Mem used: 792MB
best_loss: tensor(-0.3314, device='cuda:1')
final loss: -0.3270564079284668
Test:
Test: 0.6061946516037691
0.6061946516037691
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.60168875169292
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.82it/s]100%|██████████| 1/1 [00:00<00:00,  3.82it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.4097632169723511
Epoch 1: -0.4097632169723511
Mem used: -594MB
best_loss: tensor(-0.4088, device='cuda:1')
final loss: -0.4084392189979553
Test:
Test: 0.6071516514283827
0.6071516514283827
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205532218848335, 0.576750097652589, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.590716824024946
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.35it/s]100%|██████████| 1/1 [00:00<00:00,  5.34it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3586377799510956
Epoch 1: -0.3586377799510956
Mem used: 674MB
best_loss: tensor(-0.3677, device='cuda:1')
final loss: -0.36607638001441956
Test:
Test: 0.6052772884750786
0.6052772884750786
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127891115184
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.49it/s]100%|██████████| 1/1 [00:00<00:00,  5.48it/s]
Epoch 0, Loop Feat 0: -0.4249717891216278
Epoch 0, Loop Adj 0: -0.43145090341567993
Epoch 1: -0.43145090341567993
Mem used: 674MB
best_loss: tensor(-0.4262, device='cuda:1')
best_loss: tensor(-0.4298, device='cuda:1')
final loss: -0.4373168349266052
Test:
Test: 0.6073553157336872
0.6073553157336872
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310910559022389, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974795940327604
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.29it/s]100%|██████████| 1/1 [00:00<00:00,  4.28it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.2642604112625122
Epoch 1: -0.2642604112625122
Mem used: 1128MB
best_loss: tensor(-0.2716, device='cuda:1')
final loss: -0.27041637897491455
Test:
Test: 0.601764714666626
0.601764714666626
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483298164244
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.63it/s]100%|██████████| 1/1 [00:00<00:00,  5.62it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.40243157744407654
Epoch 1: -0.40243157744407654
Mem used: 772MB
best_loss: tensor(-0.3978, device='cuda:1')
best_loss: tensor(-0.4006, device='cuda:1')
final loss: -0.40422624349594116
Test:
Test: 0.6037974655391098
0.6037974655391098
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890690973923
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.06it/s]100%|██████████| 1/1 [00:00<00:00,  6.04it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.41750460863113403
Epoch 1: -0.41750460863113403
Mem used: 793MB
best_loss: tensor(-0.4094, device='cuda:1')
best_loss: tensor(-0.4134, device='cuda:1')
final loss: -0.42019370198249817
Test:
Test: 0.6044867389436653
0.6044867389436653
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483719525047425, 0.5836708161590052]
flatten test: 0.603494616144178
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.25it/s]100%|██████████| 1/1 [00:00<00:00,  6.24it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.41885000467300415
Epoch 1: -0.41885000467300415
Mem used: -594MB
best_loss: tensor(-0.4332, device='cuda:1')
best_loss: tensor(-0.4373, device='cuda:1')
final loss: -0.4272245466709137
Test:
Test: 0.6090764538644746
0.6090764538644746
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.5937196262431264, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747821170878
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.15it/s]100%|██████████| 1/1 [00:00<00:00,  6.13it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5818973779678345
Epoch 1: -0.5818973779678345
Mem used: 674MB
best_loss: tensor(-0.6065, device='cuda:1')
best_loss: tensor(-0.6125, device='cuda:1')
final loss: -0.6042061448097229
Test:
Test: 0.6004793418942241
0.6004793418942241
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097034228988698, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987105909036
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.02it/s]100%|██████████| 1/1 [00:00<00:00,  4.02it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.41181913018226624
Epoch 1: -0.41181913018226624
Mem used: 858MB
best_loss: tensor(-0.4259, device='cuda:1')
best_loss: tensor(-0.4356, device='cuda:1')
final loss: -0.4340209364891052
Test:
Test: 0.605609911048582
0.605609911048582
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562247297226491]
flatten test: 0.6065804387473683
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.66it/s]100%|██████████| 1/1 [00:00<00:00,  5.65it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.3221884071826935
Epoch 1: -0.3221884071826935
Mem used: 776MB
best_loss: tensor(-0.3348, device='cuda:1')
final loss: -0.3307647109031677
Test:
Test: 0.6070098648507818
0.6070098648507818
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887572372966
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.02it/s]100%|██████████| 1/1 [00:00<00:00,  7.01it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.4097632169723511
Epoch 1: -0.4097632169723511
Mem used: 674MB
best_loss: tensor(-0.4109, device='cuda:1')
best_loss: tensor(-0.4169, device='cuda:1')
final loss: -0.4181622266769409
Test:
Test: 0.6073799000170303
0.6073799000170303
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205531217034048, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168018474395
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.32it/s]100%|██████████| 1/1 [00:00<00:00,  5.31it/s]
Epoch 0, Loop Feat 0: -0.35880887508392334
Epoch 0, Loop Adj 0: -0.3586377799510956
Epoch 1: -0.3586377799510956
Mem used: 674MB
best_loss: tensor(-0.3713, device='cuda:1')
final loss: -0.3732146918773651
Test:
Test: 0.6090998863801005
0.6090998863801005
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.605312766934012
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.01it/s]100%|██████████| 1/1 [00:00<00:00,  7.00it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.43145090341567993
Epoch 1: -0.43145090341567993
Mem used: 674MB
best_loss: tensor(-0.4372, device='cuda:1')
best_loss: tensor(-0.4468, device='cuda:1')
final loss: -0.45134028792381287
Test:
Test: 0.6094348919212947
0.6094348919212947
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310911059929533, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974795995771369
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.85it/s]100%|██████████| 1/1 [00:00<00:00,  4.85it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.2642604112625122
Epoch 1: -0.2642604112625122
Mem used: 1056MB
best_loss: tensor(-0.2740, device='cuda:1')
final loss: -0.2739219069480896
Test:
Test: 0.6013360187790564
0.6013360187790564
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483298164243
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  9.20it/s]100%|██████████| 1/1 [00:00<00:00,  9.17it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.40243157744407654
Epoch 1: -0.40243157744407654
Mem used: 674MB
best_loss: tensor(-0.4032, device='cuda:1')
best_loss: tensor(-0.4129, device='cuda:1')
final loss: -0.4192746579647064
Test:
Test: 0.6063387417168042
0.6063387417168042
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890801861456
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.84it/s]100%|██████████| 1/1 [00:00<00:00,  6.83it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.41750460863113403
Epoch 1: -0.41750460863113403
Mem used: 674MB
best_loss: tensor(-0.4166, device='cuda:1')
best_loss: tensor(-0.4243, device='cuda:1')
final loss: -0.43157002329826355
Test:
Test: 0.6055556191013607
0.6055556191013607
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232557, 0.5836708161590052]
flatten test: 0.6034946161441779
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.42it/s]100%|██████████| 1/1 [00:00<00:00,  4.41it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.41885000467300415
Epoch 1: -0.41885000467300415
Mem used: 674MB
best_loss: tensor(-0.4375, device='cuda:1')
best_loss: tensor(-0.4461, device='cuda:1')
final loss: -0.43815356492996216
Test:
Test: 0.6132536770780114
0.6132536770780114
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.5937196262431264, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747765727113
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.09it/s]100%|██████████| 1/1 [00:00<00:00,  6.07it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5818973779678345
Epoch 1: -0.5818973779678345
Mem used: 674MB
best_loss: tensor(-0.6052, device='cuda:1')
final loss: -0.588878870010376
Test:
Test: 0.600105652844183
0.600105652844183
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987105909036
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.21it/s]100%|██████████| 1/1 [00:00<00:00,  5.19it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.41181913018226624
Epoch 1: -0.41181913018226624
Mem used: 674MB
best_loss: tensor(-0.4231, device='cuda:1')
final loss: -0.41704949736595154
Test:
Test: 0.6014982194465415
0.6014982194465415
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405996180406469, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.606580444291745
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.87it/s]100%|██████████| 1/1 [00:00<00:00,  5.86it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.3221884071826935
Epoch 1: -0.3221884071826935
Mem used: 674MB
best_loss: tensor(-0.3263, device='cuda:1')
final loss: -0.32384324073791504
Test:
Test: 0.6059723604343483
0.6059723604343483
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163420955350138, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887461485434
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.90it/s]100%|██████████| 1/1 [00:00<00:00,  3.90it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.4097632169723511
Epoch 1: -0.4097632169723511
Mem used: 674MB
best_loss: tensor(-0.4048, device='cuda:1')
final loss: -0.40585049986839294
Test:
Test: 0.6079215882892706
0.6079215882892706
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205531717941192, 0.576750097652589, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168073918161
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.20it/s]100%|██████████| 1/1 [00:00<00:00,  7.18it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3586377799510956
Epoch 1: -0.3586377799510956
Mem used: 674MB
best_loss: tensor(-0.3641, device='cuda:1')
final loss: -0.3653593063354492
Test:
Test: 0.6049047909088829
0.6049047909088829
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127946558952
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.74it/s]100%|██████████| 1/1 [00:00<00:00,  5.72it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.43145090341567993
Epoch 1: -0.43145090341567993
Mem used: 674MB
best_loss: tensor(-0.4265, device='cuda:1')
final loss: -0.43403810262680054
Test:
Test: 0.6075586623099662
0.6075586623099662
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310911059929533, 0.6278801467147008, 0.5383905009484999, 0.5426401818150064]
flatten test: 0.5974795829440072
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.53it/s]100%|██████████| 1/1 [00:00<00:00,  5.52it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.2642604112625122
Epoch 1: -0.2642604112625122
Mem used: 674MB
best_loss: tensor(-0.2675, device='cuda:1')
final loss: -0.267067551612854
Test:
Test: 0.6014695046858677
0.6014695046858677
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483187276712
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.10it/s]100%|██████████| 1/1 [00:00<00:00,  5.09it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.40243157744407654
Epoch 1: -0.40243157744407654
Mem used: 674MB
best_loss: tensor(-0.3980, device='cuda:1')
final loss: -0.398343950510025
Test:
Test: 0.6028014644766241
0.6028014644766241
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890746417691
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.81it/s]100%|██████████| 1/1 [00:00<00:00,  3.80it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.41750460863113403
Epoch 1: -0.41750460863113403
Mem used: 910MB
best_loss: tensor(-0.4072, device='cuda:1')
final loss: -0.4164518117904663
Test:
Test: 0.6031399650370981
0.6031399650370981
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232557, 0.5836708161590052]
flatten test: 0.6034946272329312
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.62it/s]100%|██████████| 1/1 [00:00<00:00,  5.46it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.41885000467300415
Epoch 1: -0.41885000467300415
Mem used: 674MB
best_loss: tensor(-0.4351, device='cuda:1')
final loss: -0.4261423647403717
Test:
Test: 0.6077382983577222
0.6077382983577222
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.5937196262431264, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747876614645
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.07it/s]100%|██████████| 2/2 [00:00<00:00,  4.07it/s]100%|██████████| 2/2 [00:00<00:00,  4.07it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5818973779678345
Epoch 1, Loop Feat 0: -0.6023555397987366
Epoch 1, Loop Adj 0: -0.5960915088653564
Epoch 2: -0.5960915088653564
Mem used: 674MB
best_loss: tensor(-0.6051, device='cuda:1')
best_loss: tensor(-0.6063, device='cuda:1')
final loss: -0.5985954403877258
Test:
Test: 0.6034078503216689
0.6034078503216689
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987050465271
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.65it/s]100%|██████████| 2/2 [00:00<00:00,  4.33it/s]100%|██████████| 2/2 [00:00<00:00,  4.48it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.41181913018226624
Epoch 1, Loop Feat 0: -0.4270448684692383
Epoch 1, Loop Adj 0: -0.42753341794013977
Epoch 2: -0.42753341794013977
Mem used: 800MB
best_loss: tensor(-0.4226, device='cuda:1')
best_loss: tensor(-0.4265, device='cuda:1')
final loss: -0.42127999663352966
Test:
Test: 0.604318501424697
0.604318501424697
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405996180406469, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804221142385
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.51it/s]100%|██████████| 2/2 [00:00<00:00,  5.43it/s]100%|██████████| 2/2 [00:00<00:00,  5.43it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.3221884071826935
Epoch 1, Loop Feat 0: -0.3189873695373535
Epoch 1, Loop Adj 0: -0.3209529519081116
Epoch 2: -0.3209529519081116
Mem used: 674MB
best_loss: tensor(-0.3317, device='cuda:1')
final loss: -0.3276587426662445
Test:
Test: 0.6059003550939588
0.6059003550939588
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887572372965
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  8.98it/s]100%|██████████| 2/2 [00:00<00:00,  7.02it/s]100%|██████████| 2/2 [00:00<00:00,  7.25it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.4097632169723511
Epoch 1, Loop Feat 0: -0.4118126630783081
Epoch 1, Loop Adj 0: -0.4012705385684967
Epoch 2: -0.4012705385684967
Mem used: 674MB
best_loss: tensor(-0.4091, device='cuda:1')
final loss: -0.40696093440055847
Test:
Test: 0.6071020459842864
0.6071020459842864
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205531717941192, 0.576750097652589, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168129361927
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.95it/s]100%|██████████| 2/2 [00:00<00:00,  4.57it/s]100%|██████████| 2/2 [00:00<00:00,  4.46it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3586377799510956
Epoch 1, Loop Feat 0: -0.37431764602661133
Epoch 1, Loop Adj 0: -0.3702886700630188
Epoch 2: -0.3702886700630188
Mem used: 844MB
best_loss: tensor(-0.3678, device='cuda:1')
final loss: -0.36585870385169983
Test:
Test: 0.6053317392868127
0.6053317392868127
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127780227653
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.40it/s]100%|██████████| 2/2 [00:00<00:00,  5.85it/s]100%|██████████| 2/2 [00:00<00:00,  5.77it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.43145090341567993
Epoch 1, Loop Feat 0: -0.4445720911026001
Epoch 1, Loop Adj 0: -0.43967485427856445
Epoch 2: -0.43967485427856445
Mem used: 674MB
best_loss: tensor(-0.4332, device='cuda:1')
final loss: -0.43983742594718933
Test:
Test: 0.6075077859497683
0.6075077859497683
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179836213682554, 0.6310910058115247, 0.6278801467147008, 0.5383905009484999, 0.5426401818150064]
flatten test: 0.5974795940327604
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.23it/s]100%|██████████| 2/2 [00:00<00:00,  5.01it/s]100%|██████████| 2/2 [00:00<00:00,  5.04it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.2642604112625122
Epoch 1, Loop Feat 0: -0.26803475618362427
Epoch 1, Loop Adj 0: -0.26388019323349
Epoch 2: -0.26388019323349
Mem used: 674MB
best_loss: tensor(-0.2721, device='cuda:1')
final loss: -0.2705385684967041
Test:
Test: 0.6016823037006535
0.6016823037006535
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483242720477
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.48it/s]100%|██████████| 2/2 [00:00<00:00,  6.14it/s]100%|██████████| 2/2 [00:00<00:00,  6.18it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.40243157744407654
Epoch 1, Loop Feat 0: -0.4057232737541199
Epoch 1, Loop Adj 0: -0.4004208445549011
Epoch 2: -0.4004208445549011
Mem used: 762MB
best_loss: tensor(-0.3985, device='cuda:1')
best_loss: tensor(-0.4024, device='cuda:1')
final loss: -0.4046247899532318
Test:
Test: 0.6040584402173775
0.6040584402173775
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890635530157
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.89it/s]100%|██████████| 2/2 [00:00<00:00,  6.08it/s]100%|██████████| 2/2 [00:00<00:00,  6.18it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.41750460863113403
Epoch 1, Loop Feat 0: -0.41304436326026917
Epoch 1, Loop Adj 0: -0.4189645051956177
Epoch 2: -0.4189645051956177
Mem used: 674MB
best_loss: tensor(-0.4096, device='cuda:1')
best_loss: tensor(-0.4138, device='cuda:1')
final loss: -0.4222056567668915
Test:
Test: 0.6038417887381582
0.6038417887381582
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232557, 0.5836708161590052]
flatten test: 0.603494616144178
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.58it/s]100%|██████████| 2/2 [00:00<00:00,  5.60it/s]100%|██████████| 2/2 [00:00<00:00,  5.51it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.41885000467300415
Epoch 1, Loop Feat 0: -0.4337901175022125
Epoch 1, Loop Adj 0: -0.4259507954120636
Epoch 2: -0.4259507954120636
Mem used: 674MB
best_loss: tensor(-0.4388, device='cuda:1')
final loss: -0.4293273091316223
Test:
Test: 0.6090784793870118
0.6090784793870118
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.593719576152412, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747710283345
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.24it/s]100%|██████████| 2/2 [00:00<00:00,  6.11it/s]100%|██████████| 2/2 [00:00<00:00,  6.12it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5818973779678345
Epoch 1, Loop Feat 0: -0.6165586709976196
Epoch 1, Loop Adj 0: -0.6070177555084229
Epoch 2: -0.6070177555084229
Mem used: 674MB
best_loss: tensor(-0.6164, device='cuda:1')
final loss: -0.6050622463226318
Test:
Test: 0.5998296257533355
0.5998296257533355
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987161352803
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.74it/s]100%|██████████| 2/2 [00:00<00:00,  5.85it/s]100%|██████████| 2/2 [00:00<00:00,  5.95it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.41181913018226624
Epoch 1, Loop Feat 0: -0.4428373873233795
Epoch 1, Loop Adj 0: -0.4434982240200043
Epoch 2: -0.4434982240200043
Mem used: 674MB
best_loss: tensor(-0.4341, device='cuda:1')
best_loss: tensor(-0.4363, device='cuda:1')
final loss: -0.43135935068130493
Test:
Test: 0.6108180458012745
0.6108180458012745
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.614043983654398, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804387473683
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.52it/s]100%|██████████| 2/2 [00:00<00:00,  4.33it/s]100%|██████████| 2/2 [00:00<00:00,  4.36it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.3221884071826935
Epoch 1, Loop Feat 0: -0.32708021998405457
Epoch 1, Loop Adj 0: -0.3279280960559845
Epoch 2: -0.3279280960559845
Mem used: 674MB
best_loss: tensor(-0.3380, device='cuda:1')
final loss: -0.33405596017837524
Test:
Test: 0.6096883602513363
0.6096883602513363
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887406041667
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  8.11it/s]100%|██████████| 2/2 [00:00<00:00,  6.43it/s]100%|██████████| 2/2 [00:00<00:00,  6.63it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.4097632169723511
Epoch 1, Loop Feat 0: -0.42249205708503723
Epoch 1, Loop Adj 0: -0.4141543507575989
Epoch 2: -0.4141543507575989
Mem used: 674MB
best_loss: tensor(-0.4128, device='cuda:1')
final loss: -0.4145958125591278
Test:
Test: 0.60815198154884
0.60815198154884
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205531717941192, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168184805693
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  9.86it/s]100%|██████████| 2/2 [00:00<00:00,  5.69it/s]100%|██████████| 2/2 [00:00<00:00,  6.07it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3586377799510956
Epoch 1, Loop Feat 0: -0.39134541153907776
Epoch 1, Loop Adj 0: -0.3876221477985382
Epoch 2: -0.3876221477985382
Mem used: 674MB
best_loss: tensor(-0.3842, device='cuda:1')
best_loss: tensor(-0.3878, device='cuda:1')
final loss: -0.3883489966392517
Test:
Test: 0.6062383393447666
0.6062383393447666
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127558452588
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  3.95it/s]100%|██████████| 2/2 [00:00<00:00,  4.65it/s]100%|██████████| 2/2 [00:00<00:00,  4.52it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.43145090341567993
Epoch 1, Loop Feat 0: -0.46185776591300964
Epoch 1, Loop Adj 0: -0.45781752467155457
Epoch 2: -0.45781752467155457
Mem used: 866MB
best_loss: tensor(-0.4473, device='cuda:1')
final loss: -0.4496304988861084
Test:
Test: 0.6112160411217613
0.6112160411217613
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310910058115247, 0.6278801467147008, 0.5383905009484999, 0.5426401818150064]
flatten test: 0.5974795884883838
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.59it/s]100%|██████████| 2/2 [00:00<00:00,  6.45it/s]100%|██████████| 2/2 [00:00<00:00,  6.08it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.2642604112625122
Epoch 1, Loop Feat 0: -0.2744217813014984
Epoch 1, Loop Adj 0: -0.2706453502178192
Epoch 2: -0.2706453502178192
Mem used: 674MB
best_loss: tensor(-0.2764, device='cuda:1')
final loss: -0.2757311463356018
Test:
Test: 0.6023178808999103
0.6023178808999103
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483131832945
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.59it/s]100%|██████████| 2/2 [00:00<00:00,  8.17it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.40243157744407654
Epoch 1, Loop Feat 0: -0.4255378544330597
Epoch 1, Loop Adj 0: -0.4217127561569214
Epoch 2: -0.4217127561569214
Mem used: 674MB
best_loss: tensor(-0.4140, device='cuda:1')
best_loss: tensor(-0.4173, device='cuda:1')
final loss: -0.42029398679733276
Test:
Test: 0.6037343168953045
0.6037343168953045
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890746417688
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.43it/s]100%|██████████| 2/2 [00:00<00:00,  6.81it/s]100%|██████████| 2/2 [00:00<00:00,  6.55it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.41750460863113403
Epoch 1, Loop Feat 0: -0.4283454716205597
Epoch 1, Loop Adj 0: -0.4347102642059326
Epoch 2: -0.4347102642059326
Mem used: 1008MB
best_loss: tensor(-0.4191, device='cuda:1')
best_loss: tensor(-0.4244, device='cuda:1')
final loss: -0.43223273754119873
Test:
Test: 0.6043175879537488
0.6043175879537488
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232557, 0.5836708161590052]
flatten test: 0.6034946161441779
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 10.49it/s]100%|██████████| 2/2 [00:00<00:00, 10.47it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.41885000467300415
Epoch 1, Loop Feat 0: -0.446243017911911
Epoch 1, Loop Adj 0: -0.4368865489959717
Epoch 2: -0.4368865489959717
Mem used: 674MB
best_loss: tensor(-0.4439, device='cuda:1')
best_loss: tensor(-0.4487, device='cuda:1')
final loss: -0.4374847412109375
Test:
Test: 0.6140534804672905
0.6140534804672905
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.5937196262431264, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747876614644
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  8.21it/s]100%|██████████| 2/2 [00:00<00:00,  8.32it/s]100%|██████████| 2/2 [00:00<00:00,  8.29it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5818973779678345
Epoch 1, Loop Feat 0: -0.5936278104782104
Epoch 1, Loop Adj 0: -0.591844916343689
Epoch 2: -0.591844916343689
Mem used: 674MB
best_loss: tensor(-0.6030, device='cuda:1')
best_loss: tensor(-0.6042, device='cuda:1')
final loss: -0.59087735414505
Test:
Test: 0.6012074576721392
0.6012074576721392
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987161352804
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.38it/s]100%|██████████| 2/2 [00:00<00:00,  5.55it/s]100%|██████████| 2/2 [00:00<00:00,  5.51it/s]
Epoch 0, Loop Feat 0: -0.42172563076019287
Epoch 0, Loop Adj 0: -0.41181913018226624
Epoch 1, Loop Feat 0: -0.4205600917339325
Epoch 1, Loop Adj 0: -0.42078065872192383
Epoch 2: -0.42078065872192383
Mem used: 1386MB
best_loss: tensor(-0.4217, device='cuda:1')
best_loss: tensor(-0.4219, device='cuda:1')
final loss: -0.41354089975357056
Test:
Test: 0.6031447706886077
0.6031447706886077
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405996180406469, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804387473682
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.24it/s]100%|██████████| 2/2 [00:00<00:00,  7.50it/s]100%|██████████| 2/2 [00:00<00:00,  7.27it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.3221884071826935
Epoch 1, Loop Feat 0: -0.3159555196762085
Epoch 1, Loop Adj 0: -0.3184008002281189
Epoch 2: -0.3184008002281189
Mem used: 674MB
best_loss: tensor(-0.3266, device='cuda:1')
final loss: -0.32448911666870117
Test:
Test: 0.6059575463185374
0.6059575463185374
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.616342095535014, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887461485433
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00,  9.61it/s]100%|██████████| 2/2 [00:00<00:00,  9.60it/s]
Epoch 0, Loop Feat 0: -0.40305694937705994
Epoch 0, Loop Adj 0: -0.4097632169723511
Epoch 1, Loop Feat 0: -0.40773898363113403
Epoch 1, Loop Adj 0: -0.395742803812027
Epoch 2: -0.395742803812027
Mem used: 674MB
best_loss: tensor(-0.4051, device='cuda:1')
final loss: -0.40653684735298157
Test:
Test: 0.607844260987705
0.607844260987705
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205531217034048, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168018474396
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.78it/s]100%|██████████| 2/2 [00:00<00:00,  7.34it/s]100%|██████████| 2/2 [00:00<00:00,  7.40it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3586377799510956
Epoch 1, Loop Feat 0: -0.36760735511779785
Epoch 1, Loop Adj 0: -0.36387887597084045
Epoch 2: -0.36387887597084045
Mem used: 674MB
best_loss: tensor(-0.3642, device='cuda:1')
final loss: -0.36571139097213745
Test:
Test: 0.6049452219273697
0.6049452219273697
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.605312794655895
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.29it/s]100%|██████████| 2/2 [00:00<00:00,  6.53it/s]100%|██████████| 2/2 [00:00<00:00,  6.49it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.43145090341567993
Epoch 1, Loop Feat 0: -0.4369441568851471
Epoch 1, Loop Adj 0: -0.43167147040367126
Epoch 2: -0.43167147040367126
Mem used: 674MB
best_loss: tensor(-0.4269, device='cuda:1')
final loss: -0.4347531795501709
Test:
Test: 0.6077728911053666
0.6077728911053666
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310911059929533, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974796051215137
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.10it/s]100%|██████████| 2/2 [00:00<00:00,  6.51it/s]100%|██████████| 2/2 [00:00<00:00,  6.44it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.2642604112625122
Epoch 1, Loop Feat 0: -0.26544785499572754
Epoch 1, Loop Adj 0: -0.26121100783348083
Epoch 2: -0.26121100783348083
Mem used: 674MB
best_loss: tensor(-0.2678, device='cuda:1')
final loss: -0.26729699969291687
Test:
Test: 0.6011984023949143
0.6011984023949143
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483298164243
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.69it/s]100%|██████████| 2/2 [00:00<00:00,  7.51it/s]100%|██████████| 2/2 [00:00<00:00,  7.37it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.40243157744407654
Epoch 1, Loop Feat 0: -0.3988398015499115
Epoch 1, Loop Adj 0: -0.39211565256118774
Epoch 2: -0.39211565256118774
Mem used: 674MB
best_loss: tensor(-0.3985, device='cuda:1')
final loss: -0.39999938011169434
Test:
Test: 0.6020518622733639
0.6020518622733639
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890580086391
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.12it/s]100%|██████████| 2/2 [00:00<00:00,  6.99it/s]100%|██████████| 2/2 [00:00<00:00,  7.00it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.41750460863113403
Epoch 1, Loop Feat 0: -0.4062872529029846
Epoch 1, Loop Adj 0: -0.41143664717674255
Epoch 2: -0.41143664717674255
Mem used: 674MB
best_loss: tensor(-0.4075, device='cuda:1')
final loss: -0.4161609709262848
Test:
Test: 0.6032152668161265
0.6032152668161265
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.5, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232557, 0.5836708161590052]
flatten test: 0.6034946216885546
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.06it/s]100%|██████████| 2/2 [00:00<00:00,  5.40it/s]100%|██████████| 2/2 [00:00<00:00,  5.49it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.41885000467300415
Epoch 1, Loop Feat 0: -0.4283719062805176
Epoch 1, Loop Adj 0: -0.41995903849601746
Epoch 2: -0.41995903849601746
Mem used: 890MB
best_loss: tensor(-0.4374, device='cuda:1')
final loss: -0.4258500039577484
Test:
Test: 0.6089015837521001
0.6089015837521001
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.5937196262431264, 0.6002883018849671, 0.5401741024379962, 0.5824575153695682]
flatten test: 0.5878747821170879
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.13it/s]100%|██████████| 1/1 [00:00<00:00,  5.12it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5818973779678345
Epoch 1: -0.5818973779678345
Mem used: 674MB
best_loss: tensor(-0.6024, device='cuda:1')
best_loss: tensor(-0.6056, device='cuda:1')
final loss: -0.5964040160179138
Test:
Test: 0.6029252199320314
0.6029252199320314
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097034228988698, 0.6344159165859445, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987161352803
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.28it/s]100%|██████████| 1/1 [00:00<00:00,  5.27it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.41181913018226624
Epoch 1: -0.41181913018226624
Mem used: 674MB
best_loss: tensor(-0.4210, device='cuda:1')
best_loss: tensor(-0.4257, device='cuda:1')
final loss: -0.4203309416770935
Test:
Test: 0.6057735017805534
0.6057735017805534
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405996180406469, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804221142386
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.12it/s]100%|██████████| 1/1 [00:00<00:00,  5.11it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.3221884071826935
Epoch 1: -0.3221884071826935
Mem used: 674MB
best_loss: tensor(-0.3314, device='cuda:1')
final loss: -0.3270564079284668
Test:
Test: 0.6061946516037691
0.6061946516037691
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163420955350138, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887406041668
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.07it/s]100%|██████████| 1/1 [00:00<00:00,  6.06it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.4097632169723511
Epoch 1: -0.4097632169723511
Mem used: 674MB
best_loss: tensor(-0.4088, device='cuda:1')
final loss: -0.4084392189979553
Test:
Test: 0.6071516514283827
0.6071516514283827
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205532218848335, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.590716824024946
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.10it/s]100%|██████████| 1/1 [00:00<00:00,  7.09it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3586377799510956
Epoch 1: -0.3586377799510956
Mem used: 674MB
best_loss: tensor(-0.3677, device='cuda:1')
final loss: -0.36607638001441956
Test:
Test: 0.6052772884750786
0.6052772884750786
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127724783887
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.93it/s]100%|██████████| 1/1 [00:00<00:00,  5.92it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.43145090341567993
Epoch 1: -0.43145090341567993
Mem used: 674MB
best_loss: tensor(-0.4262, device='cuda:1')
best_loss: tensor(-0.4297, device='cuda:1')
final loss: -0.43646615743637085
Test:
Test: 0.6075512751101249
0.6075512751101249
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310910559022389, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.597479599577137
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.97it/s]100%|██████████| 1/1 [00:00<00:00,  5.96it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.2642604112625122
Epoch 1: -0.2642604112625122
Mem used: 674MB
best_loss: tensor(-0.2716, device='cuda:1')
final loss: -0.27041637897491455
Test:
Test: 0.601764714666626
0.601764714666626
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483242720478
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.60it/s]100%|██████████| 1/1 [00:00<00:00,  7.59it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.40243157744407654
Epoch 1: -0.40243157744407654
Mem used: 674MB
best_loss: tensor(-0.3978, device='cuda:1')
best_loss: tensor(-0.4003, device='cuda:1')
final loss: -0.40331193804740906
Test:
Test: 0.6042776732449284
0.6042776732449284
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875724, 0.6335276710552888, 0.5433284620248718, 0.5756913030948722]
flatten test: 0.598189074641769
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.45it/s]100%|██████████| 1/1 [00:00<00:00,  5.44it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.41750460863113403
Epoch 1: -0.41750460863113403
Mem used: 674MB
best_loss: tensor(-0.4094, device='cuda:1')
best_loss: tensor(-0.4134, device='cuda:1')
final loss: -0.42143887281417847
Test:
Test: 0.6045320947620464
0.6045320947620464
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303432937956205, 0.6145207971636634, 0.6325989133050594, 0.5483720930232557, 0.5836708161590052]
flatten test: 0.6034946216885545
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.82it/s]100%|██████████| 1/1 [00:00<00:00,  4.53it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.41885000467300415
Epoch 1: -0.41885000467300415
Mem used: 674MB
best_loss: tensor(-0.4332, device='cuda:1')
best_loss: tensor(-0.4373, device='cuda:1')
final loss: -0.4274109899997711
Test:
Test: 0.6092285269192739
0.6092285269192739
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.593719576152412, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747710283345
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.32it/s]100%|██████████| 1/1 [00:00<00:00,  6.30it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5818973779678345
Epoch 1: -0.5818973779678345
Mem used: 674MB
best_loss: tensor(-0.6065, device='cuda:1')
best_loss: tensor(-0.6129, device='cuda:1')
final loss: -0.6043089628219604
Test:
Test: 0.6000836898252999
0.6000836898252999
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.644284027479605, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987161352804
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 10.72it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.41181913018226624
Epoch 1: -0.41181913018226624
Mem used: 674MB
best_loss: tensor(-0.4259, device='cuda:1')
best_loss: tensor(-0.4353, device='cuda:1')
final loss: -0.4342544376850128
Test:
Test: 0.6060159687430894
0.6060159687430894
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405996180406469, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.606580444291745
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.91it/s]100%|██████████| 1/1 [00:00<00:00,  7.89it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.3221884071826935
Epoch 1: -0.3221884071826935
Mem used: 674MB
best_loss: tensor(-0.3348, device='cuda:1')
final loss: -0.3307647109031677
Test:
Test: 0.6070098648507818
0.6070098648507818
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163421456257281, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887461485433
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.61it/s]100%|██████████| 1/1 [00:00<00:00,  4.60it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.4097632169723511
Epoch 1: -0.4097632169723511
Mem used: 674MB
best_loss: tensor(-0.4109, device='cuda:1')
best_loss: tensor(-0.4167, device='cuda:1')
final loss: -0.41790491342544556
Test:
Test: 0.6067999253972247
0.6067999253972247
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205532218848335, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168129361927
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.03it/s]100%|██████████| 1/1 [00:00<00:00,  7.02it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3586377799510956
Epoch 1: -0.3586377799510956
Mem used: 674MB
best_loss: tensor(-0.3713, device='cuda:1')
final loss: -0.3732146918773651
Test:
Test: 0.6090998863801005
0.6090998863801005
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127724783887
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  8.42it/s]100%|██████████| 1/1 [00:00<00:00,  8.40it/s]
Epoch 0, Loop Feat 0: -0.4249717593193054
Epoch 0, Loop Adj 0: -0.43145090341567993
Epoch 1: -0.43145090341567993
Mem used: 674MB
best_loss: tensor(-0.4372, device='cuda:1')
best_loss: tensor(-0.4460, device='cuda:1')
final loss: -0.4507789611816406
Test:
Test: 0.6090434100458292
0.6090434100458292
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310910559022389, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974795995771369
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.46it/s]100%|██████████| 1/1 [00:00<00:00,  6.44it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.2642604112625122
Epoch 1: -0.2642604112625122
Mem used: 674MB
best_loss: tensor(-0.2740, device='cuda:1')
final loss: -0.2739219069480896
Test:
Test: 0.6013360187790564
0.6013360187790564
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483187276713
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.50it/s]100%|██████████| 1/1 [00:00<00:00,  6.49it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.40243157744407654
Epoch 1: -0.40243157744407654
Mem used: 674MB
best_loss: tensor(-0.4032, device='cuda:1')
best_loss: tensor(-0.4135, device='cuda:1')
final loss: -0.4177551567554474
Test:
Test: 0.6022111636634919
0.6022111636634919
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890690973923
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.25it/s]100%|██████████| 1/1 [00:00<00:00,  6.24it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.41750460863113403
Epoch 1: -0.41750460863113403
Mem used: 674MB
best_loss: tensor(-0.4166, device='cuda:1')
best_loss: tensor(-0.4240, device='cuda:1')
final loss: -0.43030017614364624
Test:
Test: 0.6054350012200793
0.6054350012200793
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232557, 0.5836708161590052]
flatten test: 0.6034946216885546
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.52it/s]100%|██████████| 1/1 [00:00<00:00,  5.51it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.41885000467300415
Epoch 1: -0.41885000467300415
Mem used: 844MB
best_loss: tensor(-0.4375, device='cuda:1')
final loss: -0.43382734060287476
Test:
Test: 0.6102107464852815
0.6102107464852815
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.593719576152412, 0.6002883018849671, 0.5401741024379962, 0.5824575153695682]
flatten test: 0.5878747765727113
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.27it/s]100%|██████████| 1/1 [00:00<00:00,  6.26it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5818973779678345
Epoch 1: -0.5818973779678345
Mem used: 674MB
best_loss: tensor(-0.6053, device='cuda:1')
best_loss: tensor(-0.6059, device='cuda:1')
final loss: -0.5898343920707703
Test:
Test: 0.599524645605045
0.599524645605045
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987161352803
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.09it/s]100%|██████████| 1/1 [00:00<00:00,  7.08it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.41181913018226624
Epoch 1: -0.41181913018226624
Mem used: 674MB
best_loss: tensor(-0.4231, device='cuda:1')
final loss: -0.41704949736595154
Test:
Test: 0.6014982194465415
0.6014982194465415
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405996180406469, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804498361216
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.93it/s]100%|██████████| 1/1 [00:00<00:00,  4.92it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.3221884071826935
Epoch 1: -0.3221884071826935
Mem used: 866MB
best_loss: tensor(-0.3263, device='cuda:1')
final loss: -0.32384324073791504
Test:
Test: 0.6059723604343483
0.6059723604343483
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163420955350138, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887406041667
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.47it/s]100%|██████████| 1/1 [00:00<00:00,  5.46it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.4097632169723511
Epoch 1: -0.4097632169723511
Mem used: 674MB
best_loss: tensor(-0.4048, device='cuda:1')
final loss: -0.40585049986839294
Test:
Test: 0.6079215882892706
0.6079215882892706
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205532218848335, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168184805694
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.61it/s]100%|██████████| 1/1 [00:00<00:00,  5.60it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3586377799510956
Epoch 1: -0.3586377799510956
Mem used: 674MB
best_loss: tensor(-0.3641, device='cuda:1')
final loss: -0.3653593063354492
Test:
Test: 0.6049047909088829
0.6049047909088829
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127780227653
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.64it/s]100%|██████████| 1/1 [00:00<00:00,  5.63it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.43145090341567993
Epoch 1: -0.43145090341567993
Mem used: 1430MB
best_loss: tensor(-0.4265, device='cuda:1')
final loss: -0.43403810262680054
Test:
Test: 0.6075586623099662
0.6075586623099662
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179836213682554, 0.6310911560836675, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974796106658903
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.65it/s]100%|██████████| 1/1 [00:00<00:00,  7.63it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.2642604112625122
Epoch 1: -0.2642604112625122
Mem used: 674MB
best_loss: tensor(-0.2675, device='cuda:1')
final loss: -0.267067551612854
Test:
Test: 0.6014695046858677
0.6014695046858677
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483242720477
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  8.44it/s]100%|██████████| 1/1 [00:00<00:00,  8.42it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.40243157744407654
Epoch 1: -0.40243157744407654
Mem used: 674MB
best_loss: tensor(-0.3980, device='cuda:1')
final loss: -0.3972243070602417
Test:
Test: 0.6028014644766241
0.6028014644766241
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890801861456
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.70it/s]100%|██████████| 1/1 [00:00<00:00,  6.68it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.41750460863113403
Epoch 1: -0.41750460863113403
Mem used: 1148MB
best_loss: tensor(-0.4072, device='cuda:1')
final loss: -0.4164518117904663
Test:
Test: 0.6031399650370981
0.6031399650370981
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145208472543777, 0.6325989133050594, 0.5483719525047425, 0.5836708161590052]
flatten test: 0.6034946272329313
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.46it/s]100%|██████████| 1/1 [00:00<00:00,  6.45it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.41885000467300415
Epoch 1: -0.41885000467300415
Mem used: 674MB
best_loss: tensor(-0.4351, device='cuda:1')
final loss: -0.4261423647403717
Test:
Test: 0.6077382983577222
0.6077382983577222
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.593719576152412, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747710283346
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  8.15it/s]100%|██████████| 2/2 [00:00<00:00,  9.31it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5818973779678345
Epoch 1, Loop Feat 0: -0.6016814708709717
Epoch 1, Loop Adj 0: -0.5958034992218018
Epoch 2: -0.5958034992218018
Mem used: 674MB
best_loss: tensor(-0.6052, device='cuda:1')
best_loss: tensor(-0.6059, device='cuda:1')
final loss: -0.5988126397132874
Test:
Test: 0.6032524013959742
0.6032524013959742
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987105909036
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.05it/s]100%|██████████| 2/2 [00:00<00:00,  5.49it/s]100%|██████████| 2/2 [00:00<00:00,  5.56it/s]
Epoch 0, Loop Feat 0: -0.42172563076019287
Epoch 0, Loop Adj 0: -0.41181913018226624
Epoch 1, Loop Feat 0: -0.42655399441719055
Epoch 1, Loop Adj 0: -0.4270254671573639
Epoch 2: -0.4270254671573639
Mem used: 674MB
best_loss: tensor(-0.4225, device='cuda:1')
best_loss: tensor(-0.4263, device='cuda:1')
final loss: -0.42113596200942993
Test:
Test: 0.6043703309719712
0.6043703309719712
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.556224183928322]
flatten test: 0.6065804165698618
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.66it/s]100%|██████████| 2/2 [00:00<00:00,  6.05it/s]100%|██████████| 2/2 [00:00<00:00,  5.79it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.3221884071826935
Epoch 1, Loop Feat 0: -0.31866204738616943
Epoch 1, Loop Adj 0: -0.32070210576057434
Epoch 2: -0.32070210576057434
Mem used: 674MB
best_loss: tensor(-0.3317, device='cuda:1')
final loss: -0.32800188660621643
Test:
Test: 0.6058901877651449
0.6058901877651449
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163420955350138, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887406041667
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.97it/s]100%|██████████| 2/2 [00:00<00:00,  6.95it/s]100%|██████████| 2/2 [00:00<00:00,  6.94it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.4097632169723511
Epoch 1, Loop Feat 0: -0.4114556908607483
Epoch 1, Loop Adj 0: -0.40078026056289673
Epoch 2: -0.40078026056289673
Mem used: 674MB
best_loss: tensor(-0.4092, device='cuda:1')
final loss: -0.4078143537044525
Test:
Test: 0.6071545109896116
0.6071545109896116
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205531717941192, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168184805693
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.59it/s]100%|██████████| 2/2 [00:00<00:00,  9.01it/s]
Epoch 0, Loop Feat 0: -0.35880887508392334
Epoch 0, Loop Adj 0: -0.3586377799510956
Epoch 1, Loop Feat 0: -0.3737279772758484
Epoch 1, Loop Adj 0: -0.3697315454483032
Epoch 2: -0.3697315454483032
Mem used: 674MB
best_loss: tensor(-0.3677, device='cuda:1')
final loss: -0.3662234842777252
Test:
Test: 0.6053398016608331
0.6053398016608331
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127724783887
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.25it/s]100%|██████████| 2/2 [00:00<00:00,  5.68it/s]100%|██████████| 2/2 [00:00<00:00,  5.76it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.43145090341567993
Epoch 1, Loop Feat 0: -0.4439951181411743
Epoch 1, Loop Adj 0: -0.43908369541168213
Epoch 2: -0.43908369541168213
Mem used: 674MB
best_loss: tensor(-0.4327, device='cuda:1')
final loss: -0.4399805963039398
Test:
Test: 0.6076965567070056
0.6076965567070056
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179836213682554, 0.6310911059929533, 0.6278801467147008, 0.5383906414670132, 0.5426401818150064]
flatten test: 0.5974796051215137
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.70it/s]100%|██████████| 2/2 [00:00<00:00,  6.93it/s]100%|██████████| 2/2 [00:00<00:00,  6.89it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.2642604112625122
Epoch 1, Loop Feat 0: -0.2677162289619446
Epoch 1, Loop Adj 0: -0.2635405957698822
Epoch 2: -0.2635405957698822
Mem used: 674MB
best_loss: tensor(-0.2718, device='cuda:1')
final loss: -0.27012285590171814
Test:
Test: 0.6019664725977779
0.6019664725977779
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483298164244
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.79it/s]100%|██████████| 2/2 [00:00<00:00,  6.16it/s]100%|██████████| 2/2 [00:00<00:00,  5.90it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.40243157744407654
Epoch 1, Loop Feat 0: -0.4051452577114105
Epoch 1, Loop Adj 0: -0.39975202083587646
Epoch 2: -0.39975202083587646
Mem used: 674MB
best_loss: tensor(-0.3985, device='cuda:1')
best_loss: tensor(-0.4014, device='cuda:1')
final loss: -0.40525075793266296
Test:
Test: 0.604098156345557
0.604098156345557
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890635530157
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.26it/s]100%|██████████| 2/2 [00:00<00:00,  7.22it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.41750460863113403
Epoch 1, Loop Feat 0: -0.4124988317489624
Epoch 1, Loop Adj 0: -0.41834738850593567
Epoch 2: -0.41834738850593567
Mem used: 674MB
best_loss: tensor(-0.4097, device='cuda:1')
best_loss: tensor(-0.4135, device='cuda:1')
final loss: -0.4216328263282776
Test:
Test: 0.6042432393617968
0.6042432393617968
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483719525047425, 0.5836708161590052]
flatten test: 0.6034946272329312
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.57it/s]100%|██████████| 2/2 [00:00<00:00,  5.73it/s]100%|██████████| 2/2 [00:00<00:00,  5.52it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.41885000467300415
Epoch 1, Loop Feat 0: -0.4333895742893219
Epoch 1, Loop Adj 0: -0.4255460500717163
Epoch 2: -0.4255460500717163
Mem used: 856MB
best_loss: tensor(-0.4388, device='cuda:1')
best_loss: tensor(-0.4389, device='cuda:1')
final loss: -0.4268806576728821
Test:
Test: 0.6086150318872849
0.6086150318872849
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.5937195260616978, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.587874765483958
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.27it/s]100%|██████████| 2/2 [00:00<00:00,  5.15it/s]100%|██████████| 2/2 [00:00<00:00,  5.16it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5818973779678345
Epoch 1, Loop Feat 0: -0.6163285374641418
Epoch 1, Loop Adj 0: -0.607116162776947
Epoch 2: -0.607116162776947
Mem used: 674MB
best_loss: tensor(-0.6139, device='cuda:1')
final loss: -0.6024293303489685
Test:
Test: 0.5994503764453494
0.5994503764453494
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344159165859445, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987216796569
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.94it/s]100%|██████████| 2/2 [00:00<00:00,  7.76it/s]100%|██████████| 2/2 [00:00<00:00,  7.62it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.41181913018226624
Epoch 1, Loop Feat 0: -0.4423779249191284
Epoch 1, Loop Adj 0: -0.44305381178855896
Epoch 2: -0.44305381178855896
Mem used: 674MB
best_loss: tensor(-0.4339, device='cuda:1')
best_loss: tensor(-0.4357, device='cuda:1')
final loss: -0.43072086572647095
Test:
Test: 0.6100699925270133
0.6100699925270133
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.6140439335636838, 0.6456251035480238, 0.5428112133773625, 0.5562244568254855]
flatten test: 0.6065804165698618
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.63it/s]100%|██████████| 2/2 [00:00<00:00,  4.59it/s]100%|██████████| 2/2 [00:00<00:00,  4.66it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.3221884071826935
Epoch 1, Loop Feat 0: -0.3267715573310852
Epoch 1, Loop Adj 0: -0.3276602625846863
Epoch 2: -0.3276602625846863
Mem used: 566MB
best_loss: tensor(-0.3379, device='cuda:1')
final loss: -0.33511918783187866
Test:
Test: 0.6095974897500616
0.6095974897500616
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887516929199
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.49it/s]100%|██████████| 2/2 [00:00<00:00,  7.40it/s]100%|██████████| 2/2 [00:00<00:00,  7.02it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.4097632169723511
Epoch 1, Loop Feat 0: -0.42214253544807434
Epoch 1, Loop Adj 0: -0.4137518107891083
Epoch 2: -0.4137518107891083
Mem used: 674MB
best_loss: tensor(-0.4127, device='cuda:1')
final loss: -0.4147959351539612
Test:
Test: 0.6082174734442081
0.6082174734442081
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205531717941192, 0.5767507023125826, 0.5493893065411368, 0.5826379003947184]
flatten test: 0.590716796303063
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 12.26it/s]100%|██████████| 2/2 [00:00<00:00, 12.24it/s]
Epoch 0, Loop Feat 0: -0.35880887508392334
Epoch 0, Loop Adj 0: -0.3586377799510956
Epoch 1, Loop Feat 0: -0.3907562792301178
Epoch 1, Loop Adj 0: -0.3869999945163727
Epoch 2: -0.3869999945163727
Mem used: 674MB
best_loss: tensor(-0.3843, device='cuda:1')
best_loss: tensor(-0.3871, device='cuda:1')
final loss: -0.38731688261032104
Test:
Test: 0.6058802190169719
0.6058802190169719
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127780227653
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.86it/s]100%|██████████| 2/2 [00:00<00:00,  8.21it/s]100%|██████████| 2/2 [00:00<00:00,  7.97it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.43145090341567993
Epoch 1, Loop Feat 0: -0.4614253044128418
Epoch 1, Loop Adj 0: -0.4573558568954468
Epoch 2: -0.4573558568954468
Mem used: 674MB
best_loss: tensor(-0.4471, device='cuda:1')
final loss: -0.45025399327278137
Test:
Test: 0.6113457937125238
0.6113457937125238
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310911560836675, 0.6278801467147008, 0.5383906414670132, 0.5426401818150064]
flatten test: 0.5974796051215137
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.27it/s]100%|██████████| 2/2 [00:00<00:00,  4.54it/s]100%|██████████| 2/2 [00:00<00:00,  4.73it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.2642604112625122
Epoch 1, Loop Feat 0: -0.27411994338035583
Epoch 1, Loop Adj 0: -0.2703080177307129
Epoch 2: -0.2703080177307129
Mem used: 674MB
best_loss: tensor(-0.2764, device='cuda:1')
final loss: -0.27663958072662354
Test:
Test: 0.602751898748656
0.602751898748656
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483298164244
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.18it/s]100%|██████████| 2/2 [00:00<00:00,  8.36it/s]100%|██████████| 2/2 [00:00<00:00,  8.15it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.40243157744407654
Epoch 1, Loop Feat 0: -0.42495548725128174
Epoch 1, Loop Adj 0: -0.4210880994796753
Epoch 2: -0.4210880994796753
Mem used: 674MB
best_loss: tensor(-0.4136, device='cuda:1')
best_loss: tensor(-0.4167, device='cuda:1')
final loss: -0.41980504989624023
Test:
Test: 0.6046956457778896
0.6046956457778896
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875724, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890690973923
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  9.34it/s]100%|██████████| 2/2 [00:00<00:00, 10.09it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.41750460863113403
Epoch 1, Loop Feat 0: -0.4278605282306671
Epoch 1, Loop Adj 0: -0.43424686789512634
Epoch 2: -0.43424686789512634
Mem used: 674MB
best_loss: tensor(-0.4186, device='cuda:1')
best_loss: tensor(-0.4238, device='cuda:1')
final loss: -0.4313330054283142
Test:
Test: 0.6040312346695745
0.6040312346695745
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232557, 0.5836708161590052]
flatten test: 0.6034946105998013
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.79it/s]100%|██████████| 2/2 [00:00<00:00,  6.91it/s]100%|██████████| 2/2 [00:00<00:00,  6.88it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.41885000467300415
Epoch 1, Loop Feat 0: -0.44592124223709106
Epoch 1, Loop Adj 0: -0.4365956485271454
Epoch 2: -0.4365956485271454
Mem used: 674MB
best_loss: tensor(-0.4435, device='cuda:1')
best_loss: tensor(-0.4482, device='cuda:1')
final loss: -0.4379459619522095
Test:
Test: 0.6124531985145533
0.6124531985145533
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.5937196262431264, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747710283345
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.12it/s]100%|██████████| 2/2 [00:00<00:00,  7.95it/s]100%|██████████| 2/2 [00:00<00:00,  7.80it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5818973779678345
Epoch 1, Loop Feat 0: -0.5934549570083618
Epoch 1, Loop Adj 0: -0.5917870998382568
Epoch 2: -0.5917870998382568
Mem used: 674MB
best_loss: tensor(-0.6030, device='cuda:1')
best_loss: tensor(-0.6042, device='cuda:1')
final loss: -0.5907415747642517
Test:
Test: 0.6012331540070714
0.6012331540070714
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344159165859445, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987216796569
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.48it/s]100%|██████████| 2/2 [00:00<00:00,  7.04it/s]100%|██████████| 2/2 [00:00<00:00,  6.94it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.41181913018226624
Epoch 1, Loop Feat 0: -0.42040935158729553
Epoch 1, Loop Adj 0: -0.4206203520298004
Epoch 2: -0.4206203520298004
Mem used: 674MB
best_loss: tensor(-0.4217, device='cuda:1')
best_loss: tensor(-0.4218, device='cuda:1')
final loss: -0.4127637445926666
Test:
Test: 0.6032294057577583
0.6032294057577583
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.556224183928322]
flatten test: 0.606580416569862
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  9.34it/s]100%|██████████| 2/2 [00:00<00:00,  8.65it/s]100%|██████████| 2/2 [00:00<00:00,  8.74it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.3221884071826935
Epoch 1, Loop Feat 0: -0.3158623278141022
Epoch 1, Loop Adj 0: -0.31833040714263916
Epoch 2: -0.31833040714263916
Mem used: 674MB
best_loss: tensor(-0.3265, device='cuda:1')
final loss: -0.32456809282302856
Test:
Test: 0.6059412229898555
0.6059412229898555
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887461485434
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.39it/s]100%|██████████| 2/2 [00:00<00:00,  6.08it/s]100%|██████████| 2/2 [00:00<00:00,  6.12it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.4097632169723511
Epoch 1, Loop Feat 0: -0.40764012932777405
Epoch 1, Loop Adj 0: -0.39557862281799316
Epoch 2: -0.39557862281799316
Mem used: 970MB
best_loss: tensor(-0.4051, device='cuda:1')
final loss: -0.40655839443206787
Test:
Test: 0.6078223376849501
0.6078223376849501
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205532218848335, 0.576750097652589, 0.5493893065411368, 0.5826379003947184]
flatten test: 0.5907168129361927
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.29it/s]100%|██████████| 2/2 [00:00<00:00,  6.17it/s]100%|██████████| 2/2 [00:00<00:00,  6.18it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3586377799510956
Epoch 1, Loop Feat 0: -0.36745044589042664
Epoch 1, Loop Adj 0: -0.3637254238128662
Epoch 2: -0.3637254238128662
Mem used: 674MB
best_loss: tensor(-0.3643, device='cuda:1')
final loss: -0.36626532673835754
Test:
Test: 0.6049868047135736
0.6049868047135736
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127946558952
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.39it/s]100%|██████████| 2/2 [00:00<00:00,  5.52it/s]100%|██████████| 2/2 [00:00<00:00,  5.49it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.43145090341567993
Epoch 1, Loop Feat 0: -0.43675166368484497
Epoch 1, Loop Adj 0: -0.4314342439174652
Epoch 2: -0.4314342439174652
Mem used: 674MB
best_loss: tensor(-0.4269, device='cuda:1')
final loss: -0.4347531497478485
Test:
Test: 0.6077730896860075
0.6077730896860075
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310911059929533, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.597479599577137
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.17it/s]100%|██████████| 2/2 [00:00<00:00,  5.95it/s]100%|██████████| 2/2 [00:00<00:00,  5.81it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.2642604112625122
Epoch 1, Loop Feat 0: -0.2653614282608032
Epoch 1, Loop Adj 0: -0.2611241936683655
Epoch 2: -0.2611241936683655
Mem used: 674MB
best_loss: tensor(-0.2678, device='cuda:1')
final loss: -0.26729699969291687
Test:
Test: 0.6011983626787861
0.6011983626787861
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483242720478
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.93it/s]100%|██████████| 2/2 [00:00<00:00,  9.24it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.40243157744407654
Epoch 1, Loop Feat 0: -0.398726224899292
Epoch 1, Loop Adj 0: -0.39194104075431824
Epoch 2: -0.39194104075431824
Mem used: 674MB
best_loss: tensor(-0.3985, device='cuda:1')
final loss: -0.39933592081069946
Test:
Test: 0.6021221598202416
0.6021221598202416
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.598189074641769
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.31it/s]100%|██████████| 2/2 [00:00<00:00,  6.37it/s]100%|██████████| 2/2 [00:00<00:00,  6.36it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.41750460863113403
Epoch 1, Loop Feat 0: -0.40611732006073
Epoch 1, Loop Adj 0: -0.41122472286224365
Epoch 2: -0.41122472286224365
Mem used: 674MB
best_loss: tensor(-0.4075, device='cuda:1')
final loss: -0.4161609709262848
Test:
Test: 0.60321518738387
0.60321518738387
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.1, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232558, 0.5836708161590052]
flatten test: 0.6034946105998014
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.37it/s]100%|██████████| 2/2 [00:00<00:00,  4.56it/s]100%|██████████| 2/2 [00:00<00:00,  4.53it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.41885000467300415
Epoch 1, Loop Feat 0: -0.42823711037635803
Epoch 1, Loop Adj 0: -0.4197908639907837
Epoch 2: -0.4197908639907837
Mem used: 674MB
best_loss: tensor(-0.4374, device='cuda:1')
final loss: -0.4258500039577484
Test:
Test: 0.6089013851714593
0.6089013851714593
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.5937196262431264, 0.6002883018849671, 0.5401741024379962, 0.5824575153695682]
flatten test: 0.5878747710283346
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  8.80it/s]100%|██████████| 1/1 [00:00<00:00,  8.78it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5818973779678345
Epoch 1: -0.5818973779678345
Mem used: 674MB
best_loss: tensor(-0.6024, device='cuda:1')
best_loss: tensor(-0.6059, device='cuda:1')
final loss: -0.5953126549720764
Test:
Test: 0.6029163235193191
0.6029163235193191
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987161352804
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.29it/s]100%|██████████| 1/1 [00:00<00:00,  5.28it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.41181913018226624
Epoch 1: -0.41181913018226624
Mem used: 986MB
best_loss: tensor(-0.4210, device='cuda:1')
best_loss: tensor(-0.4256, device='cuda:1')
final loss: -0.41979336738586426
Test:
Test: 0.6057317601298369
0.6057317601298369
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405996180406469, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.556224183928322]
flatten test: 0.6065804553804982
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.05it/s]100%|██████████| 1/1 [00:00<00:00,  5.04it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.3221884071826935
Epoch 1: -0.3221884071826935
Mem used: 674MB
best_loss: tensor(-0.3314, device='cuda:1')
final loss: -0.3270564079284668
Test:
Test: 0.6061946516037691
0.6061946516037691
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163421456257283, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887572372965
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 10.41it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.4097632169723511
Epoch 1: -0.4097632169723511
Mem used: 674MB
best_loss: tensor(-0.4088, device='cuda:1')
final loss: -0.4084392189979553
Test:
Test: 0.6071516514283827
0.6071516514283827
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205532218848335, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168351136992
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.10it/s]100%|██████████| 1/1 [00:00<00:00,  6.09it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3586377799510956
Epoch 1: -0.3586377799510956
Mem used: 776MB
best_loss: tensor(-0.3678, device='cuda:1')
final loss: -0.3661381006240845
Test:
Test: 0.6051982533800013
0.6051982533800013
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127724783887
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  8.19it/s]100%|██████████| 1/1 [00:00<00:00,  8.18it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.43145090341567993
Epoch 1: -0.43145090341567993
Mem used: 674MB
best_loss: tensor(-0.4262, device='cuda:1')
best_loss: tensor(-0.4297, device='cuda:1')
final loss: -0.4361720383167267
Test:
Test: 0.6074532557057778
0.6074532557057778
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310911059929533, 0.6278801467147008, 0.5383905009484999, 0.5426401818150064]
flatten test: 0.5974795940327605
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.30it/s]100%|██████████| 1/1 [00:00<00:00,  5.29it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.2642604112625122
Epoch 1: -0.2642604112625122
Mem used: 674MB
best_loss: tensor(-0.2716, device='cuda:1')
final loss: -0.27043646574020386
Test:
Test: 0.6018379114908609
0.6018379114908609
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483242720478
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.33it/s]100%|██████████| 1/1 [00:00<00:00,  6.32it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.40243157744407654
Epoch 1: -0.40243157744407654
Mem used: 842MB
best_loss: tensor(-0.3978, device='cuda:1')
best_loss: tensor(-0.3996, device='cuda:1')
final loss: -0.40327325463294983
Test:
Test: 0.6039083132528589
0.6039083132528589
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890690973923
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.89it/s]100%|██████████| 1/1 [00:00<00:00,  5.88it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.41750460863113403
Epoch 1: -0.41750460863113403
Mem used: 674MB
best_loss: tensor(-0.4094, device='cuda:1')
best_loss: tensor(-0.4131, device='cuda:1')
final loss: -0.42090409994125366
Test:
Test: 0.6045352323361726
0.6045352323361726
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483718119862292, 0.5836708161590052]
flatten test: 0.6034946050554246
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.78it/s]100%|██████████| 1/1 [00:00<00:00,  7.48it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.41885000467300415
Epoch 1: -0.41885000467300415
Mem used: 674MB
best_loss: tensor(-0.4332, device='cuda:1')
best_loss: tensor(-0.4377, device='cuda:1')
final loss: -0.4256077706813812
Test:
Test: 0.6107660176733593
0.6107660176733593
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.5937196262431264, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747821170879
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.61it/s]100%|██████████| 1/1 [00:00<00:00,  4.61it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5818973779678345
Epoch 1: -0.5818973779678345
Mem used: -990MB
best_loss: tensor(-0.6065, device='cuda:1')
final loss: -0.5950634479522705
Test:
Test: 0.6007569179140708
0.6007569179140708
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033227174413, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987050465271
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.30it/s]100%|██████████| 1/1 [00:00<00:00,  5.29it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.41181913018226624
Epoch 1: -0.41181913018226624
Mem used: 674MB
best_loss: tensor(-0.4259, device='cuda:1')
best_loss: tensor(-0.4262, device='cuda:1')
final loss: -0.4221190810203552
Test:
Test: 0.6025191622375241
0.6025191622375241
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.556224183928322]
flatten test: 0.6065804165698618
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.35it/s]100%|██████████| 1/1 [00:00<00:00,  7.34it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.3221884071826935
Epoch 1: -0.3221884071826935
Mem used: 674MB
best_loss: tensor(-0.3348, device='cuda:1')
final loss: -0.3307647109031677
Test:
Test: 0.6070098648507818
0.6070098648507818
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163420955350138, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887461485434
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.05it/s]100%|██████████| 1/1 [00:00<00:00,  6.04it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.4097632169723511
Epoch 1: -0.4097632169723511
Mem used: 674MB
best_loss: tensor(-0.4109, device='cuda:1')
final loss: -0.4126357436180115
Test:
Test: 0.6078298043170478
0.6078298043170478
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6410351366824102, 0.6205532218848335, 0.5767507023125826, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168240249461
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.08it/s]100%|██████████| 1/1 [00:00<00:00,  4.07it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3586377799510956
Epoch 1: -0.3586377799510956
Mem used: 674MB
best_loss: tensor(-0.3713, device='cuda:1')
final loss: -0.3730699419975281
Test:
Test: 0.6090998863801005
0.6090998863801005
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127891115185
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.85it/s]100%|██████████| 1/1 [00:00<00:00,  3.84it/s]
Epoch 0, Loop Feat 0: -0.4249717593193054
Epoch 0, Loop Adj 0: -0.43145090341567993
Epoch 1: -0.43145090341567993
Mem used: 674MB
best_loss: tensor(-0.4372, device='cuda:1')
final loss: -0.44168752431869507
Test:
Test: 0.61064404944372
0.61064404944372
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310910058115247, 0.6278801467147008, 0.5383906414670132, 0.5426401818150064]
flatten test: 0.5974795829440072
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.27it/s]100%|██████████| 1/1 [00:00<00:00,  6.25it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.2642604112625122
Epoch 1: -0.2642604112625122
Mem used: 674MB
best_loss: tensor(-0.2740, device='cuda:1')
final loss: -0.2739219069480896
Test:
Test: 0.6013360187790564
0.6013360187790564
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483242720478
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.55it/s]100%|██████████| 1/1 [00:00<00:00,  5.54it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.40243157744407654
Epoch 1: -0.40243157744407654
Mem used: 674MB
best_loss: tensor(-0.4034, device='cuda:1')
final loss: -0.4018721878528595
Test:
Test: 0.6057589656776396
0.6057589656776396
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890690973923
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  9.45it/s]100%|██████████| 1/1 [00:00<00:00,  9.42it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.41750460863113403
Epoch 1: -0.41750460863113403
Mem used: 674MB
best_loss: tensor(-0.4166, device='cuda:1')
final loss: -0.42207983136177063
Test:
Test: 0.6062931078855262
0.6062931078855262
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483720930232557, 0.5836708161590052]
flatten test: 0.6034946050554247
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  4.56it/s]100%|██████████| 1/1 [00:00<00:00,  4.56it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.41885000467300415
Epoch 1: -0.41885000467300415
Mem used: 674MB
best_loss: tensor(-0.4375, device='cuda:1')
final loss: -0.43433403968811035
Test:
Test: 0.6102107464852815
0.6102107464852815
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.5937196262431264, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747765727113
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.54it/s]100%|██████████| 1/1 [00:00<00:00,  6.53it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5818973779678345
Epoch 1: -0.5818973779678345
Mem used: 674MB
best_loss: tensor(-0.6052, device='cuda:1')
final loss: -0.5887883305549622
Test:
Test: 0.6002475188540404
0.6002475188540404
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344159165859445, 0.544936696409752, 0.5785921999441106]
flatten test: 0.604698705046527
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.55it/s]100%|██████████| 1/1 [00:00<00:00,  5.54it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.41181913018226624
Epoch 1: -0.41181913018226624
Mem used: 674MB
best_loss: tensor(-0.4231, device='cuda:1')
final loss: -0.41704949736595154
Test:
Test: 0.6014982194465415
0.6014982194465415
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804387473683
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  8.68it/s]100%|██████████| 1/1 [00:00<00:00,  8.65it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.3221884071826935
Epoch 1: -0.3221884071826935
Mem used: 674MB
best_loss: tensor(-0.3263, device='cuda:1')
final loss: -0.32384324073791504
Test:
Test: 0.6059723604343483
0.6059723604343483
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163420454442996, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887350597901
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.88it/s]100%|██████████| 1/1 [00:00<00:00,  7.87it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.4097632169723511
Epoch 1: -0.4097632169723511
Mem used: 674MB
best_loss: tensor(-0.4048, device='cuda:1')
final loss: -0.40585049986839294
Test:
Test: 0.6079215882892706
0.6079215882892706
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205531217034048, 0.576750097652589, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168073918162
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.89it/s]100%|██████████| 1/1 [00:00<00:00,  5.88it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3586377799510956
Epoch 1: -0.3586377799510956
Mem used: 674MB
best_loss: tensor(-0.3641, device='cuda:1')
final loss: -0.3653593063354492
Test:
Test: 0.6049047909088829
0.6049047909088829
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527279903905, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127835671419
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  8.59it/s]100%|██████████| 1/1 [00:00<00:00,  8.57it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.43145090341567993
Epoch 1: -0.43145090341567993
Mem used: 674MB
best_loss: tensor(-0.4265, device='cuda:1')
final loss: -0.43403810262680054
Test:
Test: 0.6075586623099662
0.6075586623099662
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310910559022389, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974795829440072
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.64it/s]100%|██████████| 1/1 [00:00<00:00,  6.62it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.2642604112625122
Epoch 1: -0.2642604112625122
Mem used: 674MB
best_loss: tensor(-0.2675, device='cuda:1')
final loss: -0.267067551612854
Test:
Test: 0.6014695046858677
0.6014695046858677
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483242720477
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  5.99it/s]100%|██████████| 1/1 [00:00<00:00,  5.98it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.40243157744407654
Epoch 1: -0.40243157744407654
Mem used: 674MB
best_loss: tensor(-0.3980, device='cuda:1')
final loss: -0.398343950510025
Test:
Test: 0.6028014644766241
0.6028014644766241
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890801861456
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.94it/s]100%|██████████| 1/1 [00:00<00:00,  6.93it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.41750460863113403
Epoch 1: -0.41750460863113403
Mem used: 674MB
best_loss: tensor(-0.4071, device='cuda:1')
final loss: -0.41555243730545044
Test:
Test: 0.6032631247505826
0.6032631247505826
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=5, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=5, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483719525047425, 0.5836708161590052]
flatten test: 0.6034946161441779
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.55it/s]100%|██████████| 1/1 [00:00<00:00,  6.54it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.41885000467300415
Epoch 1: -0.41885000467300415
Mem used: 674MB
best_loss: tensor(-0.4351, device='cuda:1')
final loss: -0.4261423647403717
Test:
Test: 0.6077382983577222
0.6077382983577222
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.5937196262431264, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.587874793205841
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.41it/s]100%|██████████| 2/2 [00:00<00:00,  6.34it/s]100%|██████████| 2/2 [00:00<00:00,  5.94it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5818973779678345
Epoch 1, Loop Feat 0: -0.6010833382606506
Epoch 1, Loop Adj 0: -0.5954380035400391
Epoch 2: -0.5954380035400391
Mem used: 674MB
best_loss: tensor(-0.6051, device='cuda:1')
best_loss: tensor(-0.6058, device='cuda:1')
final loss: -0.5984256267547607
Test:
Test: 0.6034880769005915
0.6034880769005915
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.644284027479605, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987327684101
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.24it/s]100%|██████████| 2/2 [00:00<00:00,  7.73it/s]100%|██████████| 2/2 [00:00<00:00,  7.46it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.41181913018226624
Epoch 1, Loop Feat 0: -0.4263623356819153
Epoch 1, Loop Adj 0: -0.42683109641075134
Epoch 2: -0.42683109641075134
Mem used: 674MB
best_loss: tensor(-0.4222, device='cuda:1')
best_loss: tensor(-0.4258, device='cuda:1')
final loss: -0.42191311717033386
Test:
Test: 0.6042585300711458
0.6042585300711458
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.614043983654398, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804221142385
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.42it/s]100%|██████████| 2/2 [00:00<00:00,  5.32it/s]100%|██████████| 2/2 [00:00<00:00,  5.45it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.3221884071826935
Epoch 1, Loop Feat 0: -0.3185352385044098
Epoch 1, Loop Adj 0: -0.32059961557388306
Epoch 2: -0.32059961557388306
Mem used: 674MB
best_loss: tensor(-0.3317, device='cuda:1')
final loss: -0.3275298774242401
Test:
Test: 0.6058788289524856
0.6058788289524856
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163420955350138, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887461485433
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  8.62it/s]100%|██████████| 2/2 [00:00<00:00,  6.21it/s]100%|██████████| 2/2 [00:00<00:00,  6.48it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.4097632169723511
Epoch 1, Loop Feat 0: -0.41131505370140076
Epoch 1, Loop Adj 0: -0.40059176087379456
Epoch 2: -0.40059176087379456
Mem used: 674MB
best_loss: tensor(-0.4092, device='cuda:1')
final loss: -0.40798938274383545
Test:
Test: 0.6071147154291756
0.6071147154291756
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205531717941192, 0.5767507023125826, 0.5493891660226236, 0.5826381732918821]
flatten test: 0.5907168018474395
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.72it/s]100%|██████████| 2/2 [00:00<00:00,  7.69it/s]100%|██████████| 2/2 [00:00<00:00,  7.68it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3586377799510956
Epoch 1, Loop Feat 0: -0.3734981417655945
Epoch 1, Loop Adj 0: -0.36951297521591187
Epoch 2: -0.36951297521591187
Mem used: 674MB
best_loss: tensor(-0.3677, device='cuda:1')
final loss: -0.3660077750682831
Test:
Test: 0.6054230466654974
0.6054230466654974
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127946558952
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.06it/s]100%|██████████| 2/2 [00:00<00:00,  4.13it/s]100%|██████████| 2/2 [00:00<00:00,  4.33it/s]
Epoch 0, Loop Feat 0: -0.4249717593193054
Epoch 0, Loop Adj 0: -0.43145090341567993
Epoch 1, Loop Feat 0: -0.4437832236289978
Epoch 1, Loop Adj 0: -0.4388691186904907
Epoch 2: -0.4388691186904907
Mem used: 674MB
best_loss: tensor(-0.4327, device='cuda:1')
final loss: -0.43992412090301514
Test:
Test: 0.6076892489394206
0.6076892489394206
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310911059929533, 0.6278801467147008, 0.5383905009484999, 0.5426401818150064]
flatten test: 0.5974795940327604
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  8.82it/s]100%|██████████| 2/2 [00:00<00:00,  7.19it/s]100%|██████████| 2/2 [00:00<00:00,  7.39it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.2642604112625122
Epoch 1, Loop Feat 0: -0.26758426427841187
Epoch 1, Loop Adj 0: -0.26340019702911377
Epoch 2: -0.26340019702911377
Mem used: 988MB
best_loss: tensor(-0.2718, device='cuda:1')
final loss: -0.2702096104621887
Test:
Test: 0.6019595619914746
0.6019595619914746
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483298164243
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  8.20it/s]100%|██████████| 2/2 [00:00<00:00,  4.91it/s]100%|██████████| 2/2 [00:00<00:00,  5.22it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.40243157744407654
Epoch 1, Loop Feat 0: -0.4049098789691925
Epoch 1, Loop Adj 0: -0.399482399225235
Epoch 2: -0.399482399225235
Mem used: 674MB
best_loss: tensor(-0.3985, device='cuda:1')
best_loss: tensor(-0.4011, device='cuda:1')
final loss: -0.40303605794906616
Test:
Test: 0.6039374648909428
0.6039374648909428
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.598189074641769
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.81it/s]100%|██████████| 2/2 [00:00<00:00,  5.57it/s]100%|██████████| 2/2 [00:00<00:00,  5.72it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.41750460863113403
Epoch 1, Loop Feat 0: -0.4122737646102905
Epoch 1, Loop Adj 0: -0.41809701919555664
Epoch 2: -0.41809701919555664
Mem used: 674MB
best_loss: tensor(-0.4097, device='cuda:1')
best_loss: tensor(-0.4134, device='cuda:1')
final loss: -0.4222322702407837
Test:
Test: 0.604231999697522
0.604231999697522
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.01, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145208472543777, 0.6325989133050594, 0.5483719525047425, 0.5836708161590052]
flatten test: 0.6034946105998014
using validation as test...
====learning on this graph===
n_perturbations: 176
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.58it/s]100%|██████████| 2/2 [00:00<00:00,  7.32it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.41885000467300415
Epoch 1, Loop Feat 0: -0.4332295358181
Epoch 1, Loop Adj 0: -0.42538201808929443
Epoch 2: -0.42538201808929443
Mem used: 674MB
best_loss: tensor(-0.4387, device='cuda:1')
best_loss: tensor(-0.4388, device='cuda:1')
final loss: -0.4279847741127014
Test:
Test: 0.6085026749606652
0.6085026749606652
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162816883140118, 0.5937196763338406, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.587874793205841
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.23it/s]100%|██████████| 2/2 [00:00<00:00,  8.46it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5818973779678345
Epoch 1, Loop Feat 0: -0.6010833382606506
Epoch 1, Loop Adj 0: -0.5954380035400391
Epoch 2: -0.5954380035400391
Mem used: 674MB
best_loss: tensor(-0.6091, device='cuda:1')
final loss: -0.6001074910163879
Test:
Test: 0.5967801022833279
0.5967801022833279
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6442839156648061, 0.6097033728081556, 0.6344159165859445, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987161352803
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  8.29it/s]100%|██████████| 2/2 [00:00<00:00,  8.31it/s]100%|██████████| 2/2 [00:00<00:00,  8.30it/s]
Epoch 0, Loop Feat 0: -0.4217256009578705
Epoch 0, Loop Adj 0: -0.41181913018226624
Epoch 1, Loop Feat 0: -0.42725300788879395
Epoch 1, Loop Adj 0: -0.4277585446834564
Epoch 2: -0.4277585446834564
Mem used: 674MB
best_loss: tensor(-0.4251, device='cuda:1')
best_loss: tensor(-0.4311, device='cuda:1')
final loss: -0.42775222659111023
Test:
Test: 0.6029046866937626
0.6029046866937626
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405995062258479, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804276586152
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.61it/s]100%|██████████| 2/2 [00:00<00:00,  7.17it/s]100%|██████████| 2/2 [00:00<00:00,  6.88it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.3221884071826935
Epoch 1, Loop Feat 0: -0.3188048303127289
Epoch 1, Loop Adj 0: -0.32082483172416687
Epoch 2: -0.32082483172416687
Mem used: 674MB
best_loss: tensor(-0.3351, device='cuda:1')
final loss: -0.3319104313850403
Test:
Test: 0.6085596278884745
0.6085596278884745
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163421456257282, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.6016887516929199
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.04it/s]100%|██████████| 2/2 [00:00<00:00,  6.53it/s]100%|██████████| 2/2 [00:00<00:00,  6.60it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.4097632169723511
Epoch 1, Loop Feat 0: -0.4119977056980133
Epoch 1, Loop Adj 0: -0.4014815390110016
Epoch 2: -0.4014815390110016
Mem used: 674MB
best_loss: tensor(-0.4094, device='cuda:1')
best_loss: tensor(-0.4114, device='cuda:1')
final loss: -0.4125640392303467
Test:
Test: 0.6090043690918288
0.6090043690918288
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205531717941192, 0.576750097652589, 0.5493893065411368, 0.5826381732918821]
flatten test: 0.5907168184805693
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.64it/s]100%|██████████| 2/2 [00:00<00:00,  8.71it/s]
Epoch 0, Loop Feat 0: -0.35880887508392334
Epoch 0, Loop Adj 0: -0.3586377799510956
Epoch 1, Loop Feat 0: -0.37460434436798096
Epoch 1, Loop Adj 0: -0.37057262659072876
Epoch 2: -0.37057262659072876
Mem used: 674MB
best_loss: tensor(-0.3751, device='cuda:1')
final loss: -0.3770335018634796
Test:
Test: 0.6081828409804355
0.6081828409804355
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.640482212501789, 0.6075527780811049, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053128002002718
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.53it/s]100%|██████████| 2/2 [00:00<00:00,  8.00it/s]100%|██████████| 2/2 [00:00<00:00,  7.73it/s]
Epoch 0, Loop Feat 0: -0.4249718189239502
Epoch 0, Loop Adj 0: -0.43145090341567993
Epoch 1, Loop Feat 0: -0.4445812702178955
Epoch 1, Loop Adj 0: -0.4396859407424927
Epoch 2: -0.4396859407424927
Mem used: 674MB
best_loss: tensor(-0.4395, device='cuda:1')
final loss: -0.44262605905532837
Test:
Test: 0.6096479292328496
0.6096479292328496
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310910559022389, 0.6278801467147008, 0.5383906414670132, 0.5426401818150064]
flatten test: 0.5974795940327604
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.36it/s]100%|██████████| 2/2 [00:00<00:00,  6.64it/s]100%|██████████| 2/2 [00:00<00:00,  6.62it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.2642604112625122
Epoch 1, Loop Feat 0: -0.26786860823631287
Epoch 1, Loop Adj 0: -0.26369667053222656
Epoch 2: -0.26369667053222656
Mem used: 674MB
best_loss: tensor(-0.2752, device='cuda:1')
final loss: -0.2748897075653076
Test:
Test: 0.6016199890955398
0.6016199890955398
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483187276712
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.30it/s]100%|██████████| 2/2 [00:00<00:00,  7.38it/s]100%|██████████| 2/2 [00:00<00:00,  7.19it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.40243157744407654
Epoch 1, Loop Feat 0: -0.4058169424533844
Epoch 1, Loop Adj 0: -0.40051183104515076
Epoch 2: -0.40051183104515076
Mem used: 674MB
best_loss: tensor(-0.4045, device='cuda:1')
best_loss: tensor(-0.4047, device='cuda:1')
final loss: -0.410148948431015
Test:
Test: 0.6051650904129715
0.6051650904129715
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901244, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890635530157
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  8.69it/s]100%|██████████| 2/2 [00:00<00:00,  9.34it/s]100%|██████████| 2/2 [00:00<00:00,  9.22it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.41750460863113403
Epoch 1, Loop Feat 0: -0.4130897521972656
Epoch 1, Loop Adj 0: -0.4189890921115875
Epoch 2: -0.4189890921115875
Mem used: 674MB
best_loss: tensor(-0.4189, device='cuda:1')
final loss: -0.4250241219997406
Test:
Test: 0.6040246417922968
0.6040246417922968
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.05, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145207971636634, 0.6325989133050594, 0.5483719525047425, 0.5836708161590052]
flatten test: 0.6034946105998014
using validation as test...
====learning on this graph===
n_perturbations: 883
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.70it/s]100%|██████████| 2/2 [00:00<00:00,  5.50it/s]100%|██████████| 2/2 [00:00<00:00,  5.53it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.41885000467300415
Epoch 1, Loop Feat 0: -0.4336094856262207
Epoch 1, Loop Adj 0: -0.42576849460601807
Epoch 2: -0.42576849460601807
Mem used: 674MB
best_loss: tensor(-0.4401, device='cuda:1')
final loss: -0.4320717751979828
Test:
Test: 0.610374575514022
0.610374575514022
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=0, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6162818001288106, 0.5937196262431264, 0.6002883018849671, 0.5401742429565095, 0.5824575153695682]
flatten test: 0.5878747876614644
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.67it/s]100%|██████████| 2/2 [00:00<00:00,  6.69it/s]100%|██████████| 2/2 [00:00<00:00,  6.51it/s]
Epoch 0, Loop Feat 0: -0.6054831147193909
Epoch 0, Loop Adj 0: -0.5818973779678345
Epoch 1, Loop Feat 0: -0.593353807926178
Epoch 1, Loop Adj 0: -0.5917452573776245
Epoch 2: -0.5917452573776245
Mem used: 674MB
best_loss: tensor(-0.6030, device='cuda:1')
best_loss: tensor(-0.6041, device='cuda:1')
final loss: -0.5895686745643616
Test:
Test: 0.6003816402189026
0.6003816402189026
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=1, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.644284027479605, 0.6097033728081556, 0.6344165212459382, 0.544936696409752, 0.5785921999441106]
flatten test: 0.6046987272240336
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00,  8.30it/s]100%|██████████| 2/2 [00:00<00:00,  8.29it/s]
Epoch 0, Loop Feat 0: -0.42172563076019287
Epoch 0, Loop Adj 0: -0.41181913018226624
Epoch 1, Loop Feat 0: -0.42031294107437134
Epoch 1, Loop Adj 0: -0.42052075266838074
Epoch 2: -0.42052075266838074
Mem used: 674MB
best_loss: tensor(-0.4217, device='cuda:1')
best_loss: tensor(-0.4218, device='cuda:1')
final loss: -0.4135510325431824
Test:
Test: 0.6032234086224032
0.6032234086224032
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=2, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405996180406469, 0.6140439335636838, 0.6456251035480238, 0.5428112133773624, 0.5562244568254855]
flatten test: 0.6065804332029917
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.51it/s]100%|██████████| 2/2 [00:00<00:00,  5.18it/s]100%|██████████| 2/2 [00:00<00:00,  5.23it/s]
Epoch 0, Loop Feat 0: -0.3228684961795807
Epoch 0, Loop Adj 0: -0.3221884071826935
Epoch 1, Loop Feat 0: -0.31581220030784607
Epoch 1, Loop Adj 0: -0.3182910978794098
Epoch 2: -0.3182910978794098
Mem used: 674MB
best_loss: tensor(-0.3265, device='cuda:1')
final loss: -0.32456809282302856
Test:
Test: 0.6059412627059837
0.6059412627059837
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=3, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6280595883426363, 0.6163420955350138, 0.6327936138230111, 0.5477341389728096, 0.5804080576708118]
flatten test: 0.60168875169292
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.38it/s]100%|██████████| 2/2 [00:00<00:00,  9.14it/s]
Epoch 0, Loop Feat 0: -0.40305688977241516
Epoch 0, Loop Adj 0: -0.4097632169723511
Epoch 1, Loop Feat 0: -0.40757620334625244
Epoch 1, Loop Adj 0: -0.39548197388648987
Epoch 2: -0.39548197388648987
Mem used: 674MB
best_loss: tensor(-0.4051, device='cuda:1')
final loss: -0.40653684735298157
Test:
Test: 0.6078440624070642
0.6078440624070642
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=4, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.641035248497209, 0.6205532218848335, 0.5767507023125826, 0.5493891660226236, 0.5826381732918821]
flatten test: 0.590716824024946
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  4.34it/s]100%|██████████| 2/2 [00:00<00:00,  4.09it/s]100%|██████████| 2/2 [00:00<00:00,  4.12it/s]
Epoch 0, Loop Feat 0: -0.3588089048862457
Epoch 0, Loop Adj 0: -0.3586377799510956
Epoch 1, Loop Feat 0: -0.36734887957572937
Epoch 1, Loop Adj 0: -0.36362528800964355
Epoch 2: -0.36362528800964355
Mem used: 674MB
best_loss: tensor(-0.3642, device='cuda:1')
final loss: -0.36601412296295166
Test:
Test: 0.6049758033460679
0.6049758033460679
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=5, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6404821006869902, 0.6075528281718192, 0.6354637923549209, 0.5493373146912106, 0.5795044951620791]
flatten test: 0.6053127780227653
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  9.68it/s]100%|██████████| 2/2 [00:00<00:00, 10.77it/s]
Epoch 0, Loop Feat 0: -0.4249717593193054
Epoch 0, Loop Adj 0: -0.43145090341567993
Epoch 1, Loop Feat 0: -0.4366486072540283
Epoch 1, Loop Adj 0: -0.4313085079193115
Epoch 2: -0.4313085079193115
Mem used: -990MB
best_loss: tensor(-0.4269, device='cuda:1')
final loss: -0.43487149477005005
Test:
Test: 0.6076556888111089
0.6076556888111089
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=6, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6179835095534565, 0.6310910559022389, 0.6278801467147008, 0.5383906414670133, 0.5426401818150064]
flatten test: 0.5974795940327605
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 12.00it/s]100%|██████████| 2/2 [00:00<00:00, 11.98it/s]
Epoch 0, Loop Feat 0: -0.26507389545440674
Epoch 0, Loop Adj 0: -0.2642604112625122
Epoch 1, Loop Feat 0: -0.2653062641620636
Epoch 1, Loop Adj 0: -0.26106753945350647
Epoch 2: -0.26106753945350647
Mem used: 674MB
best_loss: tensor(-0.2678, device='cuda:1')
final loss: -0.26729699969291687
Test:
Test: 0.6011983626787861
0.6011983626787861
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=7, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6405480714183485, 0.6075806786089608, 0.6365050168639672, 0.5385596852385302, 0.5808747118205952]
flatten test: 0.6001483131832945
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  8.40it/s]100%|██████████| 2/2 [00:00<00:00,  9.51it/s]
Epoch 0, Loop Feat 0: -0.39423924684524536
Epoch 0, Loop Adj 0: -0.40243157744407654
Epoch 1, Loop Feat 0: -0.3986351788043976
Epoch 1, Loop Adj 0: -0.39181190729141235
Epoch 2: -0.39181190729141235
Mem used: 674MB
best_loss: tensor(-0.3985, device='cuda:1')
final loss: -0.39912113547325134
Test:
Test: 0.6020073802098028
0.6020073802098028
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=8, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6305381869901245, 0.6066464867875723, 0.6335276710552888, 0.5433284620248717, 0.5756913030948722]
flatten test: 0.5981890690973923
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  9.46it/s]100%|██████████| 2/2 [00:00<00:00,  7.19it/s]100%|██████████| 2/2 [00:00<00:00,  7.45it/s]
Epoch 0, Loop Feat 0: -0.407964289188385
Epoch 0, Loop Adj 0: -0.41750460863113403
Epoch 1, Loop Feat 0: -0.40601322054862976
Epoch 1, Loop Adj 0: -0.41110068559646606
Epoch 2: -0.41110068559646606
Mem used: 674MB
best_loss: tensor(-0.4074, device='cuda:1')
final loss: -0.4151724576950073
Test:
Test: 0.603213400158102
0.603213400158102
===========
Namespace(dataset='twitch-e', debug=1, dropout=0, epochs=10, existing_space=1, finetune=0, gpu_id=1, hidden=32, loop_adj=1, loop_feat=4, loss='LC', lr=0.01, lr_adj=0.01, lr_feat=1e-06, margin=-1, model='GCN', nlayers=2, normalize_features=True, ood=1, ratio=0.0005, seed=9, strategy='dropedge', tent=0, test_val=1, tune=1, weight_decay=0.001, with_bn=1)
Namespace(K=3, T=1, beta=1.0, cached=False, cpu=False, data_dir='../data', dataset='twitch-e', device=0, directed=False, display_step=1, dropout=0.0, epochs=10, gat_heads=4, gcnii_alpha=0.1, gcnii_lamda=1.0, gnn='gcn', gpr_alpha=0.1, hidden_channels=32, lp_alpha=0.1, lr=0.01, lr_a=0.005, method='erm', no_bn=False, num_layers=2, num_sample=5, rocauc=False, runs=5, sub_dataset='', weight_decay=0.001)
Train num nodes 9498 | num classes 2 | num node feats 3170
Val num nodes 7126 | num classes 2 | num node feats 3170
Test 0 num nodes 4648 | num classes 2 | num node feats 3170
Test 1 num nodes 6549 | num classes 2 | num node feats 3170
Test 2 num nodes 1912 | num classes 2 | num node feats 3170
Test 3 num nodes 4385 | num classes 2 | num node feats 3170
Test 4 num nodes 2772 | num classes 2 | num node feats 3170
GCN(
  (layers): ModuleList(
    (0): GCNConv(3170, 32)
    (1): GCNConv(32, 2)
  )
  (bns): ModuleList(
    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
Test accs: [0.6303431819808215, 0.6145208472543777, 0.6325989133050594, 0.5483720930232558, 0.5836708161590052]
flatten test: 0.6034946216885546
using validation as test...
====learning on this graph===
n_perturbations: 8
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  6.09it/s]100%|██████████| 2/2 [00:00<00:00,  5.67it/s]100%|██████████| 2/2 [00:00<00:00,  5.73it/s]
Epoch 0, Loop Feat 0: -0.4339154064655304
Epoch 0, Loop Adj 0: -0.41885000467300415
Epoch 1, Loop Feat 0: -0.42815104126930237
Epoch 1, Loop Adj 0: -0.4196871519088745
Epoch 2: -0.4196871519088745
Mem used: 674MB
best_loss: tensor(-0.4374, device='cuda:1')
final loss: -0.42579466104507446
Test:
Test: 0.6086795705955766
0.6086795705955766
